{
  "hash": "184c3d59565a3fe11f0750cdb97a0971",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Midterm\"\neditor: source\npublished-title: \"Due date\"\ndate: 2025-05-07\ndate-modified: last-modified\n---\n\n\n[Due on Wednesday May 7 (Week 6) at 11:59 PM]{style=\"color: #79ACBD; font-size: 24px;\"}\n\n# Description\n\nIn this midterm, you will demonstrate your ability to synthesize lecture concepts and technical skills from workshop. At this point, you have the _conceptual_ ideas you need (for example, what is the appropriate test to use if you want to compare groups?) and the _technical_ skills you need (for example, summarizing data, visualizing data). You also have the _investigative_ skills you need (for example, reading for tasks, googling!). You will use all these components to complete the midterm.  \n\nThis midterm is open note, open internet, open everything; feel free to also talk with classmates and friends. \n\n\n::: {.cell}\n\n:::\n\n\n# Set up tasks\n\nAs usual, create a new folder in your `ENVS-193DS` folder for midterm materials (a logical folder name would be `midterm`). Create an Rproject. Download all materials from Canvas into your `midterm` folder.  \n\nStart a new Quarto or RMarkdown document for your midterm. Make sure you read in your packages and data _only at the top of the document_.  \n\nRead in and store the data for Problem 3 as an object called `tussocks`.  \n\nRead in and store the data for Problem 4 as an object called `rain`.\n\n:::{.callout-note collapse=\"true\" title=\"Do we have a template?\"}\nYou will **not** have a template.  \n\nYou are responsible for creating a new Quarto document, setting the document up (i.e. reading in packages and data at the top of the doc), and making sure it renders properly (as a PDF or word doc, with the title, your name, and the date).  \n\nStuck? See the video on Canvas about creating and rendering Quarto documents for help.  \n\nIf you are using RMarkdown, the process is the same. \n:::\n \n# Problems\n\n## Problem 1. Understanding and critiquing written communication (20 points) \n\n### Skills you will demonstrate\n\nIn this problem, you will be responsible for demonstrating your understanding of the different components of a statistical test. All numbers describe a different statistical concept; how well do you understand what those numbers represent?\n\n### Description\n\n\n::: {.cell}\n\n:::\n\n\n\nYou're a fisheries manager interested in the effects of marine protected areas on the size of California sheephead _(Bodianus pulcher)_. You find a study in which researchers examined exactly this effect. In their results section, the researchers wrote:  \n\n> We found a difference in sheephead length (in centimeters) between marine protected areas and \n> non-protected areas (Welch's two-sample t-test, t(83.6) = 7.2, p < 0.001, $\\alpha$ = 0.05).\n\n### Components\n\n#### a. Hypotheses (4 points) \n\nThe researchers didn't state their hypotheses explicitly anywhere in their paper. In one sentence _each_, write the null ($H_0$) and alternative ($H_A$) hypotheses in _statistical_ terms.\n\n#### b. Test type (2 points) \n\nThe researchers ran a Welch's two sample t-test. What must have been true for them to use a Welch's t-test? Respond in 1 or 2 sentences _only_.\n\n#### c. Test summary components (10 points) \n\nIn parentheses, the researchers cite some information about their statistical test:  \n\n> t(105.6) = 6.6, p < 0.001, $\\alpha$ = 0.05  \n\nIn one sentence _each_, explain the meaning of:  \n\n- t  \n- 105.6  \n- 6.6  \n- p < 0.001  \n- $\\alpha$ = 0.05  \n\n**Be specific**: what is the term that describes the component, and what does that component represent?\n\n#### d. Missing information (4 points) \n\nUnfortunately, this one sentence is the extent of the researchers' communication about their statistics. Identify 2 other components or statistics they could have included (note that there may be more than 2 additional components that could make sense).  \n\nFor each of your pieces of \"missing information\", explain why it would be relevant to the questions or hypotheses.\n\n## Problem 2. Interpretation and communication (41 points) \n\n### Skills you will demonstrate\n\nIn this problem, you will be responsible for interpreting the results of a test with which you may be familiar, but haven't seen. You will also **demonstrate your ability to interpret code output and synthesize the statistics in writing to ground the stats in biology** for a scientific audience.  \n\n### Description\n\nIn 2014, the emergency manager of Flint, Michigan (mandated by the governor of Michigan at the time) switched the source of water for Flint from the Detroit River/Lake Huron to the Flint River. As a result, residents of Flint were exposed to lead contamination in their water. This was the start of the Flint water crisis, and Flint residents continue to deal with water contamination to this day.  \n\nWhen the crisis started, city officials recommended that residents allow pipes to clear (by flushing the pipes) before using any water. In 2015, Flint residents participated in a study to collect water samples to test for lead. Residents took water samples from their own taps at three different time points (letting the water run the whole time):  \n\n1. immediately after turning on the water  \n2. 45 seconds after turning on the water  \n3. 2 minutes after turning on the water.  \n\nIn this problem, you will work with statistical results from tests run on this data set of lead concentration in water samples collected by Flint residents. You will interpret statistical results to answer the questions:  \n\n1. Is there a difference in lead concentration (measured in parts per billion, ppb) between water samples taken immediately after turning on the water and 2 minutes after turning on the water?  \n2. Is the amount of lead in the water after 2 minutes different from 0?  \n\nBefore completing this problem, read about the study [here](https://flintwaterstudy.org/2015/09/our-sampling-of-252-homes-demonstrates-a-high-lead-in-water-risk-flint-should-be-failing-to-meet-the-epa-lead-and-copper-rule/). Additionally, make sure you understand the following figure:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](midterm_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n[**Figure 1. Lead concentrations (ppb) in Flint, Michigan water samples.** Water samples were taken from faucets immediately after turning the water on (\"first draw (immediate)\") and 2 minutes after turning the water on (\"two minutes of flushing\"). Open circles represent a water sample taken from a single faucet (n = 300). Red points represent means and 95% confidence intervals. Data from [Flint Water Study](https://flintwaterstudy.org/2015/09/our-sampling-of-252-homes-demonstrates-a-high-lead-in-water-risk-flint-should-be-failing-to-meet-the-epa-lead-and-copper-rule/).]{style=\"color: #6b6b6b; font-size: 12px;\"}\n\n### Components\n\n#### a. Hypotheses (8 points)\n\nIn one sentence _each_, write your null ($H_0$) and alternative ($H_A$) hypotheses in _statistical_ terms to answer the questions:  \n\n1. Is there a difference in lead concentration (measured in parts per billion, ppb) between water samples taken immediately after turning on the water and 2 minutes after turning on the water?  \n2. Is the amount of lead in the water after 2 minutes different from 0?  \n\nYou should have one null and alternative for question 1, and one null and alternative for question 2.  \n\n#### b. Paired t-test (14 points)\n\nThis is the result of a _paired_ t-test, which is appropriate when test subjects are measured twice in a paired study (in this case, water samples were taken at two time points from a single faucet). This would address question 1: Is there a difference in lead concentration (measured in parts per billion, ppb) between water samples taken immediately after turning on the water and 2 minutes after turning on the water?  \n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  flint_clean$pb_bottle_1_ppb_first_draw and flint_clean$pb_bottle_3_ppb_2_mins_flushing\nt = 6.3963, df = 268, p-value = 7.055e-10\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 4.881162 9.222377\nsample estimates:\nmean difference \n        7.05177 \n```\n\n\n:::\n:::\n\n\nThis is the result of a calculation of effect size:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\nFor paired samples, 'repeated_measures_d()' provides more options.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCohen's d |       95% CI\n------------------------\n0.39      | [0.27, 0.51]\n```\n\n\n:::\n:::\n\n\nIn 1-2 sentences _only_, summarize your interpretation and results of the test along with the effect size. Be sure to include all components of the test summary (for example, degrees of freedom, distribution, test statistic, confidence interval, etc.) that are important for understanding its structure.  \n\nWhere necessary, round values to 1 decimal point and/or express as < 0.001.\n\n#### c. One-sample t-test (14 points)\n\nThis is the output of a one-sample t-test to answer question 2: Is the amount of lead in the water after 2 minutes different from 0?\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  flint_clean$pb_bottle_3_ppb_2_mins_flushing\nt = 5.6212, df = 268, p-value = 4.753e-08\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 2.347136 4.877629\nsample estimates:\nmean of x \n 3.612383 \n```\n\n\n:::\n:::\n\n\nIn 1-2 sentences _only_, summarize your interpretation and results of the test. Be sure to include all components of the test summary (for example, degrees of freedom, distribution, test statistic, confidence interval, etc.) that are important for understanding its structure.  \n\nWhere necessary, round values to 1 decimal point and/or express as < 0.001.  \n\nAs stated by the Environmental Protection Agency (EPA), \"EPA has set the maximum contaminant level goal for lead in drinking water at zero because lead is a toxic metal that can be harmful to human health even at low exposure levels\" ([EPA](https://www.epa.gov/ground-water-and-drinking-water/basic-information-about-lead-drinking-water)). In your response, contextualize these results within the EPA maximum contaminant goal (for example, are the samples from Flint on average more, less, or at the EPA maximum contaminant goal for lead?).\n\n#### d. Statistical implications (5 points)\n\nImagine that you are a scientific advisor on water quality. Write 4-5 sentences about the results of both these tests in their real world context.  \n\nHow would you communicate with the Flint residents who participated in this study about the results of _both_ of these tests? Additionally, what do you make of these results within the context of the Flint water crisis, which is [ongoing in 2025](https://www.wnem.com/2025/04/25/city-still-recovering-11-years-after-flint-water-crisis/)?  \n\n:::{.callout-note collapse=\"true\" title=\"Data collection is always attached to its social context\"}\nThe leader of this study was Dr. Marc Edwards of Virginia Tech, who claimed to represent the residents of Flint. After the original study was over, his group collected new samples from Flint residents and declared that the water was safe to use. However, residents knew the water was unsafe to use given [lead and other contaminants](https://www.detroitnews.com/story/news/michigan/flint-water-crisis/2019/04/26/hero-pariah-flint-water-expert-mark-edwards-fights-for-his-reputation/3546987002/), and [filed a complaint](http://www.flintcomplaints.com/) against Dr. Edwards.\n:::\n\n## Problem 3. Reproducing an analysis (73 points) \n\n### Skills you will demonstrate\n\nIn environmental studies, open research means that researchers make their data and/or their code available for anyone to see. This means that anyone should be able to reproduce the analysis, even if they are not on the research team. **In this problem, you will demonstrate your ability to read a paper to understand the context for a research study and its statistical analysis. You will then demonstrate your ability to take a data set and analyze it, using the researchers' original analysis as a guide.**  \n\n### Description\n\nYou will reproduce the analysis in: Steketee, Jess K., Adrian V. Rocha, Laura Gough, Kevin L. Griffin, Ian Klupar, Ruby An, Nicole Williamson, and Rebecca J. Rowe. 2022. “Small Herbivores with Big Impacts: Tundra Voles (Microtus Oeconomus) Alter Post-Fire Ecosystem Dynamics.” _Ecology_ 103(7): e3689. [https://doi.org/10.1002/ecy.3689](https://doi.org/10.1002/ecy.3689)  \n\n**Read all parts of the paper before starting this problem.**  \n\nYou will specifically recreate the components in this passage:  \n\n> Although tussock density was lower at the burned site, tussocks were larger \n> (Table 1, Figure 2a).\n\n### Getting the data\n\nThis statement relies on the dataset stored here:  \n\nRocha, A. 2021. Tussock height and diameter in moist acidic tussock tundra at the site of the\n2007 Anaktuvuk River fire scar, and nearby unburned tundra measured in 2016 ver 1.\nEnvironmental Data Initiative. [https://doi.org/10.6073/pasta/1dccd3fdb3aa693f9c2b69a24f8306ed](https://doi.org/10.6073/pasta/1dccd3fdb3aa693f9c2b69a24f8306ed)  \n\nDownload the data into your midterm directory. To understand the data structure, read the metadata (under Resources > View full metadata > Data Entities).   \n\n### Components\n\n#### a. Variables (4 points) \n\nIn 1-2 sentences, describe the response variable (with units) and predictor variable (include each group). Be sure to explain the _type_ of each variable (categorical, continuous, etc.).\n\n#### b. Hypotheses (4 points) \n\nIn one sentence _each_, write the null ($H_0$) and alternative ($H_A$) hypotheses in _statistical_ terms.\n\n#### c. Cleaning and organizing data (10 points)\n\n:::{.callout-note collapse=\"true\" title=\"Response variable column in original dataset\"}\nUse the \"Average Moss (cm)\" column for tussock height.\n:::\n\nCreate an object called `tussocks_clean`. Clean the data by:  \n\n1. cleaning _all_ the column names  \n2. replacing the values in the `site` column as follows:  \n\n   a. replace `Sev` with `Burned`  \n   b. replace `Unb` with `Unburned`  \n\n3. selecting only the site and height column  \n\nUse the pipe operator to string functions together.  \n\nOnce you are done, use the `slice_sample()` function to show 5 rows from `tussocks_clean`.  \n\n#### d. Summarizing and table displays (12 points) \n\nCreate an object called `tussocks_summary` using the `tussocks_clean` data frame to calculate the:  \n\n- means,  \n- standard deviations,  \n- standard errors, and   \n- 95% confidence intervals of the means  \nfor the response variable within the two groups.  \n\nRound all numbers to 1 decimal point.  \n\nDisplay _only_ the means, standard deviations, standard errors, and 95% confidence intervals in a **table**. Choose _one_ of the following packages to do so:  \n\n- `gt` (package info [here](https://gt.rstudio.com/))  \n- `flextable` (package info [here](https://ardata-fr.github.io/flextable-book/))    \n\nMake sure the column names of the table are polished (no underscores, capitalized in sentence case).  \n\nShow _all_ code for your calculations and making/polishing the table.\n\n:::{.callout-note collapse=\"true\" title=\"Double check your table!\"}\n**Render your document to make sure your table looks right.** Do not assume that just because your code works, your table will render correctly. \n:::\n\n#### e. Tests and effect sizes (6 points) \n\nUse a Welch's t-test to compare mean tussock height between groups.  \n\nCalculate the appropriate effect size.  \n\n#### f. Written communication (14 points)\n\nThe authors communicated about the results of this test in the text above (in the Description) and in a table in the paper.  \n\nIn 1-2 sentences _only_, write an updated interpretation with results of the test and effect size. Be sure to include all components of the test summary (for example, degrees of freedom, distribution, test statistic, confidence interval, etc.) that are important for understanding its structure.  \n\n#### g. Making a new figure (13 points)\n\nPlots like Figure 3b in the paper show means and whiskers (in this case, standard error), but do not show the data structure and can mask important information about the spread of the observations in each sample.  \n\nMake a new figure that displays the mean and standard error (as in figure 3b) but shows the underlying data. For full credit:  \n\n  - take out the gridlines and make the plot and panel background white  \n  - jitter the observations horizontally but _not_ vertically  \n  - give each type a different color that is different from the `ggplot()` default color  \n  - use transparent open circles to represent the underlying data    \n  - take out the legend  \n  - include a plot title and put your name as the subtitle  \n\n#### h. Caption (10 points)\n\nWrite a caption for your figure in part g. Include a data citation.\n\n## Problem 4. Cleaning, wrangling, and visualization (33 points)\n\n### Skills you will demonstrate\n\nFigures are built on data; however, to make a figure, you need to understand the data structure and any cleaning, wrangling, or summarizing steps to create it. In this problem, **you will demonstrate your ability to clean, wrangle, and/or summarize a data set to create a figure**, using a final figure as a guide.\n\n### Description\n\n\n::: {.cell}\n\n:::\n\n\nIn this problem, you will use a data set of rainfall (measured in inches) from the rain gauge on top of Ellison Hall to recreate this figure.  \n\n![](/assignments/images/midterm/rain-gauge-figure.jpeg)\n\nThe caption for the figure is as follows:  \n\n[**Figure 2. Most rain occurs between November and March.** Lines and points represent total monthly rain (measured in inches) from Ellison Hall rain gauge for each water year starting in September and ending in August. Shown are water years 2018-2019 (purple), 2019-2020 (red), 2020-2021 (orange), 2021-2022 (yellow), 2022-2023 (green) and 2023-2024 (blue). Data source: County of Santa Barbara Public Works, [Daily Rainfall Data (XLS)](https://www.countyofsb.org/2328/Daily-Rainfall-Data-XLS). Accessed April 2025.]{style=\"color: #6b6b6b; font-size: 12px;\"}\n\n### Getting the data\n\nThis data set comes from the Count of Santa Barbara Public Works under the [Daily Rainfall Data (XLS) page](https://www.countyofsb.org/2328/Daily-Rainfall-Data-XLS).  \n\nOn the website, click the red dot next to Isla Vista (this represents the Ellison Hall rain gauge).  \n\n**MAKE SURE YOU HAVE DOWNLOADED THE CORRECT DATA FILE. YOUR FILE SHOULD BE CALLED `200dailys.xls`.**  \n\n:::{.callout-note collapse=\"true\" title=\"Look at the data in Sheets or Excel before starting!\"}\nYou will see that there is extra information at the top of the sheet. Clean up the file so that it only has data columns, and save that as a .csv file.\n:::\n\n### Components\n\n#### a. Initial cleaning, wrangling, and summarizing (14 points)\n\n:::{.callout-note collapse=\"true\" title=\"Double check your data\"}\nBefore you do this problem, make sure you have code to read in and save your data as an object called `rain` at the top of the document.\n:::\n\nThe following chunk of code creates an object called `rain_clean`. Copy and paste this code into your document to run it.  \n\nWhere prompted in the code annotations, fill in your responses to describe what each function is doing, and how the data frame changes. _Only write your responses in the annotations_. See function 7 for an example. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nrain_clean <- rain |>  \n  \n  # 1. what changes after this function? \n  # [insert response here]\n  # give an example. \n  # [insert response here]\n  clean_names() |>  \n  \n  # 2. what new column is created? \n  # [insert response here]\n  # give an example of a value in this column.\n  # [insert response here]\n  mutate(water_year_minus1 = water_year - 1) |>  \n  \n  # 3. what old column is changed?\n  # [insert response here]\n  # give an example of a value in the old column, and explain how it changed. \n  # [insert response here]\n  mutate(water_year = paste0(water_year_minus1, \"-\", water_year)) |> \n  \n  # 4. what columns are excluded from the data frame?\n  # [insert response here]\n  # give an example of a value in water_year_minus1 \n  # [insert response here]\n  # give an example of a value in code \n  # [insert response here]\n  select(!c(water_year_minus1, code)) |> \n  \n  # 5. which column is manipulated, and what changes about it? \n  # Hint: run str(rain_clean) in the Console. what do you see for the month column?\n  # [insert response here]\n  mutate(month = as_factor(month),\n         month = fct_relevel(\n           month, \n           \"9\", \"10\", \"11\", \"12\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\")\n         ) |>  \n  \n  # 6. what is being calculated? on an annual, monthly, or daily scale? \n  # [insert response here]\n  # give an example. \n  # [insert response here]\n  group_by(month, water_year) %>% \n  summarize(total_rain = sum(daily_rain, na.rm = TRUE)) |>  \n  ungroup() |>  \n  \n  # 7. what is being done to which columns? \n  # missing combinations of values of water_year and month are being filled in with 0\n  # give an example. \n  # july in 1951-1952 was not in the data frame previously, and now is present with a total rain of 0 inches\n  complete(water_year, \n           month, \n           fill = list(total_rain = 0)) |>  \n  \n  # 8. which observations are kept after this filtering step?\n  # [insert response here]\n  filter(water_year %in% c(\"2018-2019\", \n                           \"2019-2020\", \n                           \"2020-2021\", \n                           \"2021-2022\", \n                           \"2022-2023\", \n                           \"2023-2024\")) \n```\n:::\n\n\n:::{.callout-note collapse=\"true\" title=\"A possible approach\"}\nOne way to approach this problem is to delete all the pipe operators and add them back in one by one. With every additional function, look at the `rain_clean` object to describe what has changed about the data frame.\n:::\n\n#### b. Make the figure (19 points)\n\nRecreate the figure. Specifically, recreate the:  \n\n- x-axis (and label),  \n- y-axis (and label),  \n- title,  \n- legend position,  \n- panel background (blank),  \n- axis lines and ticks (blank),  \n- title position,  \n- geometries, and  \n- different colors  \n\nNote that you do not need an exact match of the colors (choose whatever colors you want) or legend position (just make sure it's inside the panel and doesn't cover any points).\n\n:::{.callout-note collapse=\"true\" title=\"My figure doesn't look right when I render my document.\"}\nYou will have to set the code chunk options to make a larger figure. Click the gear button in the code chunk to set those options.\n:::\n\n\n# Checklist\n\nYour submission should:\n\n- [ ] include your name, the title, and the date **(3 points)**  \n- [ ] include all code with annotations **(20 points)**  \n- [ ] be uploaded to Canvas as a single PDF **(2 points)**  \n- [ ] be organized and readable (for example: no messages, warnings, etc., text is formatted correctly with subscripts where necessary, text and headers are clearly different, code annotations should not run off page) **(8 points)** \n\nAdditionally, your submission should only include the components listed below:    \n\n- [ ] a set up chunk at the top of the document, where you have read in your packages and your data  \n\nfor Problem 1:  \n\n- [ ] written responses for a-d  \n\nfor Problem 2:  \n\n- [ ] written responses for a-d  \n\nfor Problem 3:  \n\n- [ ] written responses for a-b  \n- [ ] annotated code for c  \n- [ ] annotated code and table for d  \n- [ ] annotated code and test output for e  \n- [ ] written response for f  \n- [ ] annotated code and figure for g  \n- [ ] written response for h  \n\nfor Problem 4:  \n\n- [ ] responses in annotated code for a  \n- [ ] annotated code and figure for b\n\nLastly, check out the **rubric on Canvas** to see the point breakdown in more detail.  \n\n**200 points total**\n\n\n\n\n",
    "supporting": [
      "midterm_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}