{
  "hash": "033dbb557bc35f20973c16b93b47e953",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 3 figures - Lectures 5 and 6\"\neditor: source\nfreeze: auto\nexecute:\n  message: false\n  warning: false\nformat:\n  html: \n    code-fold: true\nauthor:\n  - name: An Bui\n    url: https://an-bui.com/\n    affiliation: UC Santa Barbara, Ecology, Evolution, and Marine Biology\n    affiliation-url: https://www.eemb.ucsb.edu/\npublished-title: \"Lecture date\"\ndate: 2024-04-16\ndate-modified: last-modified\ncategories: [t-test, cohen's d, confidence intervals]\ncitation:\n  url: https://spring-2024.envs-193ds.com/lecture/lecture_week-03.html\n---\n\n\n## 0. set up\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cleaning\nlibrary(tidyverse)\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\n\n# calculate effect size\nlibrary(effsize)\n\n# visualization\nlibrary(patchwork)\n```\n:::\n\n\n\n## 1. Math\n\n### a. test statistic for one sample t-test\n\n$$\nt = \\frac{\\bar{y} - \\mu}{s/\\sqrt{n}}\n$$\n\n### b. two sample t-test when variances are equal (Student's)\n\n$$\nt = \\frac{\\bar{y_A} - \\bar{y_B}}{s_p \\times \\sqrt{\\frac{1}{N_A + N_B}}}\n$$\n\n$$\ndf = (N_A - 1) + (N_B - 1)\n$$\n\n### c. when variances are not equal (Welch's)\n\n$$\nt = \\frac{\\bar{y_A} - \\bar{y_B}}{\\sqrt{\\frac{s_A^2}{N_A}+\\frac{s_B^2}{N_B}}}\n$$\n\n$$\ndf = \\frac{(\\frac{s_A^2}{N_A}+\\frac{S_B^2}{N_B})^2}{\\frac{(\\frac{s_A^2}{N_A})^2}{N_A-1}+\\frac{(\\frac{s_B^2}{N_B})^2}{N_B-1}}\n$$\n\n## 2. central limit theorem\n\nIf you were to sample a bunch of times from any distribution (i.e. take many observations within a sample, take many observations in another sample), the mean values for each sample will be normally distributed. Kareem Carr has a nice explainer of how this works [here](https://twitter.com/kareem_carr/status/1754524686606626894).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# randomly select 10000 numbers from a uniform distribution for the population\nuniform <- runif(10000, min = 2, max = 8)\n\n# make a histogram for the population\nuniformdf <- as.data.frame(uniform)\n\nggplot(uniformdf, aes(x = uniform)) +\n  geom_histogram(breaks = seq(2, 8, length.out = 41), fill = \"firebrick\", alpha = 0.7, color = \"firebrick\") +\n  geom_vline(xintercept = mean(uniform), linewidth = 2) +\n  annotate(\"text\", x = 4, y = 290, label = \"mean = 4.967\", size = 10) +\n  scale_x_continuous(breaks = seq(from = 2, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 305)) +\n  labs(x = \"Continuous value\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18))\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/clt-setup-uniform-distribution-1.png){width=1152}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# for() loop to \nstore2 <- c()\nstore5 <- c()\nstore15 <- c()\nstore30 <- c()\nstore50 <- c()\n\nfor(i in 1:100) {\n  \n  # sample 100x\n  store2[i] <- mean(sample(uniform, 2, replace = FALSE))\n  store5[i] <- mean(sample(uniform, 5, replace = FALSE))\n  store15[i] <- mean(sample(uniform, 15, replace = FALSE))\n  store30[i] <- mean(sample(uniform, 30, replace = FALSE))\n  store50[i] <- mean(sample(uniform, 50, replace = FALSE))\n\n}\n\n\ndf <- cbind(store2, store5, store15, store30, store50) %>% \n  as.data.frame()\n  \nggplot(df) +\n  geom_histogram(aes(x = store2), bins = 10, alpha = 0.7, fill = \"chocolate1\", color = \"chocolate1\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store2)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/clt-samples-1.png){width=1152}\n:::\n\n```{.r .cell-code}\nggplot(df) +\n  geom_histogram(aes(x = store5), bins = 10, alpha = 0.7, fill = \"blue3\", color = \"blue3\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store5)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/clt-samples-2.png){width=1152}\n:::\n\n```{.r .cell-code}\nggplot(df) +\n  geom_histogram(aes(x = store15), bins = 12, alpha = 0.7, fill = \"darkorchid4\", color = \"darkorchid4\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store15)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/clt-samples-3.png){width=1152}\n:::\n\n```{.r .cell-code}\nggplot(df) +\n  geom_histogram(aes(x = store30), bins = 12, alpha = 0.7, fill = \"lightseagreen\", color = \"lightseagreen\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store30)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/clt-samples-4.png){width=1152}\n:::\n\n```{.r .cell-code}\nggplot(df) +\n  geom_histogram(aes(x = store50), bins = 12, alpha = 0.7, fill = \"violetred3\", color = \"violetred3\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store50)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/clt-samples-5.png){width=1152}\n:::\n:::\n\n\n## 3. z- vs t-distribution\n\n### a. comparison with normal\n\nt-distributions allow for more uncertainty around the tails.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1, color = \"darkorange\") +\n  annotate(\"text\", x = 2.5, y = 0.4, label = \"normal\", color = \"darkorange\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#856F33\") +\n  annotate(\"text\", x = 3, y = 0.32, label = \"t-distribution (small n)\", color = \"#856F33\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 10), linewidth = 1, color = \"#56E9E7\") +\n  annotate(\"text\", x = 3, y = 0.37, label = \"t-distribution (large n)\", color = \"#56E9E7\", size = 6) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/comparison-plot-1.png){width=1152}\n:::\n:::\n\n\n### b. visual representation of significance and t-statistic\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 19), xlim = c(1.8, 5), fill = \"#0070c0\") +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 19), xlim = c(-5, -1.8), fill = \"#0070c0\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 19), linewidth = 1, color = \"#000000\") +\n  geom_hline(yintercept = 0) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.4)) +\n  theme_void() +\n  theme(panel.grid = element_blank(),\n        plot.margin = unit(c(1, 0, 0, 0), \"cm\"))\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/t-dist-and-significance-1.png){fig-align='center' width=1344}\n:::\n:::\n\n\n## 4. qqplot examples\n\nWe use qqplots (quantile-quantile plots) to visually evaluate the normality of some variable. The x-axis is the \"theoretical\" quantile, and the y-axis is the \"sample\" quantile. If the points follow a 1:1 line, then the variable is normally distributed.  \n\nThe New Haven temperature data is normally distributed:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnhtemp_hist <- as_tibble(nhtemp) %>% \n  ggplot(aes(x = x)) +\n  geom_histogram(breaks = seq(47, 55, length.out = 9), fill = \"turquoise3\", color = \"#000000\") +\n  scale_x_continuous(breaks = seq(47, 55, length.out = 9), expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 23)) +\n  theme_classic() +\n  labs(x = \"Bins\", y = \"Count\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nnhtemp_qq <- ggplot(as_tibble(nhtemp)) +\n  stat_qq(aes(sample = x), color = \"turquoise3\", size = 3) +\n  labs(x = \"Theoretical quantile\", y = \"Sample quantile\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nnhtemp_hist + nhtemp_qq\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/nhtemp-histogram-and-qq-1.png){width=1536}\n:::\n:::\n\n\nThe sunspot data is not:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsunspot_hist <- as_tibble(sunspots) %>% \n  ggplot(aes(x = x)) +\n  geom_histogram(breaks = round(seq(0, 260, length.out = 30)), fill = \"tomato2\", color = \"#000000\") +\n  scale_x_continuous(breaks = round(seq(0, 260, length.out = 30)), expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 480)) +\n  theme_classic() +\n  labs(x = \"Bins\", y = \"Count\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nsunspot_qq <- ggplot(as_tibble(sunspots)) +\n  stat_qq(aes(sample = x), color = \"tomato2\", size = 3) +\n  theme_classic() +\n  labs(x = \"Theoretical quantile\", y = \"Sample quantile\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nsunspot_hist \n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/sunspots-histogram-and-qq-1.png){width=960}\n:::\n\n```{.r .cell-code}\nsunspot_qq\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/sunspots-histogram-and-qq-2.png){width=960}\n:::\n:::\n\n\n\n## 5. One sample t-test example\n\nThis is the creosote example from lecture.\n\n### generating numbers\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\ncreosote <- rnorm(n = 41, mean = 1.8, sd = 0.3) %>% \n  round(digits = 2) \n```\n:::\n\n\n### histogram and qq plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate the range\nrange <- max(creosote) - min(creosote)\n\n# determine the number of observations\nobs <- length(creosote)\n\n# calculate the number of bins using the Rice Rule\n# note that this doesn't come out to a whole number, so it's rounded\nbins <- 2*(obs^(1/3)) %>% \n  round(digits = 0)\n\n# calculate the width of the bin\nbinwidth <- range/(bins - 1)\n\n# set up a sequence of numbers from 0 to 100\nseq <- seq(from = 1, to = 11, by = 1)\n\n# calculate the axis breaks  \naxis_breaks <- seq*binwidth + (binwidth/2)\n\n# round the axis breaks\naxis_breaks_rounded <- round(axis_breaks, \n                             digits = 3)\n\nhist <- creosote %>% \n  enframe() %>% \n  ggplot(aes(x = value)) +\n  geom_histogram(binwidth = binwidth,\n                 fill = \"#e3c922\",\n                 color = \"black\") +\n  scale_x_continuous(breaks = axis_breaks_rounded) +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 14)) +\n  labs(x = \"Creosote height (m)\",\n       y = \"Count\")\n\nqq <- creosote %>% \n  enframe() %>% \n  ggplot(aes(sample = value)) +\n  geom_qq_line() +\n  geom_qq(color = \"#e3c922\",\n          size = 4,\n          alpha = 0.8) \n\nhist + qq\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/creosote-hist-and-qq-1.png){width=1536}\n:::\n:::\n\n\n\n### calculating a critical value\n\n::: {.cell}\n\n```{.r .cell-code}\nt_critical <- qt(p = 0.05/2, df = 40, lower.tail = FALSE)\nt_critical\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.021075\n```\n\n\n:::\n:::\n\n\n### calculating t-score\n\n\"By hand\":\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# claimed mean\nmu <- 3\n\n# number of observations\nn <- length(creosote)\n\n# sample mean\nybar <- mean(creosote)\n\n# sample standard deviation\ns <- sd(creosote)\n\n# sample standard error\nse <- s/sqrt(n)\n\n# t-score\nt <- (ybar-mu)/se\n\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -28.56624\n```\n\n\n:::\n:::\n\n\nUsing `t.test()`\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(creosote, mu = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  creosote\nt = -28.566, df = 40, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 3\n95 percent confidence interval:\n 1.743305 1.909378\nsample estimates:\nmean of x \n 1.826341 \n```\n\n\n:::\n:::\n\n\nManually calculating p-value:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# manually calculating p-value\n# two-tailed: multiply probability by 2\n# lower = FALSE: probability of the value being more than t\n2*pt(q = t, df = n - 1, lower = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.158646e-28\n```\n\n\n:::\n:::\n\n\n### visual representation of sample t-statistic vs t-critical\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(t_critical, 5), fill = \"darkgrey\") +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(-5, -t_critical), fill = \"darkgrey\") +\n  \n  annotate(geom = \"linerange\", x = t_critical, ymin = 0, ymax = 0.065, linewidth = 1, lty = 2, color = \"#000000\") +\n  annotate(geom = \"linerange\", x = -t_critical, ymin = 0, ymax = 0.065, linewidth = 1, lty = 2, color = \"#000000\") +\n  \n  # annotate(geom = \"linerange\", x = t, ymin = 0, ymax = 0.075, linewidth = 1, color = \"#000000\") +\n  # annotate(geom = \"linerange\", x = -t, ymin = 0, ymax = 0.075, linewidth = 1, color = \"#000000\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  theme_void() +\n  theme(panel.grid = element_blank(),\n        plot.margin = unit(c(1, 0, 0, 0), \"cm\"))\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/sample-t-vs-t-crit-1.png){width=672}\n:::\n:::\n\n\n## 8. two-sample t-test\n\n\n::: {.cell}\n\n```{.r .cell-code}\nex1 <- ggplot(data.frame(x = -8:8), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 1, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 1), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nset.seed(2)\nx <- rnorm(30, mean = 0, sd = 2)\ny <- rnorm(30, mean = 1, sd = 2)\n\nt.test(x = x, y = y, var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  x and y\nt = -0.78852, df = 58, p-value = 0.4336\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.6721807  0.7270662\nsample estimates:\nmean of x mean of y \n0.4573436 0.9299009 \n```\n\n\n:::\n\n```{.r .cell-code}\n# 0.43\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nex2 <- ggplot(data.frame(x = -8:17), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 2, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 2), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nset.seed(1000000000)\nx <- rnorm(30, mean = 0, sd = 2)\ny <- rnorm(30, mean = 2, sd = 2)\n\nt.test(x = x, y = y, var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  x and y\nt = -3.7904, df = 58, p-value = 0.0003603\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.7905631 -0.8617609\nsample estimates:\nmean of x mean of y \n0.1435745 1.9697364 \n```\n\n\n:::\n\n```{.r .cell-code}\n# 0.6932\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nex3 <- ggplot(data.frame(x = -8:17), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 10, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 10), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nset.seed(100)\nx <- rnorm(40, mean = 0, sd = 2)\ny <- rnorm(40, mean = 10, sd = 2)\n\nt.test(x = x, y = y, var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  x and y\nt = -21.69, df = 78, p-value < 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -10.564878  -8.788488\nsample estimates:\nmean of x mean of y \n0.2003543 9.8770375 \n```\n\n\n:::\n\n```{.r .cell-code}\n# p < 0.001\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nex1 + ex2 + ex3\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/two-sample-examples-together-1.png){fig-align='center' width=1152}\n:::\n:::\n\n\n### same differences in means, different SD\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsmall <- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 2), linewidth = 2, color = \"#0070C0\") +\n  geom_vline(aes(xintercept = 3), color = \"#0070C0\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nbig <- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 0.5), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 0.5), linewidth = 2, color = \"#0070C0\") +\n  geom_vline(aes(xintercept = 3), color = \"#0070C0\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.8)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\ndiff <- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 0.5), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 1.25), linewidth = 2, color = \"#0070C0\") +\n  geom_vline(aes(xintercept = 3), color = \"#0070C0\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.85)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nsmall / big / diff\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/two-sample-means-different-variances-1.png){width=768}\n:::\n:::\n\n\n\n### F-distribution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data.frame(x = seq(from = 0, to = 4, by = 0.1)), aes(x)) +\n  stat_function(geom = \"line\", fun = df, args = list(df1 = 20, df2 = 20), color = \"#FF6B2B\", linewidth = 1, xlim = c(0, 4)) +\n  stat_function(geom = \"line\", fun = df, args = list(df1 = 5, df2 = 5), color = \"#0070C0\", linewidth = 1, xlim = c(0, 4)) +\n  stat_function(geom = \"line\", fun = df, args = list(df1 = 1, df2 = 5), linewidth = 1, xlim = c(0, 4)) +\n  annotate(\"text\", x = 1.5, y = 1, label = \"20, 20\", color = \"#FF6B2B\", size = 8) +\n  annotate(\"text\", x = -0.2, y = 0.5, label = \"5, 5\", color = \"#0070C0\", size = 8) +\n  annotate(\"text\", x = 0.5, y = 1.5, label = \"1, 5\", size = 8) + \n  scale_y_continuous(expand = c(0, 0)) +\n  theme(axis.text = element_blank(),\n        axis.line = element_blank(),\n        axis.ticks = element_blank(),\n        axis.title = element_blank())\n```\n\n::: {.cell-output-display}\n![](lecture_week-03_files/figure-html/f-distribution-1.png){width=672}\n:::\n:::\n\n\n### F-distribution example\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\nrats <- rnorm(n = 20, mean = 178, sd = 43)\nset.seed(1)\nmice <- rnorm(n = 20, mean = 120, sd = 20)\n\nmean(rats)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 186.1925\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(mice)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 123.8105\n```\n\n\n:::\n\n```{.r .cell-code}\nvar(rats)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1542.126\n```\n\n\n:::\n\n```{.r .cell-code}\nvar(mice)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 333.6129\n```\n\n\n:::\n\n```{.r .cell-code}\nvar(rats)/var(mice)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.6225\n```\n\n\n:::\n\n```{.r .cell-code}\nvar.test(rats, mice)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tF test to compare two variances\n\ndata:  rats and mice\nF = 4.6225, num df = 19, denom df = 19, p-value = 0.001619\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  1.829642 11.678519\nsample estimates:\nratio of variances \n            4.6225 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(rats, mice, var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  rats and mice\nt = 6.4415, df = 38, p-value = 1.414e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 42.77708 81.98702\nsample estimates:\nmean of x mean of y \n 186.1925  123.8105 \n```\n\n\n:::\n\n```{.r .cell-code}\nt.test(rats, mice, var.equal = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  rats and mice\nt = 6.4415, df = 26.853, p-value = 6.84e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 42.50629 82.25781\nsample estimates:\nmean of x mean of y \n 186.1925  123.8105 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n(mean(rats) - mean(mice))/sqrt((var(rats) + var(mice))/2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.036988\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncohen.d(rats, mice)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCohen's d\n\nd estimate: 2.036988 (large)\n95 percent confidence interval:\n   lower    upper \n1.248080 2.825895 \n```\n\n\n:::\n:::\n\n\n\ntesting test statistic formula to compare against t-test from above:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxa <- mean(rats)\nxb <- mean(mice)\n\nvara <- var(rats)\nvarb <- var(mice)\n\nnA <- length(rats)\nnB <- length(mice)\n\n(xa - xb)/sqrt((vara/nA)+(varb/nB))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6.441521\n```\n\n\n:::\n\n```{.r .cell-code}\n(nA - 1) + (nB - 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 38\n```\n\n\n:::\n\n```{.r .cell-code}\n(((vara/nA)+(varb/nB))^2)/((vara/nA)^2/(nA-1)+(varb/nB)^2/(nB-1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 26.85313\n```\n\n\n:::\n:::\n",
    "supporting": [
      "lecture_week-03_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}