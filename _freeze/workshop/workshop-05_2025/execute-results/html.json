{
  "hash": "c28954fed3e7292584e1a9bdacfe4877",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Coding workshop: Week 5\"\nsubtitle: \"Parametric and non-parametric comparisons of more than 2 groups\"\ncategories: [tidyverse, lterdatasampler, effectsize, rstatix, car, shapiro.test, leveneTest, aov, summary, TukeyHSD, eta_squared, kruskal.test, dunn_test, kruskal_effectsize, read_csv, pipe operators, '|>', select, rename, ggplot, geom_histogram, geom_qq, geom_qq_line, facet_wrap, group_by, summarize, as_factor, mutate]\nformat:\n  html:\n    toc: true\n    toc-depth: 8\n---\n\n\n[Workshop dates: May 1 (Thursday), May 2 (Friday)]{style=\"color: #79ACBD; font-size: 24px;\"}\n\n## 1. Summary\n\n### Packages\n- `tidyverse`  \n- `lterdatasampler`  \n- `rstatix`  \n- `car`  \n\n### Operations\n\n#### New functions\n\n- make sure a variable is a factor using `as_factor()`\n- do a Shapiro-Wilk test using `shapiro.test()`  \n- do a Levene's test using `car::leveneTest()`  \n- do an ANOVA using `aov()`  \n- look for more information from model results using `summary()`  \n- do post-hoc Tukey test using `TukeyHSD()`  \n- calculate effect size for ANOVA using `rstatix::eta_squared()`  \n- do Kruskal-Wallis test using `kruskal.test()`  \n- do Dunn's test using `rstatix::dunn_test()`  \n- calculate effect size for Kruskal-Wallis test using `rstatix::kruskal_effsize()`\n\n#### Review\n\n- read in data using `read_csv()`  \n- chain functions together using ` |> `  \n- modify columns using `mutate()`  \n- select columns using `select()`  \n- rename columns using `rename()`  \n- visualize data using `ggplot()`  \n- create histograms using `geom_histogram()`  \n- visualize QQ plots using `geom_qq()` and `geom_qq_line()`  \n- create multi-panel plots using `facet_wrap()`  \n- group data using `group_by()`  \n- summarize data using `summarize()`  \n\n### Data sources\n\nThe Plum Island Ecosystem fiddler crab data is from `lterdatasampler` (data info [here](https://lter.github.io/lterdatasampler/articles/pie_crab_vignette.html)). The ramen ratings data set is a Tidy Tuesday dataset - see more about the data and its source [here](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-06-04).\n\n## 2. Code\n\n### 1. Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(lterdatasampler)\nlibrary(effectsize)\nlibrary(rstatix)\nlibrary(car)\n\n# for parametric tests\ndata(pie_crab)\n\n# for non-parametric tests\nramen_ratings <- read_csv(\"ramen_ratings.csv\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n### 2. Parametric tests\n\n#### a. Cleaning and wrangling\n\n- Create a new object called `pie_crab_clean`.\n- Filter to only include the following sites: Cape Cod, Virginia Coastal Reserve LTER, and Zeke's Island NERR.\n- Make sure `site` is a factor.\n- Select the columns of interest: `site`, `name`, and `code`.\n- Rename the column `name` to `site_name` and `code` to `site_code`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\npie_crab_clean <- pie_crab |> # start with the pie_crab dataset\n  filter(site %in% c(\"CC\", \"ZI\", \"VCR\")) |> # filter for Cape Cod, Zeke's Island, Virginia Coastal\n  mutate(name = as_factor(name)) |> # make sure site name is being read in as a factor\n  select(site, name, size) |> # select columns of interest\n  rename(site_code = site, # rename site to be site_code\n         site_name = name) # rename name to be site_name\n\n# display some rows from the data frame\n# useful for showing a small part of the data frame\nslice_sample(pie_crab_clean, # data frame\n             n = 10) # number of rows to show\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 3\n   site_code site_name                      size\n   <chr>     <fct>                         <dbl>\n 1 ZI        Zeke's Island NERR            11.4 \n 2 ZI        Zeke's Island NERR            12.5 \n 3 CC        Cape Cod                      16.6 \n 4 CC        Cape Cod                      16.1 \n 5 VCR       Virginia Coastal Reserve LTER 12.9 \n 6 VCR       Virginia Coastal Reserve LTER 15.1 \n 7 ZI        Zeke's Island NERR             8.05\n 8 CC        Cape Cod                      15.5 \n 9 VCR       Virginia Coastal Reserve LTER 14.6 \n10 VCR       Virginia Coastal Reserve LTER 14.9 \n```\n\n\n:::\n:::\n\n\n#### b. Quick summary\n\n- Create a new object called `pie_crab_summary`.\n- Calculate the mean, variance, and sample size. Display the object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# creating a new object called pie_crab_summary\npie_crab_summary <- pie_crab_clean |> # starting with clean data frame\n  group_by(site_name) |> # group by site\n  summarize(mean = mean(size), # calculate mean size\n            var = var(size), # calculate variance of size\n            n = length(size)) # calculate number of observations per site (sample size)\n\n# display pie_crab_summary\npie_crab_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n  site_name                      mean   var     n\n  <fct>                         <dbl> <dbl> <int>\n1 Zeke's Island NERR             12.1  4.04    35\n2 Virginia Coastal Reserve LTER  16.3  8.63    30\n3 Cape Cod                       16.8  4.22    27\n```\n\n\n:::\n:::\n\n\n#### c. Exploring the data\n\nCreate a jitter plot with the mean crab size for each site.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# base layer: ggplot\nggplot(pie_crab_clean, # use the clean data set\n       aes(x = site_name, # x-axis\n           y = size)) + # y-axis\n  # first layer: jitter (each point is an individual crab)\n  geom_jitter(height = 0, # don't jitter points vertically\n              width = 0.15) + # narrower jitter (easier to see)\n  # second layer: point representing mean\n  stat_summary(geom = \"point\", # geometry being plotted\n               fun = mean, # function (calculating the mean)\n               color = \"red\", # color to make it easier to see\n               size = 5) + # larger point size\n  theme_minimal() # cleaner plot theme\n```\n\n::: {.cell-output-display}\n![](workshop-05_2025_files/figure-html/crab-explore-viz-1.png){width=672}\n:::\n:::\n\n\nIs there a difference in mean crab size between the three sites?  \n\n**Yes, and Zeke's Island NERR crabs tend to be smaller than those from Cape Cod or Virginia Coastal Reserve LTER.**\n\n#### d. Check 1: normally distributed variable\n\n- Create a histogram of crab size.\n- Facet your histogram so that you have 3 panels, with one panel for each site.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# base layer: ggplot\nggplot(data = pie_crab_clean, \n       aes(x = size)) + # x-axis\n  # first layer: histogram\n  geom_histogram(bins = 9) + # number of bins from Rice Rule\n  # faceting by site_name: creating 3 different panels\n  facet_wrap(~ site_name) \n```\n\n::: {.cell-output-display}\n![](workshop-05_2025_files/figure-html/crab-histogram-1.png){width=672}\n:::\n:::\n\n\n- Create a QQ plot of crab size. \n- Facet your QQ plot so that you have 3 panels, with one panel for each site.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# base layer: ggplot\nggplot(data = pie_crab_clean, \n       aes(sample = size)) + # y-axis\n  # first layer: QQ plot reference line\n  geom_qq_line(color = \"orange\") + \n  # second layer: QQ plot points (actual observations)\n  geom_qq() + \n  # faceting by site_name\n  facet_wrap(~ site_name, \n             scales = \"free\") # let axes vary between panels\n```\n\n::: {.cell-output-display}\n![](workshop-05_2025_files/figure-html/crab-qq-1.png){width=672}\n:::\n:::\n\n\nWhat are the outcomes of your visual checks?  \n\n**Not perfect (crab sizes from VCR LTER seem not normally distributed) but with large sample sizes for each group, this might not matter too much.**  \n\nDo Shapiro-Wilk tests:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_crabs <- pie_crab_clean |> # use the original data set\n  filter(site_code == \"CC\") |> # filter to only include Cape Cod\n  pull(size) # extract the size column as a vector\n\nvcr_crabs <- pie_crab_clean |> \n  filter(site_code == \"VCR\") |> # filter to only include Virginia Coastal\n  pull(size)\n\nzi_crabs <- pie_crab_clean |> \n  filter(site_code == \"ZI\") |> # filter to only include Zeke's Island\n  pull(size)\n\n# do the Shapiro-Wilk tests\nshapiro.test(cc_crabs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  cc_crabs\nW = 0.93547, p-value = 0.09418\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(vcr_crabs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  vcr_crabs\nW = 0.94447, p-value = 0.12\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(zi_crabs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  zi_crabs\nW = 0.97446, p-value = 0.5766\n```\n\n\n:::\n:::\n\n\nWhat are the outcomes of your statistical checks?  \n\n**With Shapiro-Wilk normality tests, there seems to be no deviation from normality for Cape Cod crab sizes (W = 0.9, p = 0.09), VCR LTER crab sizes (W = 0.9, p = 0.12), or Zeke's Island crab sizes (W = 1, p = 0.6).**  \n\n#### e. Check 2: equal variances\n\nDo a gut check: is the largest variance less than 4× the smallest variance?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n4.04*4 > 8.63\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\nUsing `leveneTest()` from `car`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# do the Levene test\nleveneTest(\n  size ~ site_name, # formula: crab size as a function of site\n  data = pie_crab_clean # data frame\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value  Pr(>F)   \ngroup  2  5.0233 0.00857 **\n      89                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nWhat are the outcomes of your variance check?  \n\n**There's a deviation from homogeneity of variance (in other words, the variances are not equal), but since the largest variance is less than 4 times the smallest variance (and the sample sizes are large), this may still be ok.**\n\n#### f. ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# creating an object called crab_anova\ncrab_anova <- aov(size ~ site_name, # formula\n                  data = pie_crab_clean) # data\n\n# gives more information\nsummary(crab_anova)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value  Pr(>F)    \nsite_name    2  442.2  221.10   39.56 5.1e-13 ***\nResiduals   89  497.4    5.59                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nSummarize results: is there a difference in crab size between the three sites?  \n\n**There is a difference in crab size between Cape Cod, Virginia Coastal Reserve LTER, and Zeke's Island NERR (one-way ANOVA, F(2, 89) = 39.6, p < 0.001, $\\alpha$ = 0.05).**\n\n#### g. Post-hoc: Tukey HSD\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTukeyHSD(crab_anova)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = size ~ site_name, data = pie_crab_clean)\n\n$site_name\n                                                      diff       lwr      upr\nVirginia Coastal Reserve LTER-Zeke's Island NERR 4.2719524  2.869912 5.673993\nCape Cod-Zeke's Island NERR                      4.7514709  3.308099 6.194843\nCape Cod-Virginia Coastal Reserve LTER           0.4795185 -1.015317 1.974354\n                                                     p adj\nVirginia Coastal Reserve LTER-Zeke's Island NERR 0.0000000\nCape Cod-Zeke's Island NERR                      0.0000000\nCape Cod-Virginia Coastal Reserve LTER           0.7255994\n```\n\n\n:::\n:::\n\n\nWhich pairwise comparisons are actually different? Which ones are not different?  \n\n**Zeke's Island NERR and Cape Cod crabs are different, and Zeke's Island NERR and Virginia Coastal Reserve LTER crabs are different. Virginial Coastal Reserve LTER and Cape Cod crabs are not different.**\n\n#### h. effect size\n\nUsing `eta_squared()` from `rstatix`\n\n\n::: {.cell}\n\n```{.r .cell-code}\neta_squared(crab_anova)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsite_name \n0.4706113 \n```\n\n\n:::\n:::\n\n\nWhat is the magnitude of the differences between sites in crab size?  \n\n**There is a large difference in crab size between sites.**\n\n#### i. Putting everything together\n\nWe found a large ($\\eta^2$ = 0.47) difference between sites in mean crab size (one-way ANOVA, F(2, 89) = 39.6, p < 0.001, $\\alpha$ = 0.05). The smallest crabs were from Zeke's Island NERR, which were on average 12.1 mm. Zeke's Island crabs were 4.8 mm (95% CI: [3.3, 6.2] mm) smaller than crabs from Cape Cod (Tukey's HSD: p < 0.001) and 4.3 mm (95% CI: [2.9, 5.7] mm) smaller than crabs from Virginia Coastal Reserve LTER (Tukey's HSD: p < 0.001).  \n\n### 3. Non-parametric tests\n\n#### a. Clean and wrangle the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nramen_ratings_clean <- ramen_ratings |> # use the ramen_ratings dataframe\n  filter(brand == \"Maruchan\") |> # filter to only include Maruchan ramen\n  mutate(style = fct_relevel(style, \"Bowl\", \"Pack\", \"Tray\", \"Cup\")) # reorder style factor\n\n# look at the structure\nstr(ramen_ratings_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [106 × 6] (S3: tbl_df/tbl/data.frame)\n $ review_number: num [1:106] 3176 3152 3141 3124 3111 ...\n $ brand        : chr [1:106] \"Maruchan\" \"Maruchan\" \"Maruchan\" \"Maruchan\" ...\n $ variety      : chr [1:106] \"Gotsumori Shio Yakisoba\" \"QTTA Curry Ramen\" \"Thai Red Curry Udon\" \"Kitsune Udon 40th Anniversary\" ...\n $ style        : Factor w/ 4 levels \"Bowl\",\"Pack\",..: 3 4 1 1 1 4 1 1 4 3 ...\n $ country      : chr [1:106] \"Japan\" \"Japan\" \"Japan\" \"Japan\" ...\n $ stars        : num [1:106] 5 5 5 4.5 4 4 3.75 2 2.5 2.5 ...\n```\n\n\n:::\n:::\n\n\n#### b. Quick summary\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a new object called ramen_ratings_summary\nramen_ratings_summary <- ramen_ratings_clean |> # start with the cleaned data frame\n  # group by stle\n  group_by(style) |> \n  # calculate the median\n  summarize(median = median(stars))\n\n# display the object\nramen_ratings_summary \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  style median\n  <fct>  <dbl>\n1 Bowl    4.25\n2 Pack    3.75\n3 Tray    3.75\n4 Cup     3.5 \n```\n\n\n:::\n:::\n\n\n\n#### c. Make a boxplot to compare star ratings across ramen styles\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# base layer: ggplot\nggplot(data = ramen_ratings_clean, \n       aes(x = style, # x-axis\n           y = stars, # y-axis\n           color = style)) + # fill geoms by ramen style\n  # first layer: boxplot\n  geom_boxplot(color = \"darkgrey\", \n               outliers = FALSE) + # taking out outliers because they will be shown in the jitter\n  # second layer: jitter\n  geom_jitter(height = 0,\n              width = 0.1,\n              size = 2,\n              alpha = 0.6) +\n  # set custom colors\n  scale_color_manual(values = c(\"firebrick4\", \"orange\", \"gold\", \"darkgreen\")) + \n  # minimal theme\n  theme_minimal() + \n  # take out the legend\n  theme(legend.position = \"none\") \n```\n\n::: {.cell-output-display}\n![](workshop-05_2025_files/figure-html/ramen-explore-viz-1.png){width=672}\n:::\n:::\n\n\n#### d. Do the Kruskal-Wallis test\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkruskal.test(\n  stars ~ style, # formula: star ratings as a function of ramen style\n  data = ramen_ratings_clean # data frame\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tKruskal-Wallis rank sum test\n\ndata:  stars by style\nKruskal-Wallis chi-squared = 15.679, df = 3, p-value = 0.00132\n```\n\n\n:::\n:::\n\n\nIs there a difference in ratings between ramen styles?  \n\n**Ramen styles differ in ratings (Kruskal-Wallis rank sum test, $\\chi^2$(3) = 15.7, p = 0.0013).**\n\n#### e. Do a Dunn's post-hoc test\n\nUsing `dunn_test()` from `rstatix`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndunn_test(\n  stars ~ style, # formula: star ratings as a function of ramen style\n  data = ramen_ratings_clean # data frame\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 9\n  .y.   group1 group2    n1    n2 statistic        p   p.adj p.adj.signif\n* <chr> <chr>  <chr>  <int> <int>     <dbl>    <dbl>   <dbl> <chr>       \n1 stars Bowl   Pack      33    30    -2.61  0.00898  0.0449  *           \n2 stars Bowl   Tray      33    17    -2.54  0.0112   0.0449  *           \n3 stars Bowl   Cup       33    26    -3.70  0.000213 0.00128 **          \n4 stars Pack   Tray      30    17    -0.323 0.747    0.985   ns          \n5 stars Pack   Cup       30    26    -1.16  0.244    0.733   ns          \n6 stars Tray   Cup       17    26    -0.686 0.492    0.985   ns          \n```\n\n\n:::\n:::\n\n\nWhich pairwise comparisons of ramen styles are different from each other?  \n\n**Bowls and packs are different, bowls and trays are different, bowls and cups are different.**\n\n#### f. Calculate an effect size\n\nUsing `kruskal_effsize()` from `rstatix`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkruskal_effsize(\n  stars ~ style, # formula: star ratings as a function of ramen style\n  data = ramen_ratings_clean # data frame\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n  .y.       n effsize method  magnitude\n* <chr> <int>   <dbl> <chr>   <ord>    \n1 stars   106   0.124 eta2[H] moderate \n```\n\n\n:::\n:::\n\n\nWhat is the magnitude of the effect of ramen style on ratings?  \n\n**There is a moderate ($\\eta^2$ = 0.12) effect of ramen style on ratings.**\n\n#### g. Putting everything together\n\nWe found a moderate ($\\eta^2$ = 0.12) difference in ratings between ramen styles (Kruskal-Wallis rank sum test, $\\chi^2$(3) = 15.7, p = 0.0013). Bowl-style ramen had a median rating of 4.25 stars, which tended to be more highly rated than pack (Dunn's post-hoc test: Holm adjusted p = 0.04, median rating = 3.75 stars), tray (Dunn's post-hoc test: Holm adjusted p = 0.04, median rating = 3.75 stars), or cup style ramen (Dunn's post-hoc test: Holm adjusted p = 0.0013, median rating = 3.5 stars).\n\n",
    "supporting": [
      "workshop-05_2025_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}