[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nFinalizing plots\n\n\ntips for making your plots readable and professional\n\n\n\n\nClear communication = interpretable stats\n\n\nCommunicating about statistical results, a few ways\n\n\n\n\nCitations in RStudio\n\n\nusing the visual editor to add citations using a DOI\n\n\n\n\nSetting up GitHub pages\n\n\nsimple options to turn your repository into a website\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to ENVS 193DS, Spring 2023!",
    "section": "",
    "text": "This is a page where the rendered outputs for all the materials we use in class are kept. There are lecture figures and workshop materials.\nInstructor: An Bui"
  },
  {
    "objectID": "resources/adding-citations.html",
    "href": "resources/adding-citations.html",
    "title": "Citations in RStudio",
    "section": "",
    "text": "Note: my understanding is that this works in Quarto and RMarkdown. But give it a try!\n\n1. Use the visual editor.\n\n\n\n2. Insert a citation.\nNavigate to Insert &gt; Citation.\n\n\n\n3. Find the paper DOI.\nDOI stands for Digital Object Identifier. It’s essentially a permanent identification number for papers, databases, etc. Pretty much all papers have a DOI, and they’re usually at the top of the page somewhere. Copy the text after the “https://doi.org/” part (that’s the DOI).\n\n\n\n4. Insert the DOI into the citation box in RStudio.\nSelect “From DOI”. Paste the DOI into the box and hit “Search”. The paper title, author, and other information should pop up.\nAt the bottom of the box, there will be an option to create a references.bib file. This is the file where all your citations will live. Note: it is important that the references.bib file is in the same folder as your script - this will happen automatically, but it’s good to double check!\nMake sure “In-text” is checked. Hit “Insert”.\n\n\n\n5. Marvel at your citation!\nOnce you look back at your script, you should see 1) something like @authorname in the text where you wanted to insert your citation, 2) bibliography: references.bib in the YAML, and 3) a references.bib file in the folder where your script is. In your script, put that citation in brackets. This is what it looks like in the visual editor:\n\nAnd in the source editor:\n\n\n\n6. Render your document.\nWhenever you’re ready, you can render/knit your document. It should have your citation in parentheses and the citation for the paper at the bottom of the page.\n\n\n\n\n\nCitationBibTeX citation:@online{bui2023,\n  author = {Bui, An},\n  title = {Citations in {RStudio}},\n  date = {2023-06-01},\n  url = {https://an-bui.github.io/ES-193DS-W23/resources/adding-citations.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2023. “Citations in RStudio.” June 1, 2023. https://an-bui.github.io/ES-193DS-W23/resources/adding-citations.html."
  },
  {
    "objectID": "resources/finalizing-plots.html",
    "href": "resources/finalizing-plots.html",
    "title": "Finalizing plots",
    "section": "",
    "text": "Data visualization is a huge part of data storytelling, one of the core parts of being a data scientist. This is especially relevant to environmental science: you’re responsible for communicating not just about the environment, but what evidence (i.e. data) supports your claim. Therefore, it is crucial that environmental scientists communicate about their data clearly and effectively.\nIn this class, your plots will be assessed using three (very broad) criteria:\n1. accuracy: is your plot accurately and truthfully representing the data?\n2. clarity: is your plot clearly representing a pattern, relationship, message?\n3. aesthetics: does your plot look good?"
  },
  {
    "objectID": "resources/finalizing-plots.html#non-negotiable-if-you-are-missing-these-you-will-not-get-full-credit-for-your-plot",
    "href": "resources/finalizing-plots.html#non-negotiable-if-you-are-missing-these-you-will-not-get-full-credit-for-your-plot",
    "title": "Finalizing plots",
    "section": "Non-negotiable (if you are missing these, you will not get full credit for your plot)",
    "text": "Non-negotiable (if you are missing these, you will not get full credit for your plot)\n\nAxes must have complete labels with units (very few exceptions to this)\n\nfor example: body_mass_g should be “Body mass (g)”\n\nIf plotting regression or correlation lines, underlying data must be displayed on plot in addition to predicted lines\nConcise, descriptive title (if presented alone and not in a report)"
  },
  {
    "objectID": "resources/finalizing-plots.html#additional-points",
    "href": "resources/finalizing-plots.html#additional-points",
    "title": "Finalizing plots",
    "section": "Additional points",
    "text": "Additional points\n\nlogical start and end values of x or y axes (these are usually by default in ggplot, but you should double check)\nif gridlines aren’t useful to understand the data, remove them\nfigure background should be white (easier to see points)\ntext labels should be large enough to see/read clearly\nuse color sparingly and be aware of color-blind friendly palettes\nuse one font throughout a plot\nfigure fonts should match text font (for example, don’t use Arial in a figure when the rest of your text is in Times New Roman)\nmake sure your plot size and aspect ratio renders correctly\n\nIn general, the simpler you can make a plot, the better."
  },
  {
    "objectID": "resources/finalizing-plots.html#bar-chart",
    "href": "resources/finalizing-plots.html#bar-chart",
    "title": "Finalizing plots",
    "section": "Bar chart",
    "text": "Bar chart\n\n\nCode\npenguins %&gt;% \n  group_by(island, species) %&gt;% \n  count() %&gt;% \n  ggplot(aes(x = species, y = n)) +\n  geom_col() +\n  labs(title = \"penguins\") +\n  facet_wrap(~island)\n\n\n\n\n\n\n\n\n\nWhy is this bad?\n- gap between bottom of bars and x-axis\n- meaningless y axis\n- gray background against gray bars and black text is hard to see\n- gridlines don’t do much\n\n\nCode\npenguins %&gt;% \n  group_by(island, species) %&gt;% \n  count() %&gt;% \n  ggplot(aes(x = island, y = n)) +\n  # fill = fills in the shape, color = controls the outline\n  geom_col(fill = \"darkgrey\", color = \"#000000\") +\n  # expand takes away the gap at the bottom and at the top of the plot\n  # limits sets the limits of the axis\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 130)) +\n  # change titles to be meaningful\n  labs(title = \"Penguin counts differ across species and islands\",\n       x = \"Island\", \n       y = \"Penguin count\") +\n  # one of the built-in themes in ggplot\n  theme_bw() +\n  theme(# changing text sizes\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14),\n        strip.text = element_text(size = 14),\n        # getting rid of gridlines\n        panel.grid = element_blank(),\n        # making the subplot titles (aka strips) have a transparent background\n        strip.background = element_blank(),\n        # making the plot title bigger and centering it\n        plot.title = element_text(size = 20, hjust = 0.5),\n        plot.title.position = \"plot\",\n        text = element_text(family = \"Times\")\n        ) +\n  facet_wrap(~species)\n\n\n\n\n\n\n\n\n\nWhy is this better?\n- text is bigger\n- gridlines are gone\n- easier to see columns agains background\n- complete axes\n- grayscale color scheme (good for printing out and paper reports in black and white)"
  },
  {
    "objectID": "resources/finalizing-plots.html#scatterplot",
    "href": "resources/finalizing-plots.html#scatterplot",
    "title": "Finalizing plots",
    "section": "Scatterplot",
    "text": "Scatterplot\n\n\nCode\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nWhy is this bad?\n- grey background, black dots\n- hides some meaningful variation across species (for example, we know that Gentoo penguins tend to be bigger than Adelie and Chinstrap)\n- axes are meaningless\n- small text size\n- points likely overlap, so some parts of the data are hidden\n\n\nCode\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, color = species, shape = species)) +\n  geom_point(size = 3, alpha = 0.7) +\n  # specify color scheme\n  scale_color_manual(values = c(\"darkorange\", \"cornflowerblue\", \"darkgreen\")) +\n  # meaningful titles\n  labs(title = \"Larger penguins tend to have longer flippers\",\n       x = \"Body mass (g)\", \n       y = \"Flipper length (mm)\",\n       # have to specify color and shape separately (based on color and shape in aes() call)\n       color = \"Penguin species\", shape = \"Penguin species\") +\n  # another ggplot built-in theme\n  theme_classic() +\n  theme(# putting legend in plot area\n        legend.position = c(0.85, 0.2),\n        # legend text sizes\n        legend.text = element_text(size = 14),\n        legend.title = element_text(size = 14),\n        # text size, position, and font adjustment\n        axis.text = element_text(size = 14), \n        axis.title = element_text(size = 16),\n        plot.title = element_text(size = 18, hjust = 0.5),\n        plot.title.position = \"plot\",\n        text = element_text(family = \"Garamond\")\n    )\n\n\n\n\n\n\n\n\n\nWhy is this better?\n- white background, no grid lines\n- points are shaped and colored by species, so you can easily see the differences between groups\n- transparency shows overlapping points\n- complete axis labels\n- text is larger and font is changed\n- legend is in plot area (if there’s space to do this, generally good)"
  },
  {
    "objectID": "resources/finalizing-plots.html#violin-boxplot",
    "href": "resources/finalizing-plots.html#violin-boxplot",
    "title": "Finalizing plots",
    "section": "violin + boxplot",
    "text": "violin + boxplot\n\n\nCode\nggplot(data = penguins, aes(x = species, y = body_mass_g)) +\n  # fill the violin shape using the species column: every species has a different color\n  # alpha argument: makes the violin shape more transparent (scale of 0 to 1)\n  geom_violin(aes(fill = species), alpha = 0.5) +\n  # fill the boxplot shape using the species column\n  # make the boxplots narrower\n  geom_boxplot(aes(fill = species), width = 0.2) +\n  # specify the colors you want to use for each species\n  scale_fill_manual(values = c(\"#F56A56\", \"#3D83F5\", \"#A9A20B\")) +\n  # relabel the axis titles, plot title, and caption\n  labs(x = \"Penguin species\", y = \"Body mass (g)\",\n       title = \"Gentoo penguins tend to be heavier than Adelie or Chinstrap\",\n       caption = \"Data source: {palmerpenguins}, \\n Horst AM, Hill AP, Gorman KB.\") +\n  # themes built in to ggplot\n  theme_bw() +\n  # other theme adjustments\n  theme(legend.position = \"none\", \n        axis.title = element_text(size = 13),\n        axis.text = element_text(size = 12),\n        plot.title = element_text(size = 14),\n        plot.caption = element_text(face = \"italic\"),\n        text = element_text(family = \"Times New Roman\"))\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "resources/finalizing-plots.html#points-with-bars-jitter",
    "href": "resources/finalizing-plots.html#points-with-bars-jitter",
    "title": "Finalizing plots",
    "section": "points with bars + jitter",
    "text": "points with bars + jitter\n\n\nCode\n# summarizing penguin data set: calculating mean and SD body mass by species\npenguin_summary &lt;- penguins %&gt;% \n  group_by(species) %&gt;% \n  summarize(mean_body_mass = mean(body_mass_g, na.rm = TRUE),\n            sd_body_mass = sd(body_mass_g, na.rm = TRUE))\n\nggplot() +\n  # using two different data frames: penguins (raw data) and penguins_summary (mean and SD)\n  # raw data are jittered\n  geom_jitter(data = penguins, aes(x = species, y = body_mass_g, color = species), alpha = 0.4) +\n  # summary data: mean is a point, bars are standard deviation\n  geom_point(data = penguin_summary, aes(x = species, y = mean_body_mass, color = species), size = 5) +\n  geom_errorbar(data = penguin_summary, aes(x = species, ymin = mean_body_mass - sd_body_mass, ymax = mean_body_mass + sd_body_mass, color = species), width = 0.2) +\n  scale_color_manual(values = c(\"#F56A56\", \"#3D83F5\", \"#A9A20B\")) +\n  labs(x = \"Penguin species\", y = \"Body mass (g)\",\n       title = \"Gentoo penguins tend to be heavier than Adelie or Chinstrap\",\n       caption = \"Data source: {palmerpenguins}, \\n Horst AM, Hill AP, Gorman KB.\") +\n  theme_bw() +\n  theme(legend.position = \"none\", \n        axis.title = element_text(size = 13),\n        axis.text = element_text(size = 12),\n        plot.title = element_text(size = 14),\n        plot.caption = element_text(face = \"italic\"),\n        text = element_text(family = \"Times New Roman\"))\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n```"
  },
  {
    "objectID": "homework.html",
    "href": "homework.html",
    "title": "Homework documents",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nhomework 2 starter code\n\n\n \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workshop/workshop-01_2023-04-05.html",
    "href": "workshop/workshop-01_2023-04-05.html",
    "title": "Coding workshop: Week 1",
    "section": "",
    "text": "0. Introduction to Scripts\nThis is a Quarto Markdown document, which we’ll learn more about next week. This week we’re working in scripts, which allow you to write your code (recipe) and run the code in the console (kitchen).\nR considers everything in the script as code to run, so you can write comments in the R Script by putting a pound sign at the beginning of the line. This is especially useful when you want to explain what your code is doing at each line in plain language.\n\n\n1. Assigning values to objects\nWe’ll start with some basics. We’ll assign values to objects.\n\n\nCode\n# assign the number 5 to an object called snail_length\nsnail_length &lt;- 5\n\n\n\n\nCode\n# print snail_length\nsnail_length\n\n\n[1] 5\n\n\nYou’ll see the output of this in the console, not your script.\nNow that you’ve assigned this value to an object, you can start to work with it. Let’s see what snail_length/2 is.\n\n\nCode\nsnail_length/2\n\n\n[1] 2.5\n\n\nThis doesn’t change the value of snail_length - check this in the console.\n\n\nCode\nsnail_length\n\n\n[1] 5\n\n\nYou can save this new variable as another object.\n\n\nCode\nhalf &lt;- snail_length/2\n\n\n\n\n2. Using functions\nFunctions are where R gets interesting. R allows you to apply functions to do calculations, from simple to complex structures.\nWe can start by calculating the square root of snail_length.\n\n\nCode\nsqrt(snail_length)\n\n\n[1] 2.236068\n\n\nWe might not want all the digits in that calculation, so we could round it using the round() function.\n\n\nCode\nround(sqrt(snail_length))\n\n\n[1] 2\n\n\nThis rounds snail_length to 4. However, we want to be a little more precise than that. Check out what round() does in the console by typing ?round.\nLet’s round snail_length to 3 digits instead of the next whole number.\n\n\nCode\nround(sqrt(snail_length), digits = 3)\n\n\n[1] 2.236\n\n\n\n\n3. Basic sorting and filtering\nNow, let’s try a vector of numbers. Let’s say that we measured a bunch of different fish and recorded their weights in kilograms.\n\n\nCode\nfish_weights &lt;- c(1, 2, 3, 1, 2)\n\n\nLet’s say “small” fish are any fish that are &lt; 2 kilograms. We want to know the weights of all the “small” fish that we collected.\n\n\nCode\nfish_weights[fish_weights &lt; 2]\n\n\n[1] 1 1\n\n\nWhat if we want all the “big” fish?\n\n\nCode\nfish_weights[fish_weights &gt; 2]\n\n\n[1] 3\n\n\n\n\n4. Packages\nPackages (or libraries) have functions that aren’t already built into R.\nYou can install packages in one of two ways. The first (most common) way is to use the functioninstall.packages(). This is for any package that is on CRAN, or the Comprehensive R Archive Network. Try installing the package {tidyverse} using the following command: install.packages(\"tidyverse\").\nNow you have a package installed! But you now need to “load it in” to your environment. Installing a package is like buying a pan - you only need to do it once if you want to cook. However, you still need to put the pan on the stove in order to start cooking.\nYou can load in any package using the function library(). Try loading in the package below.\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\nNothing shows up once you’ve loaded in the package, but now you’re ready to use the functions in it!\n\n\n5. working with data in R\nLater in the quarter, we’ll work with data sets from real examples (i.e. from research). To get acquainted with how to work with data in R, we’ll use some of the built-in examples. Go to the documentation to see the list of data sets that are pre-installed with R. The topics are all over the place, but they are useful for testing things out if the data you have to work with is big and unwieldy.\nOne of the packages that has a cool dataset to test things out with is called {palmerpenguins}. Install it in your console and load it in to your environment.\nWhat is {palmerpenguins}? Read about it here.\nThe first step to using data is looking at it! Use View(penguins) to see what it is.\n(Hint: did that not work? Remember to load in the package before you start using it.)\n\n\nCode\nlibrary(palmerpenguins)\npenguins\n\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_…¹ body_…² sex    year\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;      &lt;int&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7        181    3750 male   2007\n 2 Adelie  Torgersen           39.5          17.4        186    3800 fema…  2007\n 3 Adelie  Torgersen           40.3          18          195    3250 fema…  2007\n 4 Adelie  Torgersen           NA            NA           NA      NA &lt;NA&gt;   2007\n 5 Adelie  Torgersen           36.7          19.3        193    3450 fema…  2007\n 6 Adelie  Torgersen           39.3          20.6        190    3650 male   2007\n 7 Adelie  Torgersen           38.9          17.8        181    3625 fema…  2007\n 8 Adelie  Torgersen           39.2          19.6        195    4675 male   2007\n 9 Adelie  Torgersen           34.1          18.1        193    3475 &lt;NA&gt;   2007\n10 Adelie  Torgersen           42            20.2        190    4250 &lt;NA&gt;   2007\n# … with 334 more rows, and abbreviated variable names ¹​flipper_length_mm,\n#   ²​body_mass_g\n\n\npenguins is a data frame. Data frames have rows and columns, and their cells contain data. In this case, this data frame has 8 columns and 344 rows, which you can see in the visual display.\nFigure out what the columns are by using colnames(penguins).\n\n\nCode\ncolnames(penguins)\n\n\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\"             \n\n\nWrite out 1) the column name, 2) what type of variable it is, and 3) what data are in them. For example:\n- species: categorical, penguin species\n- island: categorical, islands were penguins were sampled\n- bill_length_mm: continuous, bill length in mm\n- bill_depth_mm: continuous, bill depth in mm\n- flipper_length_mm: continuous, flipper length in mm\n- body_mass_g: continuous, body mass in grams\n- sex: categorical, male or female\n- year: categorical (ordinal), year sampled\nYou can learn about the structure of a data frame by running the function str(). What is the output for that?\n\n\nCode\nstr(penguins)\n\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nLet’s figure out some basic information about the data set. What’s the longest bill length they measured on a penguin? Save that as an object called long_bill.\n\n\nCode\nlong_bill &lt;- 59.6\n\n\nWe did that visually, but you can do that in code. The function max() allows you to get the maximum number in a vector, which is a list of numbers. (Note: how would you double check how the function works if you hadn’t used it before?)\n\n\nCode\nmax(penguins$bill_length_mm)\n\n\n[1] NA\n\n\nHuh. That was weird. We knew the longest bill was 59.6, but why does this say NA?\n\n\nCode\nmax(penguins$bill_length_mm, na.rm = TRUE)\n\n\n[1] 59.6\n\n\nThat’s a lot better!\nTry finding the minimum bill length, and saving that as an object called short_bill.\n\n\nCode\nmin(penguins$bill_length_mm, na.rm = TRUE)\n\n\n[1] 32.1\n\n\n\n\n6. data exploration\nLet’s say you think the three different penguin species have different body masses, on average. This is where the {tidyverse} package we were using before comes in handy.\nWe know that there’s a column in the data frame that has species, and another column that has body masses. So if there’s a way we can get all the rows belonging to a species, then take all the numbers for body mass and average them, we can figure out the average body mass for a penguin species in the sample.\nThere are tidyverse functions that can help with that:\n- group_by(): identifying natural groups in the data frame (categorical variables)\n- summarize(): summarizes the data based on what you want\n- %&gt;%: a very!!! useful operator (not a function). This is called a “pipe” and it allows you to string functions together. You’re basically telling R, “… and then”. An example below:\n\n\nCode\n# tell R what data frame you want to use\npenguins %&gt;% \n  # and then, group the data frame by species\n  group_by(species) %&gt;% \n  # and then, summarize: create a new column called `mean_body_mass` from body_mass_g\n  summarize(mean_body_mass = mean(body_mass_g, na.rm = TRUE))\n\n\n# A tibble: 3 × 2\n  species   mean_body_mass\n  &lt;fct&gt;              &lt;dbl&gt;\n1 Adelie             3701.\n2 Chinstrap          3733.\n3 Gentoo             5076.\n\n\nTry figuring out what the maximum flipper length is by island.\n\n\nCode\n# tell R that you want to use the data frame penguins\npenguins %&gt;% \n  # and then, group the data frame by island\n  group_by(island) %&gt;% \n  # and then, summarize: create a new column called 'max_flipper_length' from flipper_length_mm\n  summarize(max_flipper_length = max(flipper_length_mm, na.rm = TRUE))\n\n\n# A tibble: 3 × 2\n  island    max_flipper_length\n  &lt;fct&gt;                  &lt;int&gt;\n1 Biscoe                   231\n2 Dream                    212\n3 Torgersen                210\n\n\nYou can also group by multiple columns.\n\n\nCode\n# use penguins\npenguins %&gt;% \n  # group by island, then species\n  group_by(island, species) %&gt;% \n  # summarize: get max flipper length\n  summarize(max_flipper_length = max(flipper_length_mm, na.rm = TRUE))\n\n\n`summarise()` has grouped output by 'island'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 3\n# Groups:   island [3]\n  island    species   max_flipper_length\n  &lt;fct&gt;     &lt;fct&gt;                  &lt;int&gt;\n1 Biscoe    Adelie                   203\n2 Biscoe    Gentoo                   231\n3 Dream     Adelie                   208\n4 Dream     Chinstrap                212\n5 Torgersen Adelie                   210\n\n\nWhat if you only want Biscoe island?\n- filter(): filters a data frame by data in a column\n\n\nCode\n# use the penguins data frame\npenguins %&gt;% \n  # filter the data frame to only include Biscoe Island\n  filter(island == \"Biscoe\") %&gt;% \n  # group by species\n  group_by(species) %&gt;%\n  # calculate mean body mass\n  summarize(mean_body_mass = mean(body_mass_g, na.rm = TRUE))\n\n\n# A tibble: 2 × 2\n  species mean_body_mass\n  &lt;fct&gt;            &lt;dbl&gt;\n1 Adelie           3710.\n2 Gentoo           5076.\n\n\n\n\n\n\nCitationBibTeX citation:@online{bui2023,\n  author = {Bui, An},\n  title = {Coding Workshop: {Week} 1},\n  date = {2023-04-05},\n  url = {https://an-bui.github.io/ES-193DS-W23/workshop/workshop-01_2023-04-05.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2023. “Coding Workshop: Week 1.” April 5, 2023. https://an-bui.github.io/ES-193DS-W23/workshop/workshop-01_2023-04-05.html."
  },
  {
    "objectID": "workshop/workshop-08_2023-05-24.html",
    "href": "workshop/workshop-08_2023-05-24.html",
    "title": "Coding workshop: Week 8 and 9",
    "section": "",
    "text": "---\ntitle: \"Untitled\"\nformat:\n  html:\n    toc: true\n    toc-location: left\n    code-fold: true\n    theme: yeti\nexecute:\n  message: false\n  warning: false\n---\n\n\n\n---\ntitle: \"Untitled\"\nformat:\n  html_document:\n    toc: true\n    toc-location: left\n    code_folding: true\n    theme: yeti\n---\n\n\n\n\n\nCode\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)"
  },
  {
    "objectID": "workshop/workshop-08_2023-05-24.html#yaml-options-for-a-quarto-document",
    "href": "workshop/workshop-08_2023-05-24.html#yaml-options-for-a-quarto-document",
    "title": "Coding workshop: Week 8 and 9",
    "section": "",
    "text": "---\ntitle: \"Untitled\"\nformat:\n  html:\n    toc: true\n    toc-location: left\n    code-fold: true\n    theme: yeti\nexecute:\n  message: false\n  warning: false\n---"
  },
  {
    "objectID": "workshop/workshop-08_2023-05-24.html#yaml-options-for-an-rmarkdown-document",
    "href": "workshop/workshop-08_2023-05-24.html#yaml-options-for-an-rmarkdown-document",
    "title": "Coding workshop: Week 8 and 9",
    "section": "",
    "text": "---\ntitle: \"Untitled\"\nformat:\n  html_document:\n    toc: true\n    toc-location: left\n    code_folding: true\n    theme: yeti\n---"
  },
  {
    "objectID": "workshop/workshop-08_2023-05-24.html#knitr-set-up-options-for-an-rmarkdown-document",
    "href": "workshop/workshop-08_2023-05-24.html#knitr-set-up-options-for-an-rmarkdown-document",
    "title": "Coding workshop: Week 8 and 9",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)"
  },
  {
    "objectID": "workshop/workshop-04_2023-04-26.html",
    "href": "workshop/workshop-04_2023-04-26.html",
    "title": "Coding workshop: Week 4",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(lterdatasampler)"
  },
  {
    "objectID": "workshop/workshop-04_2023-04-26.html#a.-initial-wrangling",
    "href": "workshop/workshop-04_2023-04-26.html#a.-initial-wrangling",
    "title": "Coding workshop: Week 4",
    "section": "a. initial wrangling",
    "text": "a. initial wrangling\n\n\nCode\nmaples_2003 &lt;- hbr_maples %&gt;% \n  filter(year == 2003) %&gt;% \n  mutate(watershed = case_when(\n    watershed == \"Reference\" ~ \"Reference\", \n    watershed == \"W1\" ~ \"Calcium-treated\"\n  ))\n\nhead(maples_2003, 5)\n\n\n# A tibble: 5 × 11\n   year watershed eleva…¹ trans…² sample stem_…³ leaf1…⁴ leaf2…⁵ leaf_…⁶ stem_…⁷\n  &lt;dbl&gt; &lt;chr&gt;     &lt;fct&gt;   &lt;fct&gt;   &lt;fct&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1  2003 Reference Low     R1      1         86.9   13.8    12.1   0.0453  0.03  \n2  2003 Reference Low     R1      2        114     14.6    15.3   0.0476  0.0338\n3  2003 Reference Low     R1      3         83.5   12.5     9.73  0.0423  0.0248\n4  2003 Reference Low     R1      4         68.1    9.97   10.1   0.0397  0.0194\n5  2003 Reference Low     R1      5         72.1    6.84    5.48  0.0204  0.018 \n# … with 1 more variable: corrected_leaf_area &lt;dbl&gt;, and abbreviated variable\n#   names ¹​elevation, ²​transect, ³​stem_length, ⁴​leaf1area, ⁵​leaf2area,\n#   ⁶​leaf_dry_mass, ⁷​stem_dry_mass"
  },
  {
    "objectID": "workshop/workshop-04_2023-04-26.html#b.-summary-statistics",
    "href": "workshop/workshop-04_2023-04-26.html#b.-summary-statistics",
    "title": "Coding workshop: Week 4",
    "section": "b. summary statistics",
    "text": "b. summary statistics\nRemember, we’re interested in stem lengths in 2003 between reference and calcium-treated watersheds. What groups would be useful if that was the case?\n\n\nCode\nlengths_2003_summary &lt;- maples_2003 %&gt;% \n  group_by(watershed) %&gt;% \n  summarize(mean_l = mean(stem_length),\n            sd_l = sd(stem_length),\n            var_l = var(stem_length),\n            count_l = length(stem_length),\n            se_l = sd_l/sqrt(count_l),\n            margin_l = qt(0.95, df = count_l - 1) * se_l) \n\nlengths_2003_summary\n\n\n# A tibble: 2 × 7\n  watershed       mean_l  sd_l var_l count_l  se_l margin_l\n  &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Calcium-treated   87.9  14.3  206.     120  1.31     2.17\n2 Reference         81.0  13.9  194.     120  1.27     2.11\n\n\nCode\n# not getting the digits after the decimal point that you're expecting?\n# try `as.data.frame()` piped in after the summarize call."
  },
  {
    "objectID": "workshop/workshop-04_2023-04-26.html#c.-check-for-normally-distributed-data",
    "href": "workshop/workshop-04_2023-04-26.html#c.-check-for-normally-distributed-data",
    "title": "Coding workshop: Week 4",
    "section": "c. check for normally distributed data",
    "text": "c. check for normally distributed data\n\n\nCode\nggplot(data = maples_2003) +\n  stat_qq(aes(sample = stem_length)) +\n  stat_qq_line(aes(sample = stem_length), color = \"red\") +\n  facet_wrap(~ watershed)"
  },
  {
    "objectID": "workshop/workshop-04_2023-04-26.html#c.-check-for-equal-variances",
    "href": "workshop/workshop-04_2023-04-26.html#c.-check-for-equal-variances",
    "title": "Coding workshop: Week 4",
    "section": "c. Check for equal variances",
    "text": "c. Check for equal variances\nWith an F-test, you can ask: are the sample variances between my two groups equal?\nThe assumption is that your data are normally distributed.\n\\[\nH0: s^2_1 = s^2_2\nH1: s^2_1 \\neq s^2_2\n\\]\n\n\nCode\nlength_var &lt;- var.test(stem_length ~ watershed, data = maples_2003)\n\nlength_var\n\n\n\n    F test to compare two variances\n\ndata:  stem_length by watershed\nF = 1.0587, num df = 119, denom df = 119, p-value = 0.7563\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.7378244 1.5190473\nsample estimates:\nratio of variances \n          1.058674"
  },
  {
    "objectID": "workshop/workshop-04_2023-04-26.html#c.-decide-on-a-critical-value",
    "href": "workshop/workshop-04_2023-04-26.html#c.-decide-on-a-critical-value",
    "title": "Coding workshop: Week 4",
    "section": "c. decide on a critical value",
    "text": "c. decide on a critical value\nTwo-tailed with significance level \\(\\alpha\\) = 0.05:\n\n\nCode\nqt(p = .05/2, df = 119)\n\n\n[1] -1.9801\n\n\nIf your test statistic is less than -1.98 or greater than 1.98, then you have evidence to reject the null hypothesis."
  },
  {
    "objectID": "workshop/workshop-04_2023-04-26.html#d.-do-a-t-test",
    "href": "workshop/workshop-04_2023-04-26.html#d.-do-a-t-test",
    "title": "Coding workshop: Week 4",
    "section": "d. Do a t-test",
    "text": "d. Do a t-test\n\n\nCode\nlength_ttest &lt;- t.test(stem_length ~ watershed, data = maples_2003, var.equal = TRUE)\n\nlength_ttest\n\n\n\n    Two Sample t-test\n\ndata:  stem_length by watershed\nt = 3.7797, df = 238, p-value = 0.0001985\nalternative hypothesis: true difference in means between group Calcium-treated and group Reference is not equal to 0\n95 percent confidence interval:\n  3.304134 10.497532\nsample estimates:\nmean in group Calcium-treated       mean in group Reference \n                     87.88583                      80.98500"
  },
  {
    "objectID": "workshop/workshop-04_2023-04-26.html#e.-calculate-cohens-d-effect-size",
    "href": "workshop/workshop-04_2023-04-26.html#e.-calculate-cohens-d-effect-size",
    "title": "Coding workshop: Week 4",
    "section": "e. Calculate Cohen’s d effect size",
    "text": "e. Calculate Cohen’s d effect size\nCohen’s d is a measure of how many standard deviations apart the two sample means are.\n\\[\nCohen's d = \\frac{\\bar{x_1} - \\bar{x_2}}{\\sqrt{(s^2_1 + s^2_2)/2}}\n\\]\nNote that you are using sample means in the numerator and sample variances in the denominator.\nWe can calculate this by hand (use install.packages(\"data.table\") in the console before running the chunk below):\n\n\nCode\nlibrary(data.table)\n\n# create a data frame in data table format from lengths_2003_summary\nlengths_dt &lt;- setDT(lengths_2003_summary)\n\n# pull out mean and variance values from the data table \nmean_ref_2003 &lt;- lengths_dt[watershed == \"Reference\", mean_l]\nmean_w1_2003 &lt;- lengths_dt[watershed == \"Calcium-treated\", mean_l]\nvar_ref_2003 &lt;- lengths_dt[watershed == \"Reference\", var_l]\nvar_w1_2003 &lt;- lengths_dt[watershed == \"Calcium-treated\", var_l]\n\n# calculate Cohen's d\nd_byhand &lt;- (mean_w1_2003 - mean_ref_2003) / sqrt((var_w1_2003 + var_ref_2003)/2)\nd_byhand\n\n\n[1] 0.4879597\n\n\nOr using a function in a package:\nUse install.packages(\"effsize\") in the console before running the chunk below.\n\n\nCode\nlibrary(effsize)\n\nd_effsize &lt;- cohen.d(stem_length ~ watershed, data = maples_2003)\n\n\nCompare the two calculations:\n\n\nCode\nd_byhand\n\n\n[1] 0.4879597\n\n\nCode\nd_effsize\n\n\n\nCohen's d\n\nd estimate: 0.4879597 (small)\n95 percent confidence interval:\n    lower     upper \n0.2298792 0.7460402"
  },
  {
    "objectID": "workshop/workshop-04_2023-04-26.html#make-a-plot",
    "href": "workshop/workshop-04_2023-04-26.html#make-a-plot",
    "title": "Coding workshop: Week 4",
    "section": "make a plot",
    "text": "make a plot\n\n\nCode\nggplot(data = lengths_2003_summary, aes(x = watershed, y = mean_l, color = watershed)) +\n  geom_point(size = 3) +\n  geom_linerange(aes(ymin = mean_l - margin_l, ymax = mean_l + margin_l), linewidth = 1) +\n  geom_jitter(data = maples_2003, aes(x = watershed, y = stem_length), alpha = 0.3) +\n  scale_color_manual(values = c(\"Reference\" = \"#E57B33\", \"Calcium-treated\" = \"#039199\")) +\n  labs(x = \"Watershed\", y = \"Stem length (mm)\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        text = element_text(family = \"Times New Roman\"),\n        axis.title = element_text(size = 14),\n        axis.text = element_text(size = 12),\n        plot.caption = element_text(hjust = 0),\n        plot.caption.position = \"plot\",\n        plot.title.position = \"plot\")"
  },
  {
    "objectID": "workshop/workshop-04_2023-04-26.html#f.-communicating-about-the-results-of-a-t-test",
    "href": "workshop/workshop-04_2023-04-26.html#f.-communicating-about-the-results-of-a-t-test",
    "title": "Coding workshop: Week 4",
    "section": "f. Communicating about the results of a t-test",
    "text": "f. Communicating about the results of a t-test\n\nfigure caption\nFigure 1. Sugar maple stem lengths in calcium-treated and reference watersheds. Stem lengths (mm) for calcium-treated (turquoise) and reference (orange) watersheds from Hubbard Brook Long-term Ecological Research site (HBR LTER). Dark points represent mean stem length and vertical lines represent confidence intervals with a 95% confidence level. Transparent points represent stem lengths.\n\n\nin-text references\nThere is a moderate (Cohen’s d = 0.49) but significant effect of calcium treatment on sugar maple stem lengths (Student’s t-test, t(238) = 3.78, p &lt; 0.001, \\(\\alpha\\) = 0.05). On average, sugar maple stem lengths in calcium-treated watersheds were 6.9 mm longer than those in reference watersheds (95% confidence interval: [3.3, 10.5] mm, Figure 1).\n\n\nbonus in-text references, using in-line R\nWhen rendering your document, compare the text above with the text below. Are there any differences?\nThere is a moderate (Cohen’s d = 0.49) but significant effect of calcium treatment on sugar maple stem lengths (Student’s t-test, t(238) = 3.8, p &lt; 0.001, \\(\\alpha\\) = 0.05). On average, sugar maple stem lengths in calcium-treated watersheds were 6.9 mm longer than those in reference watersheds (CI = [3.3, 10.5] mm, Figure 1)."
  },
  {
    "objectID": "workshop/workshop-07_2023-05-17.html",
    "href": "workshop/workshop-07_2023-05-17.html",
    "title": "Coding workshop: Week 7",
    "section": "",
    "text": "Code\n# should haves\nlibrary(tidyverse)\nlibrary(here)\nlibrary(lterdatasampler)\n\n# would be nice to have\nlibrary(performance)\nlibrary(broom)\nlibrary(flextable)\nlibrary(ggeffects)\nlibrary(car)"
  },
  {
    "objectID": "workshop/workshop-07_2023-05-17.html#a.-model-predictions",
    "href": "workshop/workshop-07_2023-05-17.html#a.-model-predictions",
    "title": "Coding workshop: Week 7",
    "section": "a. model predictions",
    "text": "a. model predictions\n\n\nCode\n# extract model predictions using ggpredict\npredictions &lt;- ggpredict(modelobject, terms = \"stem_length\")\n\npredictions\n\n\n# Predicted values of stem_dry_mass\n\nstem_length | Predicted |       95% CI\n--------------------------------------\n         50 |      0.02 | [0.01, 0.02]\n         60 |      0.02 | [0.02, 0.02]\n         70 |      0.02 | [0.02, 0.02]\n         80 |      0.02 | [0.02, 0.02]\n         90 |      0.02 | [0.02, 0.03]\n        100 |      0.03 | [0.02, 0.03]\n        110 |      0.03 | [0.03, 0.03]\n        120 |      0.03 | [0.03, 0.03]\n\n\n\n\nCode\nplot_predictions &lt;- ggplot(data = maples_data, \n                           aes(x = stem_length, y = stem_dry_mass)) +\n  # first plot the underlying data from maples_data\n  geom_point() +\n  # then plot the predictions\n  geom_line(data = predictions, \n            aes(x = x, y = predicted), \n            color = \"blue\", linewidth = 1) +\n  # then plot the 95% confidence interval from ggpredict\n  geom_ribbon(data = predictions, \n              aes(x = x, y = predicted, ymin = conf.low, ymax = conf.high), \n              alpha = 0.2) +\n  # theme and meaningful labels\n  theme_bw() +\n  labs(x = \"Stem length (mm)\",\n       y = \"Stem dry mass (g)\")\n\nplot_predictions"
  },
  {
    "objectID": "workshop/workshop-07_2023-05-17.html#b.-summary-tables",
    "href": "workshop/workshop-07_2023-05-17.html#b.-summary-tables",
    "title": "Coding workshop: Week 7",
    "section": "b. summary tables",
    "text": "b. summary tables\n\n\nCode\n# store the model summary as an object\nmodel_summary &lt;- summary(modelobject)\n\n# store the ANOVA table as an object\n# anova(): special function to get analysis of variance tables for a model\nmodel_squares &lt;- anova(modelobject)\n\nmodel_summary\n\n\n\nCall:\nlm(formula = stem_dry_mass ~ stem_length, data = maples_data)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.0111253 -0.0039117 -0.0009091  0.0040911  0.0164587 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 7.003e-03  3.212e-03   2.180   0.0312 *  \nstem_length 1.958e-04  3.909e-05   5.009 1.94e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.005944 on 118 degrees of freedom\nMultiple R-squared:  0.1753,    Adjusted R-squared:  0.1683 \nF-statistic: 25.09 on 1 and 118 DF,  p-value: 1.94e-06\n\n\nCode\nmodel_squares\n\n\nAnalysis of Variance Table\n\nResponse: stem_dry_mass\n             Df    Sum Sq    Mean Sq F value   Pr(&gt;F)    \nstem_length   1 0.0008864 0.00088642  25.089 1.94e-06 ***\nResiduals   118 0.0041691 0.00003533                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nmodel summary table:\n\n\nCode\n# don't name this chunk! some intricacies with Quarto: do not name chunks with tables in them\n\nmodel_squares_table &lt;- tidy(model_squares) %&gt;% \n  # round the sum of squares and mean squares columns to have 5 digits (could be less)\n  mutate(across(sumsq:meansq, ~ round(.x, digits = 5))) %&gt;% \n  # round the F-statistic to have 1 digit\n  mutate(statistic = round(statistic, digits = 1)) %&gt;% \n  # replace the very very very small p value with &lt; 0.001\n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\"\n  )) %&gt;% \n  # rename the stem_length cell to be meaningful\n  mutate(term = case_when(\n    term == \"stem_length\" ~ \"Stem length (mm)\",\n    TRUE ~ term\n  )) %&gt;% \n  # make the data frame a flextable object\n  flextable() %&gt;% \n  # change the header labels to be meaningful\n  set_header_labels(df = \"Degrees of Freedom\", \n                    sumsq = \"Sum of squares\",\n                    meansq = \"Mean squares\",\n                    statistic = \"F-statistic\",\n                    p.value = \"p-value\")\n\nmodel_squares_table\n\n\ntermDegrees of FreedomSum of squaresMean squaresF-statisticp-valueStem length (mm)10.000890.0008925.1&lt; 0.001Residuals1180.004170.00004\n\n\nNote! We didn’t get to analysis of variance in workshop on Wednesday. We will do it next week."
  },
  {
    "objectID": "lecture/lecture-08_2023-05-22.html",
    "href": "lecture/lecture-08_2023-05-22.html",
    "title": "Lecture 08 figures",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(showtext)\nlibrary(car)\nfont_add_google(\"Lato\", \"Lato\")\nshowtext_auto()\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(performance)\nlibrary(broom)\nlibrary(flextable)\nlibrary(DHARMa)\nlibrary(GGally)\nlibrary(MuMIn)"
  },
  {
    "objectID": "lecture/lecture-08_2023-05-22.html#sum-of-squares-for-linear-regression",
    "href": "lecture/lecture-08_2023-05-22.html#sum-of-squares-for-linear-regression",
    "title": "Lecture 08 figures",
    "section": "sum of squares for linear regression",
    "text": "sum of squares for linear regression\n\nregression (or model)\n\\[\nSS_{reg} = \\sum_{i = 1}^{n}(\\hat{y} - \\bar{y})^2\n\\]\n\n\nerror\n\\[\nSS_{err} = \\sum_{i = 1}^{n}(y_i - \\hat{y})^2\n\\]\n\n\ntotal\n\\[\nSS_{tot} = \\sum_{i = 1}^n(y_i - \\bar{y})\n\\]"
  },
  {
    "objectID": "lecture/lecture-08_2023-05-22.html#mean-square",
    "href": "lecture/lecture-08_2023-05-22.html#mean-square",
    "title": "Lecture 08 figures",
    "section": "mean square",
    "text": "mean square\n\nregression\n\\[\nMS_{reg} = \\frac{SS_{reg}}{1}\n\\]\n\n\nerror\n\\[\nMS_{err} = \\frac{SS_{err}}{n - 2}\n\\]"
  },
  {
    "objectID": "lecture/lecture-08_2023-05-22.html#f-statistic",
    "href": "lecture/lecture-08_2023-05-22.html#f-statistic",
    "title": "Lecture 08 figures",
    "section": "F-statistic",
    "text": "F-statistic\n\\[\nF = \\frac{MS_{reg}}{MS_{err}}\n\\]"
  },
  {
    "objectID": "lecture/lecture-08_2023-05-22.html#generating-data",
    "href": "lecture/lecture-08_2023-05-22.html#generating-data",
    "title": "Lecture 08 figures",
    "section": "generating data",
    "text": "generating data\n\n\nCode\nset.seed(666)\nfrog_n &lt;- 87\n\ndf &lt;- cbind(\n  # predictor variables\n  color = sample(x = c(\"blue\", \"green\", \"red\"), size = frog_n, replace = TRUE, prob = c(0.3, 0.3, 0.3)),\n  weight = (round(rnorm(n = frog_n, mean = 3, sd = 0.3), 2)),\n  pattern = sample(x = c(\"striped\", \"spotted\", \"none\"), size = frog_n, replace = TRUE, prob = c(0.3, 0.3, 0.3))\n) %&gt;% \n  as_tibble() %&gt;% \n  mutate(weight = as.numeric(weight),\n         color = as.factor(color),\n         pattern = as.factor(pattern)) %&gt;% \n  group_by(color, pattern) %&gt;% \n  # response variable\n  mutate(toxicity = case_when(\n    color == \"blue\" & pattern == \"striped\" ~ rnorm(n = length(color), mean = 5, sd = 1),\n    color == \"blue\" & pattern == \"spotted\" ~ rnorm(n = length(color), mean = 4, sd = 1),\n    color == \"green\" & pattern == \"striped\" ~ rnorm(n = length(color), mean = 4, sd = 1),\n    color == \"green\" & pattern == \"spotted\" ~ rnorm(n = length(color), mean = 3, sd = 1),\n    color == \"red\" ~ rnorm(n = length(color), mean = 6, sd = 1),\n    TRUE ~ rnorm(n = length(color), mean = 2, sd = 1)\n  )) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "lecture/lecture-08_2023-05-22.html#plotting-data",
    "href": "lecture/lecture-08_2023-05-22.html#plotting-data",
    "title": "Lecture 08 figures",
    "section": "plotting data",
    "text": "plotting data\n\n\nCode\nblue_col &lt;- \"cornflowerblue\"\ngreen_col &lt;- \"darkgreen\"\nred_col &lt;- \"maroon\"\n\nstriped_col &lt;- \"grey1\"\nspotted_col &lt;- \"grey50\"\nnone_col &lt;- \"grey80\"\n\nggplot(data = df, aes(x = color, y = toxicity, color = color, fill = color)) +\n  geom_jitter(width = 0.2, height = 0, alpha = 0.3) +\n  scale_color_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  scale_fill_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  stat_summary(geom = \"pointrange\", fun = mean, fun.min = function(x) mean(x) - sd(x), fun.max = function(x) mean(x) + sd(x), shape = 21, size = 1) +\n #  geom_point(position = position_jitter(width = 0.2, height = 0, seed = 666), alpha = 0.3) +\n  labs(title = \"Color\") +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        axis.title.x = element_blank(),\n        text = element_text(size = 22))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = df, aes(x = pattern, y = toxicity, shape = pattern)) +\n  geom_jitter(width = 0.2, height = 0, alpha = 0.3) +\n  # scale_color_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  # scale_fill_manual(values = c(\"striped\" = striped_col, \"spotted\" = spotted_col, \"none\" = none_col)) +\n  stat_summary(geom = \"pointrange\", fun = mean, fun.min = function(x) mean(x) - sd(x), fun.max = function(x) mean(x) + sd(x), size = 1) +\n  labs(title = \"Pattern\") +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        axis.title.x = element_blank(),\n        text = element_text(size = 22))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = df, aes(x = weight, y = toxicity)) +\n  geom_point() +\n  # geom_smooth(method = \"lm\") +\n  labs(title = \"Weight\") +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        axis.title.x = element_blank(),\n        text = element_text(size = 22))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = df, aes(x = weight, y = toxicity, color = color)) +\n  geom_point() +\n  scale_color_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Weight\")"
  },
  {
    "objectID": "lecture/lecture-08_2023-05-22.html#model",
    "href": "lecture/lecture-08_2023-05-22.html#model",
    "title": "Lecture 08 figures",
    "section": "model",
    "text": "model\n\n\nCode\nmodel &lt;- lm(toxicity ~ weight + color + pattern, data = df)\nsimulateResiduals(model, plot = TRUE)\n\n\n\n\n\n\n\n\n\nObject of Class DHARMa with simulated residuals based on 250 simulations with refit = FALSE . See ?DHARMa::simulateResiduals for help. \n \nScaled residual values: 0.208 0.608 0.196 0.468 0.744 0.792 0.908 0.792 0.992 0.256 0.324 0.768 0.468 0.32 0.204 0.908 0.288 0.76 0.156 0.104 ..."
  },
  {
    "objectID": "lecture/lecture-08_2023-05-22.html#diagnostics",
    "href": "lecture/lecture-08_2023-05-22.html#diagnostics",
    "title": "Lecture 08 figures",
    "section": "diagnostics",
    "text": "diagnostics\n\n\nCode\npar(mfrow = c(2, 2))\nplot(model)"
  },
  {
    "objectID": "lecture/lecture-08_2023-05-22.html#model-summary",
    "href": "lecture/lecture-08_2023-05-22.html#model-summary",
    "title": "Lecture 08 figures",
    "section": "model summary",
    "text": "model summary\n\n\nCode\n# F-statistic: 31.05 on 5 and 81 DF,  p-value: &lt; 2.2e-16\n# total SSE - SSE of residuals divided by degrees of freedom\ntotalSSE &lt;- 6.932+140.09+21.63\ntotaldf &lt;- 1+2+2\nerrorSSE &lt;- 88\nmodel_fstat &lt;- (totalSSE/5)/(errorSSE/81) \nmodel_fstat\n\n\n[1] 31.0473\n\n\nCode\n# for a single coefficient\nweightMS &lt;- 6.932\nweightdf &lt;- 1\nerrorMS &lt;- 1.086\nfvalweight &lt;- (weightMS/weightdf)/errorMS\nfvalweight\n\n\n[1] 6.383057\n\n\nCode\ncolorMS &lt;- 70.045\ncolordf &lt;- 2\nfvalcolor &lt;- (colorMS/colordf)/errorMS\nfvalcolor\n\n\n[1] 32.24908\n\n\nCode\n# residual mean sq = 1.086 (denominator)\n# equation: t = 5.5 - 0.74*W - 0.97*green + 2.1*red + 0.85*spotted + 1.2*striped\n\n\n\n\nCode\nmodel_summary &lt;- summary(model)\n\nAnova(model)\n\n\nAnova Table (Type II tests)\n\nResponse: toxicity\n           Sum Sq Df F value    Pr(&gt;F)    \nweight      1.547  1  1.4194     0.237    \ncolor     119.288  2 54.7107 9.229e-16 ***\npattern    44.843  2 20.5669 5.981e-08 ***\nResiduals  88.304 81                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmodel.sel(model)\n\n\nModel selection table \n      (Intrc) color pttrn weght df   logLik  AICc delta\nmodel   4.045     +     +     1  7 -124.095 263.6     0\nModels ranked by AICc(x) \n\n\n\\[\n\\hat{y}_h \\pm t_{(1-\\alpha/2, n-2)}*\\sqrt{MSE*(\\frac{1}{n}+\\frac{(x_h-\\bar{x})^2}{\\sum(x_i-\\bar{x})^2})}\n\\]\n\\[\nMSE = \\frac{\\sum(y_i-\\hat{y})^2}{n}\n\\]\n\n\nCode\ntidy(model, conf.int = TRUE, conf.level = 0.95)\n\n\n# A tibble: 6 × 7\n  term           estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)       4.04      1.26       3.21 1.92e- 3    1.54      6.55 \n2 weight           -0.504     0.423     -1.19 2.37e- 1   -1.35      0.338\n3 colorgreen       -0.289     0.267     -1.08 2.82e- 1   -0.821     0.243\n4 colorred          2.59      0.290      8.91 1.17e-13    2.01      3.17 \n5 patternspotted    0.952     0.303      3.14 2.34e- 3    0.349     1.55 \n6 patternstriped    1.70      0.264      6.41 8.92e- 9    1.17      2.22 \n\n\n\n\nCode\nc(\"lower\" = model_summary$coef[2,1] - qt(0.975, df = model_summary$df[2]) * model_summary$coef[2, 2],\n  \"upper\" = model_summary$coef[2,1] + qt(0.975, df = model_summary$df[2]) * model_summary$coef[2, 2])\n\n\n     lower      upper \n-1.3451604  0.3375674 \n\n\nConfidence interval for a single coefficient: in words: estimate plus or minus the t-value at your confidence level * standard error"
  },
  {
    "objectID": "lecture/lecture-03_2023-04-17.html",
    "href": "lecture/lecture-03_2023-04-17.html",
    "title": "Lecture 03 figures",
    "section": "",
    "text": "0. set up\n\n\nCode\n# cleaning\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\nCode\n# visualization\nlibrary(showtext)\n\n\nLoading required package: sysfonts\nLoading required package: showtextdb\n\n\nCode\nfont_add_google(\"Lato\", \"Lato\")\nshowtext_auto()\n\n\n\n\n1. 68-95-99.7 rule\n\n\nCode\nlabels &lt;- c(\n  \"\", \"\\U03BC - 3\\U03C3\", \"\\U03BC - 2\\U03C3\", \"\\U03BC - \\U03C3\", \"\\U03BC\", \"\\U03BC + \\U03C3\", \"\\U03BC + 2\\U03C3\", \"\\U03BC + 3\\U03C3\", \"\"\n)\n\nggplot(data.frame(x = -4:4), aes(x)) +\n  geom_linerange(x = 1, ymin = 0, ymax = 0.24) +\n  geom_linerange(x = -1, ymin = 0, ymax = 0.24) +\n  geom_linerange(x = 2, ymin = 0, ymax = 0.055) +\n  geom_linerange(x = -2, ymin = 0, ymax = 0.055) +\n  geom_linerange(x = 3, ymin = 0, ymax = 0.005) +\n  geom_linerange(x = -3, ymin = 0, ymax = 0.005) +\n  geom_linerange(x = 0, ymin = 0, ymax = 0.399) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1.5, color = \"darkorange\") +\n  scale_x_continuous(labels = labels, breaks = seq(-4, 4, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.41)) +\n  labs(x = \"\") +\n  theme_classic() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 22),\n        axis.line.y = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks = element_blank()) \n\n\n\n\n\n\n\n\n\n\n\n2. central limit theorem\n\n\nCode\n# randomly select 10000 numbers from a uniform distribution for the population\nuniform &lt;- runif(10000, min = 2, max = 8)\n\n# make a histogram for the population\nuniformdf &lt;- as.data.frame(uniform)\n\nggplot(uniformdf, aes(x = uniform)) +\n  geom_histogram(breaks = seq(2, 8, length.out = 41), fill = \"firebrick\", alpha = 0.7, color = \"firebrick\") +\n  geom_vline(xintercept = mean(uniform), linewidth = 2) +\n  annotate(\"text\", x = 4, y = 290, label = \"mean = 4.967\", size = 10) +\n  scale_x_continuous(breaks = seq(from = 2, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 305)) +\n  labs(x = \"Continuous value\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# for() loop to \nstore2 &lt;- c()\nstore5 &lt;- c()\nstore15 &lt;- c()\nstore30 &lt;- c()\nstore50 &lt;- c()\n\nfor(i in 1:100) {\n  \n  store2[i] &lt;- mean(sample(uniform, 2, replace = FALSE))\n\n}\n\n\nfor(i in 1:100) {\n  \n  store5[i] &lt;- mean(sample(uniform, 5, replace = FALSE))\n\n}\nfor(i in 1:100) {\n  \n  store15[i] &lt;- mean(sample(uniform, 15, replace = FALSE))\n\n}\n\nfor(i in 1:100) {\n  \n  store30[i] &lt;- mean(sample(uniform, 30, replace = FALSE))\n\n}\n\nfor(i in 1:100) {\n  \n  store50[i] &lt;- mean(sample(uniform, 50, replace = FALSE))\n\n}\n\ndf &lt;- cbind(store2, store5, store15, store30, store50) %&gt;% \n  as.data.frame()\n  \nggplot(df) +\n  geom_histogram(aes(x = store2), bins = 10, alpha = 0.7, fill = \"chocolate1\", color = \"chocolate1\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store2)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store5), bins = 10, alpha = 0.7, fill = \"blue3\", color = \"blue3\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store5)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store15), bins = 12, alpha = 0.7, fill = \"darkorchid4\", color = \"darkorchid4\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store15)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store30), bins = 12, alpha = 0.7, fill = \"lightseagreen\", color = \"lightseagreen\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store30)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store50), bins = 12, alpha = 0.7, fill = \"violetred3\", color = \"violetred3\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store50)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\n\n\n3. z- vs t-distribution\n\n\nCode\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1, color = \"darkorange\") +\n  annotate(\"text\", x = 2.5, y = 0.4, label = \"normal\", color = \"darkorange\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#856F33\") +\n  annotate(\"text\", x = 3, y = 0.32, label = \"t-distribution (small n)\", color = \"#856F33\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 10), linewidth = 1, color = \"#56E9E7\") +\n  annotate(\"text\", x = 3, y = 0.37, label = \"t-distribution (large n)\", color = \"#56E9E7\", size = 6) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\n\n\n3. math notation\n\\[\nSE_{\\bar{x}} = \\frac{s}{\\sqrt{n}}\n\\]\n\n\n4. qqplot examples\n\n\nCode\nas_tibble(nhtemp) %&gt;% \n  ggplot(aes(x = x)) +\n  geom_histogram(breaks = seq(47, 55, length.out = 9), fill = \"turquoise3\", color = \"#000000\") +\n  scale_x_continuous(breaks = seq(47, 55, length.out = 9), expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 23)) +\n  theme_classic() +\n  labs(x = \"Bins\", y = \"Count\") +\n    theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"),\n        plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\n\n\n\n\n\n\n\n\nCode\nggplot(as_tibble(nhtemp)) +\n  stat_qq(aes(sample = x), color = \"turquoise3\", size = 3) +\n  theme_classic() +\n  labs(x = \"Theoretical\", y = \"Sample\") +\n      theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"),\n        plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\n\n\n\n\nCode\nas_tibble(sunspots) %&gt;% \n  ggplot(aes(x = x)) +\n  geom_histogram(breaks = round(seq(0, 260, length.out = 30)), fill = \"tomato2\", color = \"#000000\") +\n  scale_x_continuous(breaks = round(seq(0, 260, length.out = 30)), expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 480)) +\n  theme_classic() +\n  labs(x = \"Bins\", y = \"Count\") +\n    theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"),\n        plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\n\n\n\n\n\n\n\n\nCode\nggplot(as_tibble(sunspots)) +\n  stat_qq(aes(sample = x), color = \"tomato2\", size = 3) +\n  theme_classic() +\n  labs(x = \"Theoretical\", y = \"Sample\") +\n      theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"),\n        plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{bui2023,\n  author = {Bui, An},\n  title = {Lecture 03 Figures},\n  date = {2023-04-17},\n  url = {https://an-bui.github.io/ES-193DS-W23/lecture/lecture-03_2023-04-17.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2023. “Lecture 03 Figures.” April 17, 2023. https://an-bui.github.io/ES-193DS-W23/lecture/lecture-03_2023-04-17.html."
  },
  {
    "objectID": "lecture/lecture-06_2023-05-08.html",
    "href": "lecture/lecture-06_2023-05-08.html",
    "title": "Lecture 06 figures",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(showtext)\nlibrary(car)\nfont_add_google(\"Lato\", \"Lato\")\nshowtext_auto()\nlibrary(patchwork)"
  },
  {
    "objectID": "lecture/lecture-06_2023-05-08.html#chi-square",
    "href": "lecture/lecture-06_2023-05-08.html#chi-square",
    "title": "Lecture 06 figures",
    "section": "Chi-square",
    "text": "Chi-square\n\ntest statistic:\n\\[\n\\chi^2 = \\Sigma\\frac{(O-E)^2}{E}\n\\] ### degrees of freedom \\[\ndf = (number\\;of\\;rows - 1) * (number\\;of\\;columns - 1)\n\\]\n\n\nexpected counts:\n\\[\nexpected = \\frac{row\\;total * column\\;total}{table\\;total}\n\\]\n\n\nexpected counts example from lecture\n\\[\n\\frac{126 * 118}{315} = 47.2\n\\]\n\n\ntest statistic calculation example from lecture\n\\[\n\\begin{align}\n\\chi^2 &= \\Sigma\\frac{(O-E)^2}{E} \\\\\n\\chi^2 &= \\frac{55-47.2}{47.2}+...+\\frac{45-31.9}{31.9} \\\\\n&= 15.276\n\\end{align}\n\\]\n\n\nexample code\n\n\nCode\n# create matrix\nsurvey &lt;- tribble(\n  ~distance, ~trails, ~dog_access, ~wildlife_habitat,\n  \"walking_distance\", 55, 38, 33,\n  \"driving_distance\", 41, 25, 29,\n  \"out_of_town\", 22, 27, 45\n) %&gt;% \n  column_to_rownames(\"distance\")\n\nsurvey\n\n\n                 trails dog_access wildlife_habitat\nwalking_distance     55         38               33\ndriving_distance     41         25               29\nout_of_town          22         27               45\n\n\nCode\n# calculate proportions\nsurvey_summary &lt;- tribble(\n  ~distance, ~trails, ~dog_access, ~wildlife_habitat,\n  \"walking_distance\", 55, 38, 33,\n  \"driving_distance\", 41, 25, 29,\n  \"out_of_town\", 22, 27, 45\n) %&gt;% \n  pivot_longer(cols = trails:wildlife_habitat, names_to = \"responses\", values_to = \"counts\") %&gt;% \n  group_by(distance) %&gt;% \n  mutate(sum = sum(counts)) %&gt;% \n  ungroup() %&gt;% \n  mutate(prop = counts/sum)\n  \n# do chi-square\nchisq.test(survey)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  survey\nX-squared = 15.276, df = 4, p-value = 0.004162\n\n\nCode\n# get expected matrix\nchisq.test(survey)$expected\n\n\n                  trails dog_access wildlife_habitat\nwalking_distance 47.2000   36.00000         42.80000\ndriving_distance 35.5873   27.14286         32.26984\nout_of_town      35.2127   26.85714         31.93016"
  },
  {
    "objectID": "lecture/lecture-06_2023-05-08.html#anova-variance-figure",
    "href": "lecture/lecture-06_2023-05-08.html#anova-variance-figure",
    "title": "Lecture 06 figures",
    "section": "ANOVA variance figure:",
    "text": "ANOVA variance figure:\n\n\nCode\ncol1 &lt;- \"cornflowerblue\"\ncol2 &lt;- \"orange\"\ncol3 &lt;- \"darkgreen\"\n\nggplot(data.frame(x = 0:22), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 10, sd = 2), linewidth = 1, col = col1) + \n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 8, sd = 2), linewidth = 1, col = col2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 15, sd = 2), linewidth = 1, col = col3) +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank(),\n        panel.border = element_blank(),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture-06_2023-05-08.html#anova-with-palmer-penguins",
    "href": "lecture/lecture-06_2023-05-08.html#anova-with-palmer-penguins",
    "title": "Lecture 06 figures",
    "section": "ANOVA with palmer penguins",
    "text": "ANOVA with palmer penguins\n\n\nCode\n# Adelie: 10\n# Chinstrap: 8\n# Gentoo: 10\n\nadelie &lt;- penguins %&gt;% \n  filter(species == \"Adelie\")\n\nadelie_hist &lt;- ggplot(data = adelie, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 10, fill = col1, color = col1, alpha = 0.8) +\n  labs(x = \"Bill length (mm)\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\")) \n\nadelie_qq &lt;- ggplot(data = adelie, aes(sample = bill_length_mm)) +\n  stat_qq_line(linewidth = 1) +\n  stat_qq(col = col1) +\n  labs(x = \"Theoretical\", y = \"Sample\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\")) \n\nshapiro.test(adelie$bill_length_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  adelie$bill_length_mm\nW = 0.99336, p-value = 0.7166\n\n\nCode\nchinstrap &lt;- penguins %&gt;% \n  filter(species == \"Chinstrap\")\n\nchinstrap_hist &lt;- ggplot(data = chinstrap, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 10, fill = col2, color = col2, alpha = 0.8) +\n  labs(x = \"Bill length (mm)\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\")) \n\nchinstrap_qq &lt;- ggplot(data = chinstrap, aes(sample = bill_length_mm)) +\n  stat_qq_line(linewidth = 1) +\n  stat_qq(col = col2) +\n  labs(x = \"Theoretical\", y = \"Sample\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\")) \n\nshapiro.test(chinstrap$bill_length_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  chinstrap$bill_length_mm\nW = 0.97525, p-value = 0.1941\n\n\nCode\ngentoo &lt;- penguins %&gt;% \n  filter(species == \"Gentoo\")\n\ngentoo_hist &lt;- ggplot(data = gentoo, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 10, fill = col3, color = col3, alpha = 0.8) +\n  labs(x = \"Bill length (mm)\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\")) \n\ngentoo_qq &lt;- ggplot(data = gentoo, aes(sample = bill_length_mm)) +\n  stat_qq_line(linewidth = 1) +\n  stat_qq(col = col3) +\n  labs(x = \"Theoretical\", y = \"Sample\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\")) \n\n\n(adelie_hist + adelie_qq) / (chinstrap_hist + chinstrap_qq) / (gentoo_hist + gentoo_qq)\n\n\nWarning: Removed 1 rows containing non-finite values (`stat_bin()`).\n\n\nWarning: Removed 1 rows containing non-finite values (`stat_qq_line()`).\n\n\nWarning: Removed 1 rows containing non-finite values (`stat_qq()`).\n\n\nWarning: Removed 1 rows containing non-finite values (`stat_bin()`).\n\n\nWarning: Removed 1 rows containing non-finite values (`stat_qq_line()`).\n\n\nWarning: Removed 1 rows containing non-finite values (`stat_qq()`).\n\n\n\n\n\n\n\n\n\nCode\nshapiro.test(gentoo$bill_length_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  gentoo$bill_length_mm\nW = 0.97272, p-value = 0.01349\n\n\nCode\nleveneTest(bill_length_mm ~ species, data = penguins)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)\ngroup   2  2.2425 0.1078\n      339               \n\n\nCode\npenguins_anova &lt;- aov(bill_length_mm ~ species, data = penguins)\npenguins_anova\n\n\nCall:\n   aov(formula = bill_length_mm ~ species, data = penguins)\n\nTerms:\n                 species Residuals\nSum of Squares  7194.317  2969.888\nDeg. of Freedom        2       339\n\nResidual standard error: 2.959853\nEstimated effects may be unbalanced\n2 observations deleted due to missingness\n\n\nCode\nsummary(penguins_anova)\n\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nspecies       2   7194    3597   410.6 &lt;2e-16 ***\nResiduals   339   2970       9                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2 observations deleted due to missingness\n\n\nCode\nTukeyHSD(penguins_anova)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = bill_length_mm ~ species, data = penguins)\n\n$species\n                      diff       lwr        upr     p adj\nChinstrap-Adelie 10.042433  9.024859 11.0600064 0.0000000\nGentoo-Adelie     8.713487  7.867194  9.5597807 0.0000000\nGentoo-Chinstrap -1.328945 -2.381868 -0.2760231 0.0088993"
  },
  {
    "objectID": "lecture/lecture-06_2023-05-08.html#anova-information",
    "href": "lecture/lecture-06_2023-05-08.html#anova-information",
    "title": "Lecture 06 figures",
    "section": "ANOVA information",
    "text": "ANOVA information\n\nSum of squares\n\namong groups\n\\[\n\\sum_{i=1}^{k}\\sum_{j=1}^{n}(\\bar{x}_i - \\bar{x})^2\n\\]\n\n\nwithin groups\n\\[\n\\sum_{i=1}^{k}\\sum_{j=1}^{n}({x}_{ij} - \\bar{x}_i)^2\n\\]\n\n\ntotal\n\\[\n\\sum_{i=1}^{k}\\sum_{j=1}^{n}({x}_{ij} - \\bar{x})^2\n\\]\n\n\n\nMean squares\n\namong groups\n\\[\n\\frac{SS_{among\\;group}}{k-1}\n\\] #### within group\n\\[\n\\frac{SS_{within\\;group}}{n-k}\n\\] #### total\n\\[\n\\frac{SS_{total}}{kn-1}\n\\]\n\n\n\nF-ratio\n\\[\n\\frac{MS_{among\\;group}}{MS_{within\\;group}}\n\\]"
  },
  {
    "objectID": "lecture/lecture-06_2023-05-08.html#penguins-visualization",
    "href": "lecture/lecture-06_2023-05-08.html#penguins-visualization",
    "title": "Lecture 06 figures",
    "section": "penguins visualization",
    "text": "penguins visualization\n\n\nCode\nggplot(data = penguins, aes(x = species, y = bill_length_mm, fill = species)) +\n  geom_violin(alpha = 0.6) +\n  geom_boxplot(width = 0.2) +\n  scale_fill_manual(values = c(col1, col2, col3)) +\n  labs(x = \"Species\", y = \"Bill length (mm)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"),\n        legend.position = \"none\") \n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "lecture/lecture-06_2023-05-08.html#test-statistic-1",
    "href": "lecture/lecture-06_2023-05-08.html#test-statistic-1",
    "title": "Lecture 06 figures",
    "section": "test statistic",
    "text": "test statistic\n\\[\nH = \\frac{12}{n(n+1)}\\sum_{i = 1}^{k}\\frac{R^2_i}{n_i}-3(n+1)\n\\]"
  },
  {
    "objectID": "lecture/lecture-06_2023-05-08.html#eta-squared",
    "href": "lecture/lecture-06_2023-05-08.html#eta-squared",
    "title": "Lecture 06 figures",
    "section": "eta squared",
    "text": "eta squared\n\\[\n\\eta^2 = \\frac{H - k + 1}{n - k}\n\\]"
  },
  {
    "objectID": "lecture/lecture-05_2023-05-01.html",
    "href": "lecture/lecture-05_2023-05-01.html",
    "title": "Lecture 05 figures",
    "section": "",
    "text": "test statistic for unequal variances (welch’s)\n\\[\nt_s = \\frac{\\bar{x}_A - \\bar{x}_B}{\\sqrt{\\frac{s^2_A}{n_A} + \\frac{s^2_B}{n_B}}}\n\\]\ndegrees of freedom for unequal variances (welch’s)\n\\[\ndf = \\frac{(\\frac{s^2_A}{n_A} + \\frac{s^2_B}{n_B})^2}{\\frac{(s^2_A/n_A)^2}{n_A - 1} + \\frac{(s^2_B/n_B)^2}{n_B - 1}}\n\\]\ntest statistic for equal variances (student’s t)\n\\[\nt_s = \\frac{\\bar{x}_A - \\bar{x}_B}{s_p\\sqrt{\\frac{1}{n_A} + \\frac{1}{n_B}}}\n\\]\ntest statistic for paired t-test\n\\[\nt_s = \\frac{\\bar{x}_d - \\mu_0}{s_d - \\sqrt{n}}\n\\]\ntest statistic for F test \\[\nF =  \\frac{s^2_A}{s^2_B}\n\\]\ndifferences in variances\n\n\nCode\nlibrary(tidyverse)\nlibrary(patchwork)\n\nsmall &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 3), color = \"#00A38D\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nbig &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 0.5), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 0.5), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 3), color = \"#00A38D\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.8)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nunequal &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 0.5), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 3), color = \"#00A38D\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.8)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nsmall/big/unequal\n\n\n\n\n\n\n\n\n\ndemonstration of power analysis:\n\n\nCode\nlibrary(pwr)\n\npwr.t.test(n = NULL, d = 0.5, sig.level = 0.05, power = 0.95)\n\n\n\n     Two-sample t test power calculation \n\n              n = 104.9279\n              d = 0.5\n      sig.level = 0.05\n          power = 0.95\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nCode\npwr.t.test(n = NULL, d = 0.7, sig.level = 0.05, power = 0.80)\n\n\n\n     Two-sample t test power calculation \n\n              n = 33.02457\n              d = 0.7\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nU statistic: \\[\n\\begin{align}\nU_1 &= \\Sigma R_1 - n_1(n_1 + 1)/2 = 17 - 5(5+1)/2 = 2 \\\\\nU_2 &= \\Sigma R_2 - n_2(n_2 + 1)/2 = 38 - 5(5+1)/2 = 23\n\\end{align}\n\\]\n\n\nCode\nSample1 &lt;- c(1.1, 2.4, 1.8, 0.4, 1.6)\nSample2 &lt;- c(5.4, 3.1, 2.3, 1.9, 4.2)\nwilcox.test(Sample1, Sample2)\n\n\n\n    Wilcoxon rank sum exact test\n\ndata:  Sample1 and Sample2\nW = 2, p-value = 0.03175\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nCode\n# for a comparison of one group against a theoretical median\nwilcox.test(SampleA, mu = theoretical)\n\n# for a comparison of two groups\nwilcox.test(SampleA, SampleB, paired = TRUE)\n\n\nbalanced design using Student’s t:\n\\[\n\\begin{align}\nSE_{\\bar{x}_A-\\bar{x}_B} &= s_p\\sqrt{\\frac{1}{n_A} + \\frac{1}{n_B}} \\\\\nScenario 1 &: s_p\\sqrt{\\frac{1}{5} + \\frac{1}{25}} = s_p*0.49 \\\\\nScenario 2 &: s_p\\sqrt{\\frac{1}{15} + \\frac{1}{15}} = s_p*0.37\n\\end{align}\n\\]\n\n\n\nCitationBibTeX citation:@online{bui2023,\n  author = {Bui, An},\n  title = {Lecture 05 Figures},\n  date = {2023-05-01},\n  url = {https://an-bui.github.io/ES-193DS-W23/lecture/lecture-05_2023-05-01.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2023. “Lecture 05 Figures.” May 1, 2023. https://an-bui.github.io/ES-193DS-W23/lecture/lecture-05_2023-05-01.html."
  },
  {
    "objectID": "lecture/lecture-04_2023-04-24.html",
    "href": "lecture/lecture-04_2023-04-24.html",
    "title": "Lecture 04 figures",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\nCode\n# visualization\nlibrary(showtext)\n\n\nLoading required package: sysfonts\nLoading required package: showtextdb\n\n\nCode\nfont_add_google(\"Lato\", \"Lato\")\nshowtext_auto()\n\n# panels together\nlibrary(patchwork)\n\n# cohen's d\nlibrary(effsize)"
  },
  {
    "objectID": "lecture/lecture-04_2023-04-24.html#random-numbers-from-t-distribution",
    "href": "lecture/lecture-04_2023-04-24.html#random-numbers-from-t-distribution",
    "title": "Lecture 04 figures",
    "section": "random numbers from t-distribution",
    "text": "random numbers from t-distribution\n\n\nCode\nset.seed(7)\n# acorns &lt;- rt(n = 41, df = 40, ncp = 2.5) \nacorns &lt;- rnorm(n = 41, mean = 2, sd = 1)"
  },
  {
    "objectID": "lecture/lecture-04_2023-04-24.html#histogram",
    "href": "lecture/lecture-04_2023-04-24.html#histogram",
    "title": "Lecture 04 figures",
    "section": "histogram",
    "text": "histogram\n\n\nCode\nhist &lt;- enframe(acorns) %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 7, fill = \"cornflowerblue\", color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 11.5), breaks = c(0, 3, 6, 9, 12)) +\n  theme_classic() +\n  labs(x = \"Acorn mass (g)\", y = \"Count\")"
  },
  {
    "objectID": "lecture/lecture-04_2023-04-24.html#qq-plot",
    "href": "lecture/lecture-04_2023-04-24.html#qq-plot",
    "title": "Lecture 04 figures",
    "section": "qq plot",
    "text": "qq plot\n\n\nCode\nqq &lt;- enframe(acorns) %&gt;% \n  ggplot(aes(sample = value)) +\n  stat_qq_line(aes(sample = value)) +\n  stat_qq(aes(sample = value), color = \"cornflowerblue\", size = 3) +\n  theme_classic() +\n  labs(x = \"Theoretical quantiles\", y = \"Sample quantiles\")\n\n\n\n\nCode\nhist + qq"
  },
  {
    "objectID": "lecture/lecture-04_2023-04-24.html#calculating-a-critical-value",
    "href": "lecture/lecture-04_2023-04-24.html#calculating-a-critical-value",
    "title": "Lecture 04 figures",
    "section": "calculating a critical value",
    "text": "calculating a critical value\n\n\nCode\nqt(p = .05/2, df = 40)\n\n\n[1] -2.021075"
  },
  {
    "objectID": "lecture/lecture-04_2023-04-24.html#calculating-t-score",
    "href": "lecture/lecture-04_2023-04-24.html#calculating-t-score",
    "title": "Lecture 04 figures",
    "section": "calculating t-score",
    "text": "calculating t-score\n\n\nCode\n# population mean\nmu0 &lt;- 2\n\n# number of observations\nn &lt;- 41\n\n# sample mean\nxbar &lt;- mean(acorns)\n\n# sample standard deviation\ns &lt;- sd(acorns)\n\n# sample standard error\nse &lt;- s/sqrt(n)\n\n# degrees of freedom\ndf &lt;- n - 1\n\n# t-score\nt &lt;- (xbar-mu0)/se\n\nt\n\n\n[1] 1.803471\n\n\n\\[\nt_s = \\frac{\\bar{x} - \\mu}{s/\\sqrt{n}} = \\frac{2.29 - 2}{1.04/\\sqrt{41}} = 1.8\n\\] ## visual representation of sample t-statistic vs t-critical\n\n\nCode\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(1.8, 5), fill = \"darkgrey\") +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(-5, -1.8), fill = \"darkgrey\") +\n  geom_linerange(aes(x = 1.8, ymin = 0, ymax = 0.075), linewidth = 1, lty = 2, color = \"#000000\") +\n  geom_linerange(aes(x = -1.8, ymin = 0, ymax = 0.075), linewidth = 1, lty = 2, color = \"#000000\") +\n  \n  geom_linerange(aes(x = 2.021, ymin = 0, ymax = 0.075), linewidth = 1, lty = 3, color = \"#FFFFFF\") +\n  geom_linerange(aes(x = -2.021, ymin = 0, ymax = 0.075), linewidth = 1, lty = 3, color = \"#FFFFFF\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  theme_void() +\n  theme(panel.grid = element_blank(),\n        plot.margin = unit(c(1, 0, 0, 0), \"cm\"))"
  },
  {
    "objectID": "lecture/lecture-04_2023-04-24.html#manually-calculating-p-value",
    "href": "lecture/lecture-04_2023-04-24.html#manually-calculating-p-value",
    "title": "Lecture 04 figures",
    "section": "manually calculating p-value",
    "text": "manually calculating p-value\n\n\nCode\n# two-tailed: multiply probability by 2\n# lower = FALSE: probability of the value being more than t\n2*pt(t, df, lower = FALSE)\n\n\n[1] 0.07885024"
  },
  {
    "objectID": "lecture/lecture-04_2023-04-24.html#doing-a-t-test",
    "href": "lecture/lecture-04_2023-04-24.html#doing-a-t-test",
    "title": "Lecture 04 figures",
    "section": "doing a t-test",
    "text": "doing a t-test\n\n\nCode\nt.test(acorns, mu = 2)\n\n\n\n    One Sample t-test\n\ndata:  acorns\nt = 1.8035, df = 40, p-value = 0.07885\nalternative hypothesis: true mean is not equal to 2\n95 percent confidence interval:\n 1.964535 2.623323\nsample estimates:\nmean of x \n 2.293929"
  },
  {
    "objectID": "lecture/lecture-04_2023-04-24.html#same-differences-in-means-different-sd",
    "href": "lecture/lecture-04_2023-04-24.html#same-differences-in-means-different-sd",
    "title": "Lecture 04 figures",
    "section": "same differences in means, different SD",
    "text": "same differences in means, different SD\n\n\nCode\nsmall &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 3), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nbig &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 0.5), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 0.5), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 3), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.8)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nsmall / big"
  },
  {
    "objectID": "lecture/lecture-07_2023-05-15.html",
    "href": "lecture/lecture-07_2023-05-15.html",
    "title": "Lecture 07 figures",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(showtext)\nlibrary(car)\nfont_add_google(\"Lato\", \"Lato\")\nshowtext_auto()\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(performance)\nlibrary(broom)\nlibrary(flextable)"
  },
  {
    "objectID": "lecture/lecture-07_2023-05-15.html#generating-data-and-model",
    "href": "lecture/lecture-07_2023-05-15.html#generating-data-and-model",
    "title": "Lecture 07 figures",
    "section": "generating data and model",
    "text": "generating data and model\n\n\nCode\nx_lm &lt;- seq(from = 1, to = 30, by = 1)\n\nset.seed(666)\ny_lm &lt;- round(runif(length(x_lm), min = 1, max = 1.5), 1)*x_lm + runif(length(x_lm), min = 1, max = 10)\n\ndf_lm &lt;- cbind(\n  x = x_lm,\n  y = y_lm\n) %&gt;% \n  as_tibble() %&gt;% \n  mutate(outlier = case_when(\n    rownames(.) %in% c(23, 27, 28) ~ \"outlier\",\n    TRUE ~ \"ok\"\n  ))"
  },
  {
    "objectID": "lecture/lecture-07_2023-05-15.html#model-summaries",
    "href": "lecture/lecture-07_2023-05-15.html#model-summaries",
    "title": "Lecture 07 figures",
    "section": "model summaries",
    "text": "model summaries\n\n\nCode\nmodel1 &lt;- lm(y ~ x, data = df_lm)\nmodel1\n\n\n\nCall:\nlm(formula = y ~ x, data = df_lm)\n\nCoefficients:\n(Intercept)            x  \n      6.404        1.156  \n\n\nCode\nsummary(model1)\n\n\n\nCall:\nlm(formula = y ~ x, data = df_lm)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.323 -1.020  0.002  2.393  6.645 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   6.4043     1.3421   4.772 5.17e-05 ***\nx             1.1561     0.0756  15.293 4.02e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.584 on 28 degrees of freedom\nMultiple R-squared:  0.8931,    Adjusted R-squared:  0.8893 \nF-statistic: 233.9 on 1 and 28 DF,  p-value: 4.021e-15\n\n\nCode\nanova(model1)\n\n\nAnalysis of Variance Table\n\nResponse: y\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nx          1 3003.92 3003.92  233.87 4.021e-15 ***\nResiduals 28  359.64   12.84                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmodel1_nooutliers &lt;- lm(y ~ x, data = df_lm %&gt;% filter(outlier == \"ok\"))\nsummary(model1_nooutliers)\n\n\n\nCall:\nlm(formula = y ~ x, data = df_lm %&gt;% filter(outlier == \"ok\"))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.6611 -1.2596 -0.5039  1.6229  4.7197 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.12314    1.02352   5.982 3.02e-06 ***\nx            1.20027    0.06177  19.431  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.668 on 25 degrees of freedom\nMultiple R-squared:  0.9379,    Adjusted R-squared:  0.9354 \nF-statistic: 377.6 on 1 and 25 DF,  p-value: &lt; 2.2e-16\n\n\n\\[\n\\begin{align}\nR^2 &= 1 - \\frac{SS_{residuals}}{SS_{total}} \\\\\n&= 1 - \\frac{359.64}{359.64 + 3003.92} \\\\\n&= 0.8931\n\\end{align}\n\\]\n\n\nCode\n# if using quarto, don't label chunk with a table... so weird\nanova_tbl &lt;- broom::tidy(anova(model1)) %&gt;% \n  mutate(across(where(is.numeric), ~ round(.x, digits = 2))) %&gt;% \n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\"\n  )) \n\nflextable(anova_tbl) %&gt;% \n  set_header_labels(term = \"Term\", \n                    df = \"Degrees of freedom\", \n                    sumsq = \"Sum of squares\", \n                    meansq = \"Mean squares\", \n                    statistic = \"F-statistic\", \n                    p.value = \"p-value\") %&gt;% \n  set_table_properties(layout = \"autofit\", width = 0.8)\n\n\nTermDegrees of freedomSum of squaresMean squaresF-statisticp-valuex13,003.923,003.92233.87&lt; 0.001Residuals28359.6412.84"
  },
  {
    "objectID": "lecture/lecture-07_2023-05-15.html#model-plots",
    "href": "lecture/lecture-07_2023-05-15.html#model-plots",
    "title": "Lecture 07 figures",
    "section": "model plots",
    "text": "model plots\n\n\nCode\nmodel1_pred &lt;- ggpredict(model1, terms = ~ x)\nmodel1_nooutliers_pred &lt;- ggpredict(model1_nooutliers, terms = ~ x)\n\nmodel1_plot_noline &lt;- ggplot(data = df_lm, aes(x = x, y = y)) +\n  geom_point(shape = 19, size = 3, color = \"cornflowerblue\") +\n  theme_classic() +\n  theme(text = element_text(size = 14))\n\nmodel1_plot &lt;- ggplot(data = df_lm, aes(x = x, y = y)) +\n  geom_point(shape = 19, size = 3, color = \"cornflowerblue\") +\n  geom_line(data = model1_pred, aes(x = x, y = predicted), linewidth = 1) +\n  theme_classic() +\n  theme(text = element_text(size = 14))\n\nmodel1_plot_nooutliers &lt;- ggplot(data = df_lm %&gt;% filter(outlier == \"ok\"), aes(x = x, y = y)) +\n  geom_point(aes(color = outlier), shape = 19, size = 3) +\n  scale_color_manual(values = c(\"ok\" = \"cornflowerblue\", \"outlier\" = \"red\")) +\n  geom_line(data = model1_nooutliers_pred, aes(x = x, y = predicted), linewidth = 1) +\n  theme_classic() +\n  theme(text = element_text(size = 14),\n        legend.position = \"none\")"
  },
  {
    "objectID": "lecture/lecture-07_2023-05-15.html#model-summary",
    "href": "lecture/lecture-07_2023-05-15.html#model-summary",
    "title": "Lecture 07 figures",
    "section": "model summary",
    "text": "model summary\n\n\nCode\nsummary(lm_ex)\n\n\n\nCall:\nlm(formula = y ~ x, data = df_ex)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1081.0  -843.2  -226.3   660.5  2756.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -9431.3     1111.3  -8.486 3.16e-09 ***\nx             1642.0      156.5  10.492 3.30e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1023 on 28 degrees of freedom\nMultiple R-squared:  0.7972,    Adjusted R-squared:   0.79 \nF-statistic: 110.1 on 1 and 28 DF,  p-value: 3.298e-11"
  },
  {
    "objectID": "lecture/lecture-07_2023-05-15.html#model-plots-1",
    "href": "lecture/lecture-07_2023-05-15.html#model-plots-1",
    "title": "Lecture 07 figures",
    "section": "model plots",
    "text": "model plots\n\n\nCode\nlm_pred &lt;- ggpredict(lm_ex, terms = ~x)\n\nex_plot_noline &lt;- ggplot(df_ex, aes(x= x, y = y)) +\n  geom_point(shape = 17, size = 3, color = \"orange\") +\n  theme_classic() +\n  theme(text = element_text(size = 14))\n\nex_plot &lt;- ggplot(df_ex, aes(x= x, y = y)) +\n  geom_point(shape = 17, size = 3, color = \"orange\") +\n  geom_line(data = lm_pred, aes(x = x, y = predicted), linewidth = 1) +\n  theme_classic() +\n  theme(text = element_text(size = 14))"
  },
  {
    "objectID": "lecture/lecture-07_2023-05-15.html#formula-for-pearsons-correlation",
    "href": "lecture/lecture-07_2023-05-15.html#formula-for-pearsons-correlation",
    "title": "Lecture 07 figures",
    "section": "formula for Pearson’s correlation",
    "text": "formula for Pearson’s correlation\n\\[\nr = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum(x_i-\\bar{x})^2}\\sqrt{\\sum(y_i - \\bar{y})^2}}\n\\]"
  },
  {
    "objectID": "lecture/lecture-07_2023-05-15.html#test-statistic-for-pearson-correlation",
    "href": "lecture/lecture-07_2023-05-15.html#test-statistic-for-pearson-correlation",
    "title": "Lecture 07 figures",
    "section": "test statistic for pearson correlation",
    "text": "test statistic for pearson correlation\n\\[\n\\begin{align}\nt &= \\frac{r\\sqrt{n - 2}}{\\sqrt{1-r^2}} \\\\\ndf &= n -2\n\\end{align}\n\\]\nuses a t-distribution"
  },
  {
    "objectID": "lecture/lecture-07_2023-05-15.html#no-correlation-but-clear-relationship",
    "href": "lecture/lecture-07_2023-05-15.html#no-correlation-but-clear-relationship",
    "title": "Lecture 07 figures",
    "section": "no correlation but clear relationship",
    "text": "no correlation but clear relationship\n\n\nCode\nx_lm &lt;- seq(from = 1, to = 30, length.out = 50)\n# y = a( x – h) 2 + k\ndf_para &lt;- cbind(\n  x = x_lm,\n  y = 0.1*(x_lm - 15)^2 + 12\n) %&gt;% \n  as_tibble()\n\nggplot(df_para, aes(x = x, y = y)) +\n  geom_point(size = 3) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\ncor.test(df_para$x, df_para$y, method = \"pearson\")\n\n\n\n    Pearson's product-moment correlation\n\ndata:  df_para$x and df_para$y\nt = 0.90749, df = 48, p-value = 0.3687\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1540408  0.3939806\nsample estimates:\n      cor \n0.1298756"
  },
  {
    "objectID": "lecture/lecture-01_2023-04-03.html",
    "href": "lecture/lecture-01_2023-04-03.html",
    "title": "Lecture 01 figures",
    "section": "",
    "text": "0. set up\n\n\nCode\n# cleaning\nlibrary(tidyverse)\n\n# visualization\nlibrary(showtext)\nfont_add_google(\"Lato\", \"Lato\")\n\n\n\n\n1. anemone regression example\n\n\nCode\n# number of anemones in a clump\nclump &lt;- seq(from = 1, to = 60, by = 1)\n\n# circumference: anemones can be up to 8 cm long\nset.seed(10)\ncirc &lt;- rnorm(length(clump), mean = seq(from = 1, to = 5, length = length(clump)), sd = 1) \n\n# create a data frame\ndf &lt;- cbind(circ, clump) %&gt;% \n  as.data.frame() \n\n# linear model\nlm(circ ~ clump, data = df) %&gt;% summary()\n\n\n\nCall:\nlm(formula = circ ~ clump, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.88621 -0.62425  0.06147  0.58350  2.17217 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.451168   0.236422   1.908   0.0613 .  \nclump       0.076068   0.006741  11.285 2.91e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9042 on 58 degrees of freedom\nMultiple R-squared:  0.6871,    Adjusted R-squared:  0.6817 \nF-statistic: 127.3 on 1 and 58 DF,  p-value: 2.914e-16\n\n\nCode\nshowtext_auto()\nggplot(df, aes(x = clump, y = circ)) +\n  geom_point(size = 2) +\n  # just using geom smooth for the purposes of visualization\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 2) +\n  labs(x = \"Number of anemones in a colony\", y = \"Circumference (cm)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n2. histogram example\n\n\nCode\nggplot(df, aes(x = circ)) +\n  scale_x_continuous(breaks = seq(from = 0, to = 7, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 19), breaks = seq(from = 0, to = 18, by = 3)) +\n  geom_histogram(breaks = seq(from = 0, to = 7, by = 1), color = \"#000000\", fill = \"lightblue\") +\n  labs(x = \"Anemone circumference (cm)\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\n\n\n3. Probability mass example\n\n\nCode\nggplot(data.frame(x = 1:55), aes(x)) +\n  stat_function(geom = \"bar\", n = 55, fun = dpois, args = list(lambda = 10), fill = \"coral\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.13)) +\n  coord_cartesian(xlim = c(0, 22)) +\n  labs(x = \"Mussel clump size (count)\", y = \"Probability mass\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\n\n\n4. Probability density example\n\n\nCode\nggplot(data.frame(x = 1:20), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 10, sd = 2), linewidth = 1) +\n  stat_function(geom = \"area\", fun = dnorm, args = list(mean = 10, sd = 2), xlim = c(12, 14), fill = \"turquoise3\") +\n  geom_vline(xintercept = 12, lty = 2, color = \"grey\", linewidth = 1) +\n  geom_vline(xintercept = 14, lty = 2, color = \"grey\", linewidth = 1) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.22)) +\n  # coord_cartesian(xlim = c(0, 22)) +\n  labs(x = \"Individual mussel weight (g)\", y = \"Probability density\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\nCode\nshowtext_auto(FALSE)\n\n\n\n\n\n\nCitationBibTeX citation:@online{bui2023,\n  author = {Bui, An},\n  title = {Lecture 01 Figures},\n  date = {2023-04-03},\n  url = {https://an-bui.github.io/ES-193DS-W23/lecture/lecture-01_2023-04-03.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2023. “Lecture 01 Figures.” April 3, 2023. https://an-bui.github.io/ES-193DS-W23/lecture/lecture-01_2023-04-03.html."
  },
  {
    "objectID": "lecture/lecture-10_2023-06-05.html",
    "href": "lecture/lecture-10_2023-06-05.html",
    "title": "Lecture 10 figures",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(showtext)\nfont_add_google(\"Lato\", \"Lato\")\nshowtext_auto()\nlibrary(patchwork)\nlibrary(palmerpenguins)\nlibrary(ggeffects)\nlibrary(equatiomatic)\nlibrary(lmtest)"
  },
  {
    "objectID": "lecture/lecture-10_2023-06-05.html#simple-linear-regression",
    "href": "lecture/lecture-10_2023-06-05.html#simple-linear-regression",
    "title": "Lecture 10 figures",
    "section": "simple linear regression",
    "text": "simple linear regression\n\\[\nE[y_i] = a + bx_i\n\\]\n\\[\nvar[y_i] = s^2\n\\]"
  },
  {
    "objectID": "lecture/lecture-10_2023-06-05.html#generalized-form",
    "href": "lecture/lecture-10_2023-06-05.html#generalized-form",
    "title": "Lecture 10 figures",
    "section": "generalized form:",
    "text": "generalized form:\n\\[\nE[y_i] = a + bx_i\n\\]\n\\[\nvar[y_i] = v(E[y_i])\n\\]"
  },
  {
    "objectID": "lecture/lecture-10_2023-06-05.html#random-component",
    "href": "lecture/lecture-10_2023-06-05.html#random-component",
    "title": "Lecture 10 figures",
    "section": "random component",
    "text": "random component\n\\[\nY_i \\sim N(\\mu_i, \\sigma^2)\n\\]"
  },
  {
    "objectID": "lecture/lecture-10_2023-06-05.html#systematic-component",
    "href": "lecture/lecture-10_2023-06-05.html#systematic-component",
    "title": "Lecture 10 figures",
    "section": "systematic component",
    "text": "systematic component\n\\[\n\\eta_i = \\sum^{p-1}_{n = 0}\\beta_jx_{ij}\n\\]"
  },
  {
    "objectID": "lecture/lecture-10_2023-06-05.html#link",
    "href": "lecture/lecture-10_2023-06-05.html#link",
    "title": "Lecture 10 figures",
    "section": "link",
    "text": "link\n\\[\ng(\\mu_i) = \\eta_i\n\\]"
  },
  {
    "objectID": "lecture/lecture-02_2023-04-10.html",
    "href": "lecture/lecture-02_2023-04-10.html",
    "title": "Lecture 02 figures",
    "section": "",
    "text": "0. set up\n\n\nCode\n# cleaning\nlibrary(tidyverse)\n\n# visualization\nlibrary(showtext)\nfont_add_google(\"Lato\", \"Lato\")\n\n\n\n\n1. probability distribution\n\n\nCode\nset.seed(1)\nnormdist &lt;- rnorm(n = 100000, mean = 0, sd = 1) %&gt;% \n  as_tibble(rownames = \"x\")\n\nshowtext_auto()\nggplot(normdist) +\n  geom_histogram(aes(x = value, after_stat(density)), fill = \"white\", color = \"black\", bins = 100) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), color = \"blue\", linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\n\n\n2. normal distribution\n\n\nCode\nggplot(data.frame(x = -10:25), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1, color = \"darkorange\") +\n  annotate(\"text\", x = 4.5, y = 0.4, label = \"\\U03BC = 0, \\U03C3 = 1\", color = \"darkorange\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 15, sd = 3), linewidth = 1, color = \"blue\") +\n  annotate(\"text\", x = 16, y = 0.15, label = \"\\U03BC = 15, \\U03C3 = 3\", color = \"blue\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 5, sd = 5), linewidth = 1, color = \"darkgreen\") +\n  annotate(\"text\", x = 7, y = 0.1, label = \"\\U03BC = 5, \\U03C3 = 5\", color = \"darkgreen\", size = 6) +\n  scale_x_continuous(breaks = seq(-10, 25, 5)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\n\n\n3. Student’s t distribution\n\n\nCode\nggplot(data.frame(x = -10:10), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#856F33\") +\n  annotate(\"text\", x = 3.5, y = 0.3, label = \"\\U03BD = 1\", color = \"#856F33\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 3), linewidth = 1, color = \"#E6821C\") + \n  annotate(\"text\", x = 3.5, y = 0.35, label = \"\\U03BD = 3\", color = \"#E6821C\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 5), linewidth = 1, color = \"#56E9E7\") +\n  annotate(\"text\", x = 3.5, y = 0.37, label = \"\\U03BD = 5\", color = \"#56E9E7\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 100), linewidth = 1, color = \"#04B37F\") +\n    annotate(\"text\", x = 3.5, y = 0.4, label = \"\\U03BD = 100\", color = \"#04B37F\", size = 6) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\n\n\n4. Uniform distribution\n\n\nCode\nggplot(data.frame(x = 0:10), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dunif, args = list(min = 2, max = 8), linewidth = 1, color = \"firebrick4\") +\n  annotate(\"text\", x = 2, y = 0.172, label = \"a = 2\", color = \"firebrick4\", size = 6) + \n  annotate(\"text\", x = 8, y = 0.172, label = \"b = 8\", color = \"firebrick4\", size = 6) + \n  scale_x_continuous(breaks = seq(0, 10, 2)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(-0.001, 0.18)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\n\n\n5. Binomial distribution\n\n\nCode\nggplot(data.frame(x = 1:20), aes(x)) +\n  stat_function(geom = \"line\", n = 20, fun = dbinom, args = list(size = 20, p = 0.1), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dbinom, args = list(size = 20, p = 0.1), color = \"#6D9929\", size = 3) +\n  annotate(\"text\", x = 5.5, y = 0.29, label = \"n = 20, p = 0.1\", color = \"#6D9929\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dbinom, args = list(size = 20, p = 0.4), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dbinom, args = list(size = 20, p = 0.4), color = \"#4A76E5\", size = 3) +\n  annotate(\"text\", x = 8, y = 0.2, label = \"n = 20, p = 0.4\", color = \"#4A76E5\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dbinom, args = list(size = 20, p = 0.7), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dbinom, args = list(size = 20, p = 0.7), color = \"#E67960\", size = 3) +\n  annotate(\"text\", x = 15, y = 0.21, label = \"n = 20, p = 0.7\", color = \"#E67960\", size = 6) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  labs(x = \"Number of successes\", y = \"Mass\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\n\n\n6. Poisson distribution\n\n\nCode\nggplot(data.frame(x = 1:20), aes(x)) +\n  stat_function(geom = \"line\", n = 20, fun = dpois, args = list(lambda = 1), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dpois, args = list(lambda = 1), color = \"coral\", size = 4) +\n  annotate(\"text\", x = 3, y = 0.37, label = \"\\U03BB = 1\", color = \"coral\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dpois, args = list(lambda = 4), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dpois, args = list(lambda = 4), color = \"darkgreen\", size = 4) +\n  annotate(\"text\", x = 6, y = 0.2, label = \"\\U03BB = 4\", color = \"darkgreen\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dpois, args = list(lambda = 10), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dpois, args = list(lambda = 10), color = \"turquoise\", size = 4) +\n  annotate(\"text\", x = 14, y = 0.12, label = \"\\U03BB = 10\", color = \"turquoise\", size = 6) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Discrete value\", y = \"Mass\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\nCode\nshowtext_auto(FALSE)\n\n\n\n\n\n\nCitationBibTeX citation:@online{bui2023,\n  author = {Bui, An},\n  title = {Lecture 02 Figures},\n  date = {2023-04-10},\n  url = {https://an-bui.github.io/ES-193DS-W23/lecture/lecture-02_2023-04-10.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2023. “Lecture 02 Figures.” April 10, 2023. https://an-bui.github.io/ES-193DS-W23/lecture/lecture-02_2023-04-10.html."
  },
  {
    "objectID": "workshop/workshop-06_2023-05-10.html",
    "href": "workshop/workshop-06_2023-05-10.html",
    "title": "Coding workshop: Week 6",
    "section": "",
    "text": "Set up\nLoading packages:\n\n\nCode\nlibrary(tidyverse) # general usage\nlibrary(here) # organization\nlibrary(naniar) # missing data visualization\n\nlibrary(skimr) # quick glimpse at data\nlibrary(plotly) # interactive plots\nlibrary(magick) # insert images into plots\nlibrary(NatParksPalettes) # one example of color palette package\nlibrary(wesanderson) # another example of color palette package\nlibrary(patchwork) # put plots together\n\n\n\n\nload in the data\n\n\nCode\n# create a new object called whales\n# read in the whales data\nwhales &lt;- read_csv(\n  here(\"workshop\", \"data\", \"Graywhale_watching_2007_2019.csv\")\n)\n\n\nlook at missing data:\n\n\nCode\ngg_miss_var(whales)\n\n\n\n\n\n\n\n\n\nuse skimr package to quickly glimpse the data:\n\n\nCode\nskim(whales)\n\n\n\nData summary\n\n\nName\nwhales\n\n\nNumber of rows\n5005\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nDate\n1\n\n\ndifftime\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncondition\n75\n0.99\n4\n13\n0\n37\n0\n\n\ndirection\n86\n0.98\n3\n14\n0\n2589\n0\n\n\nspecies\n0\n1.00\n21\n21\n0\n1\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate\n0\n1\n2007-02-01\n2019-05-19\n2014-04-07\n1021\n\n\n\nVariable type: difftime\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nlocal_time\n284\n0.94\n2520 secs\n63420 secs\n12:26:00\n547\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ntotal\n0\n1.00\n2.25\n2.46\n0\n1\n2\n2\n65\n▇▁▁▁▁\n\n\ncalves\n141\n0.97\n0.33\n0.66\n0\n0\n0\n1\n6\n▇▁▁▁▁\n\n\n\n\n\n\n\nwrangling\n\n\nCode\nwhales_clean &lt;- whales %&gt;% \n  # creating new columns for years and months\n  mutate(year_new = lubridate::year(date)) %&gt;% \n  mutate(month_new = lubridate::month(date)) %&gt;% \n  # create a new column for month names\n  mutate(month_name = case_when(\n    month_new == 2 ~ \"February\",\n    month_new == 3 ~ \"March\",\n    month_new == 4 ~ \"April\",\n    month_new == 5 ~ \"May\"\n  ),\n  month_name = forcats::as_factor(month_name),\n  month_name = forcats::fct_relevel(month_name, \"February\", \"March\", \"April\", \"May\")\n  ) %&gt;% \n  mutate(condition_new = case_when(\n    stringr::str_detect(condition, \"Excellent\") ~ \"excellent\",\n    stringr::str_detect(condition, \"Good\") ~ \"good\",\n    stringr::str_detect(condition, \"Fair\") ~ \"fair\",\n    stringr::str_detect(condition, \"Poor\") ~ \"poor\"\n  ))\n\n\n\n\ncreate a plot and insert an image\n\n\nCode\n# create a new data frame to filter 2019 observations\nwhales_2019 &lt;- whales_clean %&gt;% \n  filter(year_new == 2019)\n\n# read in the whale png as a raster\nwhale_image &lt;- magick::image_read(\n  here(\"workshop\", \"images\", \"noaa-gray-whale.png\")\n) %&gt;% \n  as.raster()\n\n# make a boxplot\nwhales_2019_boxplot &lt;- ggplot(data = whales_2019, aes(x = month_name, y = total)) +\n  geom_boxplot(aes(fill = month_name)) +\n  geom_point(position = position_jitter(width = 0.3, height = 0, seed = 1000)) +\n  scale_fill_manual(values = natparks.pals(\"RockyMtn\", 4)) +\n  annotation_raster(whale_image, xmin = 2.5, xmax = 4.5, ymin = 30, ymax = 60)\n\nwhales_2019_boxplot\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplotly(whales_2019_boxplot)\n\n\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{bui2023,\n  author = {Bui, An},\n  title = {Coding Workshop: {Week} 6},\n  date = {2023-05-10},\n  url = {https://an-bui.github.io/ES-193DS-W23/workshop/workshop-06_2023-05-10.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2023. “Coding Workshop: Week 6.” May 10, 2023. https://an-bui.github.io/ES-193DS-W23/workshop/workshop-06_2023-05-10.html."
  },
  {
    "objectID": "workshop/workshop-03_2023-04-19.html",
    "href": "workshop/workshop-03_2023-04-19.html",
    "title": "Coding workshop: Week 3",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\nCode\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "workshop/workshop-03_2023-04-19.html#a.-review",
    "href": "workshop/workshop-03_2023-04-19.html#a.-review",
    "title": "Coding workshop: Week 3",
    "section": "a. Review",
    "text": "a. Review\nFind the mean and standard deviation flipper length and bill length for each penguin species on Biscoe and Dream islands.\n\n\nCode\npenguin_subset &lt;- penguins %&gt;% \n  group_by(island, species) %&gt;% \n  filter(island %in% c(\"Biscoe\", \"Dream\")) %&gt;% \n  summarize(mean_flip = mean(flipper_length_mm, na.rm = TRUE),\n            sd_flip = sd(flipper_length_mm, na.rm = TRUE),\n            mean_bill = mean(bill_length_mm, na.rm = TRUE),\n            sd_bill = sd(bill_length_mm, na.rm = TRUE))\n\n\n`summarise()` has grouped output by 'island'. You can override using the\n`.groups` argument.\n\n\nCode\npenguin_subset\n\n\n# A tibble: 4 × 6\n# Groups:   island [2]\n  island species   mean_flip sd_flip mean_bill sd_bill\n  &lt;fct&gt;  &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 Biscoe Adelie         189.    6.73      39.0    2.48\n2 Biscoe Gentoo         217.    6.48      47.5    3.08\n3 Dream  Adelie         190.    6.59      38.5    2.47\n4 Dream  Chinstrap      196.    7.13      48.8    3.34"
  },
  {
    "objectID": "workshop/workshop-03_2023-04-19.html#b.-new-functions-count-mutate-case_when",
    "href": "workshop/workshop-03_2023-04-19.html#b.-new-functions-count-mutate-case_when",
    "title": "Coding workshop: Week 3",
    "section": "b. New functions: count(), mutate(), case_when()",
    "text": "b. New functions: count(), mutate(), case_when()\nMore functions to add to your tidyverse toolkit:\n\ncount()\n\n\nCode\n# new object names penguin_count from penguins\npenguin_count &lt;- penguins %&gt;% \n  # group by island and species\n  group_by(island, species) %&gt;% \n  # count function counts number of rows (i.e. observations)\n  count()\n\npenguin_count\n\n\n# A tibble: 5 × 3\n# Groups:   island, species [5]\n  island    species       n\n  &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt;\n1 Biscoe    Adelie       44\n2 Biscoe    Gentoo      124\n3 Dream     Adelie       56\n4 Dream     Chinstrap    68\n5 Torgersen Adelie       52\n\n\n\n\nmutate() + case_when()\nFirst, remember how we calculated mean body mass across penguin species last week:\n\n\nCode\npenguins %&gt;% \n  group_by(species) %&gt;% \n  summarize(mean_body_mass = mean(body_mass_g, na.rm = TRUE))\n\n\n# A tibble: 3 × 2\n  species   mean_body_mass\n  &lt;fct&gt;              &lt;dbl&gt;\n1 Adelie             3701.\n2 Chinstrap          3733.\n3 Gentoo             5076.\n\n\nmutate() creates a new column, while case_when() within mutate() allows you to tell R, “in the case when…”. For example:\n\n\nCode\n# create new object called penguin_newcol from penguins\npenguin_newcol &lt;- penguins %&gt;% \n  # group by species\n  group_by(species) %&gt;% \n  # make a new column called body_mass_cat\n  mutate(body_mass_cat = case_when(\n    # in the case when year matches 2007, put \"first\"\n    year == 2007 ~ \"first\", \n    # in the case when year matches 2008, put \"second\"\n    year == 2008 ~ \"second\",\n    # in the case when year matches 2009, put \"third\"\n    year == 2009 ~ \"third\"\n  ))\n\npenguin_newcol\n\n\n# A tibble: 344 × 9\n# Groups:   species [3]\n   species island    bill_length_mm bill_d…¹ flipp…² body_…³ sex    year body_…⁴\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;    &lt;dbl&gt;   &lt;int&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt;  \n 1 Adelie  Torgersen           39.1     18.7     181    3750 male   2007 first  \n 2 Adelie  Torgersen           39.5     17.4     186    3800 fema…  2007 first  \n 3 Adelie  Torgersen           40.3     18       195    3250 fema…  2007 first  \n 4 Adelie  Torgersen           NA       NA        NA      NA &lt;NA&gt;   2007 first  \n 5 Adelie  Torgersen           36.7     19.3     193    3450 fema…  2007 first  \n 6 Adelie  Torgersen           39.3     20.6     190    3650 male   2007 first  \n 7 Adelie  Torgersen           38.9     17.8     181    3625 fema…  2007 first  \n 8 Adelie  Torgersen           39.2     19.6     195    4675 male   2007 first  \n 9 Adelie  Torgersen           34.1     18.1     193    3475 &lt;NA&gt;   2007 first  \n10 Adelie  Torgersen           42       20.2     190    4250 &lt;NA&gt;   2007 first  \n# … with 334 more rows, and abbreviated variable names ¹​bill_depth_mm,\n#   ²​flipper_length_mm, ³​body_mass_g, ⁴​body_mass_cat"
  },
  {
    "objectID": "workshop/workshop-02_2023-04-12.html",
    "href": "workshop/workshop-02_2023-04-12.html",
    "title": "Coding workshop: Week 2",
    "section": "",
    "text": "This is a Quarto document. It allows you to write in plain text and code at the same time. If you have used RMarkdown before, this is a similar concept.\n\n\nYou can format your document with headers, italics and bold text, and color.\nYou can insert code chunks using Command (or Control) + Shift + I.\n\n\nCode\n# this is a code chunk!\n\n\nYou can also adjust code chunk options using the options listed here inside of the {r} curly brackets. For example, if I want to run code but not display it, the option is echo = FALSE.\n\n\n[1] 11\n\n\nIn contrast, if I want to display code but not run it, the option is eval = FALSE.\n\n\nCode\n2 + 5\n\n\nPutting text and code together makes writing documents very streamlined. You can do all your analysis and write about it in the same document.\n\n\n\nThe right-pointing arrow at the top of the document labelled “Render” allows you to put all the text and code together into one clean document.\nFor this class, homework assignments will be expected in Quarto Markdown or RMarkdown format submitted in PDF form. This means that you can either 1) render to PDF or 2) render to one of the other formats (e.g. docx or html) and convert it to PDF.\nNote about rendering: if you’re having trouble rendering your document, the error will pop up in the “Background Jobs” tab down below. Similarly to troubleshooting your code when you get error messages while you’re writing, you can be a detective and figure out which line caused the error. Rendering will work best if you make sure your code runs from top to bottom. A good way to check this is to restart your R session, then run each code chunk sequentially."
  },
  {
    "objectID": "workshop/workshop-02_2023-04-12.html#a.-formatting",
    "href": "workshop/workshop-02_2023-04-12.html#a.-formatting",
    "title": "Coding workshop: Week 2",
    "section": "",
    "text": "You can format your document with headers, italics and bold text, and color.\nYou can insert code chunks using Command (or Control) + Shift + I.\n\n\nCode\n# this is a code chunk!\n\n\nYou can also adjust code chunk options using the options listed here inside of the {r} curly brackets. For example, if I want to run code but not display it, the option is echo = FALSE.\n\n\n[1] 11\n\n\nIn contrast, if I want to display code but not run it, the option is eval = FALSE.\n\n\nCode\n2 + 5\n\n\nPutting text and code together makes writing documents very streamlined. You can do all your analysis and write about it in the same document."
  },
  {
    "objectID": "workshop/workshop-02_2023-04-12.html#b.-rendering",
    "href": "workshop/workshop-02_2023-04-12.html#b.-rendering",
    "title": "Coding workshop: Week 2",
    "section": "",
    "text": "The right-pointing arrow at the top of the document labelled “Render” allows you to put all the text and code together into one clean document.\nFor this class, homework assignments will be expected in Quarto Markdown or RMarkdown format submitted in PDF form. This means that you can either 1) render to PDF or 2) render to one of the other formats (e.g. docx or html) and convert it to PDF.\nNote about rendering: if you’re having trouble rendering your document, the error will pop up in the “Background Jobs” tab down below. Similarly to troubleshooting your code when you get error messages while you’re writing, you can be a detective and figure out which line caused the error. Rendering will work best if you make sure your code runs from top to bottom. A good way to check this is to restart your R session, then run each code chunk sequentially."
  },
  {
    "objectID": "workshop/workshop-02_2023-04-12.html#a.-using-ggplot",
    "href": "workshop/workshop-02_2023-04-12.html#a.-using-ggplot",
    "title": "Coding workshop: Week 2",
    "section": "a. Using ggplot",
    "text": "a. Using ggplot\nWe’ll do most of our data visualization using {ggplot2} (also commonly referred to as {ggplot}), which is a {tidyverse} package. Making a plot using {ggplot} takes 3 important parts:\n1. the ggplot() call: you’re telling R that you want to use ggplot on a specific data frame\n2. the aes() call: within the ggplot() call, you’re telling R which columns contain the x- and y- axes\n3. the geom_() call: you’re telling R what kind of plot you want to make."
  },
  {
    "objectID": "workshop/workshop-02_2023-04-12.html#b.-histograms",
    "href": "workshop/workshop-02_2023-04-12.html#b.-histograms",
    "title": "Coding workshop: Week 2",
    "section": "b. histograms",
    "text": "b. histograms\nOne of the first plots you should make when working with a new data set is a histogram. You’ve seen these plots in lecture, so now let’s make them with code.\nThe Rice Rule is one of many rules to figure out how many bins should be in your histogram:\n\\[\nbins = 2n^{1/3}\n\\]\nSo, for example, the penguin data set has 344 observations. Therefore, according to the Rice Rule, you could use around 14 bins.\n\n\nCode\n# step 1. use the ggplot() function call\n# step 2. use the aes() call\nggplot(data = penguins, aes(x = body_mass_g)) +\n  # step 3. specify a geom (geometry)\n  geom_histogram(bins = 14) \n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "workshop/workshop-02_2023-04-12.html#c.-central-tendency-and-data-spread",
    "href": "workshop/workshop-02_2023-04-12.html#c.-central-tendency-and-data-spread",
    "title": "Coding workshop: Week 2",
    "section": "c. central tendency and data spread",
    "text": "c. central tendency and data spread\nUsually, calculating the central tendency or data spread can only go so far. To communicate effectively, we can represent these two characteristics of our data set visually. There are a few ways to do this:\n- box plot (aka box and whisker plot)\n- violin plot\n- jitter plot\n- points with bars\n- some combination of the above\n- some other form (e.g. beeswarm)\n\ni. box plots\nFor example, let’s make a box plot of body masses for the different penguin species.\n\n\nCode\nggplot(data = penguins, aes(x = species, y = body_mass_g)) +\n  geom_boxplot()\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nBox plots are the most common way of representing central tendency and spread, but they’re not easy to parse. They usually include 1) the median, 2) the 25th quartile (median of bottom half of dataset), 3) the 75th quartile (median of top half of data set), and 4) the 1.5*inter-quartile range (distance between lower and upper quartiles). If there are any outliers, they’ll be represented as dots.\n\n\nii. violin plots\nViolin plots show a symmetrical shape, and the width is based on the number of points at that particular value.\n\n\nCode\nggplot(data = penguins, aes(x = species, y = body_mass_g)) +\n  geom_violin()\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\n\n\n\n\n\n\n\n\n\niii. jitter plot\nJitter plots are a random smattering of points in a cloud, but the y-axis position corresponds to the real value.\n\n\nCode\nggplot(data = penguins, aes(x = species, y = body_mass_g)) +\n  geom_jitter() \n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\niv. points with bars\nYou can also represent central tendency and spread using a single point to represent the mean and bars to represent standard deviation. We can use the data frame we created above: penguin_summary.\n\n\nCode\nggplot(data = penguin_summary, aes(x = species, y = mean_body_mass)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = mean_body_mass - sd_body_mass, \n                    ymax = mean_body_mass + sd_body_mass))\n\n\n\n\n\n\n\n\n\n\n\nv. some combination of the above\nThere are some common combinations of the above plots, for example:\n\nviolin plot with boxplot\n\n\nCode\nggplot(data = penguins, aes(x = species, y = body_mass_g)) +\n  geom_violin() +\n  # width argument controls boxplot width\n  geom_boxplot(width = 0.2)\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_ydensity()`).\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\nboxplot with jittered points\n\n\nCode\nggplot(data = penguins, aes(x = species, y = body_mass_g)) +\n  geom_boxplot() +\n  geom_jitter()\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "workshop/workshop-10_2023-06-07.html",
    "href": "workshop/workshop-10_2023-06-07.html",
    "title": "Coding workshop: Week 10",
    "section": "",
    "text": "# model packages\nlibrary(MASS) # have to read this in before tidyverse \nlibrary(lme4)\nlibrary(glmmTMB) # ok if you don't have this - just comment it out\n\n# diagnostics and model info\nlibrary(DHARMa)\nlibrary(MuMIn)\nlibrary(ggeffects)\nlibrary(lmtest)\nlibrary(broom)\n\n# general usage\nlibrary(tidyverse)\nlibrary(here)\nlibrary(naniar)\nlibrary(skimr)\nlibrary(GGally)\nlibrary(flextable)\n\nsalamanders &lt;- read_csv(here(\"data\", \"salamanders.csv\"))"
  },
  {
    "objectID": "workshop/workshop-10_2023-06-07.html#histogram-of-counts",
    "href": "workshop/workshop-10_2023-06-07.html#histogram-of-counts",
    "title": "Coding workshop: Week 10",
    "section": "histogram of counts:",
    "text": "histogram of counts:\n\nggplot(salamanders, aes(x = count)) +\n  geom_histogram(bins = 17)"
  },
  {
    "objectID": "workshop/workshop-10_2023-06-07.html#missingness",
    "href": "workshop/workshop-10_2023-06-07.html#missingness",
    "title": "Coding workshop: Week 10",
    "section": "Missingness:",
    "text": "Missingness:\n\ngg_miss_var(salamanders) # nothing missing!"
  },
  {
    "objectID": "workshop/workshop-10_2023-06-07.html#skim",
    "href": "workshop/workshop-10_2023-06-07.html#skim",
    "title": "Coding workshop: Week 10",
    "section": "Skim:",
    "text": "Skim:\n\nskim(salamanders)\n\n\nData summary\n\n\nName\nsalamanders\n\n\nNumber of rows\n644\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsite\n0\n1\n3\n5\n0\n23\n0\n\n\nmined\n0\n1\n2\n3\n0\n2\n0\n\n\nspp\n0\n1\n2\n5\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncover\n0\n1\n0.00\n0.98\n-1.59\n-0.70\n-0.05\n0.60\n1.89\n▅▇▇▅▃\n\n\nsample\n0\n1\n2.50\n1.12\n1.00\n1.75\n2.50\n3.25\n4.00\n▇▇▁▇▇\n\n\nDOP\n0\n1\n0.00\n0.98\n-2.20\n-0.30\n-0.09\n0.00\n3.17\n▂▇▅▂▁\n\n\nWtemp\n0\n1\n0.00\n0.98\n-3.02\n-0.61\n0.04\n0.60\n2.21\n▁▃▇▆▂\n\n\nDOY\n0\n1\n0.00\n1.00\n-2.71\n-0.57\n-0.06\n0.97\n1.46\n▁▅▇▅▇\n\n\ncount\n0\n1\n1.32\n2.64\n0.00\n0.00\n0.00\n2.00\n36.00\n▇▁▁▁▁"
  },
  {
    "objectID": "workshop/workshop-10_2023-06-07.html#pairs-plot",
    "href": "workshop/workshop-10_2023-06-07.html#pairs-plot",
    "title": "Coding workshop: Week 10",
    "section": "Pairs plot:",
    "text": "Pairs plot:\n\nsalamanders %&gt;% \n  select(!site) %&gt;% \n  ggpairs()"
  },
  {
    "objectID": "workshop/workshop-10_2023-06-07.html#build-models",
    "href": "workshop/workshop-10_2023-06-07.html#build-models",
    "title": "Coding workshop: Week 10",
    "section": "Build models",
    "text": "Build models\n\n# linear model, we know this is wrong\nsalmod1 &lt;- lm(count ~ cover + mined + spp, data = salamanders)\n\n# generalized linear model with Poisson distribution\nsalmod2 &lt;- glm(count ~ cover + mined + spp, data = salamanders, family = \"poisson\")\nsalmod2.a &lt;- glm(count ~ cover + mined + spp, data = salamanders, family = \"poisson\")\n\n# generalized linear model with negative binomial distribution\nsalmod3 &lt;- glm.nb(count ~ cover + mined + spp, data = salamanders)\nsalmod3.a &lt;- glmmTMB(count ~ cover + mined + spp, data = salamanders, family = \"nbinom2\")\n\n# generalized linear model with Poisson distribution and random effect of site\nsalmod4 &lt;- glmer(count ~ cover + mined  + spp + (1|site), data = salamanders, family = \"poisson\")\nsalmod4.a &lt;- glmmTMB(count ~ cover + mined  + spp + (1|site), data = salamanders, family = \"poisson\")\n\n# generalized linear model with negative binomial distribution and random effect of site\nsalmod5 &lt;- glmer.nb(count ~ cover + mined  + spp + (1|site), data = salamanders)\nsalmod5.a &lt;- glmmTMB(count ~ cover + mined + spp + (1|site), data = salamanders, family = \"nbinom2\")"
  },
  {
    "objectID": "workshop/workshop-10_2023-06-07.html#look-at-residuals",
    "href": "workshop/workshop-10_2023-06-07.html#look-at-residuals",
    "title": "Coding workshop: Week 10",
    "section": "Look at residuals",
    "text": "Look at residuals\n\n# check diagnostics\nplot(simulateResiduals(salmod1)) # bad\n\n\n\n\n\n\n\nplot(simulateResiduals(salmod2)) # bad\n\n\n\n\n\n\n\nplot(simulateResiduals(salmod3)) # ok?\n\n\n\n\n\n\n\nplot(simulateResiduals(salmod4)) # bad\n\n\n\n\n\n\n\nplot(simulateResiduals(salmod5)) # ok?"
  },
  {
    "objectID": "workshop/workshop-10_2023-06-07.html#which-distribution-to-use",
    "href": "workshop/workshop-10_2023-06-07.html#which-distribution-to-use",
    "title": "Coding workshop: Week 10",
    "section": "Which distribution to use?",
    "text": "Which distribution to use?\n\nMuMIn::model.sel(salmod1, salmod2, salmod3, salmod4, salmod5)\n\nModel selection table \n        (Intrc)   cover mined spp       family    class init.theta link random\nsalmod5   1.409 -0.1042     +   + NB(0.9424,l) glmerMod                      s\nsalmod3   1.465 -0.1418     +   + NB(0.8333,l)   negbin      0.833  log       \nsalmod4   1.385 -0.1205     +   +         p(l) glmerMod                      s\nsalmod2   1.486 -0.2309     +   +         p(l)      glm                       \nsalmod1   3.447 -0.3426     +   +         g(i)       lm                       \n        df    logLik   AICc   delta weight\nsalmod5 11  -825.964 1674.3    0.00      1\nsalmod3 10  -836.039 1692.4   18.08      0\nsalmod4 10  -972.141 1964.6  290.28      0\nsalmod2  9 -1001.066 2020.4  346.07      0\nsalmod1 10 -1457.026 2934.4 1260.05      0\nAbbreviations:\n family: g(i) = 'gaussian(identity)', \n         NB(0.8333,l) = 'Negative Binomial(0.8333,log)', \n         NB(0.9424,l) = 'Negative Binomial(0.9424,log)', p(l) = 'poisson(log)'\nModels ranked by AICc(x) \nRandom terms: \n s: 1 | site"
  },
  {
    "objectID": "workshop/workshop-10_2023-06-07.html#model-summary",
    "href": "workshop/workshop-10_2023-06-07.html#model-summary",
    "title": "Coding workshop: Week 10",
    "section": "Model summary",
    "text": "Model summary\n\n# model object\nsalmod3\n\n\nCall:  glm.nb(formula = count ~ cover + mined + spp, data = salamanders, \n    init.theta = 0.8332590711, link = log)\n\nCoefficients:\n(Intercept)        cover     minedyes        sppDF        sppDM      sppEC-A  \n     1.4647      -0.1418      -2.1802      -0.4806      -0.3982      -1.4829  \n    sppEC-L        sppGP        sppPR  \n    -0.2155      -0.8030      -2.0647  \n\nDegrees of Freedom: 643 Total (i.e. Null);  635 Residual\nNull Deviance:      885.6 \nResidual Deviance: 549.2    AIC: 1692\n\n# summary \nsummary(salmod3)\n\n\nCall:\nglm.nb(formula = count ~ cover + mined + spp, data = salamanders, \n    init.theta = 0.8332590711, link = log)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.7966  -0.8511  -0.6062   0.0812   3.4038  \n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.46467    0.15733   9.309  &lt; 2e-16 ***\ncover       -0.14180    0.07715  -1.838 0.066062 .  \nminedyes    -2.18017    0.17186 -12.686  &lt; 2e-16 ***\nsppDF       -0.48061    0.21439  -2.242 0.024977 *  \nsppDM       -0.39819    0.21264  -1.873 0.061123 .  \nsppEC-A     -1.48291    0.24619  -6.023 1.71e-09 ***\nsppEC-L     -0.21550    0.20909  -1.031 0.302713    \nsppGP       -0.80299    0.22230  -3.612 0.000304 ***\nsppPR       -2.06472    0.27822  -7.421 1.16e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(0.8333) family taken to be 1)\n\n    Null deviance: 885.60  on 643  degrees of freedom\nResidual deviance: 549.16  on 635  degrees of freedom\nAIC: 1692.1\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.833 \n          Std. Err.:  0.108 \n\n 2 x log-likelihood:  -1672.078 \n\n# confidence intervals\nconfint(salmod3)\n\n                 2.5 %      97.5 %\n(Intercept)  1.1619452  1.78160994\ncover       -0.2951066  0.01123174\nminedyes    -2.5140207 -1.85565670\nsppDF       -0.9135120 -0.04834588\nsppDM       -0.8214220  0.02428889\nsppEC-A     -1.9694420 -1.00469459\nsppEC-L     -0.6235862  0.19129668\nsppGP       -1.2339240 -0.37486002\nsppPR       -2.6278646 -1.52359253\n\n# adjusted R2\nr.squaredGLMM(salmod3)\n\n                R2m       R2c\ndelta     0.4341864 0.4341864\nlognormal 0.5806880 0.5806880\ntrigamma  0.2400616 0.2400616\n\n\n\n# model object in table\nsalmod3 %&gt;% \n  as_flextable()\n\nEstimateStandard Errorz valuePr(&gt;|z|)(Intercept)1.4650.1579.3090.0000***cover-0.1420.077-1.8380.0661  .minedyes-2.1800.172-12.6860.0000***sppDF-0.4810.214-2.2420.0250  *sppDM-0.3980.213-1.8730.0611  .sppEC-A-1.4830.246-6.0230.0000***sppEC-L-0.2150.209-1.0310.3027   sppGP-0.8030.222-3.6120.0003***sppPR-2.0650.278-7.4210.0000***Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05 (Dispersion parameter for Negative Binomial(0.8333) family taken to be 1)Null deviance: 885.6 on 643 degrees of freedomResidual deviance: 549.2 on 635 degrees of freedom"
  },
  {
    "objectID": "workshop/workshop-10_2023-06-07.html#visualizing",
    "href": "workshop/workshop-10_2023-06-07.html#visualizing",
    "title": "Coding workshop: Week 10",
    "section": "Visualizing:",
    "text": "Visualizing:\n\npredictions &lt;- ggpredict(salmod3, terms = c(\"cover\", \"mined\", \"spp\")) %&gt;% \n  rename(mined = group,\n         spp = facet)\n\nggplot(salamanders, aes(x = cover, y = count, fill = mined)) +\n  geom_point(aes(color = mined), alpha = 0.5) +\n  facet_wrap(~spp, scales = \"free_y\") +\n  geom_line(data = predictions, aes(x = x, y = predicted, color = mined)) +\n  geom_ribbon(data = predictions, aes(x = x, y = predicted, ymin = conf.low, ymax = conf.high, fill = mined), alpha = 0.2) +\n  scale_fill_manual(values = c(\"yes\" = \"blue\", \"no\" = \"orange\")) +\n  scale_color_manual(values = c(\"yes\" = \"blue\", \"no\" = \"orange\")) +\n  theme_bw() +\n  facet_wrap(~spp, scales = \"free_y\") +\n  labs(fill = \"Mined\", color = \"Mined\")"
  },
  {
    "objectID": "workshop.html",
    "href": "workshop.html",
    "title": "Workshop documents",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nCoding workshop: Week 10\n\n\nJun 7, 2023\n\n\n\n\nCoding workshop: Week 8 and 9\n\n\nMay 24, 2023\n\n\n\n\nCoding workshop: Week 7\n\n\nMay 17, 2023\n\n\n\n\nCoding workshop: Week 6\n\n\nMay 10, 2023\n\n\n\n\nCoding workshop: Week 4\n\n\nApr 26, 2023\n\n\n\n\nCoding workshop: Week 3\n\n\nApr 19, 2023\n\n\n\n\nCoding workshop: Week 2\n\n\nApr 12, 2023\n\n\n\n\nCoding workshop: Week 1\n\n\nApr 5, 2023\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "resources/github-pages.html",
    "href": "resources/github-pages.html",
    "title": "Setting up GitHub pages",
    "section": "",
    "text": "Why set up GitHub pages?\nIf you render/knit your documents to html, someone else who wants to see your document will have to fork/clone your repo into their computer, and open up your html document. By setting up GitHub pages, you can essentially make your repository into a website and create a URL to your rendered html document. Then, if you want to share your code, someone can just look at the page on that URL and not have to deal with your whole repository.\nIn class, we walked through the simplest way to set up GitHub pages. However, there are lots of advanced options to make your repository into a website. For example, in CHOYOA 2, you’ll set some different options when you set up GitHub pages.\n\n\n1. Create a new repository on GitHub\nMake sure you have the repository set to be public and that you are adding a README.\n\n\n\n2. Set up GitHub pages\nNavigate to the main page of your repository. Click on Settings &gt; Pages. Select your main branch as the deployed branch. Click save.\n\nYou know that this worked if you get a message at the top of the window saying “GitHub Pages source saved.”\n\n\n3. Clone your repo to your computer and create some code.\nIn the demo, we put all our code into a new folder in the repo called code. Then, create a new Quarto/RMarkdown document and make sure it is saved as either an HTML (ideal) or a PDF (also works but not as aesthetically pleasing). Save that document in the code folder.\n\n\n\n4. Adjust the YAML options.\nThere are lots of document options you can adjust in the metadata. In class, we went through how to set global options for code chunks using execute:.\n\nIn RMarkdown: this happens in the knitr set up chunk:\n\n\nCode\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\n\n\n\n\n5. Render/knit your code.\nNote the file path for the .qmd document is: code/newcode.qmd. That means the file path for the .html document is: code/newcode.html.\n\n\n\n6. Stage/commit/push those changes\nIf you are using Quarto, you’ll see a lot of files for the rendered plots, formatting options, etc. If you are using RMarkdown, you won’t. This is just a little difference between Quarto and RMarkdown.\n\n\n\n7. Return to GitHub and look at the environment\nGo back to your repository on GitHub. You should see two visual cues that this has worked:\n1. You have a brown circle by your most recent commit. This corresponds to what’s happening in…\n2. The “Environments”. You will see github-pages marked as “active”.\n\n\n\n8. Check the deployment\nClick on github-pages under Environments. You should see that the deployment (your commit/push) shows up as “Queued”. This will eventually turn into “In Progress”, then “Active”.\n\nNote: depending how how many other actions are happening on GitHub at any given time, this may take a couple minutes. Be patient! Eventually it will be active.\n\n\n9. Look at the your rendered document!\nYour deployed repository will have the URL your-github-username.github.io/repository-name. In this example, the URL is an-bui.github.io/my-repository.\nTo find your rendered html document, use the file path as your URL. In this example, the file path to the rendered document is code/newcode.html. This means the URL for the .html on my deployed repository is an-bui.github.io/my-repository/code/newcode.html.\n\nNote: sometimes it’s useful to link this URL in the README!\n\n\nexample repo\nThe repo for this example is here.\n\n\n\n\nCitationBibTeX citation:@online{bui2023,\n  author = {Bui, An},\n  title = {Setting up {GitHub} Pages},\n  date = {2023-05-17},\n  url = {https://an-bui.github.io/ES-193DS-W23/resources/github-pages.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2023. “Setting up GitHub Pages.” May 17, 2023. https://an-bui.github.io/ES-193DS-W23/resources/github-pages.html."
  },
  {
    "objectID": "resources/communicating-results.html",
    "href": "resources/communicating-results.html",
    "title": "Clear communication = interpretable stats",
    "section": "",
    "text": "Obviously, this is a stats class - however, stats exists within the data science world, and data science includes communication about stats. It’s important for us, in this class, to understand the mechanics of the tests we use (assumptions, underlying math, etc.) but the real challenge is being able to communicate about those tests and ground what those tests reveal in the biology of the system we’re studying - that’s environmental science.\nCommunication about what statistical methods you use to address a question/answer a hypothesis should include writing along with some visualization (figures and/or tables). The following are examples from lecture. You’ve also done a lot of reading in this class, and have seen a lot of examples of how to communicate about statistics from other researchers.\nEach code chunk with what is potentially new information is annotated - however, I haven’t annotated things like tests, creating plots, etc. because we’ve gone over that in class.\n\n\nCode\n# general use\nlibrary(tidyverse)\n\n# data\nlibrary(palmerpenguins)\n\n# visualization\nlibrary(patchwork)\nlibrary(flextable)\n\n# model summary table tools\nlibrary(broom)\nlibrary(car)\nlibrary(ggeffects)\nlibrary(equatiomatic)\n\n# using the Lato font from Google fonts\nlibrary(showtext)\nfont_add_google(\"Lato\", \"Lato\")\nshowtext_auto()"
  },
  {
    "objectID": "resources/communicating-results.html#one-sample-t-test",
    "href": "resources/communicating-results.html#one-sample-t-test",
    "title": "Clear communication = interpretable stats",
    "section": "One sample t-test",
    "text": "One sample t-test\nThis example from lecture was about comparing a sample of acorn masses to a theoretical mean (2 g).\nJust generating some fake data for this example:\n\n\nCode\nset.seed(7)\nacorns &lt;- rnorm(n = 41, mean = 2, sd = 1)\n\n\n\nChecking assumptions\nFor a t-test, one of the assumptions you can check is that your variable is normally distributed. Doing this with a histogram and a QQ plot makes sense:\n\n\nCode\n```{r hist-and-qq}\n#| fig.width: 12\n#| fig.height: 6\n#| out.width: 90%\n#| fig.align: center\n\nhist &lt;- enframe(acorns) %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 7, fill = \"cornflowerblue\", color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 11.5), breaks = c(0, 3, 6, 9, 12)) +\n  geom_vline(xintercept = 2, color = \"maroon\", lty = 2, linewidth = 1) +\n  theme_classic() +\n  labs(x = \"Acorn mass (g)\", y = \"Count\", \n       title = \"A)\") +\n  theme(plot.title.position = \"plot\")\n\nqq &lt;- enframe(acorns) %&gt;% \n  ggplot(aes(sample = value)) +\n  stat_qq_line(aes(sample = value)) +\n  stat_qq(aes(sample = value), color = \"cornflowerblue\", size = 3) +\n  theme_classic() +\n  labs(x = \"Theoretical quantiles\", y = \"Sample quantiles\",\n       title = \"B)\") +\n  theme(plot.title.position = \"plot\")\n\nhist + qq\n```\n\n\n\n\n\n\n\n\n\nExample caption:\n\nFigure 1. Visual checks for normally distributed variable. A) Histogram of acorn masses (g). Bars in histogram represent counts of acorns in each bin. Dashed red line represents theoretical mean (\\(\\mu\\) = 0). B) Quantile-quantile (QQ) plot. Points in QQ plot represent sample quantiles compared against theoretical quantiles from a normal distribution. Solid black line represents a 1:1 relationship between sample and theoretical quantiles.\n\n\n\n\n\n\n\nMaking sure your figures render properly\n\n\n\n\n\nYou put a lot of effort into making figures, so it’s worth making sure they appear the way you think they would in your final document! You can control these in your chunk options (i.e. within the curly brackets). There are many ways to do this, but I like adjusting the a) aspect ratio using fig.width and fig.height and b) proportion using out.width.\nIn Quarto, you can set those options within the chunk (see above) or in the curly brackets. In RMarkdown, you can only use the curly brackets, which would look like:\n{r fig.width = 12, fig.height = 6, out.width = \"90%\", fig.align = \"center\"}\n\n\n\n\n\n\n\n\n\nFormatting captions\n\n\n\n\n\nYou can write a caption in text (the easiest way) or you can try using code chunk options if you’re using Quarto. There are tips for how to do that here, though the formatting might not be the standard (i.e. bold text for figure number and title). I also changed the caption color - not required, but nice to add another visual cue that the caption is attached to the figure.\nGenerally, the font size in captions tends to be smaller than the main text. You can insert these options in Quarto by wrapping your text in a “fenced div” (see the source code for how to do that). In RMarkdown, you can use an HTML wrapper (here’s an example).\n\n\n\nExample text:\nWe visually assessed normality using a histogram and a QQ plot (Figure 1), and determined that acorn mass in our sample was normally distributed.\n\n\nTest\n\n\nCode\nacorn_test &lt;- t.test(acorns, mu = 2)\n\n\nExample text:\nWe assessed whether acorn masses in our sample differed from the claim of 2g using a one-sample two-tailed t-test. Our null hypothesis was that the mean acorn mass in our sample was the same as the claim.\n\n\nTest results\n\n\nCode\nacorn_test\n\n\n\n    One Sample t-test\n\ndata:  acorns\nt = 1.8035, df = 40, p-value = 0.07885\nalternative hypothesis: true mean is not equal to 2\n95 percent confidence interval:\n 1.964535 2.623323\nsample estimates:\nmean of x \n 2.293929 \n\n\nExample text:\nWe collected 41 acorns and found no significant difference between our sample mean mass and the claim (One-sample two-tailed t-test, t(40) = 1.8, \\(\\alpha\\) = 0.05, p = 0.079). Our data suggest that acorn masses in our sampling area are on average the same mass as the claimed mass (Figure 1A)."
  },
  {
    "objectID": "resources/communicating-results.html#chi-square",
    "href": "resources/communicating-results.html#chi-square",
    "title": "Clear communication = interpretable stats",
    "section": "Chi-square",
    "text": "Chi-square\nThis example from lecture was about surveying people to understand their priorities for restoration.\nAgain, generating fake data:\n\n\nCode\n# making a matrix (not a data frame) called `survey` ----\nsurvey &lt;- tribble(\n  ~distance, ~trails, ~dog_access, ~wildlife_habitat,\n  \"walking_distance\", 55, 38, 33,\n  \"driving_distance\", 41, 25, 29,\n  \"out_of_town\", 22, 27, 45\n) %&gt;% \n  \n  # turning the column `distance` into the matrix rownames ----\n  column_to_rownames(\"distance\")\n\n\n\nTest\n\n\nCode\nsurvey_test &lt;- chisq.test(survey)\n\n\nExample text:\nTo determine whether there was a relationship between living distance from wetland and restoration priority, we used a chi-square test using survey data from visitors (Table 1). Our null hypothesis was that there was no relationship between living distance from the wetland and restoration priority.\n\n\nTable\nExample caption:\nNote: Table captions usually go above the table.\n\nTable 1. Wetland restoration priority by living distance. Numbers in parentheses indicate proportion of responses (i.e. the 55 respondents living within walking distance of the wetland who prioritize trail development represent 44% of the total number of respondents living within walking distance (n = 126)).\n\n\n\nCode\n# calculate proportions\nsurvey_summary &lt;- survey %&gt;% \n  # turning `survey` into a data frame ----\n  as_tibble(rownames = \"distance\") %&gt;% \n  # making it long format\n  pivot_longer(cols = trails:wildlife_habitat, names_to = \"responses\", values_to = \"counts\") %&gt;% \n  \n  # calculating proportions ----\n  # grouping by living distance\n  group_by(distance) %&gt;% \n  # counting the total number of respondents per living distance\n  mutate(sum = sum(counts)) %&gt;% \n  # ungrouping to make sure that distance groups don't mess up downstream functions\n  ungroup() %&gt;% \n  # calculating proportion of responses per living distance\n  mutate(prop = counts/sum) %&gt;% \n  \n  # making the table look nicer ----\n  # making a new column where counts and proportions are displayed together\n  mutate(text = paste0(counts, \" (\", round(prop, digits = 2), \")\")) %&gt;% \n  # selecting columns of interest\n  select(distance, responses, text) %&gt;% \n  # making the data frame wider so that the columns are responses and rows are distance\n  pivot_wider(names_from = \"responses\", values_from = \"text\") %&gt;% \n  # making the row labels nicer\n  mutate(distance = case_match(\n    distance,\n    \"walking_distance\" ~ \"Walking distance\",\n    \"driving_distance\" ~ \"Driving distance\",\n    \"out_of_town\" ~ \"Out of town\"\n  )) %&gt;% \n  \n  # turning everything into a table ----\n  flextable() %&gt;% \n  # changing the column names to look nicer\n  set_header_labels(distance = \"Living distance\",\n                    trails = \"Trails\",\n                    dog_access = \"Dog access\",\n                    wildlife_habitat = \"Wildlife habitat\") %&gt;% \n  # making the table fit the viewer window\n  autofit()\n  \nsurvey_summary\n\n\nLiving distanceTrailsDog accessWildlife habitatWalking distance55 (0.44)38 (0.3)33 (0.26)Driving distance41 (0.43)25 (0.26)29 (0.31)Out of town22 (0.23)27 (0.29)45 (0.48)\n\n\n\n\n\n\n\n\nWarning\n\n\n\nRemember not to name code chunks with tables in them! Rendering gets stuck on the chunk if you do.\n\n\n\n\nTest results\n\n\nCode\nsurvey_test\n\n\n\n    Pearson's Chi-squared test\n\ndata:  survey\nX-squared = 15.276, df = 4, p-value = 0.004162\n\n\nExample text:\nBased on responses from individuals living within walking distance (n = 126), within driving distance (n = 95), and out of town (n = 94), restoration priorities differ significantly by living distance category (Table 1, \\(\\chi^2\\)(4) = 15.3, p = 0.004, \\(\\alpha\\) = 0.05).\nWhile the majority of residents within walking distance and driving distance prioritize trail use (44% and 43% respectively), residents outside the city prioritize wildlife habitat (48%).\nThese results indicate that wetland users living outside the city may have different intentions for visiting the wetland than local residents, but that restorationists can consider both trails and wildlife habitat in designing a restoration plan to suit user needs."
  },
  {
    "objectID": "resources/communicating-results.html#analysis-of-variance",
    "href": "resources/communicating-results.html#analysis-of-variance",
    "title": "Clear communication = interpretable stats",
    "section": "Analysis of variance",
    "text": "Analysis of variance\nThis example from lecture used the penguins data set from {palmerpenguins}.\n\nChecking assumptions\nFor ANOVA, you should be checking that your variable is normally distributed and that your groups have equal variances. You can check the first assumption visually using histograms and QQ plots:\n\n\nCode\n```{r penguin-hist-and-qq}\n#| fig.height: 12\n#| fig.width: 10\n#| out.width: 60%\n#| fig.align: center\n\n# setting some color options\ncol1 &lt;- \"cornflowerblue\"\ncol2 &lt;- \"orange\"\ncol3 &lt;- \"darkgreen\"\n\n# making separate data frames for each species\nadelie &lt;- penguins %&gt;% \n  filter(species == \"Adelie\")\n\nchinstrap &lt;- penguins %&gt;% \n  filter(species == \"Chinstrap\")\n\ngentoo &lt;- penguins %&gt;% \n  filter(species == \"Gentoo\")\n\n# making histograms for each species\n\nadelie_hist &lt;- ggplot(data = adelie, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 10, fill = col1, color = col1, alpha = 0.8) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 32)) +\n  labs(x = \"Bill length (mm)\", y = \"Count\",\n       title = \"A)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\nchinstrap_hist &lt;- ggplot(data = chinstrap, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 10, fill = col2, color = col2, alpha = 0.8) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 23)) +\n  labs(x = \"Bill length (mm)\", y = \"Count\",\n       title = \"C)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\ngentoo_hist &lt;- ggplot(data = gentoo, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 10, fill = col3, color = col3, alpha = 0.8) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 37)) +\n  labs(x = \"Bill length (mm)\", y = \"Count\",\n       title = \"E)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\n# making QQ plots for each species\nadelie_qq &lt;- ggplot(data = adelie, aes(sample = bill_length_mm)) +\n  stat_qq_line(linewidth = 1) +\n  stat_qq(col = col1) +\n  labs(x = \"Theoretical\", y = \"Sample\",\n       title = \"B)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\nchinstrap_qq &lt;- ggplot(data = chinstrap, aes(sample = bill_length_mm)) +\n  stat_qq_line(linewidth = 1) +\n  stat_qq(col = col2) +\n  labs(x = \"Theoretical\", y = \"Sample\",\n       title = \"D)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\ngentoo_qq &lt;- ggplot(data = gentoo, aes(sample = bill_length_mm)) +\n  stat_qq_line(linewidth = 1) +\n  stat_qq(col = col3) +\n  labs(x = \"Theoretical\", y = \"Sample\",\n       title = \"F)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\n# putting all the plots together using `patchwork`\n\n(adelie_hist + adelie_qq) / (chinstrap_hist + chinstrap_qq) / (gentoo_hist + gentoo_qq)\n```\n\n\n\n\n\n\n\n\n\nExample caption:\n\nFigure 2. Visual checks for normally distributed variable. Visual checks for normally distributed variable. A, C, E) Histograms of penguin bill length (mm) for Adelie (A), Chinstrap (C), and Gentoo (E) penguins. Bars represent counts of bill lengths in each bin. B, D, F) QQ plots of penguin bill length. Points in QQ plot represent sample quantiles compared against theoretical quantiles from a normal distribution. Solid black lines represent a 1:1 relationship between sample and theoretical quantiles.\n\nNow a series of Shapiro-Wilk tests to statistically test for normal distribution:\n\n\nCode\nshapiro.test(adelie$bill_length_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  adelie$bill_length_mm\nW = 0.99336, p-value = 0.7166\n\n\nCode\nshapiro.test(chinstrap$bill_length_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  chinstrap$bill_length_mm\nW = 0.97525, p-value = 0.1941\n\n\nCode\nshapiro.test(gentoo$bill_length_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  gentoo$bill_length_mm\nW = 0.97272, p-value = 0.01349\n\n\n\n\n\n\n\n\nMaking decisions about normality\n\n\n\n\n\nIn lecture, we talked about making a decision: do you think this deviation from normality is a big enough deal or not? ANOVA is fairly robust against violations of the normality assumption, and we have a lot of observations. We might decide to continue with the ANOVA (especially since the variances between groups are equal - see below). However, you could also try a transformation (e.g. a log transformation) on bill length, and see if that fixes your problem.\n\n\n\nChecking for equal variances:\n\n\nCode\nleveneTest(bill_length_mm ~ species, data = penguins)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)\ngroup   2  2.2425 0.1078\n      339               \n\n\nExample text:\n Prior to our analysis, we checked assumptions for analysis of variance. We tested for equality of variances between groups using Levene’s test and found no statistically significant differences in variances between groups (F(2, 339) = 2.24, p = 0.11, \\(\\alpha\\) = 0.05). We visually assessed normality using histograms and QQ plots (Figure 2) and statistically tested for normality of penguin bill length using Shapiro-Wilk tests for each species. Adelie and Chinstrap bill length did not indicate any deviations from normality (Adelie: W W = 0.99, p = 0.72; Chinstrap: W = 0.98, p = 0.19), but Gentoo bill length did (W = 0.97, p = 0.01). Taking this together, we decided to continue using analysis of variance given our sample size (n = 342) and that analysis of variance tends to be robust to slight violations of the normality assumption.Note that you only really need to state your \\(\\alpha\\) once in a report. The assumption is that you’re not changing your significance level for each test.\n\n\nTest\nANOVA:\n\n\nCode\npenguins_anova &lt;- aov(bill_length_mm ~ species, data = penguins)\n\n\nTukey HSD:\n\n\nCode\npenguins_HSD &lt;- TukeyHSD(penguins_anova)\n\n\nExample text:\nWe tested for differences between penguin species in bill length using analysis of variance. Our null hypothesis was that species did not differ in mean bill length. We used Tukey’s Honestly Significant Difference (Tukey HSD) as a post-hoc test to determine pair-wise differences between groups.\n\n\nTest results\n\n\nCode\npenguins_anova\n\n\nCall:\n   aov(formula = bill_length_mm ~ species, data = penguins)\n\nTerms:\n                 species Residuals\nSum of Squares  7194.317  2969.888\nDeg. of Freedom        2       339\n\nResidual standard error: 2.959853\nEstimated effects may be unbalanced\n2 observations deleted due to missingness\n\n\nANOVA table:\nExample caption:\n\nTable 2. ANOVA table. Bolded p-value indicates significance.\n\n\n\nCode\n# getting table from ANOVA object ----\ntidy(penguins_anova) %&gt;% \n  # changing very small p-values to &lt; 0.001\n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\"\n  )) %&gt;%\n  # rounding values in numerical columns to 1 decimal point\n  mutate(across(sumsq:statistic, ~ round(.x, digits = 1))) %&gt;% \n  # changing the row names to be nicer (capitalizing Species)\n  mutate(term = case_match(\n    term, \n    \"species\" ~ \"Species\",\n    .default = term\n  )) %&gt;% \n  \n  # turning the data frame into a flextable ----\n  flextable() %&gt;% \n  # changing the column names to be nicer\n  set_header_labels(term = \"Source of variation\",\n                    df = \"Degrees of freedom\",\n                    sumsq = \"Sum of squares\",\n                    meansq = \"Mean squares\",\n                    statistic = \"F-statistic\",\n                    p.value = \"p-value\") %&gt;% \n  # making small p-values bold\n  bold(~ p.value == \"&lt; 0.001\", 6) %&gt;% \n  # fitting the table to the viewer\n  autofit()\n\n\nSource of variationDegrees of freedomSum of squaresMean squaresF-statisticp-valueSpecies27,194.33,597.2410.6&lt; 0.001Residuals3392,969.98.8\n\n\nTukey HSD results:\n\n\nCode\npenguins_HSD\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = bill_length_mm ~ species, data = penguins)\n\n$species\n                      diff       lwr        upr     p adj\nChinstrap-Adelie 10.042433  9.024859 11.0600064 0.0000000\nGentoo-Adelie     8.713487  7.867194  9.5597807 0.0000000\nGentoo-Chinstrap -1.328945 -2.381868 -0.2760231 0.0088993\n\n\nExample text (if you decided not to make a table:\n We found a significant difference in bill length across species (analysis of variance, F(2, 339) = 410.6, p &lt; 0.001). Adelie penguins tend to have the shortest bills: on average, Gentoo penguins have 8.7 mm (Tukey HSD 95% confidence interval: [7.9, 9.6] mm) longer bills than Adelie penguins, and Chinstrap penguins have 10.0 mm ([9.0, 11.1] mm) longer bills than Adelie penguins.If you decide not to go with a table, the F-statistic, degrees of freedom, and p-value should be in parentheses. This is the only difference between this example and the one below.\nExample text (with a table):\nWe found a significant difference in bill length across species (Table 2). Adelie penguins tend to have the shortest bills: on average, Gentoo penguins have 8.7 mm (Tukey HSD 95% confidence interval: [7.9, 9.6] mm) longer bills than Adelie penguins, and Chinstrap penguins have 10.0 mm ([9.0, 11.1] mm) longer bills than Adelie penguins."
  },
  {
    "objectID": "resources/communicating-results.html#linear-models",
    "href": "resources/communicating-results.html#linear-models",
    "title": "Clear communication = interpretable stats",
    "section": "Linear models",
    "text": "Linear models\nThis first example was from lecture. We only talked about the equation and significant predictors, but I’ll break it down further here.\nGenerating data:\n\n\nCode\nset.seed(666)\n# sample size\nn &lt;- 64\nplant_df &lt;- tibble(\n  # predictor variables\n  temperature = round(rnorm(n = n, mean = 28, sd = 1), digits = 1),\n  light = round(rnorm(n = n, mean = 1, sd = 0.2), digits = 1),\n  ph = rnorm(n = n, mean = 7, sd = 0.01),\n  \n  # response: growth in cm/week\n  growth = light*rnorm(n = n, mean = 0.3, sd = 0.1) + temperature/round(rnorm(n = n, mean = 5, sd = 0.1))\n) \n\n\n\nBuilding a model\n\n\nCode\nplant_model &lt;- lm(growth ~ light + temperature + ph, data = plant_df)\n\n\nDiagnostics:\nI changed the chunk options for this to make sure it displayed correctly - see the code chunk! I also chose which plots to plot using the which() function, and added a title to each using title(). The syntax is a little different from a standard ggplot() figure because these are all done in base R, but labelling plots is an option.\n\n\nCode\n```{r plant-diagnostics}\n#| fig-width: 10\n#| fig-height: 10\n#| out.width: 90%\n#| fig.align: center\n\npar(mfrow = c(2, 2))\nplot(plant_model, which = c(1))\ntitle(\"A)\", adj = 0)\nplot(plant_model, which = c(2))\ntitle(\"B)\", adj = 0)\nplot(plant_model, which = c(3))\ntitle(\"C)\", adj = 0)\nplot(plant_model, which = c(5))\ntitle(\"D)\", adj = 0)\n```\n\n\n\n\n\n\n\n\n\nExample caption:\n\nFigure 3. Model diagnostic plots. In all plots, points represent residuals. Red lines (residuals vs fitted, scale-location, and residuals vs leverage) are lines depicting patterns in residuals. Grey dashed lines represent reference lines.\n\nExample text:\nWe tested the predictive relationship between plant growth and light, temperature, and soil pH using a linear model. Our null hypothesis was that none of these variables would predict plant growth. We used diagnostic plots to visually assess residual normality (Figure 3B) and homoskedasticity (Figures 3A and 3C). Additionally, we determined there were no outliers influencing our model predictions using Cook’s distance (Figure 3D).\n\n\nModel predictions\nJust to see what the original summary object is:\n\n\nCode\nsummary(plant_model)\n\n\n\nCall:\nlm(formula = growth ~ light + temperature + ph, data = plant_df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23209 -0.06571  0.01010  0.06173  0.19950 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -6.67140    6.80194  -0.981    0.331    \nlight        0.35196    0.05939   5.926 1.63e-07 ***\ntemperature  0.19626    0.01058  18.558  &lt; 2e-16 ***\nph           0.96241    0.96806   0.994    0.324    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0911 on 60 degrees of freedom\nMultiple R-squared:  0.8759,    Adjusted R-squared:  0.8696 \nF-statistic: 141.1 on 3 and 60 DF,  p-value: &lt; 2.2e-16\n\n\nTable option 1:\n\nTable 3. Model prediction table. Bolded p-value indicates significant difference from 0.\n\n\n\nCode\nplant_model %&gt;%\n  # turning the model object into a flextable ----\n  as_flextable() %&gt;% \n  \n  # changing the row labels using `compose()` ----\n  # i selects the row, j selects the column\n  compose(i = 2, j = 1, \n          # value is whatever you want to change the text to\n          value = as_paragraph(\n            # `as_sup()` makes something a superscript - good for units etc.\n            \"Light (watts/m\", as_sup(\"2\"), \")\"\n          )) %&gt;% \n  compose(i = 3, j = 1, \n          value = as_paragraph(\n            \"Temperature (°C)\"\n          )) %&gt;% \n  compose(i = 4, j = 1, \n          value = as_paragraph(\n            \"pH\"\n          )) %&gt;% \n  \n  # formatting the numbers to display to 3 decimal points ----\n  set_formatter(estimate = function(x) sprintf(\"%.03f\", x),\n                std.error = function(x) sprintf(\"%.03f\", x),\n                statistic = function(x) sprintf(\"%.03f\", x),\n                p.value = function(x) sprintf(\"%.03f\", x)) %&gt;% \n  \n  # changing the p.value to display as &lt; 0.001 when very small ----\n  compose(j = \"p.value\", i = ~ p.value &lt; 0.001,\n          value = as_paragraph(\n            \"&lt; 0.001\"\n          )) %&gt;% \n  \n  # adding model equation at the top ----\n  # inserting new header row (to make space for equation)\n  add_header_lines(\"\", top = TRUE) %&gt;% \n  # putting in equation\n  compose(\n    # choosing row 1, column 1, indicating that is a header\n    j = 1, i = 1, part = \"header\",\n    # putting in the equation using as_equation and extract_eq from {equatiomatic}\n    value = as_paragraph(\n      as_equation(extract_eq(plant_model), \n                  # formatting equation\n                  width = 2, height = .5)\n    )) %&gt;% \n  # making sure the equation is centered on the table\n  align(i = 1, part = \"header\", align = \"center\") %&gt;% \n  \n  # formatting header labels ----\n  set_header_labels(statistic = \"t-statistic\",\n                    p.value = \"p-value\") %&gt;% \n  \n  # making cells bold when p.value &lt; 0.05 ----\n  bold(i = ~ p.value &lt; .05, j = \"p.value\") %&gt;% \n  \n  # making table fit viewer ----\n  autofit()\n\n\n\ngrowth⁡=α+β1(light⁡)+β2(temperature⁡)+β3(ph⁡)+ϵ\\operatorname{growth} = \\alpha + \\beta_{1}(\\operatorname{light}) + \\beta_{2}(\\operatorname{temperature}) + \\beta_{3}(\\operatorname{ph}) + \\epsilongrowth=α+β1​(light)+β2​(temperature)+β3​(ph)+ϵEstimateStandard Errort-statisticp-value(Intercept)-6.6716.802-0.9810.331   Light (watts/m2)0.3520.0595.926&lt; 0.001***Temperature (°C)0.1960.01118.558&lt; 0.001***pH0.9620.9680.9940.324   Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05Residual standard error: 0.0911 on 60 degrees of freedomMultiple R-squared: 0.8759, Adjusted R-squared: 0.8696F-statistic: 141.1 on 60 and 3 DF, p-value: 0.0000\n\n\n\n\n\n\n\n\nIncluding tables and full tables with {flextable}\n\n\n\n\n\nWhen writing about models, you have to make decisions about whether or not you want to include a table of the model summary. In multiple linear regression (and for more complex models), it’s a good idea to include a table of the model summary.\nIf you wanted to make a table of the model estimates and the relevant information at the bottom of that summary (for example, \\(R^2\\), F-statistic, degrees of freedom, etc.), you could use flextable::as_flextable() which takes the model object - this is Table 3. This skips the step of creating an intermediate data frame and just turns everything into a flextable object. However, this can be a bit tricky: the formatting to make it look “good” takes some getting used to. You can go either way, but this is one option if you’d rather condense the information from the model prediction table and ANOVA table into one. It is also somewhat easier to interpret than the model prediction + ANOVA table combo (Tables 4 + 5).\n\n\n\nTable option 2:\nTable 4. Model prediction table. Bolded p-value indicates significance.\n\n\nCode\nplant_model %&gt;% \n  tidy() %&gt;% \n  mutate(across(estimate:p.value, ~round(.x, digits = 3))) %&gt;% \n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\",\n    TRUE ~ as.character(p.value)\n  )) %&gt;% \n  flextable() %&gt;% \n  # changing the row labels using `compose()`\n  compose(i = 2, j = 1, \n          value = as_paragraph(\n            \"Light (watts/m\", as_sup(\"2\"), \")\"\n          )) %&gt;% \n  compose(i = 3, j = 1, \n          value = as_paragraph(\n            \"Temperature (°C)\"\n          )) %&gt;% \n  compose(i = 4, j = 1, \n          value = as_paragraph(\n            \"pH\"\n          )) %&gt;% \n  # formatting header labels\n  set_header_labels(term = \"Term\",\n                    estimate = \"Estimate\",\n                    std.error = \"Standard error\",\n                    statistic = \"t-statistic\",\n                    p.value = \"p-value\") %&gt;% \n  bold(j = 5, i = ~p.value == \"&lt; 0.001\") %&gt;% \n  autofit()\n\n\nTermEstimateStandard errort-statisticp-value(Intercept)-6.6716.802-0.9810.331Light (watts/m2)0.3520.0595.926&lt; 0.001Temperature (°C)0.1960.01118.558&lt; 0.001pH0.9620.9680.9940.324\n\n\nANOVA table:\nTable 5. Model ANOVA table. Bolded p-value indicates significant difference from 0.\n\n\nCode\nAnova(plant_model) %&gt;% \n  tidy() %&gt;% \n  mutate(across(sumsq:p.value, ~round(.x, digits = 3))) %&gt;% \n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\",\n    TRUE ~ as.character(p.value)\n  )) %&gt;% \n  flextable() %&gt;% \n  # changing the row labels using `compose()`\n  compose(i = 1, j = 1, \n          value = as_paragraph(\n            \"Light (watts/m\", as_sup(\"2\"), \")\"\n          )) %&gt;% \n  compose(i = 2, j = 1, \n          value = as_paragraph(\n            \"Temperature (°C)\"\n          )) %&gt;% \n  compose(i = 3, j = 1, \n          value = as_paragraph(\n            \"pH\"\n          )) %&gt;% \n  # formatting header labels\n  set_header_labels(term = \"Source of variation\",\n                    sumsq = \"Sum of squares\",\n                    df = \"Degrees of freedom\",\n                    statistic = \"F-statistic\",\n                    p.value = \"p-value\") %&gt;% \n  bold(j = 5, i = ~p.value == \"&lt; 0.001\") %&gt;% \n  autofit()\n\n\nSource of variationSum of squaresDegrees of freedomF-statisticp-valueLight (watts/m2)0.291135.122&lt; 0.001Temperature (°C)2.8581344.412&lt; 0.001pH0.00810.9880.324Residuals0.49860\n\n\n\n\nVisualization\n\n\nCode\ntemp_pred &lt;- ggpredict(plant_model, terms = \"temperature\")\n\nlight_pred &lt;- ggpredict(plant_model, terms = \"light\")\n\ntemp_plot &lt;- ggplot(data = plant_df, aes(x = temperature, y = growth)) +\n  geom_point() +\n  geom_ribbon(data = temp_pred, aes(x = x, y = predicted, ymin = conf.low, ymax = conf.high), alpha = 0.2) +\n  geom_line(data = temp_pred, aes(x = x, y = predicted), color = \"blue\", linewidth = 1) +\n  theme_classic() +\n  labs(x = \"Temperature (°C)\", y = \"Growth (cm/week)\",\n       title = \"A)\") +\n  theme(plot.title.position = \"plot\",\n        text = element_text(size = 15))\n\nlight_plot &lt;- ggplot(data = plant_df, aes(x = light, y = growth)) +\n  geom_point() +\n  geom_ribbon(data = light_pred, aes(x = x, y = predicted, ymin = conf.low, ymax = conf.high), alpha = 0.2) +\n  geom_line(data = light_pred, aes(x = x, y = predicted), color = \"darkorange\", linewidth = 1) +\n  theme_classic() +\n  labs(x = expression(paste(\"Light (watts/\"~m^2~\")\")), y = \"Growth (cm/week)\",\n       title = \"B)\") +\n  theme(plot.title.position = \"plot\",\n        text = element_text(size = 15))\n\ntemp_plot + light_plot\n\n\n\n\n\n\n\n\n\nExample caption:\n\nFigure 4. Predicted growth as a function of A) temperature and B) light. In both panels, points represent observations, colored lines represent model predictions, and shaded areas represent 95% confidence intervals. In A), growth is predicted as a function of temperature for a constant light level of 0.98 watts/m2 and pH 7. In B), growth is predicted as a function of light for a constant temperature of 27.9 °C and pH 7.\n\n\n\n\n\n\n\nUnderstanding predictions\n\n\n\n\n\nRemember that for multiple linear regression, the slopes represent change in the response variable for each 1 unit change in the predictor for all else held constant. When getting model estimates for slopes, the “constant” values are the mean of the variable. When using ggeffects::ggpredict(), these values are printed below the prediction table (you can double check this by calculating the mean yourself!).\n\n\n\n\n\nTest results\nExample text:\nWe found that light and temperature significantly predicted plant growth, but not pH (Table 3). The overall model accounted for 87% of the variance in plant growth. For each 1 °C increase in temperature at constant light and pH, we expect 0.20 \\(\\pm\\) 0.01 increase in plant growth (Figure 4A). For each 1 watt/m2 increase in light at constant temperature and pH, we expect a 0.35 \\(\\pm\\) 0.06 increase in plant growth (Figure 4B).\n\n\n\n\n\n\nChoosing which parameters to highlight\n\n\n\n\n\nWith multiple linear regression and generalized linear models, you’re usually working with pretty complex model structure. It’d be impossible (and not that interesting, necessarily) to discuss all the predictors. You can choose which one(s) you want to highlight in your visualizations and text based on what you think is most interesting/biologically relevant."
  },
  {
    "objectID": "lecture.html",
    "href": "lecture.html",
    "title": "Lecture visualizations",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nLecture 10 figures\n\n\nJun 5, 2023\n\n\n\n\nLecture 08 figures\n\n\nMay 22, 2023\n\n\n\n\nLecture 07 figures\n\n\nMay 15, 2023\n\n\n\n\n\nLecture 06 figures\n\n\n\nMay 8, 2023\n\n\n\n\n\nLecture 05 figures\n\n\nMay 1, 2023\n\n\n\n\nLecture 04 figures\n\n\nApr 24, 2023\n\n\n\n\n\nLecture 03 figures\n\n\n\nApr 17, 2023\n\n\n\n\n\n\nLecture 02 figures\n\n\n\nApr 10, 2023\n\n\n\n\n\nLecture 01 figures\n\n\nApr 3, 2023\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "homework/homework-02_starter-code.html",
    "href": "homework/homework-02_starter-code.html",
    "title": "homework 2 starter code",
    "section": "",
    "text": "# directions: comment each line of code with:  \n# 1) what package the function comes from\n# 2) what the function does\n# 3) how the data frame changes after running that function\ndata &lt;- read.csv(\"Newman_etal_JAPPL_California_chaparral_birds_2017.csv\") %&gt;% \n  # \n  clean_names() %&gt;% \n  # \n  mutate_all(tolower) %&gt;% \n  #\n  mutate(surv_date_stable = as_date(surv_date_stable)) %&gt;% \n  #\n  mutate(grow_year = as_factor(grow_year))"
  }
]