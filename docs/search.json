[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nFinalizing plots\n\n\ntips for making your plots readable and professional\n\n\n\n\nClear communication = interpretable stats\n\n\nCommunicating about statistical results, a few ways\n\n\n\n\nUsing the virtual machine\n\n\nGeneral use\n\n\n\n\nCitations in RStudio\n\n\nusing the visual editor to add citations using a DOI\n\n\n\n\nSetting up GitHub pages\n\n\nsimple options to turn your repository into a website\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "weekly-materials/week01.html",
    "href": "weekly-materials/week01.html",
    "title": "Week 1 materials",
    "section": "",
    "text": "Lecture\n [Slides]  [Slides with annotations]  Lecture figures\n\n\nWorkshop\n\n\nAssignments\n\n\n\n\n\n\nCitationBibTeX citation:@online{bui2024,\n  author = {Bui, An},\n  title = {Week 1 Materials},\n  date = {2024-04-01},\n  url = {https://spring-2024.envs-193ds.com/weekly-materials/week01},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2024. “Week 1 Materials.” April 1, 2024. https://spring-2024.envs-193ds.com/weekly-materials/week01."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to ENVS 193DS, Spring 2024!",
    "section": "",
    "text": "Artwork by @allison_horst\n\n\nCourse description\nEnvironmental scientists use data to understand the world around them. In this class, we’ll learn about the tools used in environmental science and beyond to work with, analyze, and communicate about data.\nBy the end of the quarter, students will be able to:\n1. Describe basic concepts of probability and statistics\n2. Identify appropriate statistical analyses to test hypotheses\n3. Conduct statistical analyses and visualize data using the R programming language\n4. Implement best practices for reproducible analysis and collaborative work\n5. Interpret and contextualize statistical results in general concepts from environmental studies\n\n\nInstructional team\n\n\n\nInstructor: An Bui\nEmail: an_bui [at] ucsb.edu\nDrop-in hours: Wednesdays 3:30 - 5:30 PM\nDrop-in location: At the tables outside the UCen 1st floor (facing the lagoon)\nMore about me: an-bui.com\n\n\n\n\nTA: Caitlin Nordheim-Maestas\nEmail: caitlinnordheim [at] ucsb.edu\nDrop-in hours: Tuesdays 9:30 - 10:30 AM\nDrop-in location: Noble Hall 2201\nMore about me: cnordheim-maestas.github.io\n\n\n\nAcknowledgements\nI took much of my inspiration for this course from Allison Horst’s Environmental Data Science and Statistics course, Sam Sambado’s Biometry course, and Sam Csik’s Data Visualization and Communication course."
  },
  {
    "objectID": "resources/adding-citations.html",
    "href": "resources/adding-citations.html",
    "title": "Citations in RStudio",
    "section": "",
    "text": "Note: my understanding is that this works in Quarto and RMarkdown. But give it a try!\n\n1. Use the visual editor.\n\n\n\n2. Insert a citation.\nNavigate to Insert &gt; Citation.\n\n\n\n3. Find the paper DOI.\nDOI stands for Digital Object Identifier. It’s essentially a permanent identification number for papers, databases, etc. Pretty much all papers have a DOI, and they’re usually at the top of the page somewhere. Copy the text after the “https://doi.org/” part (that’s the DOI).\n\n\n\n4. Insert the DOI into the citation box in RStudio.\nSelect “From DOI”. Paste the DOI into the box and hit “Search”. The paper title, author, and other information should pop up.\nAt the bottom of the box, there will be an option to create a references.bib file. This is the file where all your citations will live. Note: it is important that the references.bib file is in the same folder as your script - this will happen automatically, but it’s good to double check!\nMake sure “In-text” is checked. Hit “Insert”.\n\n\n\n5. Marvel at your citation!\nOnce you look back at your script, you should see 1) something like @authorname in the text where you wanted to insert your citation, 2) bibliography: references.bib in the YAML, and 3) a references.bib file in the folder where your script is. In your script, put that citation in brackets. This is what it looks like in the visual editor:\n\nAnd in the source editor:\n\n\n\n6. Render your document.\nWhenever you’re ready, you can render/knit your document. It should have your citation in parentheses and the citation for the paper at the bottom of the page.\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{bui2023,\n  author = {Bui, An},\n  title = {Citations in {RStudio}},\n  date = {2023-06-01},\n  url = {https://an-bui.github.io/ES-193DS-W23/resources/adding-citations.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2023. “Citations in RStudio.” June 1, 2023. https://an-bui.github.io/ES-193DS-W23/resources/adding-citations.html."
  },
  {
    "objectID": "resources/using-virtual-machine.html",
    "href": "resources/using-virtual-machine.html",
    "title": "Using the virtual machine",
    "section": "",
    "text": "1. What is the virtual machine?\nFor this class, we have a virtual machine: it allows you to run R and RStudio in a browser (e.g. Google Chrome, Safari, Firefox). Find the virtual machine here!\nThe benefits of using the virtual machine are plenty:\n\nyou don’t have to download R, RStudio, and Quarto\n\nthe versions of all the software you need are updated\n\nthe packages you need for the class are already installed\n\nyou can download everything you’ve worked on\n\nand more!\nThe one con is that you do need to be connected to the internet. But compared to the benefits, this is hopefully not a major hurdle.\nBasically, if you’re having any issues with your versions of R, RStudio, or Quarto, try running your code on the virtual machine.\n\n\n2. Logging in and opening things up\nOnce you open up the virtual machine, you’ll be asked to log in. Use your UCSB email to do that. You should then get a screen that looks like this:\n Click RStudio.\nYou should then see a screen that looks exactly like an RStudio screen!\n\n\n\n3. Setting up\nIf you’re opening this up for the first time, do task 3 in the Getting set up guide: Change your workspace save settings.\n\n\n4. Getting files into the machine\nDownload the zipped file of workshop materials from Canvas. Hit the Upload button (yellow arrow pointing up against a white paper). You should see a window that looks like this:\n\nHit Choose file and select the .zip file.\nThe machine will automatically unzip the file and create a new folder with all the file contents.\n\n\n\n5. Creating a project\nWe’re going to create a lot of Rprojects in this class to get used to it. You can create a project in an existing directory (aka folder) in the same way that you would in the desktop version of RStudio. Go to the button in the top left that says Project: (None) and click. Hit New Project.\n Then, select the “Existing Directory” option.\n\nYou should now see the new Rproject in two locations: 1) in the upper left and 2) in the list of files in your directory.\n\n\n\n6. Downloading your files\nIf you want to hold onto your files on your computer, you can download a whole directory. Click on the folder you want to download and go to More &gt; Export in the lower right pane.\n\nThe machine will download the whole folder as a .zip file, which you can then unzip on your computer."
  },
  {
    "objectID": "resources/github-pages.html",
    "href": "resources/github-pages.html",
    "title": "Setting up GitHub pages",
    "section": "",
    "text": "Why set up GitHub pages?\nIf you render/knit your documents to html, someone else who wants to see your document will have to fork/clone your repo into their computer, and open up your html document. By setting up GitHub pages, you can essentially make your repository into a website and create a URL to your rendered html document. Then, if you want to share your code, someone can just look at the page on that URL and not have to deal with your whole repository.\nIn class, we walked through the simplest way to set up GitHub pages. However, there are lots of advanced options to make your repository into a website. For example, in CHOYOA 2, you’ll set some different options when you set up GitHub pages.\n\n\n1. Create a new repository on GitHub\nMake sure you have the repository set to be public and that you are adding a README.\n\n\n\n2. Set up GitHub pages\nNavigate to the main page of your repository. Click on Settings &gt; Pages. Select your main branch as the deployed branch. Click save.\n\nYou know that this worked if you get a message at the top of the window saying “GitHub Pages source saved.”\n\n\n3. Clone your repo to your computer and create some code.\nIn the demo, we put all our code into a new folder in the repo called code. Then, create a new Quarto/RMarkdown document and make sure it is saved as either an HTML (ideal) or a PDF (also works but not as aesthetically pleasing). Save that document in the code folder.\n\n\n\n4. Adjust the YAML options.\nThere are lots of document options you can adjust in the metadata. In class, we went through how to set global options for code chunks using execute:.\n\nIn RMarkdown: this happens in the knitr set up chunk:\n\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\n\n\n\n5. Render/knit your code.\nNote the file path for the .qmd document is: code/newcode.qmd. That means the file path for the .html document is: code/newcode.html.\n\n\n\n6. Stage/commit/push those changes\nIf you are using Quarto, you’ll see a lot of files for the rendered plots, formatting options, etc. If you are using RMarkdown, you won’t. This is just a little difference between Quarto and RMarkdown.\n\n\n\n7. Return to GitHub and look at the environment\nGo back to your repository on GitHub. You should see two visual cues that this has worked:\n1. You have a brown circle by your most recent commit. This corresponds to what’s happening in…\n2. The “Environments”. You will see github-pages marked as “active”.\n\n\n\n8. Check the deployment\nClick on github-pages under Environments. You should see that the deployment (your commit/push) shows up as “Queued”. This will eventually turn into “In Progress”, then “Active”.\n\nNote: depending how how many other actions are happening on GitHub at any given time, this may take a couple minutes. Be patient! Eventually it will be active.\n\n\n9. Look at the your rendered document!\nYour deployed repository will have the URL your-github-username.github.io/repository-name. In this example, the URL is an-bui.github.io/my-repository.\nTo find your rendered html document, use the file path as your URL. In this example, the file path to the rendered document is code/newcode.html. This means the URL for the .html on my deployed repository is an-bui.github.io/my-repository/code/newcode.html.\n\nNote: sometimes it’s useful to link this URL in the README!\n\n\nexample repo\nThe repo for this example is here.\n\n\n\n\n\n\nCitationBibTeX citation:@online{bui2023,\n  author = {Bui, An},\n  title = {Setting up {GitHub} Pages},\n  date = {2023-05-17},\n  url = {https://an-bui.github.io/ES-193DS-W23/resources/github-pages.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2023. “Setting up GitHub Pages.” May 17, 2023. https://an-bui.github.io/ES-193DS-W23/resources/github-pages.html."
  },
  {
    "objectID": "assignments/optional-problem-02.html",
    "href": "assignments/optional-problem-02.html",
    "title": "OPTIONAL practice problem - One sample t-test",
    "section": "",
    "text": "In this optional problem, you’ll try a one-sample t-test in code. In lecture, we talked about the different values you’ll want to keep in mind: the tstatistic, the p-value, the tcritical, and the significance level (or \\(\\alpha\\))."
  },
  {
    "objectID": "assignments/optional-problem-02.html#description",
    "href": "assignments/optional-problem-02.html#description",
    "title": "OPTIONAL practice problem - One sample t-test",
    "section": "",
    "text": "In this optional problem, you’ll try a one-sample t-test in code. In lecture, we talked about the different values you’ll want to keep in mind: the tstatistic, the p-value, the tcritical, and the significance level (or \\(\\alpha\\))."
  },
  {
    "objectID": "assignments/optional-problem-02.html#creosote-heights",
    "href": "assignments/optional-problem-02.html#creosote-heights",
    "title": "OPTIONAL practice problem - One sample t-test",
    "section": "2. Creosote heights",
    "text": "2. Creosote heights\n\n\n\n\n\nYou overhear a conversation where someone makes a claim that creosote (Larrea tridentata) shrubs are 3 m tall. On your next walk through the desert, you decide to measure some shrubs (n = 40). From these 40 shrubs, you calculate the following summary statistics:\n\\[\n\\begin{align}\n\\bar{y} &= 1.8 m \\\\\ns &= 0.26 m\n\\end{align}\n\\]\nUsing your sample, you ask: how does my sample compare to the claim that I heard?\nFor this problem, use a 95% confidence level with the corresponding significance level for a two tailed test."
  },
  {
    "objectID": "assignments/optional-problem-02.html#steps",
    "href": "assignments/optional-problem-02.html#steps",
    "title": "OPTIONAL practice problem - One sample t-test",
    "section": "3. Steps",
    "text": "3. Steps\n\nDraw a t-distribution and label the tcritical and the significance level.\n\nCreate a script or Quarto document to work in.\n\nCopy/paste the code in the Set up code chunk into your script. Run the code.\n\nWrite your hypotheses in biological and statistical terms.\n\nCalculate the tstatistic using the test statistic formula for a one sample t-test.\n\nCalculate the tcritical using qt().\nCalculate the p-value for your test statistic using pt().\n\nDraw the tstatistic and p-value on your distribution from step 0. Take a moment to think: do you have evidence to suggest that creosote shrubs are not 3 m tall?\n\nUse t.test() to verify that your calculations from steps 3-5 are correct.\n\nIn one sentence, summarize your findings.\n\n\nSet up code\n\n# read in the tidyverse\nlibrary(tidyverse)\n\n# data\ncreosote &lt;- c(1.61, 1.86, 1.55, 2.28, 1.90, \n              1.55, 1.95, 2.02, 1.97, 1.71,\n              2.25, 1.92, 1.61, 1.14, 2.14, \n              1.79, 1.80, 2.08, 2.05, 1.98, \n              2.08, 2.03, 1.82, 1.20, 1.99,\n              1.78, 1.75, 1.36, 1.66, 1.93,\n              2.21, 1.77, 1.92, 1.78, 1.39,\n              1.68, 1.68, 1.78, 2.13, 2.03)"
  },
  {
    "objectID": "assignments/optional-problem-02.html#solution",
    "href": "assignments/optional-problem-02.html#solution",
    "title": "OPTIONAL practice problem - One sample t-test",
    "section": "3. Solution",
    "text": "3. Solution\n\n0. draw a t-distribution and label\nYou should do this by hand, but this is just here for reference.\n\n# calculating t-critical (need this for the plot)\nt_critical &lt;- qt(p = 0.05/2, df = 40 - 1, lower.tail = FALSE)\n\n# plotting the distribution\ntdist_plot &lt;- ggplot(data.frame(x = -5:5), aes(x)) +\n  \n  # first plotting the shaded areas under the curve (significance level)\n  # this is the area to the right\n  stat_function(geom = \"area\", \n                fun = dt, \n                args = list(df = 1), \n                xlim = c(t_critical, 30), \n                fill = \"darkgrey\") +\n  # this is the area to the left\n  stat_function(geom = \"area\", \n                fun = dt, \n                args = list(df = 1), \n                xlim = c(-30, -t_critical), \n                fill = \"darkgrey\") +\n  \n  # then, plotting the boundaries at the critical t value: 2.022\n  # this is the line on the right\n  annotate(geom = \"linerange\", \n           x = t_critical, \n           ymin = 0, \n           ymax = 0.065, \n           linewidth = 1, \n           lty = 2, \n           color = \"#000000\") +\n  # this is the line on the left\n  annotate(geom = \"linerange\", \n           x = -t_critical, \n           ymin = 0, \n           ymax = 0.065, \n           linewidth = 1, \n           lty = 2, \n           color = \"#000000\") +\n  \n  # lastly, plot the t-distribution\n  stat_function(geom = \"line\", \n                n = 1000, \n                fun = dt, \n                args = list(df = 1), \n                linewidth = 1, \n                color = \"#000000\") +\n  \n  # controlling plot aesthetics\n  scale_x_continuous(limits = c(-10, 10)) +\n  scale_y_continuous(expand = c(0, 0), \n                     limits = c(0, 0.32)) +\n  theme_void() +\n  theme(panel.grid = element_blank(),\n        plot.margin = unit(c(1, 0, 0, 0), \"cm\"))\n\ntdist_plot\n\n\n\n\n\n\n\n\nIn this plot, the dashed line is the tcritical, and the shaded areas are the significance level. They are split between the two tails because this is a two tailed test (not directional).\n\n\n3. Write your hypotheses in biological and statistical terms.\n\nBiological\nCreosote shrub height is different from the claim.\n\n\nStatistical\nH0: Mean creosote shrub height is 3 m.\nHA: Mean creosote shrub height is not 3 m.\n\n\n\n4. Calculate the t-statistic.\n\n# claimed mean\nmu &lt;- 3\n\n# number of observations\nn &lt;- length(creosote)\n\n# sample mean\nybar &lt;- mean(creosote)\n\n# sample standard deviation\ns &lt;- sd(creosote)\n\n# sample standard error\nse &lt;- s/sqrt(n)\n\n# t-score\nt &lt;- (ybar-mu)/se\n\nt\n\n[1] -27.84555\n\n\n\n\n5. Calculate tcritical\n\nt_critical &lt;- qt(p = 0.05/2, df = n - 1, lower.tail = FALSE)\n\nt_critical\n\n[1] 2.022691\n\n\n\n\n6. Calculate the p-value\n\n2*pt(q = t, df = n - 1, lower = TRUE)\n\n[1] 2.390222e-27\n\n\n\n\n7. Draw the tstatistic and p-value\n\ntdist_plot +\n\n  # this is the line on the right\n  annotate(geom = \"linerange\", \n           x = t, \n           ymin = 0, \n           ymax = 0.3, \n           linewidth = 1, \n           color = \"#239a89\") +\n  # this is the line on the left\n  annotate(geom = \"linerange\", \n           x = -t, \n           ymin = 0, \n           ymax = 0.3, \n           linewidth = 1, \n           color = \"#239a89\") +\n  scale_x_continuous(limits = c(-30, 30))\n\n\n\n\n\n\n\n\nIn this plot, the teal lines represent the tstatistic. They are way way way past the tcritical. I’m not plotting the p-value here, because I know for sure that the threshold has been met for me to think, “It’s so unlikely that these creosote shrubs come from a population with a mean height of 3 m that I actually think they came from a population with a different mean height.”\n\n\n8. Use t.test()\n\nt.test(creosote, mu = 3)\n\n\n    One Sample t-test\n\ndata:  creosote\nt = -27.846, df = 39, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 3\n95 percent confidence interval:\n 1.743134 1.913366\nsample estimates:\nmean of x \n  1.82825 \n\n\n\n\n9. Report your findings\nWe tested the hypothesis that creosote height was different from the claim of 3 m. We measured the height of 40 creosote shrubs and found a significant difference between our sample and the claim (two-tailed one sample t-test, t(39) = -27.8, p &lt; 0.001, \\(\\alpha\\) = 0.05).\n\n\n\n\n\n\nReporting your findings\n\n\n\nFor most tests, the information in the parentheses would be:\n(test, distribution(degrees of freedom) = test statistic, p-value, \\(\\alpha\\)).\nThis changes slightly based on the test, but this is the general form."
  },
  {
    "objectID": "assignments/reflection-01.html",
    "href": "assignments/reflection-01.html",
    "title": "Reflection 1",
    "section": "",
    "text": "Due on Wednesday April 10 (Week 2) at 11:59 PM\nIn this assignment, you’ll introduce yourself and come up with a plan for what you’d like to get out of the class and roughly outline what you’d like to accomplish over the course of the quarter. You’ll continue visiting the goals you set for yourself in this assignment throughout the quarter, so it’s worth it to be as clear and specific as you can."
  },
  {
    "objectID": "assignments/reflection-01.html#components",
    "href": "assignments/reflection-01.html#components",
    "title": "Reflection 1",
    "section": "Components",
    "text": "Components\n\nA brief introduction\n\nyour name\n\nyour major\nyour year\n\npronouns (only if you feel comfortable sharing)\n\n\n\nSome questions about school and life\n\nWhy are you taking this class?\n\nWhat do you hope to get out of this class?\n\nIf you have a career in mind, how does this course apply to your future career, if at all?\n\nWhat do you wish your instructors knew about you, but don’t?\n\n\n\nSome questions about the way you like to learn\n\nWhat kinds of assignments, skills, or behaviors have you felt most comfortable with/enjoy from past classes? Why do you enjoy them?\n\nHow confident do you feel in your statistics skills (however you want to interpret that)? Why?\n\nHow confident do you feel in your coding skills (again, however you want to interpret that)? Why?\n\nWhat have you struggled with in the past in math or statistics courses? Why?\n\nOf the courses you’re taking this quarter, which do you expect to be the most challenging? Most demanding?\n\nWhich learning goals from the syllabus are you most excited about?\n\nWhat other learning goals do you have for the course?\n\nMost importantly, how do you plan on accomplishing your learning goals for this course?\n\n\n\n\n\n\n\nNote\n\n\n\nBe specific here! Instead of writing, “I will complete homework assignments” or “I will study”, you can make these more specific strategies: “I will use the homework assignments as opportunities for practice. I will communicate with classmates for help after trying…”\n\n\n\n\nChecklist\nYour reflection should include\n\nyour name, major, and year (if you feel comfortable, please also include the pronouns you want to be used)\n\n1-2 sentences in response to each point (Note: you can copy/paste the questions into a document and fill them out like a form!)"
  },
  {
    "objectID": "assignments/getting-set-up.html",
    "href": "assignments/getting-set-up.html",
    "title": "Getting set up",
    "section": "",
    "text": "Optional check in due on Wednesday April 3 (Week 1) at 11:59 PM\nIn this class, we’ll be using R and RStudio to code up our statistical analyses. Walk through these steps to make sure you have both programs on your computer and that everything is working properly. You need to make sure these tasks are completed before workshop on Thursday.\n\n\n\n\n\n\nDo these set up steps as soon as possible!\n\n\n\nEveryone needs to do tasks 1 - 7. If you want to submit the optional check-in for Caitlin/An to verify that you’ve done things correctly, you can do task 8 and submit your screenshot on Canvas.\nIf you do not have R, RStudio, and Quarto installed and running, we cannot stop for you. Do this before class starts!\n\n\n\nTask 1. Install R, RStudio, and Quarto\nIf you already have both things installed, great. If not, follow these instructions:\n\nFor MacOS, do set up steps 1-3 here\n\nFor Windows, do set up steps 1-3 here\n\n\n\n\n\n\n\nInstalling Quarto\n\n\n\nIf you cannot install Quarto on your computer (because it doesn’t work with your operating system, etc.), that is fine - you just might have some differences between what we do in class and what you see on your own computer.\n\n\n\n\n\n\n\n\nUpdating existing programs\n\n\n\nYou may want to update your R and RStudio version if you haven’t used either in the last year or so. If not, some of the packages we use in the class might not work with your set up.\n\n\n\n\nTask 2. Open RStudio\nWhen we say we’re “using R” in the class, what we’re really using is RStudio, which is a graphical user interface (GUI) for R (the language). Basically, we’re never going to open up “R”, but we’ll always open up “RStudio”.\nOpen RStudio on your computer.\n\n\nTask 3. Change your workspace save settings\nWhen you’re using RStudio, you’ll get the option to “save your workspace” if you close out of the program. We’re going to make sure you don’t do that, because we want to make sure our code runs independently of any old information that was saved on your computer from RStudio.\nGo to Tools &gt; Global Options &gt; General and make sure that:\n\n“Restore .Rdata into workspace at startup” is unchecked\n\n“Save workspace to .RData on exit” is on “Never”\n\nHit “Apply”.\n\n\n\n\n\n\n\nTask 4. Change your color scheme\nYou don’t have to stick with the boring RStudio color scheme! Go to Appearance (from Tools &gt; Global Options) and choose an Editor Theme. Hit “Apply” to save it.\n\n\n\n\n\n\n\nTask 5. Test out installing a package\nPackages are the best part of using R. We’ll talk more about what packages are in workshop, but for now try installing a package. Go to your Console (the bottom left pane in the RStudio window), and type (or copy paste) install.packages(\"tidyverse\"). Hit Enter.\nYou should get a message that looks something like this:\n\n\n\n\n\n\n\n\n\n\n\nOperating system differences\n\n\n\nThe database that holds all these packages will automatically detect which version you need based on your operating system. Don’t worry if your output message doesn’t look exactly the same as the one here - just as long as you get something like “The downloaded binary packages are in…”, you’ve probably got the package installed.\n\n\n\n\nTask 6. Test out reading in a package\nNow you’ve installed a package, but you want to make sure you can actually run it. Again in the Console (the bottom left pane), type library(tidyverse) and hit Enter.\nYou should get a message that looks something like this:\n\n\n\n\n\n\n\nTask 7. Set up a folder on your computer for class materials\nUsing R/RStudio requires you to know how your computer is organized and where your files are. For now, we’ll want to set up a folder in your computer called ENVS-193DS (note no spaces in the folder name).\nAll operating systems are different, but make sure that your folder is not in the “iCloud” or “Google Drive” folders in your computer. Basically, you want to be sure that you can get from your “root” directory (i.e. your actual computer hard drive) to the folder you’re using.\nYou can check this using the file path, or the folders you would need to open to get to the folder called ENVS-193DS. One example for MacOS is below, where the file path is written out at the bottom of the pane:\n\n\n\n\n\n\n\nTask 8. Take a screenshot of your RStudio set up\nSo that the instructors can verify that you’ve gotten everything set up, take a screenshot of your RStudio window with the code for install.packages(\"tidyverse\") and library(tidyverse) in your Console and submit it to the portal on Canvas. Your screenshot should look something like this:\n\n\n\n\n\n\n\n\n\n\n\nDouble check your screenshot!\n\n\n\nMake sure that the messages in the orange box (above) are visible in your screenshot! Otherwise we will not be able to troubleshoot whatever issues you are having with installation (if you are actually having any)."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Order By\n       Default\n         \n          Due date - Oldest\n        \n         \n          Due date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDue date\n\n\n\n\n\n\nGetting set up\n\n\nApr 3, 2024\n\n\n\n\nReflection 1\n\n\nApr 10, 2024\n\n\n\n\nHomework 1\n\n\nApr 17, 2024\n\n\n\n\nOPTIONAL practice problem - Central Limit Theorem\n\n\nApr 18, 2024\n\n\n\n\nOPTIONAL practice problem - One sample t-test\n\n\nApr 18, 2024\n\n\n\n\nHomework 2\n\n\nApr 24, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workshop/workshop-01_2024-04-05.html",
    "href": "workshop/workshop-01_2024-04-05.html",
    "title": "Coding workshop: Week 1",
    "section": "",
    "text": "tidyverse\n\n\n\n\n\ncalculations using mean() and max()\n\nread in data using read_csv()\n\nfilter data using filter()\n\narrange data using arrange()\n\ncreate new column using mutate()\n\ngroup data using group_by()\n\ncount observations using count()\n\nchain functions together using %&gt;%\n\nvisualize data using ggplot()\n\ncreating points and lines using geom_point() and geom_line()\n\n\n\n\nThis workshop’s data comes from Tidy Tuesday 2023-06-20, which was from the National UFO Reporting Center and sunrise-sunset.org by Jon Harmon."
  },
  {
    "objectID": "workshop/workshop-01_2024-04-05.html#summary",
    "href": "workshop/workshop-01_2024-04-05.html#summary",
    "title": "Coding workshop: Week 1",
    "section": "",
    "text": "tidyverse\n\n\n\n\n\ncalculations using mean() and max()\n\nread in data using read_csv()\n\nfilter data using filter()\n\narrange data using arrange()\n\ncreate new column using mutate()\n\ngroup data using group_by()\n\ncount observations using count()\n\nchain functions together using %&gt;%\n\nvisualize data using ggplot()\n\ncreating points and lines using geom_point() and geom_line()\n\n\n\n\nThis workshop’s data comes from Tidy Tuesday 2023-06-20, which was from the National UFO Reporting Center and sunrise-sunset.org by Jon Harmon."
  },
  {
    "objectID": "workshop/workshop-01_2024-04-05.html#code",
    "href": "workshop/workshop-01_2024-04-05.html#code",
    "title": "Coding workshop: Week 1",
    "section": "2. Code",
    "text": "2. Code\n\n1. Intro to scripts\nIn class, we use an R Script. It allows you to write your code (recipe) and run the code in the console (kitchen).\nR considers everything in the script as code to run, so you can write comments in the R Script by putting a pound sign at the beginning of the line. This is especially useful when you want to explain what your code is doing at each line in plain language.\nTry writing a comment of your own in the line below.\n\n# This is a comment!\n\n\n\n2. Intro to functions\nR allows you to apply functions to do calculations, from simple to complex structures. Run code by putting your cursor on the line and hitting Ctrl + Enter or Cmd + Enter.\n\nmean(c(4, 5, 1, 2, 1))\n\n[1] 2.6\n\n\nYou can store things you want to use over and over again as objects.\n\nnumbers &lt;- c(4, 6, 2, 5, 3, 10)\n\nand then you can use those objects in functions.\n\nmax(numbers)\n\n[1] 10\n\n\n\n\n3. loading in packages and data\n\nlibrary(tidyverse)\n\n\nufo_sightings &lt;- read_csv(\"ufo_sightings.csv\")\n\n\nView(ufo_sightings)\n\n\n\n4. cleaning and wranging\nThese are all functions in the tidyverse that allow you to work with your data in R.\nFirst, you can filter by state to only include California.\n\ndf1 &lt;- filter(ufo_sightings, \n              state == \"CA\") \n\nThen, you can arrange the data frame by date.\n\ndf2 &lt;- arrange(df1,\n               reported_date_time)\n\nThen, you can make a new column just with the year.\n\ndf3 &lt;- mutate(df2,\n              extracted_year = year(reported_date_time)) \n\nThen, you can group the data frame by year and shape.\n\ndf4 &lt;- group_by(df3, \n                extracted_year, shape)\n\nThen, you can count the number of occurrences by year and shape.\n\ndf5 &lt;- count(df4) \n\nThen, you can filter the data frame by the shapes you’re interested in.\n\ndf6 &lt;- filter(df5, \n              shape %in% c(\"formation\", \"circle\", \"orb\", \"changing\", \"light\"))\n\n\n\n5. an easier way to clean and wrangle\nYou can use what’s called a pipe operator to chain functions together. The keyboard shortcut for a pipe is Ctrl + Shift + M or Cmd + Shift + M.\nWhen reading your code aloud, you can read the pipe as “and then”\n\nnew_mexico &lt;- ufo_sightings %&gt;% # use the ufo_sightings data frame\n  filter(state == \"NM\") %&gt;% # and then, filter by state to only include New Mexico\n  arrange(reported_date_time) %&gt;% # and then, arrange by date\n  mutate(extracted_year = year(reported_date_time)) %&gt;% # and then, create a new column for the year\n  group_by(extracted_year, shape) %&gt;% # and then, group by extracted_year and shape\n  count() # and then, count occurrences\n\n\n\n6. data visualization\n\nggplot(data = df6, \n       aes(x = extracted_year, \n           y = n,\n           color = shape)) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"Year\",\n       y = \"Number of sightings\",\n       title = \"UFOs in California are mostly light\")"
  },
  {
    "objectID": "workshop/workshop-04_2024-04-25.html",
    "href": "workshop/workshop-04_2024-04-25.html",
    "title": "Coding workshop: Week 4",
    "section": "",
    "text": "tidyverse\n\njanitor\n\n\n\n\n\n\n\nread in data using read_csv()\n\nvisualize data using ggplot()\n\n\n\n\n\nThe fish migration data is from the Columbia River DART (Data Access in Real Time) on fish migration through the Columbia River Basin in 2023.\nThe candy rankings data is from FiveThirtyEight’s candy power rankings (source, story).\nThe desert rodent measurements are from the Portal Project.\nThe shark incident data is from Riley et al.\nThe trash wheel pick up data is from the Waterfront Partnership of Baltimore."
  },
  {
    "objectID": "workshop/workshop-04_2024-04-25.html#summary",
    "href": "workshop/workshop-04_2024-04-25.html#summary",
    "title": "Coding workshop: Week 4",
    "section": "",
    "text": "tidyverse\n\njanitor\n\n\n\n\n\n\n\nread in data using read_csv()\n\nvisualize data using ggplot()\n\n\n\n\n\nThe fish migration data is from the Columbia River DART (Data Access in Real Time) on fish migration through the Columbia River Basin in 2023.\nThe candy rankings data is from FiveThirtyEight’s candy power rankings (source, story).\nThe desert rodent measurements are from the Portal Project.\nThe shark incident data is from Riley et al.\nThe trash wheel pick up data is from the Waterfront Partnership of Baltimore."
  },
  {
    "objectID": "workshop/workshop-04_2024-04-25.html#code",
    "href": "workshop/workshop-04_2024-04-25.html#code",
    "title": "Coding workshop: Week 4",
    "section": "2. Code",
    "text": "2. Code\n\n1. Set up\n\na. packages\n\nlibrary(tidyverse)\nlibrary(janitor)\n\n\n\nb. data\nData info:\n\nfish migration\n\ncandy rankings\n\ndesert rodent measurements\n\nshark incidents\n\ntrash wheel pick ups\n\n\n# fish migration\n# if you're working with fish data, note that these are cumulative counts\nfish &lt;- read_csv(\"adultdaily_1713852195_223.csv\")\n\n# candy rankings\ncandy &lt;- read_csv(\"candy-data.csv\")\n\n# desert rodent measurements\nrodents &lt;- read_csv(\"rodent_surveys.csv\")\n\n# shark incidents\nsharks &lt;- read_csv(\"sharks.csv\")\n\n# trash wheel\ntrashwheel &lt;- read_csv(\"trashwheel.csv\")\n\n\n\nc. Roles\nFill in the names of your group members/roles here:\n\nReporter: insert name here\nThis person will report out at the end of class, summarizing notes from the note-taker (if there is one) or taking notes themselves on what the process of creating a visualization from a caption was like: were there any challenges? easy parts? etc.\nMain coder: insert name here\nWith the group’s guidance, this person will write the code for the final visualization and the text for the caption. This person will also post the figure and the caption on the google slides.\nNote-taker (not every group will have this role): insert name here\nThis person will keep track of all the steps to create the final visualization and share these notes with the reporter to summarize.\n\n\n\n\n2. Create your visualization below!\nMy data set is [insert name of data set here].\nREMEMBER TO LOOK AT YOUR DATA BEFORE STARTING\n\na. cleaning/summarizing (individual)\n\n# insert code for cleaning and/or summarizing here IF NEEDED\n\n\n\nb. exploratory visualization (individual)\nDo this part on your own!\n\n# insert code for your own exploratory visualization here\n\nAfter you’re done with your exploratory visualization, discuss with your group members and decide which visualization to finalize.\n\n\nc. final visualization (group)\nThe coder will write this in their script, but follow along on yours too!\n\n# insert code for the finalized visualization here\n\nKeep this visualization to yourself; you will compare the other group’s visualization to your own!\n\n\nd. Write a caption\ninsert the text for your caption here\nCopy-paste your caption into the google slides!\nCheck links in template script\n\n\n\n3. Create a visualization based on the other group’s caption\nUse the other group’s caption to make a visualization. They will do the same for your caption, and at the end you’ll compare their visualization to your own to see how well your caption described your figure.\n\na. Caption\ninsert the other group’s caption here\n\n\nb. visualization (group)\n\n# insert code for the other group's visualization here\n\nOnce you’re done, take a screenshot of your visualization and post it on the google slides!\nRENDER YOUR DOCUMENT"
  },
  {
    "objectID": "lecture/lecture_week-02.html#math",
    "href": "lecture/lecture_week-02.html#math",
    "title": "Week 2 figures - Lectures 3 and 4",
    "section": "1. Math",
    "text": "1. Math\n\na. standard error\n\\[\nstandard \\: error = SE_{\\bar{y}} = \\frac{s}{\\sqrt{n}}\n\\]\n\n\nb. confidence interval\n\\[\n\\begin{align}\nCI = estimate \\: &\\pm \\: margin \\: of \\: error \\\\\nCI = \\bar{y} \\: &\\pm \\: t_{\\alpha(2), df} \\times \\frac{s}{\\sqrt{n}} \\\\\nCI = \\bar{y} \\: &\\pm \\: z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\n\\end{align}\n\\]\n\n\nc. t-statistic\n\\[\nt_{\\alpha(2), df}\n\\]\n\\[\nt_{0.05(2), 19}\n\\]\n\n\nd. z-score\n\\[\nz = \\frac{\\bar{y} - \\mu}{\\sigma - \\sqrt{n}}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-02.html#confidence-intervals",
    "href": "lecture/lecture_week-02.html#confidence-intervals",
    "title": "Week 2 figures - Lectures 3 and 4",
    "section": "2. confidence intervals",
    "text": "2. confidence intervals\nThis is the leaf example from lecture.\n\nrandom number generation\nThis generates the “population”: 10000 trees.\n\n\nCode\nset.seed(7)\nleaf_pop &lt;- rnorm(n = 10000, mean = 4.92, sd = 0.5)\nleaves &lt;- sample(leaf_pop, size = 20, replace = FALSE)\n\n\n\n\npopulation histogram\n\n\nCode\n# population histogram\nenframe(leaf_pop) %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(fill = \"darkgreen\", \n                 color = \"darkgreen\",\n                 alpha = 0.8) +\n  geom_vline(xintercept = mean(leaf_pop),\n             linetype = 2,\n             linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0)) +\n  labs(x = \"Leaf length (cm)\",\n       y = \"Count\") +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nsample histogram\n\n\nCode\nbreakpoints &lt;- round(seq(from = min(leaves), to = max(leaves), length.out = 7), 2)\n\nhist &lt;- enframe(leaves) %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 7, fill = \"cornflowerblue\", color = \"#000000\", breaks = breakpoints) +\n  scale_x_continuous(breaks = breakpoints) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 6), breaks = c(0, 1, 2, 3, 4, 5, 6)) +\n  theme_classic() +\n  labs(x = \"Leaf length (cm)\", y = \"Count\")\nhist\n\n\n\n\n\n\n\n\n\n\n\nsample density plot\n\n\nCode\nenframe(leaves) %&gt;% \n  ggplot(aes(x = value)) +\n  geom_density(fill = \"cornflowerblue\", color = \"#000000\", linewidth = 1) +\n  scale_x_continuous(limits = c(2.5, 7)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.65)) +\n  geom_vline(xintercept = mean(leaves)) +\n  annotate(\"text\", x = 6, y = 0.6, label = \"sample mean = 4.84 cm\", size = 6) +\n  theme_classic() +\n  labs(x = \"Leaf length (cm)\", \n       y = \"Density\")\n\n\n\n\n\n\n\n\n\n\n\nsample dot and whisker plot with confidence intervals\n\n\nCode\nleaf_conflev &lt;- tribble(\n  ~ conflev,\n  0.85,\n  0.90,\n  0.95,\n  0.99\n) %&gt;% \n  mutate(lower = case_when(\n    conflev == 0.85 ~ mean(leaves) - -qt(p = 0.15/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.90 ~ mean(leaves) - -qt(p = 0.1/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.95 ~ mean(leaves) - -qt(p = 0.05/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.99 ~ mean(leaves) - -qt(p = 0.01/2, df = 19)*sd(leaves)/sqrt(length(leaves)) \n  ), \n  upper = case_when(\n    conflev == 0.85 ~ mean(leaves) + -qt(p = 0.15/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.90 ~ mean(leaves) + -qt(p = 0.1/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.95 ~ mean(leaves) + -qt(p = 0.05/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.99 ~ mean(leaves) + -qt(p = 0.01/2, df = 19)*sd(leaves)/sqrt(length(leaves))\n  )) %&gt;% \n  mutate(mean = mean(leaves))\n  # se &lt;- s/sqrt(n)\n\nggplot() +\n  geom_point(data = enframe(leaves), aes(x = 0.84, y = leaves),\n             alpha = 0.6, shape = 21) +\n  geom_point(data = enframe(leaves), aes(x = 0.89, y = leaves),\n             alpha = 0.6, shape = 21) +\n  geom_point(data = enframe(leaves), aes(x = 0.94, y = leaves),\n             alpha = 0.6, shape = 21) +\n  geom_point(data = enframe(leaves), aes(x = 0.98, y = leaves),\n             alpha = 0.6, shape = 21) +\n  geom_point(data = leaf_conflev, aes(x = conflev, y = mean), \n             size = 3,\n             color = \"cornflowerblue\") +\n  geom_errorbar(data = leaf_conflev, aes(x = conflev, y = mean, ymin = lower, ymax = upper), \n                width = 0.006, \n                linewidth = 1,\n                color = \"cornflowerblue\") +\n  theme_void() +\n  theme(panel.grid = element_blank()) +\n  labs(x = \"Confidence levels\", \n       y = \"Leaf length (cm)\") \n\n\n\n\n\n\n\n\n\n\n\nsample qq plot\n\n\nCode\nqq &lt;- enframe(leaves) %&gt;% \n  ggplot(aes(sample = value)) +\n  stat_qq_line(aes(sample = value)) +\n  stat_qq(aes(sample = value), color = \"cornflowerblue\", size = 3) +\n  theme_classic() +\n  labs(x = \"Theoretical quantiles\", y = \"Sample quantiles\")\n\n\n\n\nCode\nhist + qq\n\n\n\n\n\n\n\n\n\n\n\nresampling visual\n\nresampling with different sample sizes\n\n\nCode\nleaf_5 &lt;- rep(NA, length = 1000)\nleaf_20 &lt;- rep(NA, length = 1000)\nleaf_40 &lt;- rep(NA, length = 1000)\n\nleaf_20_sd &lt;- rep(NA, length = 1000)\n\n# sample 5 leaves from population 1000x\nfor(i in 1:1000) {\n  \n  # sample 5 leaves from population\n  sample_5 &lt;- sample(leaf_pop, size = 5, replace = FALSE) \n  sample_20 &lt;- sample(leaf_pop, size = 20, replace = FALSE) \n  sample_40 &lt;- sample(leaf_pop, size = 40, replace = FALSE) \n  \n  leaf_5[i] &lt;- mean(sample_5)\n  leaf_20[i] &lt;- mean(sample_20)\n  leaf_40[i] &lt;- mean(sample_40)\n  \n  leaf_20_sd[i] &lt;- sd(sample_20)\n}\n\nleaf_df &lt;- cbind(leaf_5, leaf_20, leaf_40) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:3) %&gt;% \n  mutate(name = case_when(\n    name == \"leaf_5\" ~ \"n = 5\",\n    name == \"leaf_20\" ~ \"n = 20\",\n    name == \"leaf_40\" ~ \"n = 40\"\n  ),\n  name = fct_relevel(name, \"n = 5\", \"n = 20\", \"n = 40\"))\n\nleaf_df %&gt;% \n  filter(name == \"n = 20\") %&gt;% \n  ggplot() +\n  geom_histogram(aes(x = value),\n                 color = \"cornflowerblue\",\n                 fill = \"cornflowerblue\",\n                 alpha = 0.8) +\n  geom_vline(xintercept = mean(leaf_pop),\n             linetype = 2,\n             linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 280)) +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        strip.text = element_text(size = 18)) +\n  labs(x = \"Mean leaf length (cm)\") +\n  facet_wrap(~name, ncol = 1) \n\n\n\n\n\n\n\n\n\nCode\nggplot(leaf_df) +\n  geom_histogram(aes(x = value),\n                 color = \"cornflowerblue\",\n                 fill = \"cornflowerblue\",\n                 alpha = 0.8) +\n  geom_vline(xintercept = mean(leaf_pop),\n             linetype = 2,\n             linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 280)) +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.line.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        strip.text = element_text(size = 18)) +\n  labs(x = \"Mean leaf length (cm)\") +\n  facet_wrap(~name, ncol = 1) \n\n\n\n\n\n\n\n\n\n\n\nresampling confidence intervals\n\n\nCode\nleaf_20_ci &lt;- cbind(leaf_20, leaf_20_sd) %&gt;% \n  as_tibble() %&gt;% \n  mutate(ci_low = leaf_20 - -qt(p = 0.05/2, df = 19)*leaf_20_sd/sqrt(20),\n         ci_high = leaf_20 + -qt(p = 0.05/2, df = 19)*leaf_20_sd/sqrt(20),\n         iter = rownames(.)) %&gt;% \n  mutate(color = case_when(\n    ci_low &lt;= mean(leaf_pop) & ci_high &gt;= mean(leaf_pop) ~ \"yes\",\n    TRUE ~ \"no\"\n  ),\n  color = fct_relevel(color, \"yes\", \"no\"))\n\n# selecting 8 resamples to plot\nleaf_20_ci_sample &lt;- leaf_20_ci %&gt;% \n  group_by(color) %&gt;% \n  sample_n(4) %&gt;% \n  ungroup() %&gt;% \n  mutate(iter = fct_inorder(iter))\n\nleaf_20_ci_sample\n\n\n# A tibble: 8 × 6\n  leaf_20 leaf_20_sd ci_low ci_high iter  color\n    &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;\n1    4.90      0.429   4.70    5.10 158   yes  \n2    4.86      0.443   4.66    5.07 108   yes  \n3    4.97      0.429   4.77    5.17 712   yes  \n4    4.75      0.459   4.53    4.96 298   yes  \n5    4.71      0.432   4.51    4.91 500   no   \n6    4.75      0.369   4.58    4.92 983   no   \n7    5.28      0.483   5.06    5.51 824   no   \n8    5.22      0.450   5.00    5.43 973   no   \n\n\nCode\nggplot(data = leaf_20_ci_sample, aes(x = leaf_20, y = iter, color = color)) +\n  geom_vline(xintercept = mean(leaf_pop),\n             lty = 2) +\n  geom_pointrange(aes(xmin = ci_low, xmax = ci_high)) +\n  scale_color_manual(values = c(\"yes\" = \"darkgreen\", \"no\" = \"orange\")) +\n  scale_x_continuous(limits = c(mean(leaf_pop)*0.85, mean(leaf_pop)*1.15)) +\n  scale_y_discrete(limits = rev) +\n  theme(axis.title.y = element_blank(),\n        axis.line.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) +\n  theme(legend.position = \"none\") +\n  labs(x = \"Leaf length (cm)\")\n\n\n\n\n\n\n\n\n\n\n\n\nplotting standard error\n\n\nCode\nenframe(leaves) %&gt;% \n  mutate(group = \"Sample\") %&gt;% \n  ggplot(aes(x = group, y = value)) +\n  geom_point(position = position_jitter(width = 0.2, height = 0, seed = 1),\n             shape = 21,\n             alpha = 0.8) +\n  geom_point(aes(x = group, y = mean(value)),\n             color = \"cornflowerblue\",\n             size = 4) +\n  geom_errorbar(aes(ymin = mean(value) - sd(value)/sqrt(20), \n                    ymax = mean(value) + sd(value)/sqrt(20),\n                    width = 0.2),\n                color = \"cornflowerblue\",\n                linewidth = 1) +\n  labs(y = \"Leaf length (cm)\") +\n  theme(axis.title.x = element_blank())\n\n\n\n\n\n\n\n\n\n\n\ncalculating CI using function\n\n\nCode\nHmisc::smean.cl.normal(leaves)\n\n\n    Mean    Lower    Upper \n4.844110 4.578826 5.109393 \n\n\nCode\nggplot2::mean_cl_normal(leaves)\n\n\n        y     ymin     ymax\n1 4.84411 4.578826 5.109393\n\n\n\n\nplotting with “dry” trees\n\n\nCode\nenframe(leaves) %&gt;% \n  mutate(group = \"Sample\") %&gt;% \n  ggplot() +\n  geom_point(aes(x = group, y = value),\n             position = position_jitter(width = 0.2, height = 0, seed = 1),\n             shape = 21,\n             alpha = 0.8) +\n  geom_point(aes(x = group, y = mean(value)),\n             color = \"cornflowerblue\",\n             size = 3) +\n  geom_errorbar(data = leaf_conflev %&gt;% filter(conflev == 0.95) %&gt;% mutate(group = \"Sample\"),\n                aes(x = group, ymin = lower, ymax = upper),\n                width = 0,\n                color = \"cornflowerblue\",\n                size = 1) +\n  geom_pointrange(data = data.frame(group = \"Dry\", mean = 3.2, lower = 3.0, upper = 3.4),\n                  aes(x = group, y = mean, ymin = lower, ymax = upper),\n                  color = \"firebrick\",\n                  size = 1,\n                  linewidth = 1) +\n  labs(y = \"Leaf length (cm)\") +\n  theme(axis.title.x = element_blank())"
  },
  {
    "objectID": "lecture/lecture_week-02.html#hypothesis-testing-z-distribution",
    "href": "lecture/lecture_week-02.html#hypothesis-testing-z-distribution",
    "title": "Week 2 figures - Lectures 3 and 4",
    "section": "3. Hypothesis testing: z-distribution",
    "text": "3. Hypothesis testing: z-distribution\nExample: You’re told that the mean weight of a coast live oak acorn is \\(2.1 g\\). You question that claim. You then choose to randomly sample 30 acorns and calculate the sample mean: \\(\\bar{y} = 2.6 g\\). You also (miraculously) know the population standard deviation: \\(\\sigma = 0.3 g\\).\nDo you have evidence to refute this claim?\nFirst, store some numbers:\n\n\nCode\nacorn_mean &lt;- 2.1\nacorn_sd &lt;- 0.45\nsample_mean &lt;- 2.2\n\n\nPlotting the acorn population distribution:\n\n\nCode\nmin &lt;- acorn_mean-(3*acorn_sd)\nmax &lt;- acorn_mean+(3*acorn_sd)\n\nacorn_pop_hist &lt;- data.frame(x = min:max) %&gt;% \n  ggplot(aes(x)) +\n  stat_function(geom = \"line\", \n                n = 1000, \n                fun = dnorm, \n                args = list(mean = acorn_mean, sd = acorn_sd), \n                linewidth = 2, \n                color = \"darkgoldenrod\") +\n  geom_vline(xintercept = acorn_mean, \n             linetype = 2, \n             linewidth = 2) +\n  scale_x_continuous(breaks = c(acorn_mean-3*acorn_sd,\n                                acorn_mean-2*acorn_sd, \n                                acorn_mean-acorn_sd,\n                                acorn_mean, \n                                acorn_mean+acorn_sd,\n                                acorn_mean+2*acorn_sd,\n                                acorn_mean+3*acorn_sd),\n                     limits = c(min, max)) +\n  labs(x = \"Acorn mass (g)\") +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank())\n\nacorn_pop_hist\n\n\n\n\n\n\n\n\n\nAnd with the sample mean:\n\n\nCode\npop_with_sample &lt;- acorn_pop_hist +\n  geom_vline(xintercept = sample_mean, \n             color = \"tomato3\",\n             linewidth = 2)\npop_with_sample\n\n\n\n\n\n\n\n\n\nAnd with a sample mean at least that different:\n\n\nCode\npop_with_sample +\n  geom_vline(xintercept = acorn_mean - (sample_mean - acorn_mean), \n             color = \"tomato3\",\n             linewidth = 2)\n\n\n\n\n\n\n\n\n\nWe can calculate a z-score using the formula:\n\\[\n\\begin{align}\nz &= \\frac{\\bar{y} - \\mu}{\\sigma/\\sqrt{n}} \\\\\n&= \\frac{2.2 - 2.10}{0.45/\\sqrt{30}} \\\\\n&= 1.22\n\\end{align}\n\\]\nIn this version of the z-score formula, the number of observations \\(n\\) is included; technically, the one from before also included \\(n\\), but since we were only choosing one individual and asking about the probability of selecting that individual, \\(\\sqrt{n} = 1\\) so it cancelled out.\n\n\nCode\nacorn_z &lt;- (sample_mean - acorn_mean)/(acorn_sd/sqrt(30))\nacorn_z\n\n\n[1] 1.217161\n\n\nCode\npnorm(acorn_z, mean = 0, sd = 1, lower.tail = FALSE)\n\n\n[1] 0.1117714\n\n\nWe can plot the z-scores against each other:\n\n\nCode\ndata.frame(x = -3:3) %&gt;% \n  ggplot(aes(x)) +\n  stat_function(geom = \"area\",\n                fun = dnorm,\n                args = list(mean = 0, sd = 1),\n                xlim = c(1.96, 3),\n                fill = \"lightgrey\") +\n  stat_function(geom = \"area\",\n                fun = dnorm,\n                args = list(mean = 0, sd = 1),\n                xlim = c(-3, -1.96),\n                fill = \"lightgrey\") +\n  geom_linerange(x = 1.96, ymin = 0, ymax = 0.06) +\n  geom_linerange(x = -1.96, ymin = 0, ymax = 0.06) +\n  geom_linerange(x = acorn_z, linetype = 2, linewidth = 2,\n                 ymin = 0, ymax = 0.18) +\n  geom_linerange(x = -acorn_z, linetype = 2, linewidth = 2,\n                 ymin = 0, ymax = 0.18) +\n  stat_function(geom = \"line\", \n                n = 1000, \n                fun = dnorm, \n                args = list(mean = 0, sd = 1), \n                linewidth = 2, \n                color = \"darkgoldenrod\") +\n  scale_x_continuous(breaks = seq(-3, 3, by = 1)) +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 0.45)) +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank()) +\n  labs(x = \"Z\")"
  },
  {
    "objectID": "lecture/lecture_week-02.html#one-vs-two-tailed-figure",
    "href": "lecture/lecture_week-02.html#one-vs-two-tailed-figure",
    "title": "Week 2 figures - Lectures 3 and 4",
    "section": "4. one vs two tailed figure",
    "text": "4. one vs two tailed figure\nIn a one-tailed test (directional, greater or lesser), all the significance is in one tail of the distribution. In a two-tailed test (not directional, different from), the significance is split between two tails of the distribution.\n\n\nCode\ntwo &lt;- ggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(3, 5), fill = \"darkgrey\") +\n  geom_linerange(aes(x = 3, ymin = 0, ymax = 0.032), linewidth = 1, lty = 2, color = \"#000000\") +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(-5, -3), fill = \"darkgrey\") +\n  geom_linerange(aes(x = -3, ymin = 0, ymax = 0.032), linewidth = 1, lty = 2, color = \"#000000\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  theme_void() +\n  theme(panel.grid = element_blank())\n\none &lt;- ggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(2, 5), fill = \"darkgrey\") +\n  geom_linerange(aes(x = 2, ymin = 0, ymax = 0.063), linewidth = 1, lty = 2, color = \"#000000\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  theme_void() +\n  theme(panel.grid = element_blank())\n\none + two"
  },
  {
    "objectID": "lecture/lecture_week-07.html",
    "href": "lecture/lecture_week-07.html",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(flextable)\n\n# data\nlibrary(palmerpenguins)\n\n# analysis\nlibrary(car)\nlibrary(performance)\nlibrary(broom)"
  },
  {
    "objectID": "lecture/lecture_week-07.html#generating-data-and-model",
    "href": "lecture/lecture_week-07.html#generating-data-and-model",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "generating data and model",
    "text": "generating data and model\n\n\nCode\nx_lm &lt;- seq(from = 1, to = 30, by = 1)\n\nset.seed(666)\ny_lm &lt;- round(runif(length(x_lm), min = 1, max = 1.5), 1)*x_lm + runif(length(x_lm), min = 1, max = 10)\n\ndf_lm &lt;- cbind(\n  x = x_lm,\n  y = y_lm\n) %&gt;% \n  as_tibble() %&gt;% \n  mutate(outlier = case_when(\n    rownames(.) %in% c(23, 27, 28) ~ \"outlier\",\n    TRUE ~ \"ok\"\n  ))"
  },
  {
    "objectID": "lecture/lecture_week-07.html#model-summaries",
    "href": "lecture/lecture_week-07.html#model-summaries",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "model summaries",
    "text": "model summaries\n\n\nCode\nmodel1 &lt;- lm(y ~ x, data = df_lm)\nmodel1\n\n\n\nCall:\nlm(formula = y ~ x, data = df_lm)\n\nCoefficients:\n(Intercept)            x  \n      6.404        1.156  \n\n\nCode\nsummary(model1)\n\n\n\nCall:\nlm(formula = y ~ x, data = df_lm)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.323 -1.020  0.002  2.393  6.645 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   6.4043     1.3421   4.772 5.17e-05 ***\nx             1.1561     0.0756  15.293 4.02e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.584 on 28 degrees of freedom\nMultiple R-squared:  0.8931,    Adjusted R-squared:  0.8893 \nF-statistic: 233.9 on 1 and 28 DF,  p-value: 4.021e-15\n\n\nCode\nanova(model1)\n\n\nAnalysis of Variance Table\n\nResponse: y\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nx          1 3003.92 3003.92  233.87 4.021e-15 ***\nResiduals 28  359.64   12.84                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmodel1_nooutliers &lt;- lm(y ~ x, data = df_lm %&gt;% filter(outlier == \"ok\"))\nsummary(model1_nooutliers)\n\n\n\nCall:\nlm(formula = y ~ x, data = df_lm %&gt;% filter(outlier == \"ok\"))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.6611 -1.2596 -0.5039  1.6229  4.7197 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.12314    1.02352   5.982 3.02e-06 ***\nx            1.20027    0.06177  19.431  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.668 on 25 degrees of freedom\nMultiple R-squared:  0.9379,    Adjusted R-squared:  0.9354 \nF-statistic: 377.6 on 1 and 25 DF,  p-value: &lt; 2.2e-16\n\n\n\\[\n\\begin{align}\nR^2 &= 1 - \\frac{SS_{residuals}}{SS_{total}} \\\\\n&= 1 - \\frac{359.64}{359.64 + 3003.92} \\\\\n&= 0.8931\n\\end{align}\n\\]\n\n\nCode\n# if using quarto, don't label chunk with a table... so weird\nanova_tbl &lt;- broom::tidy(anova(model1)) %&gt;% \n  mutate(across(where(is.numeric), ~ round(.x, digits = 2))) %&gt;% \n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\"\n  )) \n\nflextable(anova_tbl) %&gt;% \n  set_header_labels(term = \"Term\", \n                    df = \"Degrees of freedom\", \n                    sumsq = \"Sum of squares\", \n                    meansq = \"Mean squares\", \n                    statistic = \"F-statistic\", \n                    p.value = \"p-value\") %&gt;% \n  set_table_properties(layout = \"autofit\", width = 0.8)\n\n\nTermDegrees of freedomSum of squaresMean squaresF-statisticp-valuex13,003.923,003.92233.87&lt; 0.001Residuals28359.6412.84"
  },
  {
    "objectID": "lecture/lecture_week-07.html#model-plots",
    "href": "lecture/lecture_week-07.html#model-plots",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "model plots",
    "text": "model plots\n\n\nCode\nmodel1_pred &lt;- ggpredict(model1, terms = ~ x)\nmodel1_nooutliers_pred &lt;- ggpredict(model1_nooutliers, terms = ~ x)\n\nmodel1_plot_noline &lt;- ggplot(data = df_lm, aes(x = x, y = y)) +\n  geom_point(shape = 19, size = 3, color = \"cornflowerblue\") +\n  theme_classic() +\n  theme(text = element_text(size = 14))\n\nmodel1_plot &lt;- ggplot(data = df_lm, aes(x = x, y = y)) +\n  geom_point(shape = 19, size = 3, color = \"cornflowerblue\") +\n  geom_line(data = model1_pred, aes(x = x, y = predicted), linewidth = 1) +\n  theme_classic() +\n  theme(text = element_text(size = 14))\n\nmodel1_plot_nooutliers &lt;- ggplot(data = df_lm %&gt;% filter(outlier == \"ok\"), aes(x = x, y = y)) +\n  geom_point(aes(color = outlier), shape = 19, size = 3) +\n  scale_color_manual(values = c(\"ok\" = \"cornflowerblue\", \"outlier\" = \"red\")) +\n  geom_line(data = model1_nooutliers_pred, aes(x = x, y = predicted), linewidth = 1) +\n  theme_classic() +\n  theme(text = element_text(size = 14),\n        legend.position = \"none\")"
  },
  {
    "objectID": "lecture/lecture_week-07.html#model-summary",
    "href": "lecture/lecture_week-07.html#model-summary",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "model summary",
    "text": "model summary\n\n\nCode\nsummary(lm_ex)\n\n\n\nCall:\nlm(formula = y ~ x, data = df_ex)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1081.0  -843.2  -226.3   660.5  2756.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -9431.3     1111.3  -8.486 3.16e-09 ***\nx             1642.0      156.5  10.492 3.30e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1023 on 28 degrees of freedom\nMultiple R-squared:  0.7972,    Adjusted R-squared:   0.79 \nF-statistic: 110.1 on 1 and 28 DF,  p-value: 3.298e-11"
  },
  {
    "objectID": "lecture/lecture_week-07.html#model-plots-1",
    "href": "lecture/lecture_week-07.html#model-plots-1",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "model plots",
    "text": "model plots\n\n\nCode\nlm_pred &lt;- ggpredict(lm_ex, terms = ~x)\n\nex_plot_noline &lt;- ggplot(df_ex, aes(x= x, y = y)) +\n  geom_point(shape = 17, size = 3, color = \"orange\") +\n  theme_classic() +\n  theme(text = element_text(size = 14))\n\nex_plot &lt;- ggplot(df_ex, aes(x= x, y = y)) +\n  geom_point(shape = 17, size = 3, color = \"orange\") +\n  geom_line(data = lm_pred, aes(x = x, y = predicted), linewidth = 1) +\n  theme_classic() +\n  theme(text = element_text(size = 14))"
  },
  {
    "objectID": "lecture/lecture_week-07.html#formula-for-pearsons-correlation",
    "href": "lecture/lecture_week-07.html#formula-for-pearsons-correlation",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "formula for Pearson’s correlation",
    "text": "formula for Pearson’s correlation\n\\[\nr = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum(x_i-\\bar{x})^2}\\sqrt{\\sum(y_i - \\bar{y})^2}}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-07.html#test-statistic-for-pearson-correlation",
    "href": "lecture/lecture_week-07.html#test-statistic-for-pearson-correlation",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "test statistic for pearson correlation",
    "text": "test statistic for pearson correlation\n\\[\n\\begin{align}\nt &= \\frac{r\\sqrt{n - 2}}{\\sqrt{1-r^2}} \\\\\ndf &= n -2\n\\end{align}\n\\]\nuses a t-distribution"
  },
  {
    "objectID": "lecture/lecture_week-07.html#no-correlation-but-clear-relationship",
    "href": "lecture/lecture_week-07.html#no-correlation-but-clear-relationship",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "no correlation but clear relationship",
    "text": "no correlation but clear relationship\n\n\nCode\nx_lm &lt;- seq(from = 1, to = 30, length.out = 50)\n# y = a( x – h) 2 + k\ndf_para &lt;- cbind(\n  x = x_lm,\n  y = 0.1*(x_lm - 15)^2 + 12\n) %&gt;% \n  as_tibble()\n\nggplot(df_para, aes(x = x, y = y)) +\n  geom_point(size = 3) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\ncor.test(df_para$x, df_para$y, method = \"pearson\")\n\n\n\n    Pearson's product-moment correlation\n\ndata:  df_para$x and df_para$y\nt = 0.90749, df = 48, p-value = 0.3687\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1540408  0.3939806\nsample estimates:\n      cor \n0.1298756"
  },
  {
    "objectID": "lecture/lecture_week-04.html",
    "href": "lecture/lecture_week-04.html",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\n\n# cohen's d\nlibrary(effectsize)\n\n# power\nlibrary(pwr)"
  },
  {
    "objectID": "lecture/lecture_week-04.html#set-up",
    "href": "lecture/lecture_week-04.html#set-up",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\n\n# cohen's d\nlibrary(effectsize)\n\n# power\nlibrary(pwr)"
  },
  {
    "objectID": "lecture/lecture_week-04.html#math",
    "href": "lecture/lecture_week-04.html#math",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "1. Math",
    "text": "1. Math\n\na. Cohen’s d\n\\[\nCohen's \\; d = \\frac{\\bar{y_A} - \\bar{y_B}}{\\sqrt{(s^2_A + s^2_B)/2}}\n\\]\n\n\nb. Cohen’s d with separated SD\n\\[\nCohen's \\; d = \\frac{\\bar{y_A} - \\bar{y_B}}{\\sqrt{\\frac{(n_A - 1)\\times s^2_A + (n_B - 1)\\times s^2_B}{n_A + n_B + 2}}}\n\\]\n\n\nb. confidence interval for two-sample t-test\n\\[\nCI = (\\bar{y_A} - \\bar{y_B}) \\pm t \\times \\sqrt{\\frac{(n_A - 1)s_A^2 + (n_B - 1)s_B^2}{n_A+n_B-2}} \\times \\sqrt{\\frac{1}{n_A}+\\frac{1}{n_B}}\n\\]\n\n\nc. test statistic for paired t-test\n\\[\nt_s = \\frac{\\bar{y}_d - \\mu_0}{s_d - \\sqrt{n}}\n\\]\n\n\nd. standard error for two-sample t-test\nIf variances are not equal:\n\\[\nSE_{\\bar{y_A} - \\bar{y_B}} = \\sqrt{\\frac{s_A^2}{n_A}+\\frac{s_B^2}{n_B}}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-04.html#interpret-this-output",
    "href": "lecture/lecture_week-04.html#interpret-this-output",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "2. Interpret this output",
    "text": "2. Interpret this output\nYou have two raised beds in which you’re growing tomatoes. One bed is in the sun, but the other is in shade. You want to know if the weight of the tomatoes is different between beds. You measure 33 tomatoes from each bed.\n\n\nCode\ntomatoes &lt;- cbind(sunny = rnorm(n = 33, mean = 150, sd = 20),\n                  shaded = rnorm(n = 33, mean = 130, sd = 10)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"sun_level\", values_to = \"weight_g\")\n\nggplot(data = tomatoes,\n       aes(x = sun_level,\n           y = weight_g)) +\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\n\nCode\nvar.test(weight_g ~ sun_level,\n         data = tomatoes)\n\n\n\n    F test to compare two variances\n\ndata:  weight_g by sun_level\nF = 0.29917, num df = 32, denom df = 32, p-value = 0.0009939\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1477587 0.6057527\nsample estimates:\nratio of variances \n         0.2991743 \n\n\nCode\nt.test(weight_g ~ sun_level,\n       data = tomatoes,\n       var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  weight_g by sun_level\nt = -3.9281, df = 49.574, p-value = 0.0002651\nalternative hypothesis: true difference in means between group shaded and group sunny is not equal to 0\n95 percent confidence interval:\n -23.876439  -7.717833\nsample estimates:\nmean in group shaded  mean in group sunny \n            129.7010             145.4981"
  },
  {
    "objectID": "lecture/lecture_week-04.html#power-analysis",
    "href": "lecture/lecture_week-04.html#power-analysis",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "3. Power analysis",
    "text": "3. Power analysis\n\n\nCode\n# higher power\npwr.t.test(n = NULL, d = 0.7, sig.level = 0.05, power = 0.95)\n\n\n\n     Two-sample t test power calculation \n\n              n = 54.01938\n              d = 0.7\n      sig.level = 0.05\n          power = 0.95\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nCode\n# lower power\npwr.t.test(n = NULL, d = 0.7, sig.level = 0.05, power = 0.80)\n\n\n\n     Two-sample t test power calculation \n\n              n = 33.02457\n              d = 0.7\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group"
  },
  {
    "objectID": "lecture/lecture_week-04.html#write-about-this-result",
    "href": "lecture/lecture_week-04.html#write-about-this-result",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "4. Write about this result",
    "text": "4. Write about this result\nYou have two worm compost bins: one in which you throw citrus peels, and the other in which you don’t. You’re curious to see if the citrus worms are bigger than the non-citrus worms. You measure 34 worms from each bin and find this result:\n\n\nCode\nworms &lt;- cbind(citrus = rnorm(n = 34, mean = 140, sd = 20),\n               non_citrus = rnorm(n = 34, mean = 160, sd = 15)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"compost_bin\", values_to = \"weight_g\")\n\nggplot(data = worms,\n       aes(x = compost_bin,\n           y = weight_g)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nCode\nvar.test(weight_g ~ compost_bin,\n         data = worms)\n\n\n\n    F test to compare two variances\n\ndata:  weight_g by compost_bin\nF = 2.0305, num df = 33, denom df = 33, p-value = 0.04565\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 1.014058 4.065579\nsample estimates:\nratio of variances \n          2.030452 \n\n\nCode\nt.test(weight_g ~ compost_bin,\n       data = worms,\n       var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  weight_g by compost_bin\nt = -4.593, df = 59.16, p-value = 2.335e-05\nalternative hypothesis: true difference in means between group citrus and group non_citrus is not equal to 0\n95 percent confidence interval:\n -30.26007 -11.89553\nsample estimates:\n    mean in group citrus mean in group non_citrus \n                140.6259                 161.7037"
  },
  {
    "objectID": "lecture/lecture_week-04.html#effect-size-examples",
    "href": "lecture/lecture_week-04.html#effect-size-examples",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "5. Effect size examples",
    "text": "5. Effect size examples\n\na. large sample size, small difference\n\n\nCode\nset.seed(1)\nsmall &lt;- cbind(a = rnorm(n = 10, mean = 10, sd = 2), \n               b = rnorm(n = 10, mean = 11, sd = 2)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"group\", values_to = \"value\")\nt.test(value ~ group,\n       data = small,\n       var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  value by group\nt = -1.4727, df = 18, p-value = 0.1581\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -2.9926364  0.5260676\nsample estimates:\nmean in group a mean in group b \n       10.26441        11.49769 \n\n\nCode\nset.seed(1)\nlarge &lt;- cbind(a = rnorm(n = 100, mean = 10, sd = 2), \n               b = rnorm(n = 100, mean = 11, sd = 2)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"group\", values_to = \"value\")\nt.test(value ~ group,\n       data = large,\n       var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  value by group\nt = -2.6906, df = 198, p-value = 0.007743\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -1.2245098 -0.1887085\nsample estimates:\nmean in group a mean in group b \n       10.21777        10.92438 \n\n\n\n\nb. needlegrass example\n\n\nCode\nset.seed(1)\nneedlegrass &lt;- cbind(ungrazed = rnorm(n = 35, mean = 80, sd = 10), \n                     grazed = rnorm(n = 35, mean = 74, sd = 5)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"plot_type\", values_to = \"height_cm\")\n\n# plot without all the adjustments\nggplot(data = needlegrass,\n       aes(x = plot_type,\n           y = height_cm,\n           color = plot_type)) +\n  geom_point(position = position_jitter(width = 0.1, height = 0, seed = 10),\n             alpha = 0.2) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_cl_normal) \n\n\n\n\n\n\n\n\n\nCode\n# \"finalized\" plot\nggplot(data = needlegrass,\n       aes(x = plot_type,\n           y = height_cm,\n           color = plot_type)) +\n  geom_point(position = position_jitter(width = 0.1, height = 0, seed = 10),\n             alpha = 0.2) +\n  scale_color_manual(values = c(\"darkgreen\", \"cornflowerblue\")) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_cl_normal,\n               size = 1,\n               linewidth = 1) +\n  labs(x = \"Plot type\",\n       y = \"Height (cm)\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nDoing a t-test:\n\n\nCode\nvar.test(height_cm ~ plot_type,\n       data = needlegrass)\n\n\n\n    F test to compare two variances\n\ndata:  height_cm by plot_type\nF = 0.26151, num df = 34, denom df = 34, p-value = 0.0001765\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1320008 0.5180813\nsample estimates:\nratio of variances \n         0.2615094 \n\n\nCode\nt.test(height_cm ~ plot_type,\n       data = needlegrass,\n       var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  height_cm by plot_type\nt = -3.2032, df = 50.644, p-value = 0.002351\nalternative hypothesis: true difference in means between group grazed and group ungrazed is not equal to 0\n95 percent confidence interval:\n -9.084836 -2.083807\nsample estimates:\n  mean in group grazed mean in group ungrazed \n              75.18323               80.76756 \n\n\nCohen’s d:\n\n\nCode\n# pooled SD\ncohens_d(height_cm ~ plot_type,\n       data = needlegrass)\n\n\nCohen's d |         95% CI\n--------------------------\n-0.77     | [-1.25, -0.28]\n\n- Estimated using pooled SD.\n\n\nCode\n# unpooled SD\ncohens_d(height_cm ~ plot_type,\n       data = needlegrass, \n       pooled_sd = FALSE)\n\n\nCohen's d |         95% CI\n--------------------------\n-0.77     | [-1.25, -0.27]\n\n- Estimated using un-pooled SD.\n\n\nCode\n# by hand\nneedlegrass_sum &lt;- needlegrass %&gt;% \n  group_by(plot_type) %&gt;% \n  reframe(\n    mean = mean(height_cm),\n    var = var(height_cm),\n    n = length(height_cm)\n  )\n\nya &lt;- pluck(needlegrass_sum, 2, 1)\nyb &lt;- pluck(needlegrass_sum, 2, 2)\nvara &lt;- pluck(needlegrass_sum, 3, 1)\nvarb &lt;- pluck(needlegrass_sum, 3, 2)\nna &lt;- pluck(needlegrass_sum, 4, 1)\nnb &lt;- pluck(needlegrass_sum, 4, 2)\n\n# by hand\n\n(ya - yb)/sqrt((vara + varb)/2)\n\n\n[1] -0.7657151\n\n\nCode\n(ya - yb)/sqrt(\n  ((na - 1)*vara + (nb - 1)*varb)/(na + nb - 2)\n)\n\n\n[1] -0.7657151"
  },
  {
    "objectID": "lecture/lecture_week-04.html#good-and-bad-results-statements",
    "href": "lecture/lecture_week-04.html#good-and-bad-results-statements",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "6. good and bad results statements",
    "text": "6. good and bad results statements\n\n\nCode\nmanaged &lt;- rnorm(n = 33, mean = 5, sd = 1) %&gt;% \n  enframe() %&gt;% \n  mutate(treatment = \"managed\")\nnonintervention &lt;- rnorm(n = 30, mean = 7, sd = 1) %&gt;% \n  enframe() %&gt;% \n  mutate(treatment = \"non-intervention\") \npools &lt;- rbind(managed, nonintervention) %&gt;% \n  select(treatment, value) %&gt;% \n  rename(temp = value)\nvar.test(temp ~ treatment,\n         data = pools)\n\n\n\n    F test to compare two variances\n\ndata:  temp by treatment\nF = 1.287, num df = 32, denom df = 29, p-value = 0.4953\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.6197933 2.6377877\nsample estimates:\nratio of variances \n          1.286962 \n\n\nCode\nt.test(temp ~ treatment,\n       data = pools)\n\n\n\n    Welch Two Sample t-test\n\ndata:  temp by treatment\nt = -11.206, df = 60.948, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group managed and group non-intervention is not equal to 0\n95 percent confidence interval:\n -2.558536 -1.783706\nsample estimates:\n         mean in group managed mean in group non-intervention \n                      4.952439                       7.123560 \n\n\nCode\ncohens_d(temp ~ treatment,\n       data = pools)\n\n\nCohen's d |         95% CI\n--------------------------\n-2.81     | [-3.51, -2.10]\n\n- Estimated using pooled SD.\n\n\nStatement: Our data suggest a difference in water temperature between managed (n = 33) and non-intervention (i.e. control, n = 30) vernal pools, with a strong (Cohen’s d = 2.19) effect of management.\nTemperatures in managed pools were different from those in non-intervention pools (two-tailed two-sample t-test, t(60.9) = -8.7, p &lt; 0.001, ⍺ = 0.05); on average, managed pools were 5.3 °C, while control pools were 7.1 °C."
  },
  {
    "objectID": "lecture/lecture_week-08.html",
    "href": "lecture/lecture_week-08.html",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(flextable)\nlibrary(GGally)\n\n# data\nlibrary(palmerpenguins)\n\n# analysis\nlibrary(car)\nlibrary(performance)\nlibrary(broom)\nlibrary(DHARMa)\nlibrary(MuMIn)"
  },
  {
    "objectID": "lecture/lecture_week-08.html#sum-of-squares-for-linear-regression",
    "href": "lecture/lecture_week-08.html#sum-of-squares-for-linear-regression",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "sum of squares for linear regression",
    "text": "sum of squares for linear regression\n\nregression (or model)\n\\[\nSS_{reg} = \\sum_{i = 1}^{n}(\\hat{y} - \\bar{y})^2\n\\]\n\n\nerror\n\\[\nSS_{err} = \\sum_{i = 1}^{n}(y_i - \\hat{y})^2\n\\]\n\n\ntotal\n\\[\nSS_{tot} = \\sum_{i = 1}^n(y_i - \\bar{y})\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-08.html#mean-square",
    "href": "lecture/lecture_week-08.html#mean-square",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "mean square",
    "text": "mean square\n\nregression\n\\[\nMS_{reg} = \\frac{SS_{reg}}{1}\n\\]\n\n\nerror\n\\[\nMS_{err} = \\frac{SS_{err}}{n - 2}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-08.html#f-statistic",
    "href": "lecture/lecture_week-08.html#f-statistic",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "F-statistic",
    "text": "F-statistic\n\\[\nF = \\frac{MS_{reg}}{MS_{err}}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-08.html#generating-data",
    "href": "lecture/lecture_week-08.html#generating-data",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "generating data",
    "text": "generating data\n\n\nCode\nset.seed(666)\nfrog_n &lt;- 87\n\ndf &lt;- cbind(\n  # predictor variables\n  color = sample(x = c(\"blue\", \"green\", \"red\"), size = frog_n, replace = TRUE, prob = c(0.3, 0.3, 0.3)),\n  weight = (round(rnorm(n = frog_n, mean = 3, sd = 0.3), 2)),\n  pattern = sample(x = c(\"striped\", \"spotted\", \"none\"), size = frog_n, replace = TRUE, prob = c(0.3, 0.3, 0.3))\n) %&gt;% \n  as_tibble() %&gt;% \n  mutate(weight = as.numeric(weight),\n         color = as.factor(color),\n         pattern = as.factor(pattern)) %&gt;% \n  group_by(color, pattern) %&gt;% \n  # response variable\n  mutate(toxicity = case_when(\n    color == \"blue\" & pattern == \"striped\" ~ rnorm(n = length(color), mean = 5, sd = 1),\n    color == \"blue\" & pattern == \"spotted\" ~ rnorm(n = length(color), mean = 4, sd = 1),\n    color == \"green\" & pattern == \"striped\" ~ rnorm(n = length(color), mean = 4, sd = 1),\n    color == \"green\" & pattern == \"spotted\" ~ rnorm(n = length(color), mean = 3, sd = 1),\n    color == \"red\" ~ rnorm(n = length(color), mean = 6, sd = 1),\n    TRUE ~ rnorm(n = length(color), mean = 2, sd = 1)\n  )) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "lecture/lecture_week-08.html#plotting-data",
    "href": "lecture/lecture_week-08.html#plotting-data",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "plotting data",
    "text": "plotting data\n\n\nCode\nblue_col &lt;- \"cornflowerblue\"\ngreen_col &lt;- \"darkgreen\"\nred_col &lt;- \"maroon\"\n\nstriped_col &lt;- \"grey1\"\nspotted_col &lt;- \"grey50\"\nnone_col &lt;- \"grey80\"\n\nggplot(data = df, aes(x = color, y = toxicity, color = color, fill = color)) +\n  geom_jitter(width = 0.2, height = 0, alpha = 0.3) +\n  scale_color_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  scale_fill_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  stat_summary(geom = \"pointrange\", fun = mean, fun.min = function(x) mean(x) - sd(x), fun.max = function(x) mean(x) + sd(x), shape = 21, size = 1) +\n #  geom_point(position = position_jitter(width = 0.2, height = 0, seed = 666), alpha = 0.3) +\n  labs(title = \"Color\") +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        axis.title.x = element_blank(),\n        text = element_text(size = 22))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = df, aes(x = pattern, y = toxicity, shape = pattern)) +\n  geom_jitter(width = 0.2, height = 0, alpha = 0.3) +\n  # scale_color_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  # scale_fill_manual(values = c(\"striped\" = striped_col, \"spotted\" = spotted_col, \"none\" = none_col)) +\n  stat_summary(geom = \"pointrange\", fun = mean, fun.min = function(x) mean(x) - sd(x), fun.max = function(x) mean(x) + sd(x), size = 1) +\n  labs(title = \"Pattern\") +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        axis.title.x = element_blank(),\n        text = element_text(size = 22))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = df, aes(x = weight, y = toxicity)) +\n  geom_point() +\n  # geom_smooth(method = \"lm\") +\n  labs(title = \"Weight\") +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        axis.title.x = element_blank(),\n        text = element_text(size = 22))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = df, aes(x = weight, y = toxicity, color = color)) +\n  geom_point() +\n  scale_color_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Weight\")"
  },
  {
    "objectID": "lecture/lecture_week-08.html#model",
    "href": "lecture/lecture_week-08.html#model",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "model",
    "text": "model\n\n\nCode\nmodel &lt;- lm(toxicity ~ weight + color + pattern, data = df)\nsimulateResiduals(model, plot = TRUE)\n\n\n\n\n\n\n\n\n\nObject of Class DHARMa with simulated residuals based on 250 simulations with refit = FALSE . See ?DHARMa::simulateResiduals for help. \n \nScaled residual values: 0.208 0.608 0.196 0.468 0.744 0.792 0.908 0.792 0.992 0.256 0.324 0.768 0.468 0.32 0.204 0.908 0.288 0.76 0.156 0.104 ..."
  },
  {
    "objectID": "lecture/lecture_week-08.html#diagnostics",
    "href": "lecture/lecture_week-08.html#diagnostics",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "diagnostics",
    "text": "diagnostics\n\n\nCode\npar(mfrow = c(2, 2))\nplot(model)"
  },
  {
    "objectID": "lecture/lecture_week-08.html#model-summary",
    "href": "lecture/lecture_week-08.html#model-summary",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "model summary",
    "text": "model summary\n\n\nCode\n# F-statistic: 31.05 on 5 and 81 DF,  p-value: &lt; 2.2e-16\n# total SSE - SSE of residuals divided by degrees of freedom\ntotalSSE &lt;- 6.932+140.09+21.63\ntotaldf &lt;- 1+2+2\nerrorSSE &lt;- 88\nmodel_fstat &lt;- (totalSSE/5)/(errorSSE/81) \nmodel_fstat\n\n\n[1] 31.0473\n\n\nCode\n# for a single coefficient\nweightMS &lt;- 6.932\nweightdf &lt;- 1\nerrorMS &lt;- 1.086\nfvalweight &lt;- (weightMS/weightdf)/errorMS\nfvalweight\n\n\n[1] 6.383057\n\n\nCode\ncolorMS &lt;- 70.045\ncolordf &lt;- 2\nfvalcolor &lt;- (colorMS/colordf)/errorMS\nfvalcolor\n\n\n[1] 32.24908\n\n\nCode\n# residual mean sq = 1.086 (denominator)\n# equation: t = 5.5 - 0.74*W - 0.97*green + 2.1*red + 0.85*spotted + 1.2*striped\n\n\n\n\nCode\nmodel_summary &lt;- summary(model)\n\nAnova(model)\n\n\nAnova Table (Type II tests)\n\nResponse: toxicity\n           Sum Sq Df F value    Pr(&gt;F)    \nweight      1.547  1  1.4194     0.237    \ncolor     119.288  2 54.7107 9.229e-16 ***\npattern    44.843  2 20.5669 5.981e-08 ***\nResiduals  88.304 81                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmodel.sel(model)\n\n\nModel selection table \n      (Intrc) color pttrn weght df   logLik  AICc delta\nmodel   4.045     +     +     1  7 -124.095 263.6     0\nModels ranked by AICc(x) \n\n\n\\[\n\\hat{y}_h \\pm t_{(1-\\alpha/2, n-2)}*\\sqrt{MSE*(\\frac{1}{n}+\\frac{(x_h-\\bar{x})^2}{\\sum(x_i-\\bar{x})^2})}\n\\]\n\\[\nMSE = \\frac{\\sum(y_i-\\hat{y})^2}{n}\n\\]\n\n\nCode\ntidy(model, conf.int = TRUE, conf.level = 0.95)\n\n\n# A tibble: 6 × 7\n  term           estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)       4.04      1.26       3.21 1.92e- 3    1.54      6.55 \n2 weight           -0.504     0.423     -1.19 2.37e- 1   -1.35      0.338\n3 colorgreen       -0.289     0.267     -1.08 2.82e- 1   -0.821     0.243\n4 colorred          2.59      0.290      8.91 1.17e-13    2.01      3.17 \n5 patternspotted    0.952     0.303      3.14 2.34e- 3    0.349     1.55 \n6 patternstriped    1.70      0.264      6.41 8.92e- 9    1.17      2.22 \n\n\n\n\nCode\nc(\"lower\" = model_summary$coef[2,1] - qt(0.975, df = model_summary$df[2]) * model_summary$coef[2, 2],\n  \"upper\" = model_summary$coef[2,1] + qt(0.975, df = model_summary$df[2]) * model_summary$coef[2, 2])\n\n\n     lower      upper \n-1.3451604  0.3375674 \n\n\nConfidence interval for a single coefficient: in words: estimate plus or minus the t-value at your confidence level * standard error"
  },
  {
    "objectID": "lecture/lecture_week-05.html",
    "href": "lecture/lecture_week-05.html",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\n\n# data\nlibrary(palmerpenguins)\n\n# analysis\nlibrary(car)"
  },
  {
    "objectID": "lecture/lecture_week-05.html#chi-square",
    "href": "lecture/lecture_week-05.html#chi-square",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "Chi-square",
    "text": "Chi-square\n\ntest statistic:\n\\[\n\\chi^2 = \\Sigma\\frac{(O-E)^2}{E}\n\\] ### degrees of freedom \\[\ndf = (number\\;of\\;rows - 1) * (number\\;of\\;columns - 1)\n\\]\n\n\nexpected counts:\n\\[\nexpected = \\frac{row\\;total * column\\;total}{table\\;total}\n\\]\n\n\nexpected counts example from lecture\n\\[\n\\frac{126 * 118}{315} = 47.2\n\\]\n\n\ntest statistic calculation example from lecture\n\\[\n\\begin{align}\n\\chi^2 &= \\Sigma\\frac{(O-E)^2}{E} \\\\\n\\chi^2 &= \\frac{55-47.2}{47.2}+...+\\frac{45-31.9}{31.9} \\\\\n&= 15.276\n\\end{align}\n\\]\nU statistic: \\[\n\\begin{align}\nU_1 &= \\Sigma R_1 - n_1(n_1 + 1)/2 = 17 - 5(5+1)/2 = 2 \\\\\nU_2 &= \\Sigma R_2 - n_2(n_2 + 1)/2 = 38 - 5(5+1)/2 = 23\n\\end{align}\n\\]\n\n\nCode\nSample1 &lt;- c(1.1, 2.4, 1.8, 0.4, 1.6)\nSample2 &lt;- c(5.4, 3.1, 2.3, 1.9, 4.2)\nwilcox.test(Sample1, Sample2)\n\n\n\n    Wilcoxon rank sum exact test\n\ndata:  Sample1 and Sample2\nW = 2, p-value = 0.03175\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nCode\n# for a comparison of one group against a theoretical median\nwilcox.test(SampleA, mu = theoretical)\n\n# for a comparison of two groups\nwilcox.test(SampleA, SampleB, paired = TRUE)"
  },
  {
    "objectID": "lecture/lecture_week-10.html",
    "href": "lecture/lecture_week-10.html",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(flextable)\nlibrary(GGally)\nlibrary(equatiomatic)\n\n# data\nlibrary(palmerpenguins)\n\n# analysis\nlibrary(car)\nlibrary(performance)\nlibrary(broom)\nlibrary(DHARMa)\nlibrary(MuMIn)\nlibrary(lmtest)"
  },
  {
    "objectID": "lecture/lecture_week-10.html#simple-linear-regression",
    "href": "lecture/lecture_week-10.html#simple-linear-regression",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "simple linear regression",
    "text": "simple linear regression\n\\[\nE[y_i] = a + bx_i\n\\]\n\\[\nvar[y_i] = s^2\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#generalized-form",
    "href": "lecture/lecture_week-10.html#generalized-form",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "generalized form:",
    "text": "generalized form:\n\\[\nE[y_i] = a + bx_i\n\\]\n\\[\nvar[y_i] = v(E[y_i])\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#random-component",
    "href": "lecture/lecture_week-10.html#random-component",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "random component",
    "text": "random component\n\\[\nY_i \\sim N(\\mu_i, \\sigma^2)\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#systematic-component",
    "href": "lecture/lecture_week-10.html#systematic-component",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "systematic component",
    "text": "systematic component\n\\[\n\\eta_i = \\sum^{p-1}_{n = 0}\\beta_jx_{ij}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#link",
    "href": "lecture/lecture_week-10.html#link",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "link",
    "text": "link\n\\[\ng(\\mu_i) = \\eta_i\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-03.html",
    "href": "lecture/lecture_week-03.html",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\n\n# calculate effect size\nlibrary(effsize)\n\n# visualization\nlibrary(patchwork)"
  },
  {
    "objectID": "lecture/lecture_week-03.html#set-up",
    "href": "lecture/lecture_week-03.html#set-up",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\n\n# calculate effect size\nlibrary(effsize)\n\n# visualization\nlibrary(patchwork)"
  },
  {
    "objectID": "lecture/lecture_week-03.html#math",
    "href": "lecture/lecture_week-03.html#math",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "1. Math",
    "text": "1. Math\n\na. test statistic for one sample t-test\n\\[\nt = \\frac{\\bar{y} - \\mu}{s/\\sqrt{n}}\n\\]\n\n\nb. two sample t-test when variances are equal (Student’s)\n\\[\nt = \\frac{\\bar{y_A} - \\bar{y_B}}{s_p \\times \\sqrt{\\frac{1}{N_A + N_B}}}\n\\]\n\\[\ndf = (N_A - 1) + (N_B - 1)\n\\]\n\n\nc. when variances are not equal (Welch’s)\n\\[\nt = \\frac{\\bar{y_A} - \\bar{y_B}}{\\sqrt{\\frac{s_A^2}{N_A}+\\frac{s_B^2}{N_B}}}\n\\]\n\\[\ndf = \\frac{(\\frac{s_A^2}{N_A}+\\frac{S_B^2}{N_B})^2}{\\frac{(\\frac{s_A^2}{N_A})^2}{N_A-1}+\\frac{(\\frac{s_B^2}{N_B})^2}{N_B-1}}\n\\]\n\n\nd. test statistic for F test\n\\[\nF =  \\frac{s^2_A}{s^2_B}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-03.html#central-limit-theorem",
    "href": "lecture/lecture_week-03.html#central-limit-theorem",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "2. central limit theorem",
    "text": "2. central limit theorem\nIf you were to sample a bunch of times from any distribution (i.e. take many observations within a sample, take many observations in another sample), the mean values for each sample will be normally distributed. Kareem Carr has a nice explainer of how this works here.\n\n\nCode\n# randomly select 10000 numbers from a uniform distribution for the population\nuniform &lt;- runif(10000, min = 2, max = 8)\n\n# make a histogram for the population\nuniformdf &lt;- as.data.frame(uniform)\n\nggplot(uniformdf, aes(x = uniform)) +\n  geom_histogram(breaks = seq(2, 8, length.out = 41), fill = \"firebrick\", alpha = 0.7, color = \"firebrick\") +\n  geom_vline(xintercept = mean(uniform), linewidth = 2) +\n  annotate(\"text\", x = 4, y = 290, label = \"mean = 4.967\", size = 10) +\n  scale_x_continuous(breaks = seq(from = 2, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 305)) +\n  labs(x = \"Continuous value\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# for() loop to \nstore2 &lt;- c()\nstore5 &lt;- c()\nstore15 &lt;- c()\nstore30 &lt;- c()\nstore50 &lt;- c()\n\nfor(i in 1:100) {\n  \n  # sample 100x\n  store2[i] &lt;- mean(sample(uniform, 2, replace = FALSE))\n  store5[i] &lt;- mean(sample(uniform, 5, replace = FALSE))\n  store15[i] &lt;- mean(sample(uniform, 15, replace = FALSE))\n  store30[i] &lt;- mean(sample(uniform, 30, replace = FALSE))\n  store50[i] &lt;- mean(sample(uniform, 50, replace = FALSE))\n\n}\n\n\ndf &lt;- cbind(store2, store5, store15, store30, store50) %&gt;% \n  as.data.frame()\n  \nggplot(df) +\n  geom_histogram(aes(x = store2), bins = 10, alpha = 0.7, fill = \"chocolate1\", color = \"chocolate1\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store2)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store5), bins = 10, alpha = 0.7, fill = \"blue3\", color = \"blue3\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store5)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store15), bins = 12, alpha = 0.7, fill = \"darkorchid4\", color = \"darkorchid4\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store15)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store30), bins = 12, alpha = 0.7, fill = \"lightseagreen\", color = \"lightseagreen\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store30)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store50), bins = 12, alpha = 0.7, fill = \"violetred3\", color = \"violetred3\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store50)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))"
  },
  {
    "objectID": "lecture/lecture_week-03.html#z--vs-t-distribution",
    "href": "lecture/lecture_week-03.html#z--vs-t-distribution",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "3. z- vs t-distribution",
    "text": "3. z- vs t-distribution\n\na. comparison with normal\nt-distributions allow for more uncertainty around the tails.\n\n\nCode\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1, color = \"darkorange\") +\n  annotate(\"text\", x = 2.5, y = 0.4, label = \"normal\", color = \"darkorange\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#856F33\") +\n  annotate(\"text\", x = 3, y = 0.32, label = \"t-distribution (small n)\", color = \"#856F33\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 10), linewidth = 1, color = \"#56E9E7\") +\n  annotate(\"text\", x = 3, y = 0.37, label = \"t-distribution (large n)\", color = \"#56E9E7\", size = 6) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\n\n\nb. visual representation of significance and t-statistic\n\n\nCode\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 19), xlim = c(1.8, 5), fill = \"#0070c0\") +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 19), xlim = c(-5, -1.8), fill = \"#0070c0\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 19), linewidth = 1, color = \"#000000\") +\n  geom_hline(yintercept = 0) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.4)) +\n  theme_void() +\n  theme(panel.grid = element_blank(),\n        plot.margin = unit(c(1, 0, 0, 0), \"cm\"))"
  },
  {
    "objectID": "lecture/lecture_week-03.html#qqplot-examples",
    "href": "lecture/lecture_week-03.html#qqplot-examples",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "5. qqplot examples",
    "text": "5. qqplot examples\nWe use qqplots (quantile-quantile plots) to visually evaluate the normality of some variable. The x-axis is the “theoretical” quantile, and the y-axis is the “sample” quantile. If the points follow a 1:1 line, then the variable is normally distributed.\nThe New Haven temperature data is normally distributed:\n\n\nCode\nnhtemp_hist &lt;- as_tibble(nhtemp) %&gt;% \n  ggplot(aes(x = x)) +\n  geom_histogram(breaks = seq(47, 55, length.out = 9), fill = \"turquoise3\", color = \"#000000\") +\n  scale_x_continuous(breaks = seq(47, 55, length.out = 9), expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 23)) +\n  theme_classic() +\n  labs(x = \"Bins\", y = \"Count\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nnhtemp_qq &lt;- ggplot(as_tibble(nhtemp)) +\n  stat_qq(aes(sample = x), color = \"turquoise3\", size = 3) +\n  labs(x = \"Theoretical quantile\", y = \"Sample quantile\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nnhtemp_hist + nhtemp_qq\n\n\n\n\n\n\n\n\n\nThe sunspot data is not:\n\n\nCode\nsunspot_hist &lt;- as_tibble(sunspots) %&gt;% \n  ggplot(aes(x = x)) +\n  geom_histogram(breaks = round(seq(0, 260, length.out = 30)), fill = \"tomato2\", color = \"#000000\") +\n  scale_x_continuous(breaks = round(seq(0, 260, length.out = 30)), expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 480)) +\n  theme_classic() +\n  labs(x = \"Bins\", y = \"Count\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nsunspot_qq &lt;- ggplot(as_tibble(sunspots)) +\n  stat_qq(aes(sample = x), color = \"tomato2\", size = 3) +\n  theme_classic() +\n  labs(x = \"Theoretical quantile\", y = \"Sample quantile\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nsunspot_hist \n\n\n\n\n\n\n\n\n\nCode\nsunspot_qq"
  },
  {
    "objectID": "lecture/lecture_week-03.html#one-sample-t-test-example",
    "href": "lecture/lecture_week-03.html#one-sample-t-test-example",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "6. One sample t-test example",
    "text": "6. One sample t-test example\nThis is the creosote example from lecture.\n\ngenerating numbers\n\n\nCode\nset.seed(1)\ncreosote &lt;- rnorm(n = 41, mean = 1.8, sd = 0.3) %&gt;% \n  round(digits = 2) \n\n\n\n\nhistogram and qq plot\n\n\nCode\n# calculate the range\nrange &lt;- max(creosote) - min(creosote)\n\n# determine the number of observations\nobs &lt;- length(creosote)\n\n# calculate the number of bins using the Rice Rule\n# note that this doesn't come out to a whole number, so it's rounded\nbins &lt;- 2*(obs^(1/3)) %&gt;% \n  round(digits = 0)\n\n# calculate the width of the bin\nbinwidth &lt;- range/(bins - 1)\n\n# set up a sequence of numbers from 0 to 100\nseq &lt;- seq(from = 1, to = 11, by = 1)\n\n# calculate the axis breaks  \naxis_breaks &lt;- seq*binwidth + (binwidth/2)\n\n# round the axis breaks\naxis_breaks_rounded &lt;- round(axis_breaks, \n                             digits = 3)\n\nhist &lt;- creosote %&gt;% \n  enframe() %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(binwidth = binwidth,\n                 fill = \"#e3c922\",\n                 color = \"black\") +\n  scale_x_continuous(breaks = axis_breaks_rounded) +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 14)) +\n  labs(x = \"Creosote height (m)\",\n       y = \"Count\")\n\nqq &lt;- creosote %&gt;% \n  enframe() %&gt;% \n  ggplot(aes(sample = value)) +\n  geom_qq_line() +\n  geom_qq(color = \"#e3c922\",\n          size = 4,\n          alpha = 0.8) \n\nhist + qq\n\n\n\n\n\n\n\n\n\n\n\ncalculating a critical value\n\n\nCode\nt_critical &lt;- qt(p = 0.05/2, df = 40, lower.tail = FALSE)\nt_critical\n\n\n[1] 2.021075\n\n\n\n\ncalculating t-score\n“By hand”:\n\n\nCode\n# claimed mean\nmu &lt;- 3\n\n# number of observations\nn &lt;- length(creosote)\n\n# sample mean\nybar &lt;- mean(creosote)\n\n# sample standard deviation\ns &lt;- sd(creosote)\n\n# sample standard error\nse &lt;- s/sqrt(n)\n\n# t-score\nt &lt;- (ybar-mu)/se\n\nt\n\n\n[1] -28.56624\n\n\nUsing t.test()\n\n\nCode\nt.test(creosote, mu = 3)\n\n\n\n    One Sample t-test\n\ndata:  creosote\nt = -28.566, df = 40, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 3\n95 percent confidence interval:\n 1.743305 1.909378\nsample estimates:\nmean of x \n 1.826341 \n\n\nManually calculating p-value:\n\n\nCode\n# manually calculating p-value\n# two-tailed: multiply probability by 2\n# lower = FALSE: probability of the value being more than t\n2*pt(q = t, df = n - 1, lower = TRUE)\n\n\n[1] 3.158646e-28\n\n\n\n\nvisual representation of sample t-statistic vs t-critical\n\n\nCode\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(t_critical, 5), fill = \"darkgrey\") +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(-5, -t_critical), fill = \"darkgrey\") +\n  \n  annotate(geom = \"linerange\", x = t_critical, ymin = 0, ymax = 0.065, linewidth = 1, lty = 2, color = \"#000000\") +\n  annotate(geom = \"linerange\", x = -t_critical, ymin = 0, ymax = 0.065, linewidth = 1, lty = 2, color = \"#000000\") +\n  \n  # annotate(geom = \"linerange\", x = t, ymin = 0, ymax = 0.075, linewidth = 1, color = \"#000000\") +\n  # annotate(geom = \"linerange\", x = -t, ymin = 0, ymax = 0.075, linewidth = 1, color = \"#000000\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  theme_void() +\n  theme(panel.grid = element_blank(),\n        plot.margin = unit(c(1, 0, 0, 0), \"cm\"))"
  },
  {
    "objectID": "lecture/lecture_week-03.html#two-sample-t-test",
    "href": "lecture/lecture_week-03.html#two-sample-t-test",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "7. two-sample t-test",
    "text": "7. two-sample t-test\n\n\nCode\nex1 &lt;- ggplot(data.frame(x = -8:8), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 1, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 1), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nset.seed(2)\nx &lt;- rnorm(30, mean = 0, sd = 2)\ny &lt;- rnorm(30, mean = 1, sd = 2)\n\nt.test(x = x, y = y, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  x and y\nt = -0.78852, df = 58, p-value = 0.4336\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.6721807  0.7270662\nsample estimates:\nmean of x mean of y \n0.4573436 0.9299009 \n\n\nCode\n# 0.43\n\n\n\n\nCode\nex2 &lt;- ggplot(data.frame(x = -8:17), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 2, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 2), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nset.seed(1000000000)\nx &lt;- rnorm(30, mean = 0, sd = 2)\ny &lt;- rnorm(30, mean = 2, sd = 2)\n\nt.test(x = x, y = y, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  x and y\nt = -3.7904, df = 58, p-value = 0.0003603\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.7905631 -0.8617609\nsample estimates:\nmean of x mean of y \n0.1435745 1.9697364 \n\n\nCode\n# 0.6932\n\n\n\n\nCode\nex3 &lt;- ggplot(data.frame(x = -8:17), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 10, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 10), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nset.seed(100)\nx &lt;- rnorm(40, mean = 0, sd = 2)\ny &lt;- rnorm(40, mean = 10, sd = 2)\n\nt.test(x = x, y = y, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  x and y\nt = -21.69, df = 78, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -10.564878  -8.788488\nsample estimates:\nmean of x mean of y \n0.2003543 9.8770375 \n\n\nCode\n# p &lt; 0.001\n\n\n\n\nCode\nex1 + ex2 + ex3\n\n\n\n\n\n\n\n\n\n\nsame differences in means, different SD\n\n\nCode\nsmall &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 2), linewidth = 2, color = \"#0070C0\") +\n  geom_vline(aes(xintercept = 3), color = \"#0070C0\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nbig &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 0.5), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 0.5), linewidth = 2, color = \"#0070C0\") +\n  geom_vline(aes(xintercept = 3), color = \"#0070C0\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.8)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\ndiff &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 0.5), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 1.25), linewidth = 2, color = \"#0070C0\") +\n  geom_vline(aes(xintercept = 3), color = \"#0070C0\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.85)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nsmall / big / diff\n\n\n\n\n\n\n\n\n\n\n\nF-distribution\n\n\nCode\nggplot(data.frame(x = seq(from = 0, to = 4, by = 0.1)), aes(x)) +\n  stat_function(geom = \"line\", fun = df, args = list(df1 = 20, df2 = 20), color = \"#FF6B2B\", linewidth = 1, xlim = c(0, 4)) +\n  stat_function(geom = \"line\", fun = df, args = list(df1 = 5, df2 = 5), color = \"#0070C0\", linewidth = 1, xlim = c(0, 4)) +\n  stat_function(geom = \"line\", fun = df, args = list(df1 = 1, df2 = 5), linewidth = 1, xlim = c(0, 4)) +\n  annotate(\"text\", x = 1.5, y = 1, label = \"20, 20\", color = \"#FF6B2B\", size = 8) +\n  annotate(\"text\", x = -0.2, y = 0.5, label = \"5, 5\", color = \"#0070C0\", size = 8) +\n  annotate(\"text\", x = 0.5, y = 1.5, label = \"1, 5\", size = 8) + \n  scale_y_continuous(expand = c(0, 0)) +\n  theme(axis.text = element_blank(),\n        axis.line = element_blank(),\n        axis.ticks = element_blank(),\n        axis.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nF-distribution example\n\n\nCode\nset.seed(1)\nrats &lt;- rnorm(n = 20, mean = 178, sd = 43)\nset.seed(1)\nmice &lt;- rnorm(n = 20, mean = 120, sd = 20)\n\nmean(rats)\n\n\n[1] 186.1925\n\n\nCode\nmean(mice)\n\n\n[1] 123.8105\n\n\nCode\nvar(rats)\n\n\n[1] 1542.126\n\n\nCode\nvar(mice)\n\n\n[1] 333.6129\n\n\nCode\nvar(rats)/var(mice)\n\n\n[1] 4.6225\n\n\nCode\nvar.test(rats, mice)\n\n\n\n    F test to compare two variances\n\ndata:  rats and mice\nF = 4.6225, num df = 19, denom df = 19, p-value = 0.001619\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  1.829642 11.678519\nsample estimates:\nratio of variances \n            4.6225 \n\n\n\n\nCode\nt.test(rats, mice, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  rats and mice\nt = 6.4415, df = 38, p-value = 1.414e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 42.77708 81.98702\nsample estimates:\nmean of x mean of y \n 186.1925  123.8105 \n\n\nCode\nt.test(rats, mice, var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  rats and mice\nt = 6.4415, df = 26.853, p-value = 6.84e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 42.50629 82.25781\nsample estimates:\nmean of x mean of y \n 186.1925  123.8105 \n\n\n\n\nCode\n(mean(rats) - mean(mice))/sqrt((var(rats) + var(mice))/2)\n\n\n[1] 2.036988\n\n\n\n\nCode\ncohen.d(rats, mice)\n\n\n\nCohen's d\n\nd estimate: 2.036988 (large)\n95 percent confidence interval:\n   lower    upper \n1.248080 2.825895 \n\n\ntesting test statistic formula to compare against t-test from above:\n\n\nCode\nxa &lt;- mean(rats)\nxb &lt;- mean(mice)\n\nvara &lt;- var(rats)\nvarb &lt;- var(mice)\n\nnA &lt;- length(rats)\nnB &lt;- length(mice)\n\n(xa - xb)/sqrt((vara/nA)+(varb/nB))\n\n\n[1] 6.441521\n\n\nCode\n(nA - 1) + (nB - 1)\n\n\n[1] 38\n\n\nCode\n(((vara/nA)+(varb/nB))^2)/((vara/nA)^2/(nA-1)+(varb/nB)^2/(nB-1))\n\n\n[1] 26.85313"
  },
  {
    "objectID": "lecture/lecture_week-01.html",
    "href": "lecture/lecture_week-01.html",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\n\n# visualization\nlibrary(patchwork)"
  },
  {
    "objectID": "lecture/lecture_week-01.html#set-up",
    "href": "lecture/lecture_week-01.html#set-up",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\n\n# visualization\nlibrary(patchwork)"
  },
  {
    "objectID": "lecture/lecture_week-01.html#math",
    "href": "lecture/lecture_week-01.html#math",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "1. Math",
    "text": "1. Math\n\nsample mean\n\\[\n\\bar{y} = \\frac{1}{n}\\sum_{i = 1}^ny_i\n\\]\n\n\nsample variance\n\\[\ns^2 = \\frac{\\sum(y_i - \\bar{y})^2}{n - 1}\n\\]\n\n\nsample standard deviation\n\\[\ns = \\sqrt{\\frac{\\sum(y_i - \\bar{y})^2}{n - 1}}\n\\]\n\n\ncoefficient of variation\n\\[\nCV = \\frac{\\sigma}{\\mu}\n\\]\n\n\nz-score for selecting a single individual\n\\[\nz = \\frac{y_i - \\mu}{\\sigma}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-01.html#mean-and-median",
    "href": "lecture/lecture_week-01.html#mean-and-median",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "2. Mean and median",
    "text": "2. Mean and median\nFor data following a symmetrical distribution, the mean and median tend to be similar.\n\n\nCode\nset.seed(1)\nrnorm(n = 40, mean = 6, sd = 1) %&gt;% \n  as_tibble() %&gt;% \n  ggplot(aes(x = value)) +\n  geom_density() +\n  geom_vline(aes(xintercept = mean(value)), color = \"blue\") +\n  annotate(\"text\", x = 5.75, y = 0.5, label = \"mean\", color = \"blue\") +\n  geom_vline(aes(xintercept = median(value))) +\n  annotate(\"text\", x = 6.5, y  = 0.5, label = \"median\") +\n  scale_x_continuous(limits = c(2.5, 10)) +\n  scale_y_continuous(limits = c(0, 0.5)) +\n  labs(x = \"Sculpin lengths (cm)\") +\n  theme(axis.text.y = element_blank(),\n        axis.title.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank())"
  },
  {
    "objectID": "lecture/lecture_week-01.html#range",
    "href": "lecture/lecture_week-01.html#range",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "3. Range",
    "text": "3. Range\n\n\nCode\nset.seed(1)\nnarrow &lt;- rnorm(n = 30, mean = 6, sd = 1) %&gt;% \n  as_tibble() %&gt;% \n  mutate(y = 0) %&gt;% \n  ggplot(aes(x = value, y = y)) +\n  geom_jitter(shape = 21) +\n  geom_point(aes(x = mean(value), y = 0), color = \"blue\", size = 3) +\n  scale_x_continuous(limits = c(0, 15)) +\n  scale_y_continuous(limits = c(-0.5, 0.5)) +\n  theme(axis.line.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.title.y = element_blank()) +\n  labs(x = \"Sculpin lengths (cm)\")\n# min: 3.78\n# max: 7.60\n\nset.seed(1)\nwide &lt;- rnorm(n = 30, mean = 6, sd = 2) %&gt;% \n  as_tibble() %&gt;% \n  mutate(y = 0) %&gt;% \n  ggplot(aes(x = value, y = y)) +\n  geom_jitter(shape = 21) +\n    geom_point(aes(x = mean(value), y = 0), color = \"blue\", size = 3) +\n  scale_x_continuous(limits = c(0, 15)) +\n  scale_y_continuous(limits = c(-0.5, 0.5)) +\n  theme(axis.line.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.title.y = element_blank()) +\n  labs(x = \"Sculpin lengths (cm)\")\n# min: 1.57\n# max: 9.19\n\nnarrow + wide\n\n\n\n\n\n\n\n\n\n\nHow would you describe this data?\n\n\nCode\nset.seed(1)\nex1 &lt;- rf(n = 100, df1 = 30, df2 = 10)\nmean(ex1)\n\n\n[1] 1.321259\n\n\nCode\nmedian(ex1)\n\n\n[1] 1.163362\n\n\nCode\nex1 %&gt;% \n  enframe() %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 9,\n                 color = \"#000000\",\n                 fill = \"orange\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  labs(x = \"Hermit crab shell length (cm)\")\n\n\n\n\n\n\n\n\n\nCode\nset.seed(1)\nex2 &lt;- rnorm(n = 100, mean = 25, sd = 5)\nmean(ex2)\n\n\n[1] 25.54444\n\n\nCode\nmedian(ex2)\n\n\n[1] 25.56955\n\n\nCode\nex2 %&gt;% \n  enframe() %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 9,\n                 color = \"#000000\",\n                 fill = \"darkgreen\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  labs(x = \"Octopus arm length (cm)\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#anemone-regression-example",
    "href": "lecture/lecture_week-01.html#anemone-regression-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "4. anemone regression example",
    "text": "4. anemone regression example\n\n\nCode\n# number of arms \narms &lt;- seq(from = 40, to = 100, by = 1)\n\n# diameter: anemones can be up to 8 cm long\nset.seed(10)\ndiam &lt;- rnorm(length(arms), mean = seq(from = 1, to = 5, length = length(arms)), sd = 1) \n\n# create a data frame\ndf &lt;- cbind(diam, arms) %&gt;% \n  as.data.frame()\n\nggplot(df, aes(x = arms, y = diam)) +\n  geom_point(size = 2) +\n  labs(x = \"Number of arms\", y = \"Diameter (cm)\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(df, aes(x = arms, y = diam)) +\n  geom_point(size = 2) +\n  # just using geom smooth for the purposes of visualization\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 2) +\n  labs(x = \"Number of arms\", y = \"Diameter (cm)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#histogram-example",
    "href": "lecture/lecture_week-01.html#histogram-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "5. histogram example",
    "text": "5. histogram example\nThe Rice rule guidelines for the calculating the number of bins in a histogram:\n\\[\nbins = 2n^{1/3}\n\\]\nwhere \\(n\\) is the number of observations. This is an example of a histogram that does follow the rice rule, where the bin number is 8.\n\n\nCode\nggplot(df, aes(x = diam)) +\n  scale_x_continuous(breaks = seq(from = 0, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 19), breaks = seq(from = 0, to = 18, by = 3)) +\n  geom_histogram(breaks = seq(from = 0, to = 8, by = 1), color = \"#000000\", fill = \"lightblue\") +\n  labs(x = \"Anemone diameter (cm)\", y = \"Count\") +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\nThese histograms do not, and it proves difficult to see the distribution:\n\n\nCode\nggplot(df, aes(x = diam)) +\n  scale_x_continuous(breaks = seq(from = 0, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 19), breaks = seq(from = 0, to = 18, by = 3)) +\n  geom_histogram(color = \"#000000\", fill = \"lightblue\") +\n  labs(x = \"Anemone diameter (cm)\", y = \"Count\") +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\nCode\nggplot(df, aes(x = diam)) +\n  scale_x_continuous(breaks = seq(from = 0, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_histogram(color = \"#000000\", fill = \"lightblue\", bins = 3) +\n  labs(x = \"Anemone diameter (cm)\", y = \"Count\") +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#jitter-plot-and-box-and-whisker-plot-example",
    "href": "lecture/lecture_week-01.html#jitter-plot-and-box-and-whisker-plot-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "6. jitter plot and box and whisker plot example",
    "text": "6. jitter plot and box and whisker plot example\n\n\nCode\nset.seed(1)\n\npretend_lengths &lt;- cbind(\n  juveniles = rnorm(20, mean = 2, sd = 0.5), \n  females = rnorm(20, mean = 8, sd = 1), \n  males = rnorm(20, mean = 4, sd = 1)\n) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:3)\n\nggplot(pretend_lengths, aes(x = name, y = value, color = name)) +\n  geom_jitter(width = 0.1, alpha = 0.8, size = 2) +\n  scale_color_manual(values = c(\"darkgreen\", \"cornflowerblue\", \"orange\")) +\n  labs(y = \"Weight (g)\") +\n  theme(axis.title.x = element_blank(),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(pretend_lengths, aes(x = name, y = value, color = name, fill = name)) +\n  geom_boxplot(alpha = 0.8) +\n  scale_color_manual(values = c(\"darkgreen\", \"cornflowerblue\", \"orange\")) +\n  scale_fill_manual(values = c(\"darkgreen\", \"cornflowerblue\", \"orange\")) +\n  labs(y = \"Weight (g)\") +\n  theme(axis.title.x = element_blank(),\n        legend.position = \"none\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#probability-mass-example",
    "href": "lecture/lecture_week-01.html#probability-mass-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "7. Probability mass example",
    "text": "7. Probability mass example\n\n\nCode\nggplot(data.frame(x = 1:55), aes(x)) +\n  stat_function(geom = \"bar\", n = 55, fun = dpois, args = list(lambda = 10), fill = \"coral\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.13)) +\n  coord_cartesian(xlim = c(0, 22)) +\n  labs(x = \"Mussel clump size (count)\", y = \"Probability mass\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#probability-density-example",
    "href": "lecture/lecture_week-01.html#probability-density-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "8. Probability density example",
    "text": "8. Probability density example\n\n\nCode\nggplot(data.frame(x = 1:20), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 10, sd = 2), linewidth = 1) +\n  stat_function(geom = \"area\", fun = dnorm, args = list(mean = 10, sd = 2), xlim = c(12, 14), fill = \"turquoise3\") +\n  geom_vline(xintercept = 12, lty = 2, color = \"grey\", linewidth = 1) +\n  geom_vline(xintercept = 14, lty = 2, color = \"grey\", linewidth = 1) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.22)) +\n  # coord_cartesian(xlim = c(0, 22)) +\n  labs(x = \"Individual mussel weight (g)\", y = \"Probability density\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#probability-distribution",
    "href": "lecture/lecture_week-01.html#probability-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "9. probability distribution",
    "text": "9. probability distribution\n\n\nCode\nset.seed(1)\nnormdist &lt;- rnorm(n = 100000, mean = 0, sd = 1) %&gt;% \n  as_tibble(rownames = \"x\")\n\nggplot(normdist) +\n  geom_histogram(aes(x = value, after_stat(density)), fill = \"white\", color = \"black\", bins = 100) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), color = \"blue\", linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#normal-distribution",
    "href": "lecture/lecture_week-01.html#normal-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "10. normal distribution",
    "text": "10. normal distribution\n\n\nCode\nggplot(data.frame(x = -10:25), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1, color = \"darkorange\") +\n  annotate(\"text\", x = 4.5, y = 0.4, label = \"\\U03BC = 0, \\U03C3 = 1\", color = \"darkorange\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 15, sd = 3), linewidth = 1, color = \"blue\") +\n  annotate(\"text\", x = 16, y = 0.15, label = \"\\U03BC = 15, \\U03C3 = 3\", color = \"blue\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 5, sd = 5), linewidth = 1, color = \"darkgreen\") +\n  annotate(\"text\", x = 7, y = 0.1, label = \"\\U03BC = 5, \\U03C3 = 5\", color = \"darkgreen\", size = 6) +\n  scale_x_continuous(breaks = seq(-10, 25, 5)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#z-score-calculation",
    "href": "lecture/lecture_week-01.html#z-score-calculation",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "11. z-score calculation",
    "text": "11. z-score calculation\n\nfigure\nWe’ll use \\(z = -1.23\\) for this example.\n\n\nCode\n# z-score\nq &lt;- -1.23\n\nggplot(data.frame(x = -4:4), aes(x)) +\n  # zscore\n  geom_linerange(x = q, ymin = 0, ymax = 0.19) +\n  # area under the curve\n  stat_function(geom = \"area\", fun = dnorm, args = list(mean = 0, sd = 1), xlim = c(-4, -1.23), fill = \"turquoise3\") +\n  # Z distribution curve\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1.5, color = \"darkorange\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.45)) +\n  theme(axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.title = element_blank(),\n        axis.line.y = element_blank())\n\n\n\n\n\n\n\n\n\n\n\ncalculation\n\n\nCode\npnorm(q, mean = 0, sd = 1)\n\n\n[1] 0.1093486\n\n\nYou can compare this with the Z-score table.\n\n\nchiton example\nWhat is the probability of selecting a chiton that is less than 6 ft long given a normally distributed population with \\(\\mu = 12\\) g with \\(\\sigma = 3\\) g?\n\n\nCode\n# calculate the z-score\nchiton_z &lt;- (6 - 12)/3\n  \n# calculate the probability under the curve\npnorm(chiton_z, mean = 0, sd = 1)\n\n\n[1] 0.02275013"
  },
  {
    "objectID": "lecture/lecture_week-01.html#rule",
    "href": "lecture/lecture_week-01.html#rule",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "12. 68-95-99.7 rule",
    "text": "12. 68-95-99.7 rule\nIn a normal distribution, 68% of values lie within 1 standard deviation of the mean, 95% within 2 standard deviations, and 99.7% within 3 standard deviations.\n\n\nCode\nlabels &lt;- c(\n  \"\", \"\\U03BC - 3\\U03C3\", \"\\U03BC - 2\\U03C3\", \"\\U03BC - \\U03C3\", \"\\U03BC\", \"\\U03BC + \\U03C3\", \"\\U03BC + 2\\U03C3\", \"\\U03BC + 3\\U03C3\", \"\"\n)\n\nggplot(data.frame(x = -4:4), aes(x)) +\n  geom_linerange(x = 1, ymin = 0, ymax = 0.24) +\n  geom_linerange(x = -1, ymin = 0, ymax = 0.24) +\n  geom_linerange(x = 2, ymin = 0, ymax = 0.055) +\n  geom_linerange(x = -2, ymin = 0, ymax = 0.055) +\n  geom_linerange(x = 3, ymin = 0, ymax = 0.005) +\n  geom_linerange(x = -3, ymin = 0, ymax = 0.005) +\n  geom_linerange(x = 0, ymin = 0, ymax = 0.399) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1.5, color = \"darkorange\") +\n  scale_x_continuous(labels = labels, breaks = seq(-4, 4, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.41)) +\n  labs(x = \"\") +\n  theme_classic() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 24),\n        axis.line.y = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks = element_blank())"
  },
  {
    "objectID": "lecture/lecture_week-01.html#students-t-distribution",
    "href": "lecture/lecture_week-01.html#students-t-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "13. Student’s t distribution",
    "text": "13. Student’s t distribution\n\n\nCode\nggplot(data.frame(x = -10:10), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#856F33\") +\n  annotate(\"text\", x = 3.5, y = 0.3, label = \"\\U03BD = 1\", color = \"#856F33\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 3), linewidth = 1, color = \"#E6821C\") + \n  annotate(\"text\", x = 3.5, y = 0.35, label = \"\\U03BD = 3\", color = \"#E6821C\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 5), linewidth = 1, color = \"#56E9E7\") +\n  annotate(\"text\", x = 3.5, y = 0.37, label = \"\\U03BD = 5\", color = \"#56E9E7\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 100), linewidth = 1, color = \"#04B37F\") +\n    annotate(\"text\", x = 3.5, y = 0.4, label = \"\\U03BD = 100\", color = \"#04B37F\", size = 6) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#uniform-distribution",
    "href": "lecture/lecture_week-01.html#uniform-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "14. Uniform distribution",
    "text": "14. Uniform distribution\n\n\nCode\nggplot(data.frame(x = 0:10), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dunif, args = list(min = 2, max = 8), linewidth = 1, color = \"firebrick4\") +\n  annotate(\"text\", x = 2, y = 0.172, label = \"a = 2\", color = \"firebrick4\", size = 6) + \n  annotate(\"text\", x = 8, y = 0.172, label = \"b = 8\", color = \"firebrick4\", size = 6) + \n  scale_x_continuous(breaks = seq(0, 10, 2)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(-0.001, 0.18)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#binomial-distribution",
    "href": "lecture/lecture_week-01.html#binomial-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "14. Binomial distribution",
    "text": "14. Binomial distribution\n\n\nCode\nggplot(data.frame(x = 1:20), aes(x)) +\n  stat_function(geom = \"line\", n = 20, fun = dbinom, args = list(size = 20, p = 0.1), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dbinom, args = list(size = 20, p = 0.1), color = \"#6D9929\", size = 3) +\n  annotate(\"text\", x = 5.5, y = 0.29, label = \"n = 20, p = 0.1\", color = \"#6D9929\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dbinom, args = list(size = 20, p = 0.4), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dbinom, args = list(size = 20, p = 0.4), color = \"#4A76E5\", size = 3) +\n  annotate(\"text\", x = 8, y = 0.2, label = \"n = 20, p = 0.4\", color = \"#4A76E5\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dbinom, args = list(size = 20, p = 0.7), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dbinom, args = list(size = 20, p = 0.7), color = \"#E67960\", size = 3) +\n  annotate(\"text\", x = 15, y = 0.21, label = \"n = 20, p = 0.7\", color = \"#E67960\", size = 6) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  labs(x = \"Number of successes\", y = \"Mass\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#poisson-distribution",
    "href": "lecture/lecture_week-01.html#poisson-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "15. Poisson distribution",
    "text": "15. Poisson distribution\n\n\nCode\nggplot(data.frame(x = 1:20), aes(x)) +\n  stat_function(geom = \"line\", n = 20, fun = dpois, args = list(lambda = 1), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dpois, args = list(lambda = 1), color = \"coral\", size = 4) +\n  annotate(\"text\", x = 3, y = 0.37, label = \"\\U03BB = 1\", color = \"coral\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dpois, args = list(lambda = 4), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dpois, args = list(lambda = 4), color = \"darkgreen\", size = 4) +\n  annotate(\"text\", x = 6, y = 0.2, label = \"\\U03BB = 4\", color = \"darkgreen\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dpois, args = list(lambda = 10), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dpois, args = list(lambda = 10), color = \"turquoise\", size = 4) +\n  annotate(\"text\", x = 14, y = 0.12, label = \"\\U03BB = 10\", color = \"turquoise\", size = 6) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Discrete value\", y = \"Mass\")"
  },
  {
    "objectID": "workshop/workshop-03_2024-04-18.html",
    "href": "workshop/workshop-03_2024-04-18.html",
    "title": "Coding workshop: Week 3",
    "section": "",
    "text": "tidyverse\n\nreadxl\n\njanitor\n\n\n\n\n\n\n\ncreate new columns based on data in existing columns using mutate() and case_when()\n\nvisualize QQ plots using geom_qq() and geom_qq_line()\n\ncreate multi-panel plots using facet_wrap()\n\ncreate jitter plots using position = position_jitter() within geom_point()\n\nvisualize summary statistics using stat_summary()\n\ncompare group variances using var.test()\n\ndo t-tests using t.test()\n\n\n\n\n\nread in data using read_csv()\n\nchain functions together using %&gt;%\n\nclean column names using clean_names()\n\nselect columns using select()\n\nmake data frame longer using pivot_longer()\n\nrename columns using rename()\n\ngroup data using group_by()\n\nsummarize data using reframe()\n\ncalculate standard deviation using sd()\n\ncalculate t-values using qt()\n\nvisualize data using ggplot()\n\ncreate histograms using geom_histogram()\n\nvisualize confidence intervals using geom_pointrange()\n\n\n\n\n\nIf you’re working in the source editor (as we did in class), you can control the appearance of text, links, images, etc. using this guide.\n\n\n\nThe bison data is a subsetted version of the bison weight data from Konza Prairie as presented in the lterdatasampler package (more about the data here). The Flint water data is from a massive citizen science sampling effort done in 2015 by the residents of Flint, Michigan - read more about this project here and download the data here."
  },
  {
    "objectID": "workshop/workshop-03_2024-04-18.html#summary",
    "href": "workshop/workshop-03_2024-04-18.html#summary",
    "title": "Coding workshop: Week 3",
    "section": "",
    "text": "tidyverse\n\nreadxl\n\njanitor\n\n\n\n\n\n\n\ncreate new columns based on data in existing columns using mutate() and case_when()\n\nvisualize QQ plots using geom_qq() and geom_qq_line()\n\ncreate multi-panel plots using facet_wrap()\n\ncreate jitter plots using position = position_jitter() within geom_point()\n\nvisualize summary statistics using stat_summary()\n\ncompare group variances using var.test()\n\ndo t-tests using t.test()\n\n\n\n\n\nread in data using read_csv()\n\nchain functions together using %&gt;%\n\nclean column names using clean_names()\n\nselect columns using select()\n\nmake data frame longer using pivot_longer()\n\nrename columns using rename()\n\ngroup data using group_by()\n\nsummarize data using reframe()\n\ncalculate standard deviation using sd()\n\ncalculate t-values using qt()\n\nvisualize data using ggplot()\n\ncreate histograms using geom_histogram()\n\nvisualize confidence intervals using geom_pointrange()\n\n\n\n\n\nIf you’re working in the source editor (as we did in class), you can control the appearance of text, links, images, etc. using this guide.\n\n\n\nThe bison data is a subsetted version of the bison weight data from Konza Prairie as presented in the lterdatasampler package (more about the data here). The Flint water data is from a massive citizen science sampling effort done in 2015 by the residents of Flint, Michigan - read more about this project here and download the data here."
  },
  {
    "objectID": "workshop/workshop-03_2024-04-18.html#code",
    "href": "workshop/workshop-03_2024-04-18.html#code",
    "title": "Coding workshop: Week 3",
    "section": "2. Code",
    "text": "2. Code\n\n1. Set up\n\n# read in packages\nlibrary(tidyverse)\n\n# Bison from Konza Prairie LTER\nknz_bison &lt;- read_csv(\"knz_bison.csv\")\n\n\n\n2. Cleaning the bison data\n\nknz_bison_clean &lt;- knz_bison %&gt;% \n  mutate(animal_sex = case_when(\n    animal_sex == \"F\" ~ \"female\",\n    animal_sex == \"M\" ~ \"male\"\n  ))\n\nThe data frame should look something like this:\n\nhead(knz_bison_clean)\n\n# A tibble: 6 × 8\n  data_code rec_year rec_month rec_day animal_code animal_sex animal_weight\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;              &lt;dbl&gt;\n1 CBH01         2011        10      27 O-101       female               316\n2 CBH01         2011        10      27 O-102       female               266\n3 CBH01         2011        10      27 O-103       male                 290\n4 CBH01         2011        10      27 O-104       male                 326\n5 CBH01         2011        10      27 O-105       male                 336\n6 CBH01         2011        10      27 O-106       male                 350\n# ℹ 1 more variable: animal_yob &lt;dbl&gt;\n\n\n\n\n3. Exploring the bison data\n\na. Histograms\n\nggplot(knz_bison_clean,\n       aes(x = animal_weight,\n           fill = animal_sex)) +\n  geom_histogram(bins = 9) +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 30)) +\n  facet_wrap(~animal_sex) +\n  theme_minimal() +\n  theme(legend.position = \"none\") \n\n\n\n\n\n\n\n\n\n\nb. QQ plots\n\nggplot(knz_bison_clean,\n       aes(sample = animal_weight,\n           color = animal_sex)) +\n  geom_qq() +\n  geom_qq_line() +\n  theme_bw() +\n  facet_wrap(~animal_sex)\n\n\n\n\n\n\n\n\n\n\nc. Jitter plots and dot and whisker\n\nggplot(knz_bison_clean,\n       aes(x = animal_sex,\n           y = animal_weight,\n           color = animal_sex)) +\n  geom_point(position = position_jitter(width = 0.1, \n                                        seed = 1),\n             alpha = 0.1) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_cl_normal) +\n  labs(x = \"Sex\",\n       y = \"Weight (pounds)\") +\n  theme_classic() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n3. t-test\n\na. check variances\n\nvar.test(animal_weight ~ animal_sex, \n         data = knz_bison_clean)\n\n\n    F test to compare two variances\n\ndata:  animal_weight by animal_sex\nF = 0.84041, num df = 71, denom df = 67, p-value = 0.4705\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.5212348 1.3505428\nsample estimates:\nratio of variances \n         0.8404117 \n\n\n\n\nb. do the t-test\n\nt.test(animal_weight ~ animal_sex, \n         data = knz_bison_clean,\n       var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  animal_weight by animal_sex\nt = -1.7396, df = 138, p-value = 0.08416\nalternative hypothesis: true difference in means between group female and group male is not equal to 0\n95 percent confidence interval:\n -33.028782   2.112115\nsample estimates:\nmean in group female   mean in group male \n            311.0417             326.5000 \n\n\n\n\nc. writing\nThere is no significant difference in weights between male and female bison calves (two-sample t-test, t(138) = -1.74, p = 0.08).\n\n\n\n4. Paired t-tests\n\na. read in data\n\n# read in packages here\nlibrary(readxl)\nlibrary(janitor)\n\n# Flint water lead data\nflint_pb &lt;- read_xlsx(\"Flint-Samples-WORKING-COPY.xlsx\", \n                      sheet = \"Samples from Flint Water homes\")\n\n\n\nb. clean and wrangle the data\n\nflint_pb_clean &lt;- flint_pb %&gt;%\n  clean_names() %&gt;% # clean names using janitor function\n  select(sample_id, pb_bottle_1_ppb_first_draw, pb_bottle_2_ppb_45_secs_flushing, pb_bottle_3_ppb_2_mins_flushing) %&gt;% # select columns of interest\n  pivot_longer(cols = pb_bottle_1_ppb_first_draw:pb_bottle_3_ppb_2_mins_flushing) %&gt;% # make data frame longer\n  rename(flushing_interval = name,\n         lead_ppb = value) %&gt;% # rename columns\n  mutate(flushing_interval = case_when(\n    flushing_interval == \"pb_bottle_1_ppb_first_draw\" ~ \"first\",\n    flushing_interval == \"pb_bottle_2_ppb_45_secs_flushing\" ~ \"45 seconds\",\n    flushing_interval == \"pb_bottle_3_ppb_2_mins_flushing\" ~ \"two minutes\"\n  )) %&gt;% # use mutate and case when to recode levels in flushing interval column\n  filter(flushing_interval != \"45 seconds\") # take out 45 seconds interval\n\n\n\nc. plot the data with confidence intervals\n\nggplot(flint_pb_clean,\n       aes(x = flushing_interval,\n           y = lead_ppb)) +\n  geom_point(position = position_jitter(width = 0.1, seed = 1),\n             alpha = 0.1,\n             shape = 21) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_cl_normal) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nd. Summarize the data\n\nflint_pb_summary &lt;- flint_pb_clean %&gt;% \n  group_by(flushing_interval) %&gt;% \n  reframe(mean = mean(lead_ppb),\n          n = length(lead_ppb),\n          sd = sd(lead_ppb),\n          se = sd/sqrt(n),\n          tval = qt(p = 0.05/2, df = n - 1, lower.tail = FALSE),\n          margin = tval*se,\n          ci_lower = mean - margin,\n          ci_higher = mean + margin)\n\n\n\ne. Do a paired t-test\n\nt.test(lead_ppb ~ flushing_interval, \n       data = flint_pb_clean,\n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  lead_ppb by flushing_interval\nt = 6.3748, df = 270, p-value = 7.891e-10\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 4.827963 9.142612\nsample estimates:\nmean difference \n       6.985288 \n\n\n\n\nf. Writing\nIn words: There was a significant difference in the amount of lead in parts per billion detected between samples collected immediately after turning the water on and after 2 minutes (paired t-test, t(270) = 6.37, p &lt; 0.001).\nOn average, samples collected after 2 minutes had lead levels of 10.6 ppb [95% CI: 8.07, 13.2], while samples collected immediately had lead levels of 3.66 ppb [95% CI: 2.40, 4.92]."
  },
  {
    "objectID": "workshop/workshop-02_2024-04-11.html",
    "href": "workshop/workshop-02_2024-04-11.html",
    "title": "Coding workshop: Week 2",
    "section": "",
    "text": "tidyverse\n\njanitor\n\n\n\n\n\nread in data using read_csv()\n\nchain functions together using %&gt;%\n\nclean column names using clean_names()\n\ncreate new columns using mutate()\n\nselect columns using select()\n\nmake data frame longer using pivot_longer()\n\nrename columns using rename()\n\ngroup data using group_by()\n\nsummarize data using reframe()\n\ncalculate standard deviation using sd()\n\ncalculate t-values using qt()\n\nexpand data frames using deframe()\n\nvisualize data using ggplot()\n\ncreate histograms using geom_histogram()\n\nvisualize means and raw data using geom_point()\n\nvisualize standard deviation, standard error, and confidence intervals using geom_errorbar() and geom_pointrange()\n\n\n\n\nThis workshop’s data comes from Tidy Tuesday 2021-10-12, which was from OurWorldinData.org."
  },
  {
    "objectID": "workshop/workshop-02_2024-04-11.html#summary",
    "href": "workshop/workshop-02_2024-04-11.html#summary",
    "title": "Coding workshop: Week 2",
    "section": "",
    "text": "tidyverse\n\njanitor\n\n\n\n\n\nread in data using read_csv()\n\nchain functions together using %&gt;%\n\nclean column names using clean_names()\n\ncreate new columns using mutate()\n\nselect columns using select()\n\nmake data frame longer using pivot_longer()\n\nrename columns using rename()\n\ngroup data using group_by()\n\nsummarize data using reframe()\n\ncalculate standard deviation using sd()\n\ncalculate t-values using qt()\n\nexpand data frames using deframe()\n\nvisualize data using ggplot()\n\ncreate histograms using geom_histogram()\n\nvisualize means and raw data using geom_point()\n\nvisualize standard deviation, standard error, and confidence intervals using geom_errorbar() and geom_pointrange()\n\n\n\n\nThis workshop’s data comes from Tidy Tuesday 2021-10-12, which was from OurWorldinData.org."
  },
  {
    "objectID": "workshop/workshop-02_2024-04-11.html#code",
    "href": "workshop/workshop-02_2024-04-11.html#code",
    "title": "Coding workshop: Week 2",
    "section": "2. Code",
    "text": "2. Code\n\n1. Set up\n\n# load in packages\nlibrary(tidyverse)\nlibrary(janitor)\n\n\n# read in data\nglobal_catch &lt;- read_csv(\"global-fishery-catch-by-sector.csv\")\n\n\n\n2. Cleaning up\nThis chunk of code cleans the column names, converts catch to catch per million tons, selects columns, makes the data frame longer, and renames the columns.\n\nglobal_catch_clean &lt;- global_catch %&gt;% # use the global_catch data frame\n  clean_names() %&gt;% # clean up column names\n  mutate(artisanal = artisanal_small_scale_commercial/1000000,\n         industrial = industrial_large_scale_commercial/1000000) %&gt;% # convert catch/1000000\n  select(year, artisanal, industrial) %&gt;% # select columns \n  pivot_longer(cols = artisanal:industrial) %&gt;% # make the data frame longer\n  rename(catch_mil = value,\n         fishery_type = name) # rename columns\n\n\n\n3. Making a histogram\nThis chunk of code creates a histogram.\n\nggplot(data = global_catch_clean,\n       aes(x = catch_mil,\n           fill = fishery_type)) + # fill the histogram based on the fishery type\n  geom_histogram(bins = 9, # set the number of bins\n                 alpha = 0.6, # make the columns transparent\n                 color = \"black\", # make the border of the columns black\n                 position = \"identity\") + # make the columns sit on top of each other\n  scale_y_continuous(expand = c(0, 0), # get rid of the space between the x-axis and the columns\n                     limits = c(0, 35)) # define the y-axis limits\n\n\n\n\n\n\n\n\n\n\n4. Visualizing standard error and confidence intervals\n\na. Calculations\n\n# calculate the confidence interval \"by hand\"\nglobal_catch_summary &lt;- global_catch_clean %&gt;% \n  group_by(fishery_type) %&gt;% \n  reframe(mean = mean(catch_mil), # calculate the mean\n            n = length(catch_mil), # count the number of observations\n            df = n - 1, # calculate the degrees of freedom\n            sd = sd(catch_mil), # calculate the standard deviation\n            se = sd/sqrt(n), # calculate the standard error\n            tval = qt(p = 0.05/2, df = df, lower.tail = FALSE), # find the t value\n            margin = tval*se, # calculate the margin of error\n            ci_lower = mean - margin, # calculate the lower bound of the confidence interval\n            ci_higher = mean + margin # calculate the upper bound of the confidence interval\n          ) \n\nThis is what your data frame should look like:\n\nglobal_catch_summary\n\n# A tibble: 2 × 10\n  fishery_type  mean     n    df    sd    se  tval margin ci_lower ci_higher\n  &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 artisanal     15.2    61    60  4.26 0.545  2.00   1.09     14.1      16.3\n2 industrial    59.5    61    60 24.2  3.10   2.00   6.21     53.3      65.7\n\n\n\n\nb. Visualizations\nWe want to visualized standard error:\n\nggplot(data = global_catch_summary,\n       aes(x = fishery_type, \n           y = mean, \n           color = fishery_type)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymin = mean - se, # plot the standard error\n                    ymax = mean + se),\n                width = 0.1) +\n  labs(title = \"Standard error\")\n\n\n\n\n\n\n\n\nand the 95% confidence interval:\n\nggplot(data = global_catch_summary,\n       aes(x = fishery_type, \n           y = mean, \n           color = fishery_type)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymin = mean - margin, # plot the 95% confidence interval\n                    ymax = mean + margin),\n                width = 0) +\n  labs(title = \"95% confidence interval\")\n\n\n\n\n\n\n\n\n\n\n\n5. Extra stuff\n\na. Controlling boundaries in a histogram\nThe general steps to do this are:\n\ncalculate the range\n\ndetermine the number of observations\n\ncalculate the number of bins you want (then round to the nearest whole number)\n\ncalculate the width of each bin by taking the range and dividing it by the number of bins - 2 (if the number of bins is odd) or bins - 1 (if the number of bins is even)\n\ndefine the line breaks by creating a sequence of numbers, calculating the boundaries for each bin (and if necessary, rounding the boundaries)\n\n\n# calculate the range\nrange &lt;- max(global_catch_clean$catch_mil) - min(global_catch_clean$catch_mil)\n\n# determine the number of observations\nobs &lt;- nrow(global_catch_clean)\n\n# calculate the number of bins using the Rice Rule\n# note that this doesn't come out to a whole number, so it's rounded\nbins &lt;- 2*(obs^(1/3)) %&gt;% \n  round(digits = 0)\n\n# calculate the width of the bin\nbinwidth &lt;- range/(bins - 2)\n\n# set up a sequence of numbers from 0 to 100\nseq &lt;- seq(from = 0, to = 100, by = 1)\n\n# calculate the axis breaks  \naxis_breaks &lt;- seq*binwidth + (binwidth/2)\n\n# round the axis breaks\naxis_breaks_rounded &lt;- round(axis_breaks, \n                             digits = 1)\n\nThen you can make your histogram with the right line breaks:\n\nggplot(data = global_catch_clean,\n       aes(x = catch_mil,\n           fill = fishery_type)) +\n  geom_histogram(binwidth = binwidth, \n                 alpha = 0.6, \n                 color = \"black\", \n                 position = \"identity\") +\n  scale_x_continuous(breaks = axis_breaks_rounded) +\n  scale_y_continuous(expand = c(0, 0), \n                     limits = c(0, 35))\n\n\n\n\n\n\n\n\n\n\nb. plotting the confidence interval using stat_summary\n\nggplot(data = global_catch_clean,\n       aes(x = fishery_type, \n           y = catch_mil, \n           color = fishery_type)) +\n  stat_summary(fun.data = mean_cl_normal, \n               geom = \"pointrange\") +\n  labs(title = \"95% confidence interval using stat_summary\")\n\n\n\n\n\n\n\n\n\n\nc. calculating the confidence interval with ggplot::mean_cl_normal\n\n# use a function to calculate the confidence interval\nglobal_catch_ci &lt;- global_catch_clean %&gt;% \n  group_by(fishery_type) %&gt;% \n  summarize(ci = mean_cl_normal(catch_mil)) %&gt;% # calculate the CI using a function\n  deframe() # expand the data frame\n\n\n\nd. Visualizing standard deviation\n\n\n\n\n\n\nNote\n\n\n\nThis is the same code that you would use if you were making a plot where your whiskers = standard error or whiskers = confidence interval.\n\n\n\nggplot(data = global_catch_summary, # use the summary data frame\n       aes(x = fishery_type, \n           y = mean, \n           color = fishery_type)) + # color the points by fishery type\n  geom_point(size = 2) + # plot the mean\n  geom_errorbar(aes(ymin = mean - sd, # plot the standard deviation\n                    ymax = mean + sd),\n                width = 0.1) +\n  labs(title = \"Standard deviation\")\n\n\n\n\n\n\n\n\n\n\ne. Visualizing the confidence interval with the underlying data\n\nggplot(data = global_catch_clean,\n       aes(x = fishery_type, \n           y = catch_mil, \n           color = fishery_type)) +\n  geom_point(position = position_jitter(width = 0.05, \n                                        seed = 1),\n             alpha = 0.2) +\n  geom_pointrange(data = global_catch_summary,\n                  aes(x = fishery_type, \n                      y = mean, \n                      ymin = mean - margin, \n                      ymax = mean + margin)) +\n  scale_color_manual(values = c(\"artisanal\" = \"cornflowerblue\",\n                                \"industrial\" = \"orange\")) +\n  labs(x = \"Fishery type\",\n       y = \"Catch per million tonnes\",\n       title = \"Industrial fisheries catch more than artisanal fisheries\") +\n  theme_light()"
  },
  {
    "objectID": "assignments/homework-02.html",
    "href": "assignments/homework-02.html",
    "title": "Homework 2",
    "section": "",
    "text": "Due on Wednesday April 24 (Week 4) at 11:59 PM\nRead the instructions carefully and double check that you have everything on the checklist."
  },
  {
    "objectID": "assignments/homework-02.html#part-1.-tasks",
    "href": "assignments/homework-02.html#part-1.-tasks",
    "title": "Homework 2",
    "section": "Part 1. Tasks",
    "text": "Part 1. Tasks\nYou do not need to submit anything for these tasks, but are expected to have completed and know the material.\n\nTask 1. Beginning steps to configure Git/GitHub: Part 2\n\nConfigure git and store your personal access token.\n\n\nInstructions for MacOS\nInstructions for Windows\n\n\n\n\n\n\n\nNote\n\n\n\nNote: make sure git is installed. You did this last week for one of your homework tasks, but if it wasn’t installed and you didn’t install it, do it now!\n\n\n\n\nTask 2. Read Lowndes and Horst 2020, “Tidy data for efficiency, reproducibility, and collaboration.”\n\n\nTask 3. Read Horst and Lowndes 2022, “GitHub for supporting, reusing, contributing, and failing safely.”\n\n\nTask 4. Install R packages\n\nlterdatasampler\nRead about the package here."
  },
  {
    "objectID": "assignments/homework-02.html#part-2.-problems",
    "href": "assignments/homework-02.html#part-2.-problems",
    "title": "Homework 2",
    "section": "Part 2. Problems",
    "text": "Part 2. Problems\n\n\n\n\n\n\nTip\n\n\n\nRemember to set up a directory specifically for this homework assignment!\n\n\n\nProblem 1. Raptor abundance between restoration plots (10 points)\nManagers at Coal Oil Point Reserve (COPR) are interested in the relationship between restored areas and raptor abundance: as different parts of the reserve are restored to native grassland, small mammal (i.e. mice, gopher, vole) abundances should increase, which should attract more raptors (i.e. hawks, falcons) to the reserve. You conduct weekly surveys for raptors at COPR from April to June in one of the restoration areas and collect the following data on the number of raptors you see for each survey:\n\\[\n0, 2, 4, 6, 1, 2, 3, 5, 1, 0\n\\]\n\nWhat kind of data did you collect, and why? Explain in 1-2 sentences. (2 points)\n\nWhat is a better description of the variability in raptor count, standard deviation or standard error? Explain why in 1-2 sentences and calculate the metric of your choice, showing your work. (4 points)\n\nWhat is a better description of the uncertainty in raptor count, standard deviation or standard error? Explain why in 1-2 sentences and calculate the metric of your choice, showing your work. (4 points)\n\n\n\nProblem 2. Sugar maple stem masses (38 points)\nUsing the hbr_maples data set from lterdatasampler, answer the question: Does mean sugar maple stem mass in 2003 differ between reference and calcium-treated watersheds?\n\n\n\n\n\n\nWorking with data in a package\n\n\n\nIf you load in the package using library(lterdatasampler), the hbr_maples data set will be ready for you to use, but you just won’t see it in your environment. To have the data set pop up in your environment, use data(hbr_maples).\n\n\nFor any calculations for which you need a confidence level, use 95% with the corresponding significance level.\n\nIn one sentence each, write your null and alternative hypotheses to address this question. (2 points)\n\nMake a QQ plot. In one sentence, describe whether the variable is normally distributed or not. (4 points)\n\nCheck variances. In one sentence, describe whether the groups have equal variances or not. (4 points)\n\nCalculate the critical value for your test. (4 points)\n\nDo a t-test. (4 points)\n\n\n\n\n\n\n\nt-test arguments\n\n\n\n\n\nDouble check your arguments to make sure you’re running the right test.\n\n\n\n\nCalculate an effect size and show the output. (4 points)\n\n\n\n\n\n\n\nCalculating an effect size\n\n\n\n\n\nYou can either calculate Cohen’s d by using the formula presented in lecture:\n\\[\nCohen's \\; d = \\frac{\\bar{y_A} - \\bar{y_B}}{\\sqrt{\\frac{(n_A - 1)\\times s^2_A + (n_B - 1)\\times s^2_B}{n_A + n_B + 2}}}\n\\]\nor you could use a function in the package effectsize called cohens_d().\n\n\n\n\nMake a figure with mean and confidence intervals showing the raw data underneath the summary information. Make sure that your plot is finalized. For full credit on your plot, adjust the ggplot()/geom_() defaults such that your plot has:\n\nDifferent colors for each watershed\n\nDifferent shapes for each watershed\n\nA different font than the default\n\nNo gridlines\n(6 points)\n\nWrite a “methods” section. In one sentence each, describe:\n\nWhy the test you chose may have been appropriate for testing your hypotheses in part a\n\nHow you evaluated normality and homogeneity of variance\n(4 points)\n\nWrite a “results” section. Describe the results in full sentences in your own words, making sure to include the:\n\nTest you ran\n\nNumber of observations for each watershed\nSignificance level\nDegrees of freedom\nTest statistic\np-value\nConfidence interval in the difference in mean stem masses between watershed\nEffect size\n(6 points)\n\n\n\n\nProblem 3. Personal data (12 points)\nBy now, you have some observations on your data sheet for your personal data. Even though it’s early on in your data collection, it’s a good idea to practice good data management. For this problem, you’ll enter your data, read it into R, and create a visualization. If you get stuck at any step, you’ll know there’s something you need to fix.\n\nCreate a spreadsheet to enter your data. Two good options include Google Sheets or Microsoft Excel.\n\nCreate the columns of your spreadsheet.\n\n\n\n\n\n\n\nSpreadsheet columns\n\n\n\n\n\nIf you organized your data sheet in “tidy format” (i.e. each row is an observation), then the columns of your spreadsheet would be exactly the same as the columns in your data sheet.\n\n\n\n\nEnter your data.\n\nSave your spreadsheet as a .csv file in your homework repository.\n\nRead your data into R.\n\nCreate a visualization to explore your data. Finalize the plot. (4 points)\n\nIn 1-2 sentences, describe what the “main message” of your visualization is. (4 points)\n\nIn 2-4 sentences, describe the process of getting your data from your spreadsheet into R. Did you encounter any challenges? If so, why do you think those challenges arose, and how did you fix them? If not, why do you think your system for collecting your data worked? (4 points)\n\n\n\n\n\n\n\nChanging your data collection scheme\n\n\n\n\n\nIf you found that entering your data from your spreadsheet and getting it into the right format to be used in R was challenging, that’s ok! This happens a lot with data collection. Feel free to change your data sheet so that you’re collecting data in a way that makes your life easier as you’re reading your data into R and using it.\n\n\n\n\n\nProblem 4. Statistical critique (10 points)\nCheck the Google sheet and choose a paper to use for your critique based on An’s/Caitlin’s recommendations. Answer the following questions about the paper in 1-2 sentences each:\n\nWhy were you interested in this paper? (2 points)\n\nWhat questions/hypotheses are the authors addressing? (2 points)\n\nWhat statistical tests are the authors doing? Is there anything confusing about what they did? (2 points)\n\nFind the figures and/or tables in the paper that is associated with the statistical tests from question (c). If you have a figure, what are the x- and y-axes, and what does the figure show (i.e. what is the main message of the figure)? If you have a table, what are the rows and columns, and what is it supposed to show? (2 points)\n\nTake a screenshot of the figures and/or tables and insert the screenshot into your homework document. (2 points)"
  },
  {
    "objectID": "assignments/homework-02.html#checklist",
    "href": "assignments/homework-02.html#checklist",
    "title": "Homework 2",
    "section": "Checklist",
    "text": "Checklist\nYour homework should\n\nInclude your name, the title (“Homework 2”), and the date you turned in the assignment (3 points)\n\nInclude for Problem 1:\n\nresponses for a-c\nfull work (hand written or R code) for parts b-c\n\nInclude for Problem 2:\n\nwritten response for part a\n\nfull work (R code), output, and written response for parts b-c\n\nfull work (R code) and output for parts d-f\n\nfull work (R code) and output for part g\n\nwritten response for parts h-i\n\n\nInclude for Problem 3:\n\nfull work (R code) and output for part f\n\nwritten responses for parts g-h\n\n\nInclude for Problem 4:\n\nwritten responses for parts a-d\n\nfigure for part e\n\n\nbe uploaded to Canvas as a single PDF (1 point)\n\nbe organized and readable (10 points)\n\n84 points total"
  },
  {
    "objectID": "assignments/homework-01.html",
    "href": "assignments/homework-01.html",
    "title": "Homework 1",
    "section": "",
    "text": "Due on Wednesday April 17 (Week 3) at 11:59 PM\nRead these instructions before starting your homework and follow them carefully. See the end of this assignment for a checklist of components that your assignment must have at minimum (i.e. to earn at least partial credit). Only submit the items in that list, in the order requested."
  },
  {
    "objectID": "assignments/homework-01.html#frequently-asked-questions",
    "href": "assignments/homework-01.html#frequently-asked-questions",
    "title": "Homework 1",
    "section": "Frequently Asked Questions",
    "text": "Frequently Asked Questions\n\nI’m having trouble rendering to PDF. What can I do?\nYou could either install all the additional things R is asking for you to install, or you can render to a word doc instead (change pdf in the top part of the document to docx) and save that doc as a PDF.\n\n\nI don’t know how to insert an image into a Quarto document. How do I do that?\nHere is a resource for Quarto. If you rendered your Quarto file to a word document, you can insert an image into that word document the same way you would with any other word doc.\n\n\nWhere is the feedback for problem 4?\nIt is in the google sheet."
  },
  {
    "objectID": "assignments/homework-01.html#part-1.-tasks",
    "href": "assignments/homework-01.html#part-1.-tasks",
    "title": "Homework 1",
    "section": "Part 1. Tasks",
    "text": "Part 1. Tasks\n\n\n\n\n\n\nNote\n\n\n\nYou will not need to submit any materials for tasks, but you are expected to complete the material.\n\n\n\nTask 1. Beginning steps to configure Git/GitHub\n\nCheck that Git is installed on your computer. It likely already is, but check anyway!\n\nInstructions for Macs\nInstructions for Windows\n\nIf you do not have git installed, follow the instructions to install it.\n\nIf you don’t have one already, create a GitHub account.\n\nRead Jenny Brian’s Happy Git with R Section 4.1: “Username advice” (for example, An’s GitHub username is an-bui and Caitlin’s is cnordheim-maestas)\n\nVisit GitHub\n\nCreate an account using your personal email (not your UCSB email, which you will lose access to once you graduate)\n\n\n\n\nTask 2. Read Julia Lowndes’ piece in Scientific American: “Open Software Means Kinder Science”"
  },
  {
    "objectID": "assignments/homework-01.html#part-2.-problems-code-and-figures",
    "href": "assignments/homework-01.html#part-2.-problems-code-and-figures",
    "title": "Homework 1",
    "section": "Part 2. Problems, code, and figures",
    "text": "Part 2. Problems, code, and figures\nCarefully read the checklist for the components that you will need to submit for each problem. Show all your work.\n\n\n\n\n\n\nSetting up\n\n\n\nYou’ll want to set up a directory specifically for this homework assignment within your class directory. For example, your class directory is called ENVS-193DS, while your directory for this homework assignment could be called something like ENVS-193DS_homework-01. Then, you can create a project within the directory for this assignment. Afterward, you can save your code and data into the same directory.\n\n\n\nProblem 1. Measures of central tendency and data spread (8 points)\nAfter the major rains this winter, you’re interested in what’s happening with the Pacific treefrog (Pseudacris hypochondriaca) population at North Campus Open Space. You’ve collected the following masses (in grams) for tree frogs in one night of sampling (frogs can be hard to catch!):\n\\[\n23, 32, 39, 25, 35, 28\n\\]\n\nIn one sentence, categorize this data set: what type of data did you collect, and why is it that type? (2 points)\n\nCalculate the sample mean. Express your answer with the correct units. (2 points)\n\nCalculate the sample variance. Express your answer with the correct units. (2 points)\n\nCalculate the sample standard deviation. Express your answer with the correct units. (2 points)\n\n\n\nProblem 2. Visualizing data (9 points)\nIn this problem, you’ll work with data collected by the National Snow and Ice Data Center on glacial mass and sea level rise.\nGetting set up:\n\nRead the overview information about the data set from the database.\n\nDownload the two data files from Canvas (linked in the Homework 1 assignment page) into your directory (aka folder) for this assignment.\n\nData file 1: glacial_volume_loss_copy.csv\n\nData file 2: glacial_volume_loss.csv\n\nOpen up the two data files and look at them side-by-side. In one sentence, explain how the data files are different. (1 point)\n\nRead the metadata (data/information about the data) in data file 2 (glacial_volume_loss.csv) to understand what each column means.\n\nCoding:\n\nMake sure your data files and your script (R script, Quarto, or RMarkdown document) is in the same folder as the data file.\n\nLoad the tidyverse package.\n\nRead in data file 1 using read_csv(“glacial_volume_loss_copy.csv”) and store that as an object named glaciers.\n\nCreate a histogram of annual sea level rise. (4 points)\n\nCreate a scatterplot of cumulative sea level rise through time (year on the x-axis, cumulative sea level rise on the y-axis). (4 points)\n\n\n\nProblem 3. Personal data (20 points total)\nThis quarter, you’ll collect data from your own life to see how data science concepts are part of your daily existence. For this homework assignment, you’ll come up with two ideas for data collection. The data you collect:\n\nhas to be something you can get at least 30 observations on by week 10 (e.g. minutes to get from ENVS 193DS to your next class, not number of shark views per week)\n\ncan’t something you can get from data collection objects (e.g. number of steps in a day)\n\nhas to be something that you could actually remember to write down (e.g. liters of water consumed in a day, not time spent on tiktok)\n\nhas to be be shaped by a question (e.g. how much water do i drink in a day?)\n\nhas to include variables that would be appropriate to share with the class\n\nFor each idea you have (remember you have to come up with two ideas), you should:\n\narticulate a question (2 points each)\n\ndescribe when you would write that data down (2 points each)\n\ndescribe what other variables you think you should measure (2 points each)\n\ndescribe what type of data your variables are (2 points each)\n\ndesign a data sheet with some example data: what are the columns and what are the rows? (2 points each)\n\nExample:\n\nQuestion: How many different types of vegetables do I eat?\n\nI would take data after every meal.\n\nDate, time of day, type of vegetable, meal, whether or not it’s cooked, if it’s eaten with other things\n\n\n\n\nDate: continuous\n\ntime of day: categorical (morning, afternoon, evening)\n\nmeal: categorical (breakfast, lunch, dinner, snack)\n\ncooked: binary (yes/no)\n\neaten with other things: binary (yes/no)\n\n\n\n\n\n\n\n\n\n\n\nWhen can you start collecting data?\n\n\n\nAn will give you feedback and recommendations for what to pursue for this project on Canvas on Thursday the 18th of April. That means that you should be able to start collecting data by the end of week 3, if not sooner.\n\n\n\n\nProblem 4. Setting up statistical critique (6 points)\nThroughout the quarter, you’ll engage in a critique of statistical methods for a published paper. Some methods are appropriate for the data and research questions, and some are not. You’ll be the judge.\nFor this homework assignment, you will find 3 candidate papers for your critique. Find 3 papers that speak to your interests - the paper could be on human health, plant restoration, agroecology, or more. Anything you might be interested in within the realm of environmental studies is fair game. Not all 3 papers have to be on the same topic.\n\nFor each paper, read the Abstract to get a general sense of what the paper is about. Then, read the Methods section, looking for information on statistical analysis. A paper is a good choice if it includes one of these terms (or something similar) in the analysis description:\n\nt-test\n\nAnalysis of variance (ANOVA)\n\nMann-Whitney U\n\nKruskal-Wallis\n\nWilcoxon rank sum\n\nLinear model or linear regression\n\nSpearman correlation\n\nPearson correlation\n\nlogistic regression\n\nGeneralized linear mixed effect model\n\nOnce you’ve verified that your paper includes at least one of the above listed terms, find the digital object identifier (DOI), which is a unique identifier in the form of a URL for a paper. You will know it is a DOI if it has doi.org somewhere in the URL.\n\nOnce you find the DOI for your paper, add it to the Google form. Repeat this for all three papers. (3 points)\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want to see what other people have chosen, see the class responses here.\n\n\n\nIn your homework document, list the papers in alphabetical order by author last name. (3 points)\nYour citations should take the form:\nLast name, first name, et al. Year. “Paper title.” Journal title volume:issue.\nExample:\nSanford, E., et al. 2019. “Widespread shifts in the coastal biota of northern California during the 2014–2016 marine heatwaves.” Scientific Reports 9:4216."
  },
  {
    "objectID": "assignments/homework-01.html#checklist",
    "href": "assignments/homework-01.html#checklist",
    "title": "Homework 1",
    "section": "Checklist",
    "text": "Checklist\nYour homework should\n\nInclude your name, the title (“Homework 1”), and the date you turned in the assignment (3 points)\n\nInclude responses for Problem 1a-d and full work (hand written or R code) for parts b-d\n\nInclude a written response to Problem 2c and all your code, annotations, and output for Problem 2h-i\n\nInclude 3 citations for Problem 3c\n\nbe uploaded to Canvas as a single PDF (1 point)\n\nbe organized and readable (2 points)\n\nAdditionally, you should\n\nPaste 3 DOIs for the papers you’re interested in in the Google form\n\n49 points total"
  },
  {
    "objectID": "assignments/optional-problem-01.html",
    "href": "assignments/optional-problem-01.html",
    "title": "OPTIONAL practice problem - Central Limit Theorem",
    "section": "",
    "text": "In this optional problem, you’ll test out the Central Limit Theorem by repeatedly “sampling” a population with a uniform distribution with sample sizes of n = 2, n = 15, and n = 30. You’ll create histograms of the sampling distributions (i.e. means from the samples you generate) to see how the spread of the sampling distribution gets narrower with increasing sample size."
  },
  {
    "objectID": "assignments/optional-problem-01.html#description",
    "href": "assignments/optional-problem-01.html#description",
    "title": "OPTIONAL practice problem - Central Limit Theorem",
    "section": "",
    "text": "In this optional problem, you’ll test out the Central Limit Theorem by repeatedly “sampling” a population with a uniform distribution with sample sizes of n = 2, n = 15, and n = 30. You’ll create histograms of the sampling distributions (i.e. means from the samples you generate) to see how the spread of the sampling distribution gets narrower with increasing sample size."
  },
  {
    "objectID": "assignments/optional-problem-01.html#general-guidance",
    "href": "assignments/optional-problem-01.html#general-guidance",
    "title": "OPTIONAL practice problem - Central Limit Theorem",
    "section": "2. General guidance",
    "text": "2. General guidance\nYou don’t have to follow these steps exactly (or at all), but this is a workflow that might make sense. Try it out on your own!\n\na. Steps\n\nCreate a script or Quarto document to work in.\n\nCopy/paste the code in the Set up code chunk into your script. Run the code.\n\nCalculate the population mean. Store this as an object.\n\nFind the function that allows you to “sample” from a vector of numbers. If you don’t know the function, one google search could be “r sample numbers”.\n\nResample (i.e. take a sample multiple times) 100 times from the population, taking a sample of n = 2 each time.\n\nCalculate the mean every time you take a sample. Store each mean in a list.\n\nCreate a histogram of your sample means using the list from step 6.\n\nRepeat steps 2-5 for n = 15, and n = 30.\n\n\n\n\n\n\n\nfor() loops\n\n\n\nDoing repetitive tasks like steps 5-6 can get tiresome. You probably do not want to sample and calculate a mean “by hand” 300 times. Instead, you can write what’s called a for() loop. One resource for writing for() loops is in the chapter on Iteration in R for Data Science. There are other resources out there too! Try finding one that you like.\n\n\n\n\nb. Set up code\n\n# read in the tidyverse\nlibrary(tidyverse)\n\n# set seed: makes sure the \"random\" generation comes up with the same combination of numbers every time\nset.seed(1)\n\n# generate 10000 numbers from a uniform distribution for the population\nuniform &lt;- runif(10000, min = 2, max = 8)\n\n# turn the vector into a data frame\nuniformdf &lt;- as.data.frame(uniform)\n\n# make a histogram for the population\nggplot(data = uniformdf, \n       aes(x = uniform)) +\n  geom_histogram(breaks = seq(2, 8, length.out = 41), \n                 fill = \"firebrick\", \n                 alpha = 0.7, \n                 color = \"firebrick\") +\n  geom_vline(xintercept = mean(uniform), \n             linewidth = 2) +\n  scale_x_continuous(breaks = seq(from = 2, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), \n                     limits = c(0, 305)) +\n  labs(x = \"Continuous value\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18))"
  },
  {
    "objectID": "assignments/optional-problem-01.html#solution",
    "href": "assignments/optional-problem-01.html#solution",
    "title": "OPTIONAL practice problem - Central Limit Theorem",
    "section": "3. Solution",
    "text": "3. Solution\n\na. Resampling using a for() loop\n\n# for() loop to sample 100x and calculate the mean\n\n# creating holding vectors\nstore2 &lt;- c()\nstore15 &lt;- c()\nstore30 &lt;- c()\n\nfor(i in 1:100) {\n  \n  # sample from the population, calculate the mean, store that mean in the vector\n  store2[i] &lt;- mean(sample(uniform, 2, replace = FALSE))\n  store15[i] &lt;- mean(sample(uniform, 15, replace = FALSE))\n  store30[i] &lt;- mean(sample(uniform, 30, replace = FALSE))\n\n}\n\n# double checking that the holding vectors actually have values in them\nhead(store2)\n\n[1] 5.274438 4.708106 5.089106 5.065707 4.728355 5.068479\n\nhead(store15)\n\n[1] 5.642239 4.914242 4.723196 5.237746 4.314470 5.602474\n\nhead(store30)\n\n[1] 5.432664 5.037553 5.165615 4.619024 4.573481 5.170263\n\n\n\n\nb. n = 2 histogram\nBefore plotting the histogram, I’ll put the output from the for() loop into a data frame.\n\n# putting everything together in a data frame (not necessary but nice to do)\ndf &lt;- cbind(store2, store15, store30) %&gt;% \n  as.data.frame()\n\nThen, I’ll plot the first histogram for n = 2.\n\n# making a histogram for n = 2\nggplot(data = df) +\n  # making a histogram\n  geom_histogram(aes(x = store2), \n                 bins = 10, \n                 alpha = 0.7, \n                 fill = \"chocolate1\", \n                 color = \"chocolate1\") +\n  # controlling the axes\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  # controlling plot aesthetics\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\n\nc. n = 15 histogram\n\n# histogram for n = 15\nggplot(data = df) +\n  # making a histogram\n  geom_histogram(aes(x = store15), \n                 bins = 12, \n                 alpha = 0.7, \n                 fill = \"darkorchid4\", \n                 color = \"darkorchid4\") +\n  # controlling the axes\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  # controlling plot aesthetics\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\n\nd. n = 30 histogram\n\n# histogram for n = 30\nggplot(data = df) +\n  # making a histogram\n  geom_histogram(aes(x = store30), \n                 bins = 12, \n                 alpha = 0.7, \n                 fill = \"lightseagreen\", \n                 color = \"lightseagreen\") +\n  # controlling the axes\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  # controlling plot aesthetics\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))"
  },
  {
    "objectID": "workshop.html",
    "href": "workshop.html",
    "title": "Workshop documents",
    "section": "",
    "text": "Order By\n       Default\n         \n          Workshop date - Oldest\n        \n         \n          Workshop date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nWorkshop date\n\n\n\n\n\n\nCoding workshop: Week 1\n\n\nApr 4, 2024\n\n\n\n\nCoding workshop: Week 2\n\n\nApr 11, 2024\n\n\n\n\nCoding workshop: Week 3\n\n\nApr 18, 2024\n\n\n\n\nCoding workshop: Week 4\n\n\nApr 25, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "resources/finalizing-plots.html",
    "href": "resources/finalizing-plots.html",
    "title": "Finalizing plots",
    "section": "",
    "text": "Data visualization is a huge part of data storytelling, one of the core parts of being a data scientist. This is especially relevant to environmental science: you’re responsible for communicating not just about the environment, but what evidence (i.e. data) supports your claim. Therefore, it is crucial that environmental scientists communicate about their data clearly and effectively.\nIn this class, your plots will be assessed using three (very broad) criteria:\n1. accuracy: is your plot accurately and truthfully representing the data?\n2. clarity: is your plot clearly representing a pattern, relationship, message?\n3. aesthetics: does your plot look good?"
  },
  {
    "objectID": "resources/finalizing-plots.html#non-negotiable-if-you-are-missing-these-you-will-not-get-full-credit-for-your-plot",
    "href": "resources/finalizing-plots.html#non-negotiable-if-you-are-missing-these-you-will-not-get-full-credit-for-your-plot",
    "title": "Finalizing plots",
    "section": "Non-negotiable (if you are missing these, you will not get full credit for your plot)",
    "text": "Non-negotiable (if you are missing these, you will not get full credit for your plot)\n\nAxes must have complete labels with units (very few exceptions to this)\n\nfor example: body_mass_g should be “Body mass (g)”\n\nIf plotting regression or correlation lines, underlying data must be displayed on plot in addition to predicted lines\n\nIn all other cases (for example, comparing means between groups), underlying data must be displayed on plot when possible\n\nConcise, descriptive title (if presented alone and not in a report)"
  },
  {
    "objectID": "resources/finalizing-plots.html#additional-points",
    "href": "resources/finalizing-plots.html#additional-points",
    "title": "Finalizing plots",
    "section": "Additional points",
    "text": "Additional points\n\nlogical start and end values of x or y axes (these are usually by default in ggplot, but you should double check)\nif gridlines aren’t useful to understand the data, remove them\nfigure background should be white (easier to see points)\ntext labels should be large enough to see/read clearly\nuse color sparingly and be aware of color-blind friendly palettes\nuse one font throughout a plot\nfigure fonts should match text font (for example, don’t use Arial in a figure when the rest of your text is in Times New Roman)\nmake sure your plot size and aspect ratio renders correctly\n\nIn general, the simpler you can make a plot, the better."
  },
  {
    "objectID": "resources/finalizing-plots.html#bar-chart",
    "href": "resources/finalizing-plots.html#bar-chart",
    "title": "Finalizing plots",
    "section": "Bar chart",
    "text": "Bar chart\n\n\nCode\npenguins %&gt;% \n  group_by(island, species) %&gt;% \n  count() %&gt;% \n  ggplot(aes(x = species, y = n)) +\n  geom_col() +\n  labs(title = \"penguins\") +\n  facet_wrap(~island)\n\n\n\n\n\n\n\n\n\nWhy is this bad?\n- gap between bottom of bars and x-axis\n- meaningless y axis\n- gray background against gray bars and black text is hard to see\n- gridlines don’t do much\n\n\nCode\npenguins %&gt;% \n  group_by(island, species) %&gt;% \n  count() %&gt;% \n  ggplot(aes(x = island, y = n)) +\n  # fill = fills in the shape, color = controls the outline\n  geom_col(fill = \"darkgrey\", color = \"#000000\") +\n  # expand takes away the gap at the bottom and at the top of the plot\n  # limits sets the limits of the axis\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 130)) +\n  # change titles to be meaningful\n  labs(title = \"Penguin counts differ across species and islands\",\n       x = \"Island\", \n       y = \"Penguin count\") +\n  # one of the built-in themes in ggplot\n  theme_bw() +\n  theme(# changing text sizes\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14),\n        strip.text = element_text(size = 14),\n        # getting rid of gridlines\n        panel.grid = element_blank(),\n        # making the subplot titles (aka strips) have a transparent background\n        strip.background = element_blank(),\n        # making the plot title bigger and centering it\n        plot.title = element_text(size = 20, hjust = 0.5),\n        plot.title.position = \"plot\",\n        text = element_text(family = \"Times\")\n        ) +\n  facet_wrap(~species)\n\n\n\n\n\n\n\n\n\nWhy is this better?\n- text is bigger\n- gridlines are gone\n- easier to see columns agains background\n- complete axes\n- grayscale color scheme (good for printing out and paper reports in black and white)"
  },
  {
    "objectID": "resources/finalizing-plots.html#bonus-plot-lollipop-plot",
    "href": "resources/finalizing-plots.html#bonus-plot-lollipop-plot",
    "title": "Finalizing plots",
    "section": "Bonus plot: lollipop plot",
    "text": "Bonus plot: lollipop plot\nOne way to represent discrete (i.e. count) variables is to make a lollipop plot. This cuts down on visual clutter, as the bars in a bar chart are thick and take up a lot of space, but lollipop plots show the same thing but with smaller shapes.\n\n\nCode\npenguins %&gt;% \n  group_by(island, species) %&gt;% \n  count() %&gt;% \n  ggplot(aes(x = island, \n             y = n)) +\n  # fill = fills in the shape, color = controls the outline\n  geom_point(size = 3) +\n  geom_segment(aes(y = 0,\n                   yend = n)) +\n  \n  # expand takes away the gap at the bottom and at the top of the plot\n  # limits sets the limits of the axis\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 130)) +\n  # change titles to be meaningful\n  labs(title = \"Penguin counts differ across species and islands\",\n       x = \"Island\", \n       y = \"Penguin count\") +\n  # one of the built-in themes in ggplot\n  theme_bw() +\n  theme(# changing text sizes\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14),\n        strip.text = element_text(size = 14),\n        # getting rid of gridlines\n        panel.grid = element_blank(),\n        # making the subplot titles (aka strips) have a transparent background\n        strip.background = element_blank(),\n        # making the plot title bigger and centering it\n        plot.title = element_text(size = 20, hjust = 0.5),\n        plot.title.position = \"plot\",\n        text = element_text(family = \"Times\")\n        ) +\n  facet_wrap(~species)"
  },
  {
    "objectID": "resources/finalizing-plots.html#scatterplot",
    "href": "resources/finalizing-plots.html#scatterplot",
    "title": "Finalizing plots",
    "section": "Scatterplot",
    "text": "Scatterplot\n\n\nCode\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nWhy is this bad?\n- grey background, black dots\n- hides some meaningful variation across species (for example, we know that Gentoo penguins tend to be bigger than Adelie and Chinstrap)\n- axes are meaningless\n- small text size\n- points likely overlap, so some parts of the data are hidden\n\n\nCode\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, color = species, shape = species)) +\n  geom_point(size = 3, alpha = 0.7) +\n  # specify color scheme\n  scale_color_manual(values = c(\"darkorange\", \"cornflowerblue\", \"darkgreen\")) +\n  # meaningful titles\n  labs(title = \"Larger penguins tend to have longer flippers\",\n       x = \"Body mass (g)\", \n       y = \"Flipper length (mm)\",\n       # have to specify color and shape separately (based on color and shape in aes() call)\n       color = \"Penguin species\", shape = \"Penguin species\") +\n  # another ggplot built-in theme\n  theme_classic() +\n  theme(# putting legend in plot area\n        legend.position = c(0.85, 0.2),\n        # legend text sizes\n        legend.text = element_text(size = 14),\n        legend.title = element_text(size = 14),\n        # text size, position, and font adjustment\n        axis.text = element_text(size = 14), \n        axis.title = element_text(size = 16),\n        plot.title = element_text(size = 18, hjust = 0.5),\n        plot.title.position = \"plot\",\n        text = element_text(family = \"Garamond\")\n    )\n\n\n\n\n\n\n\n\n\nWhy is this better?\n- white background, no grid lines\n- points are shaped and colored by species, so you can easily see the differences between groups\n- transparency shows overlapping points\n- complete axis labels\n- text is larger and font is changed\n- legend is in plot area (if there’s space to do this, generally good)"
  },
  {
    "objectID": "resources/finalizing-plots.html#boxplot-and-jitter",
    "href": "resources/finalizing-plots.html#boxplot-and-jitter",
    "title": "Finalizing plots",
    "section": "boxplot and jitter",
    "text": "boxplot and jitter\n\n\nCode\nggplot(data = penguins, aes(x = species, y = body_mass_g)) +\n  # fill the boxplot shape using the species column\n  # make the boxplots narrower\n  geom_boxplot(aes(fill = species), width = 0.2) +\n  # fill the violin shape using the species column: every species has a different color\n  # alpha argument: makes the violin shape more transparent (scale of 0 to 1)\n  geom_jitter(aes(color = species), alpha = 0.5) +\n  # specify the colors you want to use for each species\n  scale_color_manual(values = c(\"#F56A56\", \"#3D83F5\", \"#A9A20B\")) +\n  scale_fill_manual(values = c(\"#F56A56\", \"#3D83F5\", \"#A9A20B\")) +\n  # relabel the axis titles, plot title, and caption\n  labs(x = \"Penguin species\", y = \"Body mass (g)\",\n       title = \"Gentoo penguins tend to be heavier than Adelie or Chinstrap\",\n       caption = \"Data source: {palmerpenguins}, \\n Horst AM, Hill AP, Gorman KB.\") +\n  # themes built in to ggplot\n  theme_bw() +\n  # other theme adjustments\n  theme(legend.position = \"none\", \n        axis.title = element_text(size = 13),\n        axis.text = element_text(size = 12),\n        plot.title = element_text(size = 14),\n        plot.caption = element_text(face = \"italic\"),\n        text = element_text(family = \"Times New Roman\"),\n        panel.grid = element_blank())\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "resources/communicating-results.html",
    "href": "resources/communicating-results.html",
    "title": "Clear communication = interpretable stats",
    "section": "",
    "text": "Obviously, this is a stats class - however, stats exists within the data science world, and data science includes communication about stats. It’s important for us, in this class, to understand the mechanics of the tests we use (assumptions, underlying math, etc.) but the real challenge is being able to communicate about those tests and ground what those tests reveal in the biology of the system we’re studying - that’s environmental science.\nCommunication about what statistical methods you use to address a question/answer a hypothesis should include writing along with some visualization (figures and/or tables). The following are examples from lecture. You’ve also done a lot of reading in this class, and have seen a lot of examples of how to communicate about statistics from other researchers.\nEach code chunk with what is potentially new information is annotated - however, I haven’t annotated things like tests, creating plots, etc. because we’ve gone over that in class.\n\n\nCode\n# general use\nlibrary(tidyverse)\n\n# data\nlibrary(palmerpenguins)\n\n# visualization\nlibrary(patchwork)\nlibrary(flextable)\n\n# model summary table tools\nlibrary(broom)\nlibrary(car)\nlibrary(ggeffects)\nlibrary(equatiomatic)\n\n# using the Lato font from Google fonts\nlibrary(showtext)\nfont_add_google(\"Lato\", \"Lato\")\nshowtext_auto()"
  },
  {
    "objectID": "resources/communicating-results.html#one-sample-t-test",
    "href": "resources/communicating-results.html#one-sample-t-test",
    "title": "Clear communication = interpretable stats",
    "section": "One sample t-test",
    "text": "One sample t-test\nThis example from lecture was about comparing a sample of acorn masses to a theoretical mean (2 g).\nJust generating some fake data for this example:\n\n\nCode\nset.seed(7)\nacorns &lt;- rnorm(n = 41, mean = 2, sd = 1)\n\n\n\nChecking assumptions\nFor a t-test, one of the assumptions you can check is that your variable is normally distributed. Doing this with a histogram and a QQ plot makes sense:\n\n\nCode\n```{r hist-and-qq}\n#| fig.width: 12\n#| fig.height: 6\n#| out.width: 90%\n#| fig.align: center\n\nhist &lt;- enframe(acorns) %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 7, fill = \"cornflowerblue\", color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 11.5), breaks = c(0, 3, 6, 9, 12)) +\n  geom_vline(xintercept = 2, color = \"maroon\", lty = 2, linewidth = 1) +\n  theme_classic() +\n  labs(x = \"Acorn mass (g)\", y = \"Count\", \n       title = \"A)\") +\n  theme(plot.title.position = \"plot\")\n\nqq &lt;- enframe(acorns) %&gt;% \n  ggplot(aes(sample = value)) +\n  stat_qq_line(aes(sample = value)) +\n  stat_qq(aes(sample = value), color = \"cornflowerblue\", size = 3) +\n  theme_classic() +\n  labs(x = \"Theoretical quantiles\", y = \"Sample quantiles\",\n       title = \"B)\") +\n  theme(plot.title.position = \"plot\")\n\nhist + qq\n```\n\n\n\n\n\n\n\n\n\nExample caption:\n\nFigure 1. Visual checks for normally distributed variable. A) Histogram of acorn masses (g). Bars in histogram represent counts of acorns in each bin. Dashed red line represents theoretical mean (\\(\\mu\\) = 0). B) Quantile-quantile (QQ) plot. Points in QQ plot represent sample quantiles compared against theoretical quantiles from a normal distribution. Solid black line represents a 1:1 relationship between sample and theoretical quantiles.\n\n\n\n\n\n\n\nMaking sure your figures render properly\n\n\n\n\n\nYou put a lot of effort into making figures, so it’s worth making sure they appear the way you think they would in your final document! You can control these in your chunk options (i.e. within the curly brackets). There are many ways to do this, but I like adjusting the a) aspect ratio using fig.width and fig.height and b) proportion using out.width.\nIn Quarto, you can set those options within the chunk (see above) or in the curly brackets. In RMarkdown, you can only use the curly brackets, which would look like:\n{r fig.width = 12, fig.height = 6, out.width = \"90%\", fig.align = \"center\"}\n\n\n\n\n\n\n\n\n\nFormatting captions\n\n\n\n\n\nYou can write a caption in text (the easiest way) or you can try using code chunk options if you’re using Quarto. There are tips for how to do that here, though the formatting might not be the standard (i.e. bold text for figure number and title). I also changed the caption color - not required, but nice to add another visual cue that the caption is attached to the figure.\nGenerally, the font size in captions tends to be smaller than the main text. You can insert these options in Quarto by wrapping your text in a “fenced div” (see the source code for how to do that). In RMarkdown, you can use an HTML wrapper (here’s an example).\n\n\n\nExample text:\nWe visually assessed normality using a histogram and a QQ plot (Figure 1), and determined that acorn mass in our sample was normally distributed.\n\n\nTest\n\n\nCode\nacorn_test &lt;- t.test(acorns, mu = 2)\n\n\nExample text:\nWe assessed whether acorn masses in our sample differed from the claim of 2g using a one-sample two-tailed t-test. Our null hypothesis was that the mean acorn mass in our sample was the same as the claim.\n\n\nTest results\n\n\nCode\nacorn_test\n\n\n\n    One Sample t-test\n\ndata:  acorns\nt = 1.8035, df = 40, p-value = 0.07885\nalternative hypothesis: true mean is not equal to 2\n95 percent confidence interval:\n 1.964535 2.623323\nsample estimates:\nmean of x \n 2.293929 \n\n\nExample text:\nWe collected 41 acorns and found no significant difference between our sample mean mass and the claim (One-sample two-tailed t-test, t(40) = 1.8, \\(\\alpha\\) = 0.05, p = 0.079). Our data suggest that acorn masses in our sampling area are on average the same mass as the claimed mass (Figure 1A)."
  },
  {
    "objectID": "resources/communicating-results.html#chi-square",
    "href": "resources/communicating-results.html#chi-square",
    "title": "Clear communication = interpretable stats",
    "section": "Chi-square",
    "text": "Chi-square\nThis example from lecture was about surveying people to understand their priorities for restoration.\nAgain, generating fake data:\n\n\nCode\n# making a matrix (not a data frame) called `survey` ----\nsurvey &lt;- tribble(\n  ~distance, ~trails, ~dog_access, ~wildlife_habitat,\n  \"walking_distance\", 55, 38, 33,\n  \"driving_distance\", 41, 25, 29,\n  \"out_of_town\", 22, 27, 45\n) %&gt;% \n  \n  # turning the column `distance` into the matrix rownames ----\n  column_to_rownames(\"distance\")\n\n\n\nTest\n\n\nCode\nsurvey_test &lt;- chisq.test(survey)\n\n\nExample text:\nTo determine whether there was a relationship between living distance from wetland and restoration priority, we used a chi-square test using survey data from visitors (Table 1). Our null hypothesis was that there was no relationship between living distance from the wetland and restoration priority.\n\n\nTable\nExample caption:\nNote: Table captions usually go above the table.\n\nTable 1. Wetland restoration priority by living distance. Numbers in parentheses indicate proportion of responses (i.e. the 55 respondents living within walking distance of the wetland who prioritize trail development represent 44% of the total number of respondents living within walking distance (n = 126)).\n\n\n\nCode\n# calculate proportions\nsurvey_summary &lt;- survey %&gt;% \n  # turning `survey` into a data frame ----\n  as_tibble(rownames = \"distance\") %&gt;% \n  # making it long format\n  pivot_longer(cols = trails:wildlife_habitat, names_to = \"responses\", values_to = \"counts\") %&gt;% \n  \n  # calculating proportions ----\n  # grouping by living distance\n  group_by(distance) %&gt;% \n  # counting the total number of respondents per living distance\n  mutate(sum = sum(counts)) %&gt;% \n  # ungrouping to make sure that distance groups don't mess up downstream functions\n  ungroup() %&gt;% \n  # calculating proportion of responses per living distance\n  mutate(prop = counts/sum) %&gt;% \n  \n  # making the table look nicer ----\n  # making a new column where counts and proportions are displayed together\n  mutate(text = paste0(counts, \" (\", round(prop, digits = 2), \")\")) %&gt;% \n  # selecting columns of interest\n  select(distance, responses, text) %&gt;% \n  # making the data frame wider so that the columns are responses and rows are distance\n  pivot_wider(names_from = \"responses\", values_from = \"text\") %&gt;% \n  # making the row labels nicer\n  mutate(distance = case_match(\n    distance,\n    \"walking_distance\" ~ \"Walking distance\",\n    \"driving_distance\" ~ \"Driving distance\",\n    \"out_of_town\" ~ \"Out of town\"\n  )) %&gt;% \n  \n  # turning everything into a table ----\n  flextable() %&gt;% \n  # changing the column names to look nicer\n  set_header_labels(distance = \"Living distance\",\n                    trails = \"Trails\",\n                    dog_access = \"Dog access\",\n                    wildlife_habitat = \"Wildlife habitat\") %&gt;% \n  # making the table fit the viewer window\n  autofit()\n  \nsurvey_summary\n\n\nLiving distanceTrailsDog accessWildlife habitatWalking distance55 (0.44)38 (0.3)33 (0.26)Driving distance41 (0.43)25 (0.26)29 (0.31)Out of town22 (0.23)27 (0.29)45 (0.48)\n\n\n\n\n\n\n\n\nWarning\n\n\n\nRemember not to name code chunks with tables in them! Rendering gets stuck on the chunk if you do.\n\n\n\n\nTest results\n\n\nCode\nsurvey_test\n\n\n\n    Pearson's Chi-squared test\n\ndata:  survey\nX-squared = 15.276, df = 4, p-value = 0.004162\n\n\nExample text:\nBased on responses from individuals living within walking distance (n = 126), within driving distance (n = 95), and out of town (n = 94), restoration priorities differ significantly by living distance category (Table 1, \\(\\chi^2\\)(4) = 15.3, p = 0.004, \\(\\alpha\\) = 0.05).\nWhile the majority of residents within walking distance and driving distance prioritize trail use (44% and 43% respectively), residents outside the city prioritize wildlife habitat (48%).\nThese results indicate that wetland users living outside the city may have different intentions for visiting the wetland than local residents, but that restorationists can consider both trails and wildlife habitat in designing a restoration plan to suit user needs."
  },
  {
    "objectID": "resources/communicating-results.html#analysis-of-variance",
    "href": "resources/communicating-results.html#analysis-of-variance",
    "title": "Clear communication = interpretable stats",
    "section": "Analysis of variance",
    "text": "Analysis of variance\nThis example from lecture used the penguins data set from {palmerpenguins}.\n\nChecking assumptions\nFor ANOVA, you should be checking that your variable is normally distributed and that your groups have equal variances. You can check the first assumption visually using histograms and QQ plots:\n\n\nCode\n```{r penguin-hist-and-qq}\n#| fig.height: 12\n#| fig.width: 10\n#| out.width: 60%\n#| fig.align: center\n\n# setting some color options\ncol1 &lt;- \"cornflowerblue\"\ncol2 &lt;- \"orange\"\ncol3 &lt;- \"darkgreen\"\n\n# making separate data frames for each species\nadelie &lt;- penguins %&gt;% \n  filter(species == \"Adelie\")\n\nchinstrap &lt;- penguins %&gt;% \n  filter(species == \"Chinstrap\")\n\ngentoo &lt;- penguins %&gt;% \n  filter(species == \"Gentoo\")\n\n# making histograms for each species\n\nadelie_hist &lt;- ggplot(data = adelie, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 10, fill = col1, color = col1, alpha = 0.8) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 32)) +\n  labs(x = \"Bill length (mm)\", y = \"Count\",\n       title = \"A)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\nchinstrap_hist &lt;- ggplot(data = chinstrap, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 10, fill = col2, color = col2, alpha = 0.8) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 23)) +\n  labs(x = \"Bill length (mm)\", y = \"Count\",\n       title = \"C)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\ngentoo_hist &lt;- ggplot(data = gentoo, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 10, fill = col3, color = col3, alpha = 0.8) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 37)) +\n  labs(x = \"Bill length (mm)\", y = \"Count\",\n       title = \"E)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\n# making QQ plots for each species\nadelie_qq &lt;- ggplot(data = adelie, aes(sample = bill_length_mm)) +\n  stat_qq_line(linewidth = 1) +\n  stat_qq(col = col1) +\n  labs(x = \"Theoretical\", y = \"Sample\",\n       title = \"B)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\nchinstrap_qq &lt;- ggplot(data = chinstrap, aes(sample = bill_length_mm)) +\n  stat_qq_line(linewidth = 1) +\n  stat_qq(col = col2) +\n  labs(x = \"Theoretical\", y = \"Sample\",\n       title = \"D)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\ngentoo_qq &lt;- ggplot(data = gentoo, aes(sample = bill_length_mm)) +\n  stat_qq_line(linewidth = 1) +\n  stat_qq(col = col3) +\n  labs(x = \"Theoretical\", y = \"Sample\",\n       title = \"F)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\n# putting all the plots together using `patchwork`\n\n(adelie_hist + adelie_qq) / (chinstrap_hist + chinstrap_qq) / (gentoo_hist + gentoo_qq)\n```\n\n\n\n\n\n\n\n\n\nExample caption:\n\nFigure 2. Visual checks for normally distributed variable. Visual checks for normally distributed variable. A, C, E) Histograms of penguin bill length (mm) for Adelie (A), Chinstrap (C), and Gentoo (E) penguins. Bars represent counts of bill lengths in each bin. B, D, F) QQ plots of penguin bill length. Points in QQ plot represent sample quantiles compared against theoretical quantiles from a normal distribution. Solid black lines represent a 1:1 relationship between sample and theoretical quantiles.\n\nNow a series of Shapiro-Wilk tests to statistically test for normal distribution:\n\n\nCode\nshapiro.test(adelie$bill_length_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  adelie$bill_length_mm\nW = 0.99336, p-value = 0.7166\n\n\nCode\nshapiro.test(chinstrap$bill_length_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  chinstrap$bill_length_mm\nW = 0.97525, p-value = 0.1941\n\n\nCode\nshapiro.test(gentoo$bill_length_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  gentoo$bill_length_mm\nW = 0.97272, p-value = 0.01349\n\n\n\n\n\n\n\n\nMaking decisions about normality\n\n\n\n\n\nIn lecture, we talked about making a decision: do you think this deviation from normality is a big enough deal or not? ANOVA is fairly robust against violations of the normality assumption, and we have a lot of observations. We might decide to continue with the ANOVA (especially since the variances between groups are equal - see below). However, you could also try a transformation (e.g. a log transformation) on bill length, and see if that fixes your problem.\n\n\n\nChecking for equal variances:\n\n\nCode\nleveneTest(bill_length_mm ~ species, data = penguins)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)\ngroup   2  2.2425 0.1078\n      339               \n\n\nExample text:\n Prior to our analysis, we checked assumptions for analysis of variance. We tested for equality of variances between groups using Levene’s test and found no statistically significant differences in variances between groups (F(2, 339) = 2.24, p = 0.11, \\(\\alpha\\) = 0.05). We visually assessed normality using histograms and QQ plots (Figure 2) and statistically tested for normality of penguin bill length using Shapiro-Wilk tests for each species. Adelie and Chinstrap bill length did not indicate any deviations from normality (Adelie: W W = 0.99, p = 0.72; Chinstrap: W = 0.98, p = 0.19), but Gentoo bill length did (W = 0.97, p = 0.01). Taking this together, we decided to continue using analysis of variance given our sample size (n = 342) and that analysis of variance tends to be robust to slight violations of the normality assumption.Note that you only really need to state your \\(\\alpha\\) once in a report. The assumption is that you’re not changing your significance level for each test.\n\n\nTest\nANOVA:\n\n\nCode\npenguins_anova &lt;- aov(bill_length_mm ~ species, data = penguins)\n\n\nTukey HSD:\n\n\nCode\npenguins_HSD &lt;- TukeyHSD(penguins_anova)\n\n\nExample text:\nWe tested for differences between penguin species in bill length using analysis of variance. Our null hypothesis was that species did not differ in mean bill length. We used Tukey’s Honestly Significant Difference (Tukey HSD) as a post-hoc test to determine pair-wise differences between groups.\n\n\nTest results\n\n\nCode\npenguins_anova\n\n\nCall:\n   aov(formula = bill_length_mm ~ species, data = penguins)\n\nTerms:\n                 species Residuals\nSum of Squares  7194.317  2969.888\nDeg. of Freedom        2       339\n\nResidual standard error: 2.959853\nEstimated effects may be unbalanced\n2 observations deleted due to missingness\n\n\nANOVA table:\nExample caption:\n\nTable 2. ANOVA table. Bolded p-value indicates significance.\n\n\n\nCode\n# getting table from ANOVA object ----\ntidy(penguins_anova) %&gt;% \n  # changing very small p-values to &lt; 0.001\n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\"\n  )) %&gt;%\n  # rounding values in numerical columns to 1 decimal point\n  mutate(across(sumsq:statistic, ~ round(.x, digits = 1))) %&gt;% \n  # changing the row names to be nicer (capitalizing Species)\n  mutate(term = case_match(\n    term, \n    \"species\" ~ \"Species\",\n    .default = term\n  )) %&gt;% \n  \n  # turning the data frame into a flextable ----\n  flextable() %&gt;% \n  # changing the column names to be nicer\n  set_header_labels(term = \"Source of variation\",\n                    df = \"Degrees of freedom\",\n                    sumsq = \"Sum of squares\",\n                    meansq = \"Mean squares\",\n                    statistic = \"F-statistic\",\n                    p.value = \"p-value\") %&gt;% \n  # making small p-values bold\n  bold(~ p.value == \"&lt; 0.001\", 6) %&gt;% \n  # fitting the table to the viewer\n  autofit()\n\n\nSource of variationDegrees of freedomSum of squaresMean squaresF-statisticp-valueSpecies27,194.33,597.2410.6&lt; 0.001Residuals3392,969.98.8\n\n\nTukey HSD results:\n\n\nCode\npenguins_HSD\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = bill_length_mm ~ species, data = penguins)\n\n$species\n                      diff       lwr        upr     p adj\nChinstrap-Adelie 10.042433  9.024859 11.0600064 0.0000000\nGentoo-Adelie     8.713487  7.867194  9.5597807 0.0000000\nGentoo-Chinstrap -1.328945 -2.381868 -0.2760231 0.0088993\n\n\nExample text (if you decided not to make a table:\n We found a significant difference in bill length across species (analysis of variance, F(2, 339) = 410.6, p &lt; 0.001). Adelie penguins tend to have the shortest bills: on average, Gentoo penguins have 8.7 mm (Tukey HSD 95% confidence interval: [7.9, 9.6] mm) longer bills than Adelie penguins, and Chinstrap penguins have 10.0 mm ([9.0, 11.1] mm) longer bills than Adelie penguins.If you decide not to go with a table, the F-statistic, degrees of freedom, and p-value should be in parentheses. This is the only difference between this example and the one below.\nExample text (with a table):\nWe found a significant difference in bill length across species (Table 2). Adelie penguins tend to have the shortest bills: on average, Gentoo penguins have 8.7 mm (Tukey HSD 95% confidence interval: [7.9, 9.6] mm) longer bills than Adelie penguins, and Chinstrap penguins have 10.0 mm ([9.0, 11.1] mm) longer bills than Adelie penguins."
  },
  {
    "objectID": "resources/communicating-results.html#linear-models",
    "href": "resources/communicating-results.html#linear-models",
    "title": "Clear communication = interpretable stats",
    "section": "Linear models",
    "text": "Linear models\nThis first example was from lecture. We only talked about the equation and significant predictors, but I’ll break it down further here.\nGenerating data:\n\n\nCode\nset.seed(666)\n# sample size\nn &lt;- 64\nplant_df &lt;- tibble(\n  # predictor variables\n  temperature = round(rnorm(n = n, mean = 28, sd = 1), digits = 1),\n  light = round(rnorm(n = n, mean = 1, sd = 0.2), digits = 1),\n  ph = rnorm(n = n, mean = 7, sd = 0.01),\n  \n  # response: growth in cm/week\n  growth = light*rnorm(n = n, mean = 0.3, sd = 0.1) + temperature/round(rnorm(n = n, mean = 5, sd = 0.1))\n) \n\n\n\nBuilding a model\n\n\nCode\nplant_model &lt;- lm(growth ~ light + temperature + ph, data = plant_df)\n\n\nDiagnostics:\nI changed the chunk options for this to make sure it displayed correctly - see the code chunk! I also chose which plots to plot using the which() function, and added a title to each using title(). The syntax is a little different from a standard ggplot() figure because these are all done in base R, but labelling plots is an option.\n\n\nCode\n```{r plant-diagnostics}\n#| fig-width: 10\n#| fig-height: 10\n#| out.width: 90%\n#| fig.align: center\n\npar(mfrow = c(2, 2))\nplot(plant_model, which = c(1))\ntitle(\"A)\", adj = 0)\nplot(plant_model, which = c(2))\ntitle(\"B)\", adj = 0)\nplot(plant_model, which = c(3))\ntitle(\"C)\", adj = 0)\nplot(plant_model, which = c(5))\ntitle(\"D)\", adj = 0)\n```\n\n\n\n\n\n\n\n\n\nExample caption:\n\nFigure 3. Model diagnostic plots. In all plots, points represent residuals. Red lines (residuals vs fitted, scale-location, and residuals vs leverage) are lines depicting patterns in residuals. Grey dashed lines represent reference lines.\n\nExample text:\nWe tested the predictive relationship between plant growth and light, temperature, and soil pH using a linear model. Our null hypothesis was that none of these variables would predict plant growth. We used diagnostic plots to visually assess residual normality (Figure 3B) and homoskedasticity (Figures 3A and 3C). Additionally, we determined there were no outliers influencing our model predictions using Cook’s distance (Figure 3D).\n\n\nModel predictions\nJust to see what the original summary object is:\n\n\nCode\nsummary(plant_model)\n\n\n\nCall:\nlm(formula = growth ~ light + temperature + ph, data = plant_df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23209 -0.06571  0.01010  0.06173  0.19950 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -6.67140    6.80194  -0.981    0.331    \nlight        0.35196    0.05939   5.926 1.63e-07 ***\ntemperature  0.19626    0.01058  18.558  &lt; 2e-16 ***\nph           0.96241    0.96806   0.994    0.324    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0911 on 60 degrees of freedom\nMultiple R-squared:  0.8759,    Adjusted R-squared:  0.8696 \nF-statistic: 141.1 on 3 and 60 DF,  p-value: &lt; 2.2e-16\n\n\nTable option 1:\n\nTable 3. Model prediction table. Bolded p-value indicates significant difference from 0.\n\n\n\nCode\nplant_model %&gt;%\n  # turning the model object into a flextable ----\n  as_flextable() %&gt;% \n  \n  # changing the row labels using `compose()` ----\n  # i selects the row, j selects the column\n  compose(i = 2, j = 1, \n          # value is whatever you want to change the text to\n          value = as_paragraph(\n            # `as_sup()` makes something a superscript - good for units etc.\n            \"Light (watts/m\", as_sup(\"2\"), \")\"\n          )) %&gt;% \n  compose(i = 3, j = 1, \n          value = as_paragraph(\n            \"Temperature (°C)\"\n          )) %&gt;% \n  compose(i = 4, j = 1, \n          value = as_paragraph(\n            \"pH\"\n          )) %&gt;% \n  \n  # formatting the numbers to display to 3 decimal points ----\n  set_formatter(estimate = function(x) sprintf(\"%.03f\", x),\n                std.error = function(x) sprintf(\"%.03f\", x),\n                statistic = function(x) sprintf(\"%.03f\", x),\n                p.value = function(x) sprintf(\"%.03f\", x)) %&gt;% \n  \n  # changing the p.value to display as &lt; 0.001 when very small ----\n  compose(j = \"p.value\", i = ~ p.value &lt; 0.001,\n          value = as_paragraph(\n            \"&lt; 0.001\"\n          )) %&gt;% \n  \n  # adding model equation at the top ----\n  # inserting new header row (to make space for equation)\n  add_header_lines(\"\", top = TRUE) %&gt;% \n  # putting in equation\n  compose(\n    # choosing row 1, column 1, indicating that is a header\n    j = 1, i = 1, part = \"header\",\n    # putting in the equation using as_equation and extract_eq from {equatiomatic}\n    value = as_paragraph(\n      as_equation(extract_eq(plant_model), \n                  # formatting equation\n                  width = 2, height = .5)\n    )) %&gt;% \n  # making sure the equation is centered on the table\n  align(i = 1, part = \"header\", align = \"center\") %&gt;% \n  \n  # formatting header labels ----\n  set_header_labels(statistic = \"t-statistic\",\n                    p.value = \"p-value\") %&gt;% \n  \n  # making cells bold when p.value &lt; 0.05 ----\n  bold(i = ~ p.value &lt; .05, j = \"p.value\") %&gt;% \n  \n  # making table fit viewer ----\n  autofit()\n\n\n\ngrowth⁡=α+β1(light⁡)+β2(temperature⁡)+β3(ph⁡)+ϵ\\operatorname{growth} = \\alpha + \\beta_{1}(\\operatorname{light}) + \\beta_{2}(\\operatorname{temperature}) + \\beta_{3}(\\operatorname{ph}) + \\epsilongrowth=α+β1​(light)+β2​(temperature)+β3​(ph)+ϵEstimateStandard Errort-statisticp-value(Intercept)-6.6716.802-0.9810.331   Light (watts/m2)0.3520.0595.926&lt; 0.001***Temperature (°C)0.1960.01118.558&lt; 0.001***pH0.9620.9680.9940.324   Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05Residual standard error: 0.0911 on 60 degrees of freedomMultiple R-squared: 0.8759, Adjusted R-squared: 0.8696F-statistic: 141.1 on 60 and 3 DF, p-value: 0.0000\n\n\n\n\n\n\n\n\nIncluding tables and full tables with {flextable}\n\n\n\n\n\nWhen writing about models, you have to make decisions about whether or not you want to include a table of the model summary. In multiple linear regression (and for more complex models), it’s a good idea to include a table of the model summary.\nIf you wanted to make a table of the model estimates and the relevant information at the bottom of that summary (for example, \\(R^2\\), F-statistic, degrees of freedom, etc.), you could use flextable::as_flextable() which takes the model object - this is Table 3. This skips the step of creating an intermediate data frame and just turns everything into a flextable object. However, this can be a bit tricky: the formatting to make it look “good” takes some getting used to. You can go either way, but this is one option if you’d rather condense the information from the model prediction table and ANOVA table into one. It is also somewhat easier to interpret than the model prediction + ANOVA table combo (Tables 4 + 5).\n\n\n\nTable option 2:\nTable 4. Model prediction table. Bolded p-value indicates significance.\n\n\nCode\nplant_model %&gt;% \n  tidy() %&gt;% \n  mutate(across(estimate:p.value, ~round(.x, digits = 3))) %&gt;% \n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\",\n    TRUE ~ as.character(p.value)\n  )) %&gt;% \n  flextable() %&gt;% \n  # changing the row labels using `compose()`\n  compose(i = 2, j = 1, \n          value = as_paragraph(\n            \"Light (watts/m\", as_sup(\"2\"), \")\"\n          )) %&gt;% \n  compose(i = 3, j = 1, \n          value = as_paragraph(\n            \"Temperature (°C)\"\n          )) %&gt;% \n  compose(i = 4, j = 1, \n          value = as_paragraph(\n            \"pH\"\n          )) %&gt;% \n  # formatting header labels\n  set_header_labels(term = \"Term\",\n                    estimate = \"Estimate\",\n                    std.error = \"Standard error\",\n                    statistic = \"t-statistic\",\n                    p.value = \"p-value\") %&gt;% \n  bold(j = 5, i = ~p.value == \"&lt; 0.001\") %&gt;% \n  autofit()\n\n\nTermEstimateStandard errort-statisticp-value(Intercept)-6.6716.802-0.9810.331Light (watts/m2)0.3520.0595.926&lt; 0.001Temperature (°C)0.1960.01118.558&lt; 0.001pH0.9620.9680.9940.324\n\n\nANOVA table:\nTable 5. Model ANOVA table. Bolded p-value indicates significant difference from 0.\n\n\nCode\nAnova(plant_model) %&gt;% \n  tidy() %&gt;% \n  mutate(across(sumsq:p.value, ~round(.x, digits = 3))) %&gt;% \n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\",\n    TRUE ~ as.character(p.value)\n  )) %&gt;% \n  flextable() %&gt;% \n  # changing the row labels using `compose()`\n  compose(i = 1, j = 1, \n          value = as_paragraph(\n            \"Light (watts/m\", as_sup(\"2\"), \")\"\n          )) %&gt;% \n  compose(i = 2, j = 1, \n          value = as_paragraph(\n            \"Temperature (°C)\"\n          )) %&gt;% \n  compose(i = 3, j = 1, \n          value = as_paragraph(\n            \"pH\"\n          )) %&gt;% \n  # formatting header labels\n  set_header_labels(term = \"Source of variation\",\n                    sumsq = \"Sum of squares\",\n                    df = \"Degrees of freedom\",\n                    statistic = \"F-statistic\",\n                    p.value = \"p-value\") %&gt;% \n  bold(j = 5, i = ~p.value == \"&lt; 0.001\") %&gt;% \n  autofit()\n\n\nSource of variationSum of squaresDegrees of freedomF-statisticp-valueLight (watts/m2)0.291135.122&lt; 0.001Temperature (°C)2.8581344.412&lt; 0.001pH0.00810.9880.324Residuals0.49860\n\n\n\n\nVisualization\n\n\nCode\ntemp_pred &lt;- ggpredict(plant_model, terms = \"temperature\")\n\nlight_pred &lt;- ggpredict(plant_model, terms = \"light\")\n\ntemp_plot &lt;- ggplot(data = plant_df, aes(x = temperature, y = growth)) +\n  geom_point() +\n  geom_ribbon(data = temp_pred, aes(x = x, y = predicted, ymin = conf.low, ymax = conf.high), alpha = 0.2) +\n  geom_line(data = temp_pred, aes(x = x, y = predicted), color = \"blue\", linewidth = 1) +\n  theme_classic() +\n  labs(x = \"Temperature (°C)\", y = \"Growth (cm/week)\",\n       title = \"A)\") +\n  theme(plot.title.position = \"plot\",\n        text = element_text(size = 15))\n\nlight_plot &lt;- ggplot(data = plant_df, aes(x = light, y = growth)) +\n  geom_point() +\n  geom_ribbon(data = light_pred, aes(x = x, y = predicted, ymin = conf.low, ymax = conf.high), alpha = 0.2) +\n  geom_line(data = light_pred, aes(x = x, y = predicted), color = \"darkorange\", linewidth = 1) +\n  theme_classic() +\n  labs(x = expression(paste(\"Light (watts/\"~m^2~\")\")), y = \"Growth (cm/week)\",\n       title = \"B)\") +\n  theme(plot.title.position = \"plot\",\n        text = element_text(size = 15))\n\ntemp_plot + light_plot\n\n\n\n\n\n\n\n\n\nExample caption:\n\nFigure 4. Predicted growth as a function of A) temperature and B) light. In both panels, points represent observations, colored lines represent model predictions, and shaded areas represent 95% confidence intervals. In A), growth is predicted as a function of temperature for a constant light level of 0.98 watts/m2 and pH 7. In B), growth is predicted as a function of light for a constant temperature of 27.9 °C and pH 7.\n\n\n\n\n\n\n\nUnderstanding predictions\n\n\n\n\n\nRemember that for multiple linear regression, the slopes represent change in the response variable for each 1 unit change in the predictor for all else held constant. When getting model estimates for slopes, the “constant” values are the mean of the variable. When using ggeffects::ggpredict(), these values are printed below the prediction table (you can double check this by calculating the mean yourself!).\n\n\n\n\n\nTest results\nExample text:\nWe found that light and temperature significantly predicted plant growth, but not pH (Table 3). The overall model accounted for 87% of the variance in plant growth. For each 1 °C increase in temperature at constant light and pH, we expect 0.20 \\(\\pm\\) 0.01 increase in plant growth (Figure 4A). For each 1 watt/m2 increase in light at constant temperature and pH, we expect a 0.35 \\(\\pm\\) 0.06 increase in plant growth (Figure 4B).\n\n\n\n\n\n\nChoosing which parameters to highlight\n\n\n\n\n\nWith multiple linear regression and generalized linear models, you’re usually working with pretty complex model structure. It’d be impossible (and not that interesting, necessarily) to discuss all the predictors. You can choose which one(s) you want to highlight in your visualizations and text based on what you think is most interesting/biologically relevant."
  },
  {
    "objectID": "lecture.html",
    "href": "lecture.html",
    "title": "Lecture visualizations",
    "section": "",
    "text": "Order By\n       Default\n         \n          Lecture date - Oldest\n        \n         \n          Lecture date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nLecture date\n\n\n\n\n\n\nWeek 1 figures - Lectures 1 and 2\n\n\nApr 1, 2024\n\n\n\n\n\nWeek 2 figures - Lectures 3 and 4\n\n\n\nApr 8, 2024\n\n\n\n\n\n\nWeek 3 figures - Lectures 5 and 6\n\n\n\nApr 16, 2024\n\n\n\n\n\nWeek 4 figures - Lectures 7 and 8\n\n\nApr 21, 2024\n\n\n\n\nWeek 5 figures - Lectures 9 and 10\n\n\nApr 29, 2024\n\n\n\n\nWeek 7 figures - Lectures 12 and 13\n\n\nMay 13, 2024\n\n\n\n\nWeek 8 figures - Lectures 14 and 15\n\n\nMay 21, 2024\n\n\n\n\nWeek 10 figures - Lectures 17 and 18\n\n\nJun 3, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "weekly-materials.html",
    "href": "weekly-materials.html",
    "title": "Weekly materials",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nWeek 1 materials\n\n\nApr 1, 2024\n\n\n\n\n\nNo matching items"
  }
]