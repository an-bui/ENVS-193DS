[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nCampus resources\n\n\nplaces you can get help\n\n\n\n\nFixing code and getting help\n\n\nNeed help? Check here!\n\n\n\n\nGit/GitHub Part 1: prechecks\n\n\ncreating an account and making sure git is on your computer and configured correctly\n\n\n\n\nGit/GitHub Part 2: personal access token\n\n\nstoring your personal access token\n\n\n\n\nGit/GitHub basics\n\n\ncloning, committing, pushing, forking, pulling\n\n\n\n\nHow to resubmit an assignment\n\n\nMade some mistakes? Fix them!\n\n\n\n\nUsing the virtual machine\n\n\nCan’t install R/RStudio on your computer? Don’t have a computer? Use the virtual machine!\n\n\n\n\nWriting an informative README\n\n\nmaking sure people know what they’re looking at\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "ENVS 193DS",
    "section": "Instructor",
    "text": "Instructor\n\n\n\n\n\n\n\n\nName: An Bui\nEmail: an_bui [at] ucsb [dot] edu\nDrop-in hours: Wednesdays 3:30 - 5:30 PM\nDrop-in location: At the tables outside the UCen 1st floor (facing the lagoon)\nMore about me: an-bui.com"
  },
  {
    "objectID": "index.html#teaching-assistants",
    "href": "index.html#teaching-assistants",
    "title": "ENVS 193DS",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\nName: Thuy-Tien Bui\nEmail: thuy-tienbui [at] ucsb [dot] edu\nTeaching day: Thursdays\nDrop-in hours: Thursdays 2:00 - 3:00 PM\nDrop-in location: At the tables outside the UCen 1st floor (facing the lagoon)\nMore about me: https://thuy-tienbui.github.io/\n\n\n\n\nTA: Grace Lewin\nEmail: glewin [at] ucsb [dot] edu\nTeaching day: Fridays\nDrop-in hours: Fridays 11:00 AM - 12:00 PM\nDrop-in location: Library 6541\nMore about me: TBD\n\n\n\nAcknowledgements\nI took much of my inspiration for this course from Allison Horst’s Environmental Data Science and Statistics course, Sam Sambado’s Biometry course, and Sam Shanny-Csik’s Data Visualization and Communication course."
  },
  {
    "objectID": "resources/campus-resources.html",
    "href": "resources/campus-resources.html",
    "title": "Campus resources",
    "section": "",
    "text": "The Office of Student Conduct has a list of the resources available to students at UCSB. Some especially useful ones include:\n\nDisabled Students Program: testing accommodations, note-taking help\n\nCounseling & Psychological Services: mental health care and counseling\n\nResource Center for Sexual & Gender Diversity: resources to support members of the LGBTQIA+ community"
  },
  {
    "objectID": "resources/writing-a-readme.html",
    "href": "resources/writing-a-readme.html",
    "title": "Writing an informative README",
    "section": "",
    "text": "A README is a file that gives a broad overview of what is in a directory or repository. If you’re using GitHub, the README shows up on the repository page and is a markdown file (has the suffix .md). A README in a data repository (which you’ve seen on your midterm) is usually a plain text file (.txt)."
  },
  {
    "objectID": "resources/writing-a-readme.html#what-is-a-readme",
    "href": "resources/writing-a-readme.html#what-is-a-readme",
    "title": "Writing an informative README",
    "section": "",
    "text": "A README is a file that gives a broad overview of what is in a directory or repository. If you’re using GitHub, the README shows up on the repository page and is a markdown file (has the suffix .md). A README in a data repository (which you’ve seen on your midterm) is usually a plain text file (.txt)."
  },
  {
    "objectID": "resources/writing-a-readme.html#why-have-a-readme",
    "href": "resources/writing-a-readme.html#why-have-a-readme",
    "title": "Writing an informative README",
    "section": "Why have a README?",
    "text": "Why have a README?\nYou might know how your code and data are organized, but no one else does. By writing an informative README, people can read about the repository and then explore it to find what they’re looking for. You can also write a README for yourself to keep things organized (i.e. understand where you’ve put things so that you can find them again).\nIt’s an extra little step that future you and anyone else working with your code/data will use to understand how your files are organized and where they come from."
  },
  {
    "objectID": "resources/writing-a-readme.html#what-does-a-readme-look-like-on-github",
    "href": "resources/writing-a-readme.html#what-does-a-readme-look-like-on-github",
    "title": "Writing an informative README",
    "section": "What does a README look like on GitHub?",
    "text": "What does a README look like on GitHub?\nYou can look at this repository to see where the README shows up in a repository. It is one of the first things anyone will see.\n\nYou can format your README using headers and subheaders to make it easier to navigate. The button with three lines in the top right of the README will display a table of contents."
  },
  {
    "objectID": "resources/writing-a-readme.html#what-should-go-in-a-readme",
    "href": "resources/writing-a-readme.html#what-should-go-in-a-readme",
    "title": "Writing an informative README",
    "section": "What should go in a README?",
    "text": "What should go in a README?\nFor this class, any README should have at least:\n\nGeneral information\nThis is where a general description of the repo would go. This could include (but is not limited to):\n\nnames of people working in the repo\n\nwhere the data came from\n\nbroad research questions and analyses to address those questions\n\n\n\nData and file information\nThis is where a description of the data and files could go. For example, you could describe:\n\nthe data file format, when you accessed the data, etc.\n\nthe different code files and what they contain\n\n\n\nRendered output (specifically for this class, but nice to have in other README files too)\nFor 193DS assignments, you should put a link to the rendered file here so that it is easy to access."
  },
  {
    "objectID": "resources/writing-a-readme.html#more-information-about-readme-files",
    "href": "resources/writing-a-readme.html#more-information-about-readme-files",
    "title": "Writing an informative README",
    "section": "More information about README files",
    "text": "More information about README files\n\nUCSB Library Data Service guide to writing a README\n\nCornell Data Service guide to writing “readme” stype metadata\n\nMatias Singers’s list of awesome READMEs and README 101"
  },
  {
    "objectID": "resources/storing-personal-access-token.html",
    "href": "resources/storing-personal-access-token.html",
    "title": "Git/GitHub Part 2: personal access token",
    "section": "",
    "text": "Have you completed all steps in Git/GitHub Part 1?\n\n\n\nIf you have not created a GitHub account and entered your information in the Terminal, go back to Part 1 and complete those steps before moving on to the steps in this part."
  },
  {
    "objectID": "resources/storing-personal-access-token.html#canvas-video",
    "href": "resources/storing-personal-access-token.html#canvas-video",
    "title": "Git/GitHub Part 2: personal access token",
    "section": "Canvas video",
    "text": "Canvas video\nThere is a video on going through all these steps in the Week 6 module on Canvas (and here)."
  },
  {
    "objectID": "resources/storing-personal-access-token.html#what-is-a-personal-access-token",
    "href": "resources/storing-personal-access-token.html#what-is-a-personal-access-token",
    "title": "Git/GitHub Part 2: personal access token",
    "section": "What is a personal access token?",
    "text": "What is a personal access token?\nFrom GitHub’s documentation:\n\nPersonal access tokens are an alternative to using passwords for authentication to GitHub when using the GitHub API or the command line."
  },
  {
    "objectID": "resources/storing-personal-access-token.html#in-rstudio",
    "href": "resources/storing-personal-access-token.html#in-rstudio",
    "title": "Git/GitHub Part 2: personal access token",
    "section": "In RStudio",
    "text": "In RStudio\n\n1. Install usethis\nDo this in the console!\n\ninstall.packages(\"usethis\")\n\n\n\n\n2. Generate a personal access token using usethis\nAgain, do this in the console!\n\nusethis::create_github_token()\n\n\nThis will lead you to a web browser.\n(if prompted) in the web browser, enter your GitHub password."
  },
  {
    "objectID": "resources/storing-personal-access-token.html#in-your-browser",
    "href": "resources/storing-personal-access-token.html#in-your-browser",
    "title": "Git/GitHub Part 2: personal access token",
    "section": "In your browser",
    "text": "In your browser\n\n3. Fill in the information about your personal access token.\nUnder “Note”, name your PAT. A logical name could be “PAT spring 2025”.\nUnder “Expiration”, select 90 days.\n\n\n\n4. Scroll to the bottom of the page, hit Generate token\nDO NOT MODIFY ANY OF THE PRE-SELECTED CHECK BOXES.\n\n\n\n5. Copy the personal access token to your clipboard"
  },
  {
    "objectID": "resources/storing-personal-access-token.html#back-in-rstudio",
    "href": "resources/storing-personal-access-token.html#back-in-rstudio",
    "title": "Git/GitHub Part 2: personal access token",
    "section": "Back in RStudio",
    "text": "Back in RStudio\n\n6. Set the personal access token.\nRun this in the console!\n\ngitcreds::gitcreds_set()\n\n\n\n\n7. Paste your personal access token when prompted\nPaste your PERSONAL ACCESS TOKEN. NOT YOUR GITHUB PASSWORD. NOT YOUR COMPUTER PASSWORD.\nPASTE YOUR PERSONAL ACCESS TOKEN.\n\n\n\n8. Double check that the personal access token is stored\nAgain, run this in the console:\n\nusethis::git_sitrep()\n\nCheck that your user name and email are correct.\nCheck the Personal access token field under GitHub. This should say &lt;discovered&gt;."
  },
  {
    "objectID": "resources/asking-for-code-help.html#before-doing-any-coding-remember",
    "href": "resources/asking-for-code-help.html#before-doing-any-coding-remember",
    "title": "Fixing code and getting help",
    "section": "Before doing any coding, remember:",
    "text": "Before doing any coding, remember:\n\nThings will go wrong when you are coding.\nThis happens to everyone, and is normal! It is totally ok to ask someone on the teaching team to help fix your code; however, you should feel empowered to figure out what is wrong with your code on your own, and we will talk through best practices to do so.\n\n\nStart assignments with enough time to troubleshoot!\nYou will run into errors when doing your assignments. Don’t leave things to the last minute! This class requires you to plan in advance to get things done correctly and on time. We talk about assignments in class a week before the due date - take that week to read the assignment, do the easy problems first, try your code, troubleshoot, and finally submit!\nHere are some tried-and-true steps to troubleshooting code in this class, and beyond:"
  },
  {
    "objectID": "resources/asking-for-code-help.html#step-1.-take-a-deep-breath-seriously",
    "href": "resources/asking-for-code-help.html#step-1.-take-a-deep-breath-seriously",
    "title": "Fixing code and getting help",
    "section": "Step 1. Take a deep breath (seriously)!",
    "text": "Step 1. Take a deep breath (seriously)!\nErrors show up in red text and look super alarmed. Easier said than done, but do not be alarmed! Take a moment before panicking, and then…"
  },
  {
    "objectID": "resources/asking-for-code-help.html#step-2.-look-for-typos.",
    "href": "resources/asking-for-code-help.html#step-2.-look-for-typos.",
    "title": "Fixing code and getting help",
    "section": "Step 2. Look for typos.",
    "text": "Step 2. Look for typos.\nDo you have a period where there should be a comma? Have you spelled everything correctly? Are you missing a parenthesis somewhere? All sorts of things can happen when you’re typing a bunch; double check your code to make sure you don’t have any typos."
  },
  {
    "objectID": "resources/asking-for-code-help.html#step-3.-google-the-error.",
    "href": "resources/asking-for-code-help.html#step-3.-google-the-error.",
    "title": "Fixing code and getting help",
    "section": "Step 3. Google the error.",
    "text": "Step 3. Google the error.\nChances are you are not the only person who has ever experienced the specific error you are encountering. So, google it!\nYou can be smart about how you google things to find a solution to your problem. See Sam Shanny-Csik’s tutorial called “Teach Me How to Google” for tips on how to google to find solutions to coding problems.\nFor the next step, try at least 2 of these options:"
  },
  {
    "objectID": "resources/asking-for-code-help.html#step-4a.-ask-someone-to-look-at-your-code",
    "href": "resources/asking-for-code-help.html#step-4a.-ask-someone-to-look-at-your-code",
    "title": "Fixing code and getting help",
    "section": "Step 4a. Ask someone to look at your code!",
    "text": "Step 4a. Ask someone to look at your code!\nThis can be anyone: your housemate who knows how to code, your friend who took this class last year, etc.. Show your code to an actual human being (who knows how to code) and ask them if they can see anything wrong!"
  },
  {
    "objectID": "resources/asking-for-code-help.html#step-4b.-try-rubber-duck-debugging",
    "href": "resources/asking-for-code-help.html#step-4b.-try-rubber-duck-debugging",
    "title": "Fixing code and getting help",
    "section": "Step 4b. Try rubber duck debugging!",
    "text": "Step 4b. Try rubber duck debugging!\nRubber duck debugging is a silly way of talking through what you’re trying to do with your code. Generally, the steps are as follows (feel free to replace the rubber duck with an actual person or another object you want to use):\n\nObtain a rubber duck.\n\nLook at the rubber duck.\n\nExplain to the duck out loud, in words what you are trying to do with your code, line by line.\n\nAt some point, you will figure out what you did wrong!"
  },
  {
    "objectID": "resources/asking-for-code-help.html#step-4c.-go-to-sleep",
    "href": "resources/asking-for-code-help.html#step-4c.-go-to-sleep",
    "title": "Fixing code and getting help",
    "section": "Step 4c. Go to sleep!",
    "text": "Step 4c. Go to sleep!\nThis says it all:\n\n\n\n\n\nClose your computer! Go for a walk! Take a shower! Go to sleep! Do whatever you want other than keep coding. When you take a break, you might be able to figure out your problem.\nIf you’re still stuck then…"
  },
  {
    "objectID": "resources/asking-for-code-help.html#step-5.-email-someone-on-the-teaching-team-grace-thuy-tien-or-an",
    "href": "resources/asking-for-code-help.html#step-5.-email-someone-on-the-teaching-team-grace-thuy-tien-or-an",
    "title": "Fixing code and getting help",
    "section": "Step 5. Email someone on the teaching team (Grace, Thuy-Tien, or An)",
    "text": "Step 5. Email someone on the teaching team (Grace, Thuy-Tien, or An)\nWe are here to help you! However, inquiries about how to fix code will only be addressed if they include brief (1-2 sentences each) descriptions of the following:\n\nWhat you’re trying to do\n\nWhat the problem is\n\nWhat you have done to try to solve the problem on your own\n\nWe can also best help you if you provide a screenshot of your code or the script so that we can see what is happening.\n\n\n\n\n\n\nBe patient with a response!\n\n\n\nAgain, we are here to help you - but if you email at 11:58 on Wednesdays right before the homework is due, it’s unlikely that you’ll get a response right away! You can expect a response from one of us within 36 hours of emailing (though we will try to respond sooner than that); plan accordingly!"
  },
  {
    "objectID": "workshop.html",
    "href": "workshop.html",
    "title": "Workshop documents",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nCoding workshop: Week 8\n\n\nMultiple linear regression\n\n\n\n\nCoding workshop: Week 7\n\n\nusing Git and GitHub\n\n\n\n\nCoding workshop: Week 6\n\n\nPrepping your computer to use Git/GitHub\n\n\n\n\nCoding workshop: Week 5\n\n\nParametric and non-parametric comparisons of more than 2 groups\n\n\n\n\nCoding workshop: Week 4\n\n\nggplot customization\n\n\n\n\nCoding workshop: Week 3\n\n\nbasic t-tests and their assumptions\n\n\n\n\nCoding workshop: Week 2\n\n\nusing Quarto, data wrangling, visualizing uncertainty\n\n\n\n\nCoding workshop: Week 1\n\n\nbasics of using RStudio, intro to tidyverse\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "assignments/optional-problem-02.html",
    "href": "assignments/optional-problem-02.html",
    "title": "OPTIONAL practice problem - everything is a linear model",
    "section": "",
    "text": "Linear models share the same parametric base as ANOVAs (and t-tests!). This means that if you were to compare your results from an ANOVA to a linear model, you would see the same result.\nHowever, the presentation of those results is slightly different, so it’s not always obvious if you’re just looking at R output. For example, with a linear model, you would see the estimates for each level of a factor relative to a reference level. Compare this with an ANOVA, where you would see sum of squares, mean squares, F-statistic, and p-value.\nProve to yourself that ANOVAs are actually just linear models!"
  },
  {
    "objectID": "assignments/optional-problem-02.html#description",
    "href": "assignments/optional-problem-02.html#description",
    "title": "OPTIONAL practice problem - everything is a linear model",
    "section": "",
    "text": "Linear models share the same parametric base as ANOVAs (and t-tests!). This means that if you were to compare your results from an ANOVA to a linear model, you would see the same result.\nHowever, the presentation of those results is slightly different, so it’s not always obvious if you’re just looking at R output. For example, with a linear model, you would see the estimates for each level of a factor relative to a reference level. Compare this with an ANOVA, where you would see sum of squares, mean squares, F-statistic, and p-value.\nProve to yourself that ANOVAs are actually just linear models!"
  },
  {
    "objectID": "assignments/optional-problem-02.html#set-up",
    "href": "assignments/optional-problem-02.html#set-up",
    "title": "OPTIONAL practice problem - everything is a linear model",
    "section": "Set up",
    "text": "Set up\nInstall palmerpenguins if you don’t have it already. Read in the data using data(penguins).\nThe question we will ask is: How does body mass differ between penguin species?\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(car)\nlibrary(ggeffects)\n\ndata(penguins)"
  },
  {
    "objectID": "assignments/optional-problem-02.html#problem",
    "href": "assignments/optional-problem-02.html#problem",
    "title": "OPTIONAL practice problem - everything is a linear model",
    "section": "Problem",
    "text": "Problem\n\n1. Calculate the mean body masses and lower and upper bounds of the 95% CI around the mean for each penguins species.\n\npenguins |&gt; \n  group_by(species) |&gt; # group by species\n  reframe(mean = mean(body_mass_g, na.rm = TRUE), # calculating mean\n          se = sd(body_mass_g, na.rm = TRUE)/sqrt(length(body_mass_g)), # calculating SE\n          tval = qt(p = 0.05/2, df = length(body_mass_g), lower.tail = FALSE), # finding t-value\n          margin = se*tval, # calculating margin of error\n          conf_low = mean - margin, # calculating the lower bound of the CI\n          conf_high = mean + margin, # calculating the upper bound of the CI\n          var = var(body_mass_g, na.rm = TRUE) # also calculating variance here for efficiency\n          ) \n\n# A tibble: 3 × 8\n  species    mean    se  tval margin conf_low conf_high     var\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 Adelie    3701.  37.2  1.98   73.5    3627.     3774. 210283.\n2 Chinstrap 3733.  46.6  2.00   93.0    3640.     3826. 147713.\n3 Gentoo    5076.  45.3  1.98   89.6    4986.     5166. 254133.\n\n\n\n\n\n\n\n\nNote\n\n\n\nStop and think: keep in mind what those means and 95% CI around the means are!\n\n\n\n\n2. Create a figure with species on the x-axis and body mass on the y-axis, with means, 95% CIs, and the underlying data.\n\nggplot(data = penguins, # penguins data\n       aes(x = species, # x-axis\n           y = body_mass_g)) + # y-axis\n  geom_point(position = position_jitter(width = 0.2, # shake points left and right\n                                        height = 0), # not up and down\n             alpha = 0.2) + # transparency\n  stat_summary(geom = \"pointrange\", # plot means and CIs\n               fun.data = mean_cl_normal) # calculating mean and 95% confidence interval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nStop and think: do you think there’s a difference between species in body mass?\n\n\n\n\n3. Use ANOVA to determine the difference in body mass between penguin species.\nDo any assumption checks as needed.\nFirst, Levene’s test:\n\nleveneTest(body_mass_g ~ species, # formula\n           data = penguins) # data\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value   Pr(&gt;F)   \ngroup   2  5.1203 0.006445 **\n      339                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSignificantly different variances in body mass between species! But looking at the calculated variances, they are for practical purposes equal.\nVisually evaluating normality:\n\nggplot(data = penguins,\n       aes(sample = body_mass_g)) + # argument for a QQ plot\n  geom_qq_line(lty = 2, \n               color = \"grey\") + # adding a reference line\n  geom_qq() + # QQ\n  theme_classic() + # cleaner background, easier to see things\n  facet_wrap(~species)\n\n\n\n\n\n\n\n\nStatistically evaluating normality:\n\nadelie &lt;- penguins |&gt; \n  filter(species == \"Adelie\") |&gt; # filtering for Adelie\n  pull(body_mass_g) # pulling body mass as a vector\n\nshapiro.test(adelie)\n\n\n    Shapiro-Wilk normality test\n\ndata:  adelie\nW = 0.98071, p-value = 0.0324\n\nchinstrap &lt;- penguins |&gt; \n  filter(species == \"Chinstrap\") |&gt; # filtering for chinstrap\n  pull(body_mass_g)\n\nshapiro.test(chinstrap)\n\n\n    Shapiro-Wilk normality test\n\ndata:  chinstrap\nW = 0.98449, p-value = 0.5605\n\ngentoo &lt;- penguins |&gt; \n  filter(species == \"Gentoo\") |&gt; # filtering for Gentoo\n  pull(body_mass_g)\n\nshapiro.test(gentoo)\n\n\n    Shapiro-Wilk normality test\n\ndata:  gentoo\nW = 0.98593, p-value = 0.2336\n\n\nProbably ok.\n\npenguins_anova &lt;- aov(body_mass_g ~ species, # formula\n                      data = penguins) # data\n\n# show the ANOVA table: sums of squares, mean squares, f-statistic, p-value\nsummary(penguins_anova)\n\n             Df    Sum Sq  Mean Sq F value Pr(&gt;F)    \nspecies       2 146864214 73432107   343.6 &lt;2e-16 ***\nResiduals   339  72443483   213698                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2 observations deleted due to missingness\n\n\n\n\n\n\n\n\nNote\n\n\n\nStop and think: what is the result of your ANOVA?\n\n\nThen, do a post-hoc:\n\nTukeyHSD(penguins_anova)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = body_mass_g ~ species, data = penguins)\n\n$species\n                       diff       lwr       upr     p adj\nChinstrap-Adelie   32.42598 -126.5002  191.3522 0.8806666\nGentoo-Adelie    1375.35401 1243.1786 1507.5294 0.0000000\nGentoo-Chinstrap 1342.92802 1178.4810 1507.3750 0.0000000\n\n\n\n\n\n\n\n\nNote\n\n\n\nStop and think: what is the result of your post-hoc test?\n\n\n\n\n4. Use a linear model to determine the difference in body mass between penguin species.\n\npenguins_lm &lt;- lm(body_mass_g ~ species,\n                  data = penguins)\n\npar(mfrow = c(2, 2)) # displaying all diagnostic plots in 2x2 grid\nplot(penguins_lm) # diagnostic plots\n\n\n\n\n\n\n\nsummary(penguins_lm) # model estimates and information\n\n\nCall:\nlm(formula = body_mass_g ~ species, data = penguins)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1126.02  -333.09   -33.09   316.91  1223.98 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       3700.66      37.62   98.37   &lt;2e-16 ***\nspeciesChinstrap    32.43      67.51    0.48    0.631    \nspeciesGentoo     1375.35      56.15   24.50   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 462.3 on 339 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.6697,    Adjusted R-squared:  0.6677 \nF-statistic: 343.6 on 2 and 339 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nStop and think about this result.\n\nHow do the estimates compare to your calculated means?\n\nHow do the F-statistic, degrees of freedom, and p-value for the model compare to the ANOVA summary?\n\nWhat components of the ANOVA summary go into the R2?\n\n\n\nThen, get the model predictions:\n\nggpredict(penguins_lm, \n          terms = c(\"species\")) # only predictor in the model is species\n\n# Predicted values of body_mass_g\n\nspecies   | Predicted |           95% CI\n----------------------------------------\nAdelie    |   3700.66 | 3626.67, 3774.66\nChinstrap |   3733.09 | 3622.82, 3843.36\nGentoo    |   5076.02 | 4994.03, 5158.00\n\n\n\n\n\n\n\n\nNote\n\n\n\nStop and think: compare these with your calculated means and 95% CIs.\n\n\nThen, plot for good measure!\n\nggpredict(penguins_lm, # getting model predictions\n          terms = c(\"species\")) |&gt; # only predictor is species\n  # quick option to plot from ggpredict\n  plot(show_data = TRUE, # show the underlying data\n       jitter = TRUE) # shake the points around a bit"
  },
  {
    "objectID": "assignments/optional-problem-01.html",
    "href": "assignments/optional-problem-01.html",
    "title": "OPTIONAL practice problem - Do a Wilcoxon signed rank test by hand",
    "section": "",
    "text": "In this practice problem, you’ll do a Wilcoxon signed rank test comparing paired samples to each other by hand, then double check your work with R. This is the non-parametric version of the paired t-test."
  },
  {
    "objectID": "assignments/optional-problem-01.html#description",
    "href": "assignments/optional-problem-01.html#description",
    "title": "OPTIONAL practice problem - Do a Wilcoxon signed rank test by hand",
    "section": "",
    "text": "In this practice problem, you’ll do a Wilcoxon signed rank test comparing paired samples to each other by hand, then double check your work with R. This is the non-parametric version of the paired t-test."
  },
  {
    "objectID": "assignments/optional-problem-01.html#steps",
    "href": "assignments/optional-problem-01.html#steps",
    "title": "OPTIONAL practice problem - Do a Wilcoxon signed rank test by hand",
    "section": "2. Steps",
    "text": "2. Steps\n\na. Values\nStart with these values:\n\n\n\n\n\nBefore\nAfter\n\n\n\n\n1.2\n1.6\n\n\n2.0\n2.8\n\n\n0.8\n0.7\n\n\n0.6\n0.6\n\n\n1.3\n1.5\n\n\n3.2\n2.7\n\n\n0.9\n1.1\n\n\n\n\n\n\n\nb. Calculate the differences between samples\nThen, calculate the differences between those values. You should get something that looks like this:\n\n\n\n\n\nDifferences\n\n\n\n\n-0.4\n\n\n-0.8\n\n\n0.1\n\n\n0.0\n\n\n-0.2\n\n\n0.5\n\n\n-0.2\n\n\n\n\n\n\n\nc. Take out 0, arrange by magnitude\nThen, omit all observations of 0 and arrange your numbers by magnitude. You should get something that looks like this:\n\n\n\n\n\nOrdered magnitude\n\n\n\n\n0.1\n\n\n-0.2\n\n\n-0.2\n\n\n-0.4\n\n\n0.5\n\n\n-0.8\n\n\n\n\n\n\n\nd. Give each value a “sign” and a “rank”\nThis is the “signed rank” part of the test: assign each value a sign (+ or -), then rank (1, 2, 3, 4, etc.) You should get something that looks like this:\n\n\n\n\n\nOrdered magnitude\nSigned rank\n\n\n\n\n0.1\n+ 1\n\n\n-0.2\n- 2\n\n\n-0.2\n- 2\n\n\n-0.4\n- 4\n\n\n0.5\n+ 5\n\n\n-0.8\n- 6\n\n\n\n\n\n\n\ne. Sum the magnitudes of the + and - values\nSum the magnitudes of the + and - values. This will be the -W and +W statistic. You then choose the lower statistic.\nIn this case, you should get:\n+W = 1 + 5 = 6\n-W = 2 + 2 + 4 + 6 = 14\nPick the lowest one: +W = 6.\n\n\ne. Run the test in R to check your work.\nStart with this data frame:\n\n# creating a data frame with \"before\" and \"after\" values\n# each row is an individual with a measurement taken \"before\" and \"after\"\ndf &lt;- tibble(before = c(1.2, 2.0, 0.8, 0.6, 1.3, 3.2, 0.9), \n             after = c(1.6, 2.8, 0.7, 0.6, 1.5, 2.7, 1.1)) \n\nThen run a Wilcoxon signed rank test (note the paired = TRUE argument).\n\nwilcox.test(x = df$before,\n            y = df$after,\n            paired = TRUE) # argument for a paired test\n\nWarning in wilcox.test.default(x = df$before, y = df$after, paired = TRUE):\ncannot compute exact p-value with zeroes\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  df$before and df$after\nV = 6, p-value = 0.4017\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nf. Try a one-sample test.\nCompare the following values to \\(\\mu = 7\\):\n\n\n\n\n\nSample\n\n\n\n\n2.8\n\n\n8.3\n\n\n4.5\n\n\n6.7\n\n\n8.1\n\n\n7.2\n\n\n7.8\n\n\n\n\n\nFirst, calculate the difference between each observation and the \\(\\mu\\), which is 7:\n\n\n\n\n\nSample\nDifference\n\n\n\n\n2.8\n-4.2\n\n\n8.3\n1.3\n\n\n4.5\n-2.5\n\n\n6.7\n-0.3\n\n\n8.1\n1.1\n\n\n7.2\n0.2\n\n\n7.8\n0.8\n\n\n\n\n\nThen order each difference and assign a sign and rank:\n\n\n\n\n\nOrdered magnitude\nSigned rank\n\n\n\n\n0.2\n+ 1\n\n\n-0.3\n- 2\n\n\n0.8\n+ 3\n\n\n1.1\n+ 4\n\n\n1.3\n+ 5\n\n\n-2.5\n- 6\n\n\n-4.2\n- 7\n\n\n\n\n\nThen sum the magnitudes:\n+W = 1 + 3 + 4 + 5 = 13\n-W = 2 + 6 + 7 = 15\nFor this example, W = 13.\nThen, double check your work in R:\n\nwilcox.test(c(2.8, 8.3, 4.5, 6.7, 8.1, 7.2, 7.8),\n            mu = 7)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  c(2.8, 8.3, 4.5, 6.7, 8.1, 7.2, 7.8)\nV = 13, p-value = 0.9375\nalternative hypothesis: true location is not equal to 7"
  },
  {
    "objectID": "assignments/midterm.html",
    "href": "assignments/midterm.html",
    "title": "Midterm",
    "section": "",
    "text": "Due on Wednesday May 7 (Week 6) at 11:59 PM"
  },
  {
    "objectID": "assignments/midterm.html#problem-1.-understanding-and-critiquing-written-communication-20-points",
    "href": "assignments/midterm.html#problem-1.-understanding-and-critiquing-written-communication-20-points",
    "title": "Midterm",
    "section": "Problem 1. Understanding and critiquing written communication (20 points)",
    "text": "Problem 1. Understanding and critiquing written communication (20 points)\n\nSkills you will demonstrate\nIn this problem, you will be responsible for demonstrating your understanding of the different components of a statistical test. All numbers describe a different statistical concept; how well do you understand what those numbers represent?\n\n\nDescription\nYou’re a fisheries manager interested in the effects of marine protected areas on the size of California sheephead (Bodianus pulcher). You find a study in which researchers examined exactly this effect. In their results section, the researchers wrote:\n\nWe found a difference in sheephead length (in centimeters) between marine protected areas and non-protected areas (Welch’s two-sample t-test, t(83.6) = 7.2, p &lt; 0.001, \\(\\alpha\\) = 0.05).\n\n\n\nComponents\n\na. Hypotheses (4 points)\nThe researchers didn’t state their hypotheses explicitly anywhere in their paper. In one sentence each, write the null (\\(H_0\\)) and alternative (\\(H_A\\)) hypotheses in statistical terms.\n\n\nb. Test type (2 points)\nThe researchers ran a Welch’s two sample t-test. What must have been true for them to use a Welch’s t-test? Respond in 1 or 2 sentences only.\n\n\nc. Test summary components (10 points)\nIn parentheses, the researchers cite some information about their statistical test:\n\nt(105.6) = 6.6, p &lt; 0.001, \\(\\alpha\\) = 0.05\n\nIn one sentence each, explain the meaning of:\n\nt\n\n105.6\n\n6.6\n\np &lt; 0.001\n\n\\(\\alpha\\) = 0.05\n\nBe specific: what is the term that describes the component, and what does that component represent?\n\n\nd. Missing information (4 points)\nUnfortunately, this one sentence is the extent of the researchers’ communication about their statistics. Identify 2 other components or statistics they could have included (note that there may be more than 2 additional components that could make sense).\nFor each of your pieces of “missing information”, explain why it would be relevant to the questions or hypotheses."
  },
  {
    "objectID": "assignments/midterm.html#problem-2.-interpretation-and-communication-41-points",
    "href": "assignments/midterm.html#problem-2.-interpretation-and-communication-41-points",
    "title": "Midterm",
    "section": "Problem 2. Interpretation and communication (41 points)",
    "text": "Problem 2. Interpretation and communication (41 points)\n\nSkills you will demonstrate\nIn this problem, you will be responsible for interpreting the results of a test with which you may be familiar, but haven’t seen. You will also demonstrate your ability to interpret code output and synthesize the statistics in writing to ground the stats in biology for a scientific audience.\n\n\nDescription\nIn 2014, the emergency manager of Flint, Michigan (mandated by the governor of Michigan at the time) switched the source of water for Flint from the Detroit River/Lake Huron to the Flint River. As a result, residents of Flint were exposed to lead contamination in their water. This was the start of the Flint water crisis, and Flint residents continue to deal with water contamination to this day.\nWhen the crisis started, city officials recommended that residents allow pipes to clear (by flushing the pipes) before using any water. In 2015, Flint residents participated in a study to collect water samples to test for lead. Residents took water samples from their own taps at three different time points (letting the water run the whole time):\n\nimmediately after turning on the water\n\n45 seconds after turning on the water\n\n2 minutes after turning on the water.\n\nIn this problem, you will work with statistical results from tests run on this data set of lead concentration in water samples collected by Flint residents. You will interpret statistical results to answer the questions:\n\nIs there a difference in lead concentration (measured in parts per billion, ppb) between water samples taken immediately after turning on the water and 2 minutes after turning on the water?\n\nIs the amount of lead in the water after 2 minutes different from 0?\n\nBefore completing this problem, read about the study here. Additionally, make sure you understand the following figure:\n\n\n\n\n\n\n\n\n\nFigure 1. Lead concentrations (ppb) in Flint, Michigan water samples. Water samples were taken from faucets immediately after turning the water on (“first draw (immediate)”) and 2 minutes after turning the water on (“two minutes of flushing”). Open circles represent a water sample taken from a single faucet (n = 300). Red points represent means and 95% confidence intervals. Data from Flint Water Study.\n\n\nComponents\n\na. Hypotheses (8 points)\nIn one sentence each, write your null (\\(H_0\\)) and alternative (\\(H_A\\)) hypotheses in statistical terms to answer the questions:\n\nIs there a difference in lead concentration (measured in parts per billion, ppb) between water samples taken immediately after turning on the water and 2 minutes after turning on the water?\n\nIs the amount of lead in the water after 2 minutes different from 0?\n\nYou should have one null and alternative for question 1, and one null and alternative for question 2.\n\n\nb. Paired t-test (15 points)\nThis is the result of a paired t-test, which is appropriate when test subjects are measured twice in a paired study (in this case, water samples were taken at two time points from a single faucet). This would address question 1: Is there a difference in lead concentration (measured in parts per billion, ppb) between water samples taken immediately after turning on the water and 2 minutes after turning on the water?\n\n\n\n    Paired t-test\n\ndata:  flint_clean$pb_bottle_1_ppb_first_draw and flint_clean$pb_bottle_3_ppb_2_mins_flushing\nt = 6.3963, df = 268, p-value = 7.055e-10\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 4.881162 9.222377\nsample estimates:\nmean difference \n        7.05177 \n\n\nThis is the result of a calculation of effect size:\n\n\nFor paired samples, 'repeated_measures_d()' provides more options.\n\n\nCohen's d |       95% CI\n------------------------\n0.39      | [0.27, 0.51]\n\n\nIn 1-2 sentences only, summarize your interpretation and results of the test along with the effect size. Be sure to include all components of the test summary (for example, degrees of freedom, distribution, test statistic, confidence interval, etc.) that are important for understanding its structure.\nWhere necessary, round values to 1 decimal point and/or express as &lt; 0.001.\n\n\nc. One-sample t-test (15 points)\nThis is the output of a one-sample t-test to answer question 2: Is the amount of lead in the water after 2 minutes different from 0?\n\n\n\n    One Sample t-test\n\ndata:  flint_clean$pb_bottle_3_ppb_2_mins_flushing\nt = 5.6212, df = 268, p-value = 4.753e-08\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 2.347136 4.877629\nsample estimates:\nmean of x \n 3.612383 \n\n\nIn 1-2 sentences only, summarize your interpretation and results of the test. Be sure to include all components of the test summary (for example, degrees of freedom, distribution, test statistic, confidence interval, etc.) that are important for understanding its structure.\nWhere necessary, round values to 1 decimal point and/or express as &lt; 0.001.\nAs stated by the Environmental Protection Agency (EPA), “EPA has set the maximum contaminant level goal for lead in drinking water at zero because lead is a toxic metal that can be harmful to human health even at low exposure levels” (EPA). In your response, contextualize these results within the EPA maximum contaminant goal (for example, are the samples from Flint on average more, less, or at the EPA maximum contaminant goal for lead?).\n\n\nd. Statistical implications (5 points)\nImagine that you are a scientific advisor on water quality. Write 4-5 sentences about the results of both these tests in their real world context.\nHow would you communicate with the Flint residents who participated in this study about the results of both of these tests? Additionally, what do you make of these results within the context of the Flint water crisis, which is ongoing in 2025?\n\n\n\n\n\n\nData collection is always attached to its social context\n\n\n\n\n\nThe leader of this study was Dr. Marc Edwards of Virginia Tech, who claimed to represent the residents of Flint. After the original study was over, his group collected new samples from Flint residents and declared that the water was safe to use. However, residents knew the water was unsafe to use given lead and other contaminants, and filed a complaint against Dr. Edwards."
  },
  {
    "objectID": "assignments/midterm.html#problem-3.-reproducing-an-analysis-73-points",
    "href": "assignments/midterm.html#problem-3.-reproducing-an-analysis-73-points",
    "title": "Midterm",
    "section": "Problem 3. Reproducing an analysis (73 points)",
    "text": "Problem 3. Reproducing an analysis (73 points)\n\nSkills you will demonstrate\nIn environmental studies, open research means that researchers make their data and/or their code available for anyone to see. This means that anyone should be able to reproduce the analysis, even if they are not on the research team. In this problem, you will demonstrate your ability to read a paper to understand the context for a research study and its statistical analysis. You will then demonstrate your ability to take a data set and analyze it, using the researchers’ original analysis as a guide.\n\n\nDescription\nYou will reproduce the analysis in: Steketee, Jess K., Adrian V. Rocha, Laura Gough, Kevin L. Griffin, Ian Klupar, Ruby An, Nicole Williamson, and Rebecca J. Rowe. 2022. “Small Herbivores with Big Impacts: Tundra Voles (Microtus Oeconomus) Alter Post-Fire Ecosystem Dynamics.” Ecology 103(7): e3689. https://doi.org/10.1002/ecy.3689\nRead all parts of the paper before starting this problem.\nYou will specifically recreate the components in this passage:\n\nAlthough tussock density was lower at the burned site, tussocks were larger.\n\n\n\nGetting the data\nThis statement relies on the dataset stored here:\nRocha, A. 2021. Tussock height and diameter in moist acidic tussock tundra at the site of the 2007 Anaktuvuk River fire scar, and nearby unburned tundra measured in 2016 ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/1dccd3fdb3aa693f9c2b69a24f8306ed\nDownload the data into your midterm directory. To understand the data structure, read the metadata (under Resources &gt; View full metadata &gt; Data Entities).\n\n\nComponents\n\na. Variables (4 points)\nIn 1-2 sentences, describe the response variable (with units) and predictor variable (include each group). Be sure to explain the type of each variable (categorical, continuous, etc.).\n\n\nb. Hypotheses (4 points)\nIn one sentence each, write the null (\\(H_0\\)) and alternative (\\(H_A\\)) hypotheses in statistical terms.\n\n\nc. Cleaning and organizing data (10 points)\n\n\n\n\n\n\nResponse variable column in original dataset\n\n\n\n\n\nUse the “Average Moss (cm)” column for tussock height.\n\n\n\nCreate an object called tussocks_clean. Clean the data by:\n\ncleaning all the column names\n\nreplacing the values in the site column as follows:\n\nreplace Sev with Burned\n\nreplace Unb with Unburned\n\nselecting only the site and height column\n\nUse the pipe operator to string functions together.\nOnce you are done, display 5 rows from tussocks_clean using the slice_sample() function. DO NOT SUBSET THE DATA FRAME. THIS IS FOR DISPLAYING THE CONTENTS ONLY.\n\n\nd. Summarizing and table displays (12 points)\nCreate an object called tussocks_summary using the tussocks_clean data frame to calculate the:\n\nmeans,\n\nstandard deviations,\n\nstandard errors, and\n\n95% confidence intervals of the means\nfor the response variable within the two groups.\n\nRound all numbers to 1 decimal point.\nDisplay only the means, standard deviations, standard errors, and 95% confidence intervals in a table. Choose one of the following packages to do so:\n\ngt (package info here)\n\nflextable (package info here)\n\nMake sure the column names of the table are polished (no underscores, capitalized in sentence case).\nShow all code for your calculations and making/polishing the table.\n\n\n\n\n\n\nDouble check your table!\n\n\n\n\n\nRender your document to make sure your table looks right. Do not assume that just because your code works, your table will render correctly.\n\n\n\n\n\ne. Tests and effect sizes (6 points)\nUse a Welch’s t-test to compare mean tussock height between groups.\nCalculate the appropriate effect size.\n\n\nf. Written communication (15 points)\nThe authors communicated about the results of this test in the text above (in the Description) and in a table in the paper.\nIn 1-2 sentences only, write an updated interpretation with results of the test and effect size. Be sure to include all components of the test summary (for example, degrees of freedom, distribution, test statistic, confidence interval, etc.) that are important for understanding its structure.\n\n\ng. Making a new figure (13 points)\nPlots like Figure 3b in the paper show means and whiskers (in this case, standard error), but do not show the data structure and can mask important information about the spread of the observations in each sample.\nMake a new figure that displays the mean and standard error (as in figure 3b) but shows the underlying data. For full credit:\n\ntake out the gridlines and make the plot and panel background white\n\njitter the observations horizontally but not vertically\n\ngive each type a different color that is different from the ggplot() default color\n\nuse transparent open circles to represent the underlying data\n\ntake out the legend\n\ninclude a plot title and put your name as the subtitle\n\n\n\nh. Caption (10 points)\nWrite a caption for your figure in part g. Include a data citation."
  },
  {
    "objectID": "assignments/midterm.html#problem-4.-cleaning-wrangling-and-visualization-33-points",
    "href": "assignments/midterm.html#problem-4.-cleaning-wrangling-and-visualization-33-points",
    "title": "Midterm",
    "section": "Problem 4. Cleaning, wrangling, and visualization (33 points)",
    "text": "Problem 4. Cleaning, wrangling, and visualization (33 points)\n\nSkills you will demonstrate\nFigures are built on data; however, to make a figure, you need to understand the data structure and any cleaning, wrangling, or summarizing steps to create it. In this problem, you will demonstrate your ability to clean, wrangle, and/or summarize a data set to create a figure, using a final figure as a guide.\n\n\nDescription\nIn this problem, you will use a data set of rainfall (measured in inches) from the rain gauge on top of Ellison Hall to recreate this figure.\n\nThe caption for the figure is as follows:\nFigure 2. Most rain occurs between November and March. Lines and points represent total monthly rain (measured in inches) from Ellison Hall rain gauge for each water year starting in September and ending in August. Shown are water years 2018-2019 (purple), 2019-2020 (red), 2020-2021 (orange), 2021-2022 (yellow), 2022-2023 (green) and 2023-2024 (blue). Data source: County of Santa Barbara Public Works, Daily Rainfall Data (XLS). Accessed April 2025.\n\n\nGetting the data\nThis data set comes from the Count of Santa Barbara Public Works under the Daily Rainfall Data (XLS) page.\nOn the website, click the red dot next to Isla Vista (this represents the Ellison Hall rain gauge).\nMAKE SURE YOU HAVE DOWNLOADED THE CORRECT DATA FILE. YOUR FILE SHOULD BE CALLED 200dailys.xls.\n\n\n\n\n\n\nLook at the data in Sheets or Excel before starting!\n\n\n\n\n\nYou will see that there is extra information at the top of the sheet. Clean up the file so that it only has data columns, and save that as a .csv file.\n\n\n\n\n\nComponents\n\na. Initial cleaning, wrangling, and summarizing (14 points)\n\n\n\n\n\n\nDouble check your data\n\n\n\n\n\nBefore you do this problem, make sure you have code to read in and save your data as an object called rain at the top of the document.\n\n\n\nThe following chunk of code creates an object called rain_clean. Copy and paste this code into your document to run it.\nWhere prompted in the code annotations, fill in your responses to describe what each function is doing, and how the data frame changes. Only write your responses in the annotations. See function 7 for an example.\n\nrain_clean &lt;- rain |&gt;  \n  \n  # 1. what changes after this function? \n  # [insert response here]\n  # give an example. \n  # [insert response here]\n  clean_names() |&gt;  \n  \n  # 2. what new column is created? \n  # [insert response here]\n  # give an example of a value in this column.\n  # [insert response here]\n  mutate(water_year_minus1 = water_year - 1) |&gt;  \n  \n  # 3. what old column is changed?\n  # [insert response here]\n  # give an example of a value in the old column, and explain how it changed. \n  # [insert response here]\n  mutate(water_year = paste0(water_year_minus1, \"-\", water_year)) |&gt; \n  \n  # 4. what columns are excluded from the data frame?\n  # [insert response here]\n  # give an example of a value in water_year_minus1 \n  # [insert response here]\n  # give an example of a value in code \n  # [insert response here]\n  select(!c(water_year_minus1, code)) |&gt; \n  \n  # 5. which column is manipulated, and what changes about it? \n  # Hint: run str(rain_clean) in the Console. what do you see for the month column?\n  # [insert response here]\n  mutate(month = as_factor(month),\n         month = fct_relevel(\n           month, \n           \"9\", \"10\", \"11\", \"12\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\")\n         ) |&gt;  \n  \n  # 6. what is being calculated? on an annual, monthly, or daily scale? \n  # [insert response here]\n  # give an example. \n  # [insert response here]\n  group_by(month, water_year) %&gt;% \n  summarize(total_rain = sum(daily_rain, na.rm = TRUE)) |&gt;  \n  ungroup() |&gt;  \n  \n  # 7. what is being done to which columns? \n  # missing combinations of values of water_year and month are being filled in with 0\n  # give an example. \n  # july in 1951-1952 was not in the data frame previously, and now is present with a total rain of 0 inches\n  complete(water_year, \n           month, \n           fill = list(total_rain = 0)) |&gt;  \n  \n  # 8. which observations are kept after this filtering step?\n  # [insert response here]\n  filter(water_year %in% c(\"2018-2019\", \n                           \"2019-2020\", \n                           \"2020-2021\", \n                           \"2021-2022\", \n                           \"2022-2023\", \n                           \"2023-2024\")) \n\n\n\n\n\n\n\nA possible approach\n\n\n\n\n\nOne way to approach this problem is to delete all the pipe operators and add them back in one by one. With every additional function, look at the rain_clean object to describe what has changed about the data frame.\n\n\n\n\n\nb. Make the figure (19 points)\nRecreate the figure. Specifically, recreate the:\n\nx-axis (and label),\n\ny-axis (and label),\n\ntitle,\n\nlegend position,\n\npanel background (blank),\n\naxis lines and ticks (blank),\n\ntitle position,\n\ngeometries, and\n\ndifferent colors\n\nNote that you do not need an exact match of the colors (choose whatever colors you want) or legend position (just make sure it’s inside the panel and doesn’t cover any points).\n\n\n\n\n\n\nMy figure doesn’t look right when I render my document.\n\n\n\n\n\nYou will have to set the code chunk options to make a larger figure. Click the gear button in the code chunk to set those options."
  },
  {
    "objectID": "assignments/getting-set-up.html",
    "href": "assignments/getting-set-up.html",
    "title": "Getting set up",
    "section": "",
    "text": "Optional check in due on Wednesday April 2 (Week 1) at 11:59 PM\nIn this class, we’ll be using R and RStudio to code up our statistical analyses. Walk through these steps to make sure you have both programs on your computer and that everything is working properly. You need to make sure these tasks are completed before workshop on Thursday and Friday.\n\n\n\n\n\n\nDo these set up steps as soon as possible!\n\n\n\nEveryone needs to do tasks 1 - 7. If you want to submit the optional check-in for An to verify that you’ve done things correctly, you can do task 8 and submit your screenshot on Canvas.\nIf you do not have R, RStudio, and Quarto installed and running, we cannot stop for you. Do this before class starts!\n\n\n\n\n\n\n\n\nWhat version should I install? Do I need to update R/RStudio?\n\n\n\nYou should have at least R 4.2.2 (released November 2022) and RStudio 2023.12.1.\nIf you have downloaded R/RStudio for previously but you don’t have updated versions, then you need to update! To do so, follow the instructions for installation in Task 1.\nAn will be using R version 4.4.3 and RStudio version 2024.12.1+563.\n\n\n\nTask 1. Install R.\nGo to cran.rstudio.com. Choose the correct download for your operating system!\n\n\n\n\n\n\n\n\n\n\n\nNeed to see a bigger image?\n\n\n\n\n\nClick on the screenshot to make it bigger!\n\n\n\n\n\nTask 2. Install RStudio (and optionally Quarto)\nGo to posit.co/download/rstudio-desktop. Click on the button under “2: Install RStudio”. It should automatically show the correct version for your operating system.\n\n\n\n\n\n\n\n\n\n\n\nInstalling Quarto\n\n\n\nYou only need to install Quarto if you are running RStudio version 2022.07.1 or earlier. Follow the instructions for installing Quarto here.\nIf you cannot install Quarto on your computer (because it doesn’t work with your operating system, etc.), that is fine - you just might have some differences between what we do in class and what you see on your own computer.\n\n\n\n\nTask 3. Open RStudio\nWhen we say we’re “using R” in the class, what we’re really using is RStudio, which is a graphical user interface (GUI) for R (the language). Basically, we’re never going to open up “R”, but we’ll always open up “RStudio”.\nOpen RStudio on your computer.\n\n\nTask 4. Change your settings\n\n\n\n\n\n\nDo I really have to do all these things?\n\n\n\nThe short answer is: only if you want your life to be easier!\nIf you have used R/RStudio before and you feel comfortable about navigating things on your own, then I won’t stop you!\nIf you are new to using R, I would recommend you do follow all the steps in this task so that you can match up what is on your computer to what you’ll see on my computer when you’re in class.\nAt minimum, everyone needs to change their workspace save settings. These are listed below, but here is a recap:\n\n“Restore .Rdata into workspace at startup” is unchecked\n\n“Save workspace to .RData on exit” is on “Never”\n\n“Always save history (even when not saving .RData)” is unchecked\n\n\n\n\nYou can change some settings to make your life easier when working in RStudio. The following steps are all done in the same menu. Go to Tools &gt; Global Options.\nFirst, you can change your color scheme. You don’t have to stick with the boring RStudio color scheme! Go to Appearance and select the color scheme you want.\n\n\n\n\n\nThen, go to the General tab. Make sure that\n\n“Restore .Rdata into workspace at startup” is unchecked\n\n“Save workspace to .RData on exit” is on “Never”\n\n“Always save history (even when not saving .RData)” is unchecked\n\n\n\n\n\n\n\nSome of these may already be checked! If so, great! Double check everything though!\n\n\n\n\n\n\n\n\n\n\n\nThen, go to the Code tab. Under editing, make sure:\n\n“Insert spaces for Tab” is checked\n\n“Auto-detect code indentation” is checked\n\n“Insert matching parens/quotes” is checked\n\n“Use native pipe operator, |&gt;” is checked\n\n“Auto-indent code after paste” is checked\n\n“Vertically align arguments in auto-indent” is checked\n\n“Soft-wrap source files” is checked\n\n“Continue comment when inserting new line” is checked\n\n“Enable hyperlink highlighting in editor” is checked\n\n“Enable code snippets” is checked\n\n\n\n\n\n\nThen, go to Display (still under the Code tab). Make sure:\n\n“Highlight selected word” is checked\n\n“Show line numbers” is checked\n\n“Show margin” is checked\n\n“Blinking cursor” (if you want it) is checked\n\n“Enable preview of named and hexadecimal colors” is checked\n\n“Use rainbow parentheses” is checked\n\n\n\n\n\n\nThen, go to the R Markdown tab. Under basic, make sure the following is checked:\n\n“Soft-wrap R Markdown files” is checked\n\n“Show output preview in:” selection is “Viewer Pane”\n\n\n\n\n\n\nUnder visual (still under the R Markdown tab), make sure:\n\n“Use visual editor by default for new documents” is unchecked\n\n“Show document outline by default” is checked\n\n\n\n\n\n\n\nHit Apply to save all your changes. Do not forget to hit apply!!!\n\n\n\nTask 5. Test out installing a package\nPackages are the best part of using R. We’ll talk more about what packages are in workshop, but for now try installing a package. Go to your Console (the bottom left pane in the RStudio window), and type (or copy paste) install.packages(\"tidyverse\"). Hit Enter.\nYou should get a message that looks something like this:\n\n\n\n\n\n\n\n\n\n\n\nOperating system differences\n\n\n\nThe database that holds all these packages will automatically detect which version you need based on your operating system. Don’t worry if your output message doesn’t look exactly the same as the one here - just as long as you get something like “The downloaded binary packages are in…”, you’ve probably got the package installed.\n\n\n\n\nTask 6. Test out reading in a package\nNow you’ve installed a package, but you want to make sure you can actually run it. Again in the Console (the bottom left pane), type library(tidyverse) and hit Enter.\nYou should get a message that looks something like this:\n\n\n\n\n\n\n\nTask 7. Set up a folder on your computer for class materials\nUsing R/RStudio requires you to know how your computer is organized and where your files are. For now, we’ll want to set up a folder in your computer called ENVS-193DS (note no spaces in the folder name).\nAll operating systems are different, but make sure that your folder is not in the “iCloud” or “Google Drive” folders in your computer. Basically, you want to be sure that you can get from your “root” directory (i.e. your actual computer hard drive) to the folder you’re using.\nYou can check this using the file path, or the folders you would need to open to get to the folder called ENVS-193DS. One example for MacOS is below, where the file path is written out at the bottom of the pane:\n\n\n\n\n\n\n\nTask 8. Take a screenshot of your RStudio set up\nSo that the instructors can verify that you’ve gotten everything set up, take a screenshot of your RStudio window with the code for install.packages(\"tidyverse\") and library(tidyverse) in your Console and submit it to the portal on Canvas. Your screenshot should look something like this:\n\n\n\n\n\n\n\n\n\n\n\nDouble check your screenshot!\n\n\n\nMake sure that the messages in the orange box (above) are visible in your screenshot! Otherwise we will not be able to troubleshoot whatever issues you are having with installation (if you are actually having any)."
  },
  {
    "objectID": "assignments/homework-02.html",
    "href": "assignments/homework-02.html",
    "title": "Homework 2",
    "section": "",
    "text": "Due on Friday April 25 (Week 4) at 11:59 PM\nRead the instructions carefully and double check that you have everything on the checklist."
  },
  {
    "objectID": "assignments/homework-02.html#part-1.-tasks",
    "href": "assignments/homework-02.html#part-1.-tasks",
    "title": "Homework 2",
    "section": "Part 1. Tasks",
    "text": "Part 1. Tasks\nRemember that you are not expected to turn anything in for tasks, but you should complete all the material.\n\nTask 1. Set up your folders and Rproject.\n\na. Create a new folder for this homework assignment within your ENVS-193DS folder.\nWithin your ENVS-193DS folder, create a new folder for Homework 2. Name it whatever you want (a logical name could be homework-02).\n\n\nb. Download the files from Canvas\nDownload the homework files from Canvas into your homework folder. This includes:\n\nthe homework template\n\nsbpm.csv\n\n\n\nc. Create an Rproject for this homework assignment\nCreate an Rproj file within your homework-02 folder. If you need help with this, watch the “Creating an Rproject” video on Canvas.\n\n\nd. In the template, write code to load in the packages you need.\nYou will probably need to use the tidyverse, and potentially janitor.\n\n\ne. Read the Canvas data into R.\nStore this as an object called sbpm.\n\n\n\nTask 2. Read about the Environmental Protection Agency’s Outdoor Air Quality data.\n\na. Learn about PM 2.5\nRead the EPA’s description of particulate matter to understand the definition of PM 2.5.\n\n\nb. Read about the EPA’s data collection\nRead the EPA’s description of their Air Data to understand the source of the data you’ll be working with in Problem 2.\n\n\n\nTask 3. Enter your data for your personal data project.\n\na. Create a spreadsheet to enter your data.\nTwo good options include Google Sheets or Microsoft Excel. This will be the spreadsheet that you continually update with data for new observations, so store it in a logical place so that you can find it later.\n\n\nb. Create the columns of your spreadsheet.\nIf you have organized your data sheet in “long” format, in which each row is an observation, then your spreadsheet columns will be the same as your data sheet columns. If not, that’s ok; just make sure you’re entering your data in a way that makes sense based on how you collected it.\n\n\nc. Enter your data.\nDouble check your values!\n\n\nd. Save your spreadsheet as a .csv file in your homework-02 folder.\n\n\ne. Read your data into R.\nInclude the code to to this at the top of the template. You will want to do this the same way you read any data into R: by creating a new object (you could call this my_data) and using the left arrow operator to store and read in the data using read_csv().\n\n\nYou are now ready to start your homework!"
  },
  {
    "objectID": "assignments/homework-02.html#part-2.-problems",
    "href": "assignments/homework-02.html#part-2.-problems",
    "title": "Homework 2",
    "section": "Part 2. Problems",
    "text": "Part 2. Problems\n\nProblem 1. Burrowing owl abundance (12 points)\nManagers at Dangermond Reserve are interested in the return of burrowing owls to the reserve. You conduct weekly surveys for burrowing owls from October to February and collect the following data on the number of burrowing owls you see each week:\n\\[\n0, 2, 0, 3, 1, 4, 1, 2\n\\]\n\nWhat kind of data did you collect, and why? Explain in 1-2 sentences. (2 points)\n\nWhat is a better description of the variability in burrowing owl count, standard deviation or standard error? Explain why in 1 sentence. Calculate the metric of your choice, showing your work. Round your final answer to 1 decimal point, and show the correct units. (5 points)\n\nWhat is a better description of the uncertainty in burrowing owl count, standard deviation or standard error? Explain why in 1 sentence. Calculate the metric of your choice, showing your work. Round your final answer to 1 decimal point, and show the correct units. (5 points)\n\n\n\nProblem 2. Fire and particulate matter (96 points)\nIn 2017-2018, the Thomas Fire burned 281,893 acres in Santa Barbara County and Ventura County. At the time, it was the largest wildfire in California history. The fire started on December 4th and was fully contained on January 12, 2018. You’ll be working with EPA data on particulate matter during the fire.\nIn this problem, you will visualize the data two different ways. You will then answer the question: from the start of the Thomas Fire on December 4th until it was contained on January 12th, was there a difference in PM2.5 between Goleta and Santa Barbara?\n\nCreate a line graph with date on the x-axis and PM 2.5 on the y-axis. Color each line by the location of the sensor (hint: there should be 5 locations). Label the x-axis, y-axis, and legend colors. (18 points)\nCreate a new object called gol_sb to filter the sbpm data frame to only include observations from Goleta and Santa Barbara. Only show the code; do not display the data frame. (2 points)\nIn one sentence, write your hypotheses to answer the question: from the start of the fire until when it was contained, was there a difference in PM2.5 between Goleta and Santa Barbara? in biological terms (not statistical or mathematical terms). Make sure you have a null and alternative hypothesis. (2 points)\nUsing the gol_sb object, create a boxplot with jittered points, with location on the x-axis and PM 2.5 on the y-axis. Make sure the jittered points do not move along the y-axis. Label the x and y-axes. Additionally:\n\ncolor by site and change the colors from the default\n\nmake sure each site has a different shape\n\nuse a ggplot theme that is not the default\n\nmake sure the legend is not showing\n(26 points)\n\nUsing the gol_sb object, make a QQ plot. Make sure there are two panels for each location. You do not need to label the x and y-axes. (10 points)\nIn one sentence, describe whether the variable (PM 2.5) is normally distributed or not. Use visual components (e.g. shape, distribution) of the QQ plot you made to justify your characterization of the variable. (4 points)\nCheck your variances using var.test(). In one sentence, describe whether the groups have equal variances or not. (4 points)\nDo a t-test using t.test(). (4 points)\n\n\n\n\n\n\n\nt-test arguments\n\n\n\n\n\nDouble check your arguments to make sure you’re running the right test.\n\n\n\n\nIn one sentence each, describe:\n\nWhy a t-test would have been appropriate for testing your hypothesis in part a\n\nHow you evaluated normality and homogeneity of variance\n\nIf the variable was not normally distributed, how you justified using a t-test\n(6 points)\n\n\n\nDescribe the results in 1-2 full sentences in your own words. Make sure to include the:\n\nTest you ran\n\nNumber of observations for each location\nSignificance level\nDegrees of freedom\nTest statistic\np-value\n(20 points)\n\n\nRound any numbers with decimals to two decimal points.\n\n\n\n\n\n\nDo not simply list each component!\n\n\n\n\n\nYou will be graded on how you synthesize information. See lecture notes for an example of how to summarize the results of a statistical test in parentheses.\n\n\n\n\n\nProblem 3. Personal data (24 points)\nBy now, you have some observations on your data sheet for your personal data. Even though it’s early on in your data collection, it’s a good idea to practice good data management. For this problem, you’ll enter your data, read it into R, and create a visualization. If you get stuck at any step, you’ll know there’s something you need to fix.\n\nCreate a visualization with a categorical predictor variable on the x-axis and your response variable on the y-axis. Label the x- and y-axes. (8 points)\n\nCreate a visualization with a continuous predictor variable on the x-axis and your response variable on the y-axis. Label the x- and y-axes. (8 points)\n\nIn 2-5 sentences, describe what insights (if any) you can gain about your data from visualizations like these. Once you collect more data and update these figures, would these insights change? (4 points)\n\nIn 2-5 sentences, describe the process of getting your data from your spreadsheet into R. Did you encounter any challenges? If so, why do you think those challenges arose, and how did you fix them? If not, why do you think your system for collecting your data worked? (4 points)\n\n\n\n\n\n\n\nChanging your data collection scheme\n\n\n\n\n\nIf you found that entering your data from your spreadsheet and getting it into the right format to be used in R was challenging, that’s ok! This happens a lot with data collection. Feel free to change your data sheet so that you’re collecting data in a way that makes your life easier as you’re reading your data into R and using it.\n\n\n\n\n\nProblem 4. Statistical critique (24 points)\nCheck the Google sheet and choose a paper to use for your critique based on An’s/Thuy-Tien’s/Grace’s recommendations. Answer the following questions about the paper in 1-2 sentences each:\n\nWhy were you interested in this paper? (4 points)\n\nWhat questions/hypotheses are the authors addressing? (4 points)\n\nWhich statistical test (from Homework 1) is included in this paper? What is the response variable? What is the predictor variable? (4 points)\n\nHow does this test address the main question(s) presented by the authors? For example, how would the authors interpret a “significant” result? (4 points)\n\nFind the figure(s) and/or table(s) in the paper that are associated with the statistical tests from question (c). If there are multiple figures and tables relating to the statistical test, find the best one that demonstrates the relationship betwee the predictor and the response. Take a screenshot, and insert it into your document. 4 points\n\n\n\n\n\n\n\nMake sure your screenshot is visible in your final PDF!\n\n\n\n\n\nIf your screenshot for part e is not visible, you will not receive points for part f.\n\n\n\n\nIf you have a figure: describe the x- and y-axes, and what the figure is supposed to show (i.e. what is the main message of the figure)? If you have a table, what are the rows and columns, and what is in each cell of the table? (4 points)"
  },
  {
    "objectID": "assignments/homework-02.html#double-check-your-assignment",
    "href": "assignments/homework-02.html#double-check-your-assignment",
    "title": "Homework 2",
    "section": "Double check your assignment!",
    "text": "Double check your assignment!\nYour assignment should:\n\ninclude your name, the title, and the date (3 points)\n\ninclude all code with annotations (5 points)\n\nbe organized and readable (5 points)\n\nbe uploaded to Canvas as a single PDF (2 points)\n\nYour responses should include:\n\nwork and written responses for Problem 1\n\nwritten responses, annotated code, and figure outputs for Problem 2\n\nannotated code, figure output, and written responses for Problem 3\n\nwritten responses and screenshot for Problem 4\n\nLastly, check out the rubric on Canvas to see the point breakdown in more detail.\n171 points total"
  },
  {
    "objectID": "assignments/homework-02.html#general-formatting-points",
    "href": "assignments/homework-02.html#general-formatting-points",
    "title": "Homework 2",
    "section": "General formatting points",
    "text": "General formatting points\nYou will only receive full points for annotations if you have:\n\ncomments on each line of visualization code and/or ggplot geom/theme call (not needed for each argument, though good to have)\n\ncomments for each argument of a test call (e.g. var.test(), t.test())\n\nYou will only receive full points for readability if:\n\nall messages/warnings are hidden\n\nall code is contained in code chunks (double check line breaks in comments once you render your document)\n\nall text is where it’s supposed to be (headers and main text show up correctly)"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Order By\n       Default\n         \n          Due date - Oldest\n        \n         \n          Due date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDue date\n\n\n\n\n\n\nGetting set up\n\n\nApr 2, 2025\n\n\n\n\nReflection 1\n\n\nApr 6, 2025\n\n\n\n\nHomework 1\n\n\nApr 16, 2025\n\n\n\n\nHomework 2\n\n\nApr 25, 2025\n\n\n\n\nOPTIONAL practice problem - Do a Wilcoxon signed rank test by hand\n\n\nApr 30, 2025\n\n\n\n\nMidterm\n\n\nMay 7, 2025\n\n\n\n\nReflection 2\n\n\nMay 14, 2025\n\n\n\n\nOPTIONAL practice problem - everything is a linear model\n\n\nMay 19, 2025\n\n\n\n\nHomework 3\n\n\nMay 28, 2025\n\n\n\n\nChoose your own assignment - Advanced data visualization\n\n\nJun 4, 2025\n\n\n\n\nChoose your own assignment - Quarto website\n\n\nJun 4, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workshop/workshop-06_2025.html",
    "href": "workshop/workshop-06_2025.html",
    "title": "Coding workshop: Week 6",
    "section": "",
    "text": "Workshop dates: May 8 (Thursday), May 9 (Friday)"
  },
  {
    "objectID": "workshop/workshop-06_2025.html#note",
    "href": "workshop/workshop-06_2025.html#note",
    "title": "Coding workshop: Week 6",
    "section": "Note",
    "text": "Note\nThere is no formal instruction this week. Instead, make sure you have set up your computer to use Git and GitHub.\nWe will not be stopping for installation issues next week (Week 7)."
  },
  {
    "objectID": "workshop/workshop-06_2025.html#opportunities-to-get-help",
    "href": "workshop/workshop-06_2025.html#opportunities-to-get-help",
    "title": "Coding workshop: Week 6",
    "section": "Opportunities to get help",
    "text": "Opportunities to get help\nIn addition to drop-in hours, this week’s workshop periods are for you to get help with installation and verify that you’ve set everything up correctly.\nCome to workshop to get help from An/Grace/Thuy-Tien."
  },
  {
    "objectID": "workshop/workshop-06_2025.html#steps",
    "href": "workshop/workshop-06_2025.html#steps",
    "title": "Coding workshop: Week 6",
    "section": "Steps",
    "text": "Steps\n\nPart 1: prechecks\nFollow all steps here.\n\n\nPart 2: personal access token\nFollow all steps here."
  },
  {
    "objectID": "workshop/workshop-02_2025.html",
    "href": "workshop/workshop-02_2025.html",
    "title": "Coding workshop: Week 2",
    "section": "",
    "text": "Workshop dates: April 10 (Thursday), April 11 (Friday)"
  },
  {
    "objectID": "workshop/workshop-02_2025.html#summary",
    "href": "workshop/workshop-02_2025.html#summary",
    "title": "Coding workshop: Week 2",
    "section": "1. Summary",
    "text": "1. Summary\n\nPackages\n\ntidyverse\n\njanitor\n\n\n\nOperations\n\nread in data using read_csv()\n\nchain functions together using |&gt;\n\nclean column names using clean_names()\n\ncreate new columns using mutate()\n\nselect columns using select()\n\nmake data frame longer using pivot_longer()\n\ngroup data using group_by()\n\nsummarize data using summarize()\n\ncalculate standard deviation using sd()\n\ncalculate t-values using qt()\n\nexpand data frames using deframe()\n\nvisualize data using ggplot()\n\ncreate histograms using geom_histogram()\n\nvisualize means and raw data using geom_point()\n\nvisualize standard deviation, standard error, and confidence intervals using geom_errorbar() and geom_pointrange()\n\nvisualize trends through time using geom_point() and geom_line()\n\n\n\nData source\nThis week, we’ll work with data on seafood production types (aquaculture or capture). This workshop’s data comes from Tidy Tuesday 2021-10-12, which was from OurWorldinData.org."
  },
  {
    "objectID": "workshop/workshop-02_2025.html#code",
    "href": "workshop/workshop-02_2025.html#code",
    "title": "Coding workshop: Week 2",
    "section": "2. Code",
    "text": "2. Code\n\n1. Set up\nThis section of code includes reading in the packages you’ll need: tidyverse and janitor.\nYou’ll also read in the data using read_csv() and store the data in an object called production.\n\n# load in packages\nlibrary(tidyverse)\nlibrary(janitor)\n\n\n# read in data\nproduction &lt;- read_csv(\"captured_vs_farmed.csv\")\n\n\n\n\n\n\n\nNote\n\n\n\nRemember to look at the data before working with it! You can use View(production) in the console, or click on the production object in the Environment tab in the top right.\n\n\nBefore you start: think about what the differences might be between aquaculture and capture production in the context of fisheries. Which production type do you think would produce more seafood?\ninsert your best guess here\n\n\n2. Cleaning up\nThe data comes in what’s called “wide format”, meaning that each row represents multiple observations. For example, the first row contains the production from Afghanistan (country code AFG) in 1969 for aquaculture and capture production.\nWe want to convert the data into “long format” so that it’s easier to work with. A dataset is in long format if each row represents an observation.\nIn this chunk of code, we’ll:\n\nclean the column names using clean_names()\n\nfilter to only include the “entity” we want using filter()\n\nselect the columns of interest using select()\n\nmake the data frame longer using pivot_longer()\n\nmanipulate the type column to change the long names (e.g. aquaculture_production_metric_tons) to short names (e.g. aquaculture) using mutate() and case_when()\n\nuse mutate() to create a new column called metric_tons_mil\n\n\nproduction_clean &lt;- production |&gt; # use the production data frame\n  clean_names() |&gt; # clean up column names\n  filter(entity == \"United States\") |&gt; # filter to only include observations from the US\n  select(year, aquaculture_production_metric_tons, capture_fisheries_production_metric_tons) |&gt; # select columns of interest \n  pivot_longer(cols = aquaculture_production_metric_tons:capture_fisheries_production_metric_tons, # choose columns to pivot\n               names_to = \"type\", # name the column name with fishery type \"type\"\n               values_to = \"catch_metric_tons\") |&gt; # name the column name with the catch amount \"catch_metric_tons\"\n  mutate(type = case_when( # mutate the existing type column\n    type == \"aquaculture_production_metric_tons\" ~ \"aquaculture\", # when \"aquaculture_production_metric_tons\" appears in the \"type\" column, fill in \"aquaculture\"\n    type == \"capture_fisheries_production_metric_tons\" ~ \"capture\" # when \"capture_fisheries_production_metric_tons\" appears in the \"type\" column, fill in \"capture\"\n  )) |&gt; \n  mutate(metric_tons_mil = catch_metric_tons/1000000) # convert catch in metric tons to millions\n\n\n\n3. Making a boxplot/jitter plot\nLast week in workshop, we made a boxplot. The boxplot shows useful summary statistics (displays the central tendency and spread), while the jitter plot shows the actual observations (in this case, each point is the catch for a fishery in a given year). One way to display the underlying data is to combine a boxplot with a jitter plot.\n\nggplot(data = production_clean, # start with the production_clean data frame\n       aes(x = type, # x-axis should be type of production\n           y = metric_tons_mil, # y-axis should be metric tons of production (in millions)\n           color = type)) + # coloring by production type\n  geom_boxplot() + # first layer should be a boxplot\n  geom_jitter(width = 0.2, # making the points jitter horizontally\n              height = 0) + # making sure points don't jitter vertically\n  labs(x = \"Type\", # labelling the x-axis\n       y = \"Metric tons of production (in millions)\") # labelling the y-axis\n\n\n\n\n\n\n\n\nOn average, a) which type of production produces more fish, and b) what components of the plot are you using to come up with your answer?\na) Capture production, because b) the median of the boxplot is way higher than the median for aquaculture\n\n\n4. Making a histogram\nThis chunk of code creates a histogram. Note that for a histogram, you only need to fill in the aes() argument for the x-axis (x), not the y-axis. This is because ggplot() counts the number of observations in each bin for you.\nWithin the geom_histogram() call, you’ll need to tell R what number of bins you want using the bins argument. In this case (using the Rice Rule to determine the appropriate number of bins), we’ll use 10 bins.\n\nggplot(data = production_clean,\n       aes(x = metric_tons_mil,\n           fill = type)) + # fill the histogram based on the fishery type\n  geom_histogram(bins = 10, # set the number of bins\n                 color = \"black\") # make the border of the columns black\n\n\n\n\n\n\n\n\nCan you tell from looking at the histogram which production type tends to produce more fish? Why or why not?\nYes. There are no observations for aquaculture at high catch (in millions); most of the observations for aquaculture are lower than 1 million tons, while capture production ranges up to 6 million tons.\n\n\n5. Visualizing spread, variance, and confidence\n\na. Calculations\n\n# calculate the confidence interval \"by hand\"\nproduction_summary &lt;- production_clean |&gt; # start with the production_clean data frame\n  group_by(type) |&gt; # group by production type\n  summarize(mean = mean(metric_tons_mil), # calculate the mean\n            n = length(metric_tons_mil), # count the number of observations\n            df = n - 1, # calculate the degrees of freedom\n            sd = sd(metric_tons_mil), # calculate the standard deviation\n            se = sd/sqrt(n), # calculate the standard error\n            tval = qt(p = 0.05/2, df = df, lower.tail = FALSE), # find the t value\n            margin = tval*se, # calculate the margin of error\n            ci_lower = mean - tval*se, # calculate the lower bound of the confidence interval\n            ci_higher = mean + tval*se # calculate the upper bound of the confidence interval\n          ) \n\nproduction_summary\n\n# A tibble: 2 × 10\n  type         mean     n    df    sd     se  tval margin ci_lower ci_higher\n  &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 aquaculture 0.324    59    58 0.149 0.0194  2.00 0.0389    0.285     0.363\n2 capture     4.38     59    58 1.20  0.156   2.00 0.313     4.07      4.69 \n\n# use a function to calculate the confidence interval\nproduction_ci &lt;- production_clean |&gt;  \n  group_by(type) |&gt;  \n  summarize(ci = mean_cl_normal(metric_tons_mil)) |&gt;  # calculate the CI using a function\n  deframe() # expand the data frame\n\nproduction_ci\n\n                   y     ymin     ymax\naquaculture 0.323932 0.285032 0.362832\ncapture     4.381083 4.068038 4.694128\n\n\nWhen you compare the 95% CI from production_summary and production_ci, they should be about the same.\n\n\nb. Visualizations\nWhen visualizing the central tendency (in this case, mean) and spread (standard deviation) or variance (standard error) or confidence (confidence intervals), you can stack geoms on top of each other.\nTo visualize the mean, we’ll use geom_point(). Remember that geom_point() can be used for any plot you want to make that involves a point.\nTo visualize the spread/variance/confidence, we’ll use geom_errorbar(). This is the geom that creates two lines that can extend away from a point.\n\nStandard deviation\nFirst, we’ll visualize standard deviation.\n\nggplot(data = production_summary, # use the summary data frame\n       aes(x = type, # x-axis should be production type\n           y = mean, # y-axis should show the mean production\n           color = type)) + # color the points by fishery type\n  geom_point(size = 2) + # plot the mean\n  geom_errorbar(aes(ymin = mean - sd, # plot the standard deviation\n                    ymax = mean + sd),\n                width = 0.1) + # make the bars narrower\n  labs(title = \"Standard deviation\",\n       x = \"Type\",\n       y = \"Mean and SD million metric tons production\")\n\n\n\n\n\n\n\n\n\n\nStandard error\nThen, we want to visualize standard error.\n\nggplot(data = production_summary, # use the summary data frame\n       aes(x = type, \n           y = mean, \n           color = type)) + # color the points by fishery type\n  geom_point(size = 2) + # plot the mean\n  geom_errorbar(aes(ymin = mean - se, # plot the standard error\n                    ymax = mean + se),\n                width = 0.1) +\n  labs(title = \"Standard error\",\n       x = \"Type\",\n       y = \"Mean and SE million metric tons production\")\n\n\n\n\n\n\n\n\n\n\n95% confidence interval\nThen, we want to visualize the 95% confidence interval.\n\nggplot(data = production_summary, # use the summary data frame\n       aes(x = type, \n           y = mean, \n           color = type)) + # color the points by fishery type\n  geom_point(size = 2) + # plot the mean\n  geom_errorbar(aes(ymin = mean - margin, # plot the margin of error\n                    ymax = mean + margin),\n                width = 0.1) +\n  labs(title = \"Confidence interval\",\n       x = \"Type\",\n       y = \"Mean and 95% CI million metric tons production\")\n\n\n\n\n\n\n\n\n\n\n\nc. geom_pointrange()\nWe can also visualize means and spread/variance/confidence intervals using the geom_pointrange() function.\n\nggplot(data = production_summary, # use the summary data frame\n       aes(x = type, \n           y = mean, \n           color = type)) + # color the points by fishery type\n  geom_pointrange(aes(ymin = mean - margin, \n                      ymax = mean + margin)) +\n  labs(title = \"Confidence interval (using geom_pointrange)\",\n       x = \"Type\",\n       y = \"Mean and 95% CI million metric tons production\")\n\n\n\n\n\n\n\n\n\n\nd. Visualizing with the underlying data\nLastly, we want to visualize the 95% confidence interval with the underlying data.\n\n# base layer: ggplot\nggplot(data = production_clean,\n       aes(x = type, \n           y = metric_tons_mil, \n           color = type)) +\n  # first layer: adding data (each point shows an observation)\n  geom_jitter(width = 0.1,\n              height = 0,\n              alpha = 0.4,\n              shape = 21) +\n  # second layer: means and 95% CI\n  geom_pointrange(data = production_summary,\n                  aes(x = type, \n                      y = mean, \n                      ymin = mean - margin, \n                      ymax = mean + margin)) +\n  # changing appearance: colors, labels, and theme\n  scale_color_manual(values = c(\"aquaculture\" = \"deeppink3\",\n                                \"capture\" = \"slateblue4\")) +\n  labs(x = \"Production type\",\n       y = \"Million metric tons of production\",\n       color = \"Production type\",\n       title = \"Capture produces more than aquaculture\") +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot themes\n\n\n\n\n\nThere are lots of themes in ggplot to play around with. These are nice to use to get rid of the grey background that is the default, and generally make your plot look cleaner.\nA list of built-in themes and their theme_() function calls is here.\n\n\n\n\n\ne. Visualizing through time\nThen, if we want to visualize production through time:\n\nggplot(data = production_clean,\n       aes(x = year,\n           y = metric_tons_mil,\n           color = type,\n           shape = type)) +\n  geom_point() +\n  geom_line() +\n  scale_color_manual(values = c(\"aquaculture\" = \"deeppink3\",\n                                \"capture\" = \"slateblue4\")) +\n  labs(x = \"Year\",\n       y = \"Million metric tons of production\",\n       color = \"Production type\",\n       shape = \"Production type\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nEND OF WORKSHOP 2"
  },
  {
    "objectID": "workshop/workshop-08_2025.html",
    "href": "workshop/workshop-08_2025.html",
    "title": "Coding workshop: Week 8",
    "section": "",
    "text": "tidyverse\n\nreadxl\n\nhere\n\njanitor\n\nMuMIn\n\nggeffects\n\nscales\n\n\n\n\n\n\n\nusing scale_x_discrete() with label_wrap() to wrap axis label text\n\nusing AICc() for model selection\n\n\n\n\n\nread in data using read_csv()\n\nchain functions together using |&gt;\n\nmodify columns using mutate()\n\nselect columns using select()\n\nset factors using as_factor()\n\nreorder levels in factors using fct_relevel()\n\nrecoding variables using case_match() within mutate()\n\nlooking at data structure using str()\n\ndisplaying data using slice_sample()\n\nusing expression() to make complex plot labels\n\nusing ggpredict() to get model predictions\n\nfitting linear models using lm()\n\nlooking at model summaries using summary()\n\nusing facet_wrap() to create panels based on a categorical variable\n\nusing scale_color_manual() to manually assign colors\n\nusing geom_jitter() and geom_pointrange() to represent data and model predictions\n\n\n\n\n\nThe dataset is from Valliere, Justin; Zhang, Jacqueline; Sharifi, M.; Rundel, Philip (2019). Data from: Can we condition native plants to increase drought tolerance and improve restoration success? [Dataset]. Dryad. https://doi.org/10.5061/dryad.v0861f7.\nThe associated paper is Valliere J. M., J. Zhang, M. R. Sharifi, and P. W. Rundel. 2019. Can we condition native plants to increase drought tolerance and improve restoration success? Ecological Applications 29(3):e01863. 10.1002/eap.1863."
  },
  {
    "objectID": "workshop/workshop-08_2025.html#summary",
    "href": "workshop/workshop-08_2025.html#summary",
    "title": "Coding workshop: Week 8",
    "section": "",
    "text": "tidyverse\n\nreadxl\n\nhere\n\njanitor\n\nMuMIn\n\nggeffects\n\nscales\n\n\n\n\n\n\n\nusing scale_x_discrete() with label_wrap() to wrap axis label text\n\nusing AICc() for model selection\n\n\n\n\n\nread in data using read_csv()\n\nchain functions together using |&gt;\n\nmodify columns using mutate()\n\nselect columns using select()\n\nset factors using as_factor()\n\nreorder levels in factors using fct_relevel()\n\nrecoding variables using case_match() within mutate()\n\nlooking at data structure using str()\n\ndisplaying data using slice_sample()\n\nusing expression() to make complex plot labels\n\nusing ggpredict() to get model predictions\n\nfitting linear models using lm()\n\nlooking at model summaries using summary()\n\nusing facet_wrap() to create panels based on a categorical variable\n\nusing scale_color_manual() to manually assign colors\n\nusing geom_jitter() and geom_pointrange() to represent data and model predictions\n\n\n\n\n\nThe dataset is from Valliere, Justin; Zhang, Jacqueline; Sharifi, M.; Rundel, Philip (2019). Data from: Can we condition native plants to increase drought tolerance and improve restoration success? [Dataset]. Dryad. https://doi.org/10.5061/dryad.v0861f7.\nThe associated paper is Valliere J. M., J. Zhang, M. R. Sharifi, and P. W. Rundel. 2019. Can we condition native plants to increase drought tolerance and improve restoration success? Ecological Applications 29(3):e01863. 10.1002/eap.1863."
  },
  {
    "objectID": "workshop/workshop-08_2025.html#code",
    "href": "workshop/workshop-08_2025.html#code",
    "title": "Coding workshop: Week 8",
    "section": "2. Code",
    "text": "2. Code\nAll code is in the rendered .html file in this repository."
  },
  {
    "objectID": "workshop/workshop-04_2025.html",
    "href": "workshop/workshop-04_2025.html",
    "title": "Coding workshop: Week 4",
    "section": "",
    "text": "Workshop dates: April 24 (Thursday), April 25 (Friday)"
  },
  {
    "objectID": "workshop/workshop-04_2025.html#summary",
    "href": "workshop/workshop-04_2025.html#summary",
    "title": "Coding workshop: Week 4",
    "section": "1. Summary",
    "text": "1. Summary\n\nPackages\n\ntidyverse\n\n\n\nOperations\n\nReview\n\nread in data using read_csv()\n\nvisualize data using ggplot()\n\nmodify theme elements using theme()\n\nuse built-in themes using theme_()\n\nmodify colors using scale_color_() and scale_fill_() functions\n\ncreate multi-panel plots using facet_wrap()\n\nmake line plots using geom_point() and geom_line()\n\ngroup data using group_by()\n\nsummarize data using summarize()\n\nchain functions together using |&gt;\n\nfiltering observations using filter()\n\nmanipulate columns using mutate() and case_when()\n\n\n\n\nData sources\nThe fish migration data is from the Columbia River DART (Data Access in Real Time) on fish migration through the Columbia River Basin in 2023.\nThe shark incident data is from Riley et al.\nThe tornado data is from the NOAA National Weather Service Storm Prediction Center."
  },
  {
    "objectID": "workshop/workshop-04_2025.html#code",
    "href": "workshop/workshop-04_2025.html#code",
    "title": "Coding workshop: Week 4",
    "section": "2. Code",
    "text": "2. Code\n\nToday’s topic\nWe’re going to be exploring different ways to customize plots in ggplot2 (remember that ggplot2 is a package within the tidyverse, which you already have installed).\nEach group will be responsible for creating a figure manipulating your assigned plot component. You will spend some time exploring each part and creating a figure together. After you are done, you’ll compile slides to teach the class\na) what your assigned plot component is (what it does) and\nb) how to manipulate it (in code).\nYour challenge is to make the ugliest plot you can! Change the colors, line types, line widths, etc. - whatever your heart desires to make a fundamentally ugly plot.\n\n\nResources\nFirst, look up the function. In the Console, type a question mark, then your function name. For example:\n\n# copy paste this into the console\n?theme\n\nYou can do this with any function - whenever you want to know what it does, just look it up in the Console by hitting ? then the function name.\nRead about your function. Make sure you understand the arguments, and decide which ones are relevant to you.\nSecond, see these resources for some explanation of themes and customization:\n- ggplot2tor\n- Jumping Rivers\n- theme elements from ggplot2 handbook\n- built in themes from ggplot2 handbook\n\n\nCode\n\n1. Set up\n\nPackages and data\n\n# packages\nlibrary(tidyverse)\n\n# data\n# salmon data\nsalmon &lt;- read_csv(\"adultdaily_1745380588_196.csv\")\n\n# tornado data\ntornados &lt;- read_csv(\"tornados.csv\")\n\n# shark data\nsharks &lt;- read_csv(\"sharks.csv\")\n\n\n\nCleaning\n\nSalmon\n\n# create new clean object from salmon\nsalmon_clean &lt;- salmon |&gt; \n  # making sure the date is read as a date\n  mutate(Date = mdy(Date)) |&gt; \n  # selecting date and 3 salmonid species\n  select(Date, Chin, Stlhd, Coho) |&gt; \n  # making the data frame longer\n  pivot_longer(cols = Chin:Coho,\n               names_to = \"species\",\n               values_to = \"daily_count\") |&gt; \n  # mutating species column to display species names in full\n  mutate(species = case_when(\n    species == \"Chin\" ~ \"Chinook\",\n    species == \"Stlhd\" ~ \"Steelhead\",\n    TRUE ~ species\n  )) |&gt; \n  # filter to only include dates after December 31st 2023\n  filter(Date &gt; as_date(\"2023-12-31\")) |&gt; \n  # take out any missing values\n  drop_na(daily_count)\n\n\n\nTornados\n\n# create new clean object from tornados\ntornados_clean &lt;- tornados |&gt; \n  # group by year\n  group_by(yr) |&gt;\n  # calculate total property loss in dollars, sum number of tornados, calculate total property loss in billions of dollars\n  summarize(total_property_loss = sum(loss, na.rm = TRUE),\n            number_tornados = length(yr),\n            total_property_loss_bil = total_property_loss/1000000000) |&gt; \n  # ungroup the data frame (useful if you're going to do any further summarizing steps)\n  ungroup() \n\n\n\nSharks\n\n# create new clean object from sharks\nsharks_clean &lt;- sharks |&gt; \n  # drop any observations where shark common name is missing\n  drop_na(shark_common_name) |&gt; \n  # group by shark species and state\n  group_by(shark_common_name, state) |&gt; \n  # count observations (easy way to get total number of observations from groups)\n  count() |&gt; \n  # ungroup the data frame (good to do if you're doing any cleaning steps after this)\n  ungroup() |&gt; \n  # filter to only include New South Wales, Queensland, and Western Australia\n  filter(state %in% c(\"NSW\", \"QLD\", \"WA\")) |&gt; \n  # mutate state column to show full names for each state\n  mutate(state = case_when(\n    state == \"NSW\" ~ \"New South Wales\",\n    state == \"QLD\" ~ \"Queensland\",\n    state == \"WA\" ~ \"Western Australia\"\n  ))\n\n\n\n\n\n2. Basic visualization\n\na. Daily counts of salmon through Bonneville Dam in Columbia River Basin, Oregon in 2024\n\n               # base layer: ggplot\nsalmon_plot &lt;- ggplot(data = salmon_clean,\n                      # aesthetics: x-axis, y-axis, and color\n                      aes(x = Date,\n                          y = daily_count,\n                          color = species)) +\n  # first layer: points\n  geom_point() +\n  # second layer: line\n  geom_line() +\n  # labels\n  labs(x = \"Date\",\n       y = \"Daily fish count\")\n\n# display the plot\nsalmon_plot\n\n\n\n\n\n\n\n\n\n\nb. Total property loss (in dollars) due to tornados in US from 1950-2022\n\n                              # base layer: ggplot\ntornado_property_loss_plot &lt;- ggplot(data = tornados_clean,\n                                     # aesthetics: x-axis, y-axis\n                                     aes(x = yr,\n                                         y = total_property_loss_bil)) +\n  # first layer: points\n  geom_point() +\n  # second layer: line\n  geom_line() +\n  # labels\n  labs(x = \"Year\",\n       y = \"Total property loss (billions of dollars)\")\n\n# display the plot\ntornado_property_loss_plot\n\n\n\n\n\n\n\n\n\n\nc. Total annual tornados in US from 1950-2022\n\n                      # base layer: ggplot\ntornado_count_plot &lt;- ggplot(data = tornados_clean,\n                             # aesthetics: x-axis, y-axis\n                             aes(x = yr,\n                                 y = number_tornados)) +\n  # first layer: points\n  geom_point() +\n  # second layer: line\n  geom_line() +\n  # labels\n  labs(x = \"Year\",\n       y = \"Total annual tornados\")\n\n# display the plot\ntornado_count_plot\n\n\n\n\n\n\n\n\n\n\nd. Total number of shark incidents in New South Wales and Queensland from 1791-2022\n\n              # base layer: ggplot\nshark_plot &lt;- ggplot(data = sharks_clean,\n                     # aesthetics: x-axis, y-axis\n                     aes(x = n,\n                         y = shark_common_name)) +\n  # first layer: columns to represent counts\n  geom_col() +\n  # faceting by state\n  facet_wrap(~ state) +\n  # labels\n  labs(x = \"Year\",\n       y = \"Total number of shark incidents\")\n\n# display the plot\nshark_plot\n\n\n\n\n\n\n\n\n\n\n\n3. Plot components\nAs everyone is going through their plot components, take notes in each section.\n\na. strip in theme()\nDemonstrate how to:\n- change the background\n- change the placement\n- change the text size and font\nNote: you may want to use the shark_plot for this theme element.\n\n# insert code here for your individual plot\n\nCode for the plot your group made:\n\n# insert code here for your group plot\n\n\n\nb. plot in theme()\nDemonstrate how to:\n- change the plot margin\n- change the plot background\n- change the plot title, subtitle, and caption text position and color\nNote: you will have to add a title, subtitle, and caption to the plot you choose to manipulate.\nCode for your own independent exploration:\n\n# insert code here for your individual plot\n\nCode for the plot your group made:\n\n# insert code here for your group plot\n\n\n\nc. panel in theme()\nDemonstrate how to:\n- change the panel border\n- change the panel major grid lines (vertically and horizontally, in separate arguments)\n- change the panel minor grid lines (vertically and horizontally, in separate arguments)\n- change the panel background\nCode for your own independent exploration:\n\n# insert code here for your individual plot\n\nCode for the plot your group made:\n\n# insert code here for your group plot\n\n\n\nd. legend in theme()\nDemonstrate how to:\n- change the legend frame\n- change the legend key size\n- change the legend text size\n- change the legend position\n- change the legend row numbers\nNote: you may want to use the salmon_plot for this theme element.\nCode for your own independent exploration:\n\n# insert code here for your individual plot\n\nCode for the plot your group made:\n\n# insert code here for your group plot\n\n\n\ne. axis in theme()\nDemonstrate how to:\n- change the axis text color and font - change the axis tick length (major and minor ticks)\n- change the axis line colors and line types\nCode for your own independent exploration:\n\n# insert code here for your individual plot\n\nCode for the plot your group made:\n\n# insert code here for your group plot\n\n\n\nf. scale_color or scale_fill functions\nNote: use the shark plot for scale_fill and any other plot for scale_color\nDemonstrate how to:\n- use a color palette package\n- apply it to a color scale\nCode for your own independent exploration:\n\n# insert code here for your individual plot\n\nCode for the plot your group made:\n\n# insert code here for your group plot\n\n\n\ng. built in themes (theme_) with your own customization using theme()\nDemonstrate how to:\n\nuse a built in theme and\n\nchange additional components using the theme() elements of your choice\n\nCode for your own independent exploration:\n\n# insert code here for your individual plot\n\nCode for the plot your group made:\n\n# insert code here for your group plot"
  },
  {
    "objectID": "workshop/workshop-04_2025.html#extra-stuff",
    "href": "workshop/workshop-04_2025.html#extra-stuff",
    "title": "Coding workshop: Week 4",
    "section": "3. Extra stuff",
    "text": "3. Extra stuff\n\nThursday 4 PM plot\n\n\nCode\nggplot(data = sharks_clean,\n                     # aesthetics: x-axis, y-axis\n                     aes(x = n,\n                         y = shark_common_name,\n                         # fill columns by shark common name\n                         fill = shark_common_name)) +\n  # first layer: columns to represent counts\n  geom_col() +\n  # faceting by state, putting the strip on the bottom of the plot\n  facet_wrap(~ state,\n             strip.position = \"bottom\") +\n  # labels\n  labs(x = \"Total number of shark incidents\",\n       y = \"Species\") +\n  # manually manipulate fill colors\n  scale_fill_manual(values = c(\"bull shark\" = \"pink\",\n                               \"whaler shark\" = \"chartreuse\")) +\n  # built in theme\n  theme_dark() +\n  # theme elements\n  theme(\n    # strip elements\n    strip.placement = \"outside\",\n    strip.background = element_rect(color = \"red\", linetype = 4, linewidth = 7),\n    strip.text = element_text(color = \"hotpink\"),\n    strip.text.x.top = element_text(size = 20, face = \"italic\"),\n    # plot elements\n    plot.background = element_rect(fill = \"turquoise\", color = \"#EC4899\", linewidth = 4, linetype = \"dashed\"),\n    # panel elements\n    panel.grid.major.x = element_line(color = \"hotpink\", linewidth = 3),\n    panel.grid.major.y = element_line(color = \"dodgerblue\", linewidth = 1),\n    panel.background = element_rect(fill = \"lavender\"),\n    # legend elements\n    legend.background = element_rect(fill = \"chartreuse\"),\n    legend.key = element_rect(color = \"orange\"),\n    legend.text = element_text(size = 30),\n    # axis elements\n    axis.line.x = element_line(color = \"yellowgreen\", linewidth = 4),\n    axis.line.y = element_line(color = \"deeppink1\"),\n    axis.text.x.bottom = element_text(color = \"skyblue\"),\n    axis.text.y.left = element_text(color = \"chocolate\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nThursday 5 PM plot\n\n\nCode\nggplot(data = salmon_clean,\n                      # aesthetics: x-axis, y-axis, and color\n                      aes(x = Date,\n                          y = daily_count,\n                          color = species)) +\n  # first layer: points\n  geom_point() +\n  # second layer: line\n  geom_line(size = 2, \n            linetype = \"dashed\") +\n  # labels\n  labs(x = \"Date\",\n       y = \"Daily fish count\",\n       title = \"Daily fish count per day\",\n       subtitle = \"group 2\",\n       caption = \"thursday 5 pm\") +\n  # custom color scale\n  scale_color_manual(values = c(\"Chinook\" = \"hotpink\",\n                                \"Coho\" = \"chartreuse\",\n                                \"Sockeye\" = \"pink\")) +\n  # adding this facet \n  facet_wrap(~species) +\n  # built in theme\n  theme_dark() +\n  theme(\n    # strip elements\n    strip.text = element_text(family = \"Times New Roman\"),\n    strip.background = element_rect(fill = \"red\"),\n    # plot elements\n    plot.title = element_text(size = 30, face = \"bold\", color = \"orange\"),\n    plot.subtitle = element_text(color = \"yellow\"),\n    plot.margin = margin(t = 100, r = 0.6, b = 20, l = 0.9),\n    plot.background = element_rect(fill = \"lightgreen\"),\n    # panel elements\n    panel.grid.minor.x = element_line(color = \"orange\", linewidth = 1),\n    panel.grid.major.y = element_line(color = \"darkgreen\", linewidth = 5),\n    panel.background = element_rect(fill = \"black\", color = NA),\n    # legend elements\n    legend.direction = \"horizontal\",\n    legend.key.size = unit(3, \"line\"),\n    legend.background = element_rect(fill = \"lemonchiffon\", color = \"grey50\", linewidth = 1),\n    # axis elements\n    axis.text.y.left = element_text(size = 15, color = \"deeppink\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nFriday 9 AM plot\n\n\nCode\nggplot(data = sharks_clean,\n                     # aesthetics: x-axis, y-axis\n                     aes(x = n,\n                         y = shark_common_name)) +\n  # first layer: columns to represent counts\n  geom_col() +\n  # faceting by state\n  facet_wrap(~ state,\n             strip.position = \"bottom\") +\n  # labels\n  labs(x = \"Total number of shark incidents\",\n       y = \"Shark species\",\n       title = \"Fishy Salmon Run\",\n       subtitle = \"fishfishyfishyfishyfishy\") +\n  # built in theme\n  theme_dark() +\n  theme(\n    # strip elements\n    strip.text = element_text(color = \"brown\",\n                              family = \"Times New Roman\",\n                              size = 50,\n                              face = \"bold\"),\n    strip.background = element_rect(fill = \"cornflowerblue\",\n                                    color = \"pink2\",\n                                    size = 5),\n    # plot elements\n    plot.background = element_rect(fill = \"#EC4899\",\n                                   color = NA),\n    plot.title = element_text(angle = -20, size = 40, color = \"blue\"),\n    plot.subtitle = element_text(angle = 20, color = \"gold\"),\n    plot.margin = unit(rep(2, 4), \"cm\"),\n    # panel elements\n    panel.grid.major = element_line(size = 8),\n    panel.background = element_rect(fill = \"#EC4899\"),\n    panel.grid.minor = element_line(color = \"#32CD32\"),\n    # legend elements\n    legend.background = element_rect(fill = \"yellow\"),\n    legend.key.size = unit(3, \"cm\"),\n    legend.position.inside = c(0.6, 0.5)\n  )\n\n\n\n\n\n\n\n\n\n\n\nFriday 10 AM plot\n\n\nCode\nggplot(data = salmon_clean,\n                      # aesthetics: x-axis, y-axis, and color\n                      aes(x = Date,\n                          y = daily_count,\n                          color = species)) +\n  # first layer: points\n  geom_point() +\n  # second layer: line\n  geom_line(size = 2, \n            linetype = \"dashed\") +\n  # labels\n  labs(x = \"Date\",\n       y = \"Daily fish count\",\n       title = \"Ugly plot\",\n       caption = \"super ugly\") +\n  # custom color scale\n  scale_color_manual(values = c(\"Chinook\" = \"hotpink\",\n                                \"Coho\" = \"chartreuse\",\n                                \"Sockeye\" = \"pink\")) +\n  # adding this facet \n  facet_wrap(~species) +\n  # built in theme\n  theme_dark() +\n  theme(\n    # strip elements\n    strip.text = element_text(family = \"Courier New\",\n                              color = \"gold\",\n                              face = \"bold\"),\n    strip.background = element_rect(color = \"brown\",\n                                    fill = \"white\"),\n    # plot elements\n    plot.background = element_rect(fill = \"yellow\", color = \"red\", size = 20),\n    plot.title = element_text(color = \"purple\", size = 28, face = \"italic\", hjust = 0),\n    plot.caption = element_text(color = \"red\", size = 14, face = \"bold.italic\", hjust = 0.5),\n    # panel elements\n    panel.border = element_rect(fill = NA, color = \"chartreuse\", size = 1),\n    panel.grid.major.x = element_line(color = \"blue3\"),\n    panel.grid.minor.y = element_line(color = \"chartreuse4\"),\n    panel.background = element_rect(fill = \"deeppink\"),\n    # legend elements\n    legend.key.height = unit(3, \"cm\"),\n    legend.key.width = unit(5, \"cm\"),\n    legend.background = element_rect(fill = \"green\"),\n    legend.position = \"left\",\n    legend.box.background = element_rect(fill = \"red\"),\n    # axis elements\n    axis.text.y.left = element_text(size = 17, color = \"yellow\"),\n    axis.ticks = element_line(color = \"red\"),\n    axis.line = element_line(color = \"purple\",\n                             size = 12)\n  )"
  },
  {
    "objectID": "lecture/lecture_week-02.html#math",
    "href": "lecture/lecture_week-02.html#math",
    "title": "Week 2 figures - Lectures 3 and 4",
    "section": "1. Math",
    "text": "1. Math\n\na. standard error\n\\[\nstandard \\: error = SE_{\\bar{y}} = \\frac{s}{\\sqrt{n}}\n\\]\n\n\nb. confidence interval\n\\[\n\\begin{align}\nCI = estimate \\: &\\pm \\: margin \\: of \\: error \\\\\nCI = \\bar{y} \\: &\\pm \\: t_{\\alpha(2), df} \\times \\frac{s}{\\sqrt{n}} \\\\\nCI = \\bar{y} \\: &\\pm \\: z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\n\\end{align}\n\\]\n\n\nc. t-statistic\n\\[\nt_{\\alpha(2), df}\n\\]\n\\[\nt_{0.05(2), 19}\n\\]\n\n\nd. z-score\n\\[\nz = \\frac{\\bar{y} - \\mu}{\\sigma - \\sqrt{n}}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-02.html#confidence-intervals",
    "href": "lecture/lecture_week-02.html#confidence-intervals",
    "title": "Week 2 figures - Lectures 3 and 4",
    "section": "2. confidence intervals",
    "text": "2. confidence intervals\nThis is the leaf example from lecture.\n\nrandom number generation\nThis generates the “population”: 10000 trees.\n\n\nCode\nset.seed(7)\nleaf_pop &lt;- rnorm(n = 10000, mean = 4.92, sd = 0.5)\nleaves &lt;- sample(leaf_pop, size = 20, replace = FALSE)\n\n\n\n\npopulation histogram\n\n\nCode\n# population histogram\nenframe(leaf_pop) %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(fill = \"darkgreen\", \n                 color = \"darkgreen\",\n                 alpha = 0.8) +\n  geom_vline(xintercept = mean(leaf_pop),\n             linetype = 2,\n             linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0)) +\n  labs(x = \"Leaf length (cm)\",\n       y = \"Count\") +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nsample histogram\n\n\nCode\nbreakpoints &lt;- round(seq(from = min(leaves), to = max(leaves), length.out = 7), 2)\n\nhist &lt;- enframe(leaves) %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 7, fill = \"cornflowerblue\", color = \"#000000\", breaks = breakpoints) +\n  scale_x_continuous(breaks = breakpoints) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 6), breaks = c(0, 1, 2, 3, 4, 5, 6)) +\n  theme_classic() +\n  labs(x = \"Leaf length (cm)\", y = \"Count\")\nhist\n\n\n\n\n\n\n\n\n\n\n\nsample density plot\n\n\nCode\nenframe(leaves) %&gt;% \n  ggplot(aes(x = value)) +\n  geom_density(fill = \"cornflowerblue\", color = \"#000000\", linewidth = 1) +\n  scale_x_continuous(limits = c(2.5, 7)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.65)) +\n  geom_vline(xintercept = mean(leaves)) +\n  annotate(\"text\", x = 6, y = 0.6, label = \"sample mean = 4.84 cm\", size = 6) +\n  theme_classic() +\n  labs(x = \"Leaf length (cm)\", \n       y = \"Density\")\n\n\n\n\n\n\n\n\n\n\n\nsample dot and whisker plot with confidence intervals\n\n\nCode\nleaf_conflev &lt;- tribble(\n  ~ conflev,\n  0.85,\n  0.90,\n  0.95,\n  0.99\n) %&gt;% \n  mutate(lower = case_when(\n    conflev == 0.85 ~ mean(leaves) - -qt(p = 0.15/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.90 ~ mean(leaves) - -qt(p = 0.1/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.95 ~ mean(leaves) - -qt(p = 0.05/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.99 ~ mean(leaves) - -qt(p = 0.01/2, df = 19)*sd(leaves)/sqrt(length(leaves)) \n  ), \n  upper = case_when(\n    conflev == 0.85 ~ mean(leaves) + -qt(p = 0.15/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.90 ~ mean(leaves) + -qt(p = 0.1/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.95 ~ mean(leaves) + -qt(p = 0.05/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.99 ~ mean(leaves) + -qt(p = 0.01/2, df = 19)*sd(leaves)/sqrt(length(leaves))\n  )) %&gt;% \n  mutate(mean = mean(leaves))\n  # se &lt;- s/sqrt(n)\n\nggplot() +\n  geom_point(data = enframe(leaves), aes(x = 0.84, y = leaves),\n             alpha = 0.6, shape = 21) +\n  geom_point(data = enframe(leaves), aes(x = 0.89, y = leaves),\n             alpha = 0.6, shape = 21) +\n  geom_point(data = enframe(leaves), aes(x = 0.94, y = leaves),\n             alpha = 0.6, shape = 21) +\n  geom_point(data = enframe(leaves), aes(x = 0.98, y = leaves),\n             alpha = 0.6, shape = 21) +\n  geom_point(data = leaf_conflev, aes(x = conflev, y = mean), \n             size = 3,\n             color = \"cornflowerblue\") +\n  geom_errorbar(data = leaf_conflev, aes(x = conflev, y = mean, ymin = lower, ymax = upper), \n                width = 0.006, \n                linewidth = 1,\n                color = \"cornflowerblue\") +\n  theme_void() +\n  theme(panel.grid = element_blank()) +\n  labs(x = \"Confidence levels\", \n       y = \"Leaf length (cm)\") \n\n\n\n\n\n\n\n\n\n\n\nsample qq plot\n\n\nCode\nqq &lt;- enframe(leaves) %&gt;% \n  ggplot(aes(sample = value)) +\n  stat_qq_line(aes(sample = value)) +\n  stat_qq(aes(sample = value), color = \"cornflowerblue\", size = 3) +\n  theme_classic() +\n  labs(x = \"Theoretical quantiles\", y = \"Sample quantiles\")\n\n\n\n\nCode\nhist + qq\n\n\n\n\n\n\n\n\n\n\n\nresampling visual\n\nresampling with different sample sizes\n\n\nCode\nleaf_5 &lt;- rep(NA, length = 1000)\nleaf_20 &lt;- rep(NA, length = 1000)\nleaf_40 &lt;- rep(NA, length = 1000)\n\nleaf_20_sd &lt;- rep(NA, length = 1000)\n\n# sample 5 leaves from population 1000x\nfor(i in 1:1000) {\n  \n  # sample 5 leaves from population\n  sample_5 &lt;- sample(leaf_pop, size = 5, replace = FALSE) \n  sample_20 &lt;- sample(leaf_pop, size = 20, replace = FALSE) \n  sample_40 &lt;- sample(leaf_pop, size = 40, replace = FALSE) \n  \n  leaf_5[i] &lt;- mean(sample_5)\n  leaf_20[i] &lt;- mean(sample_20)\n  leaf_40[i] &lt;- mean(sample_40)\n  \n  leaf_20_sd[i] &lt;- sd(sample_20)\n}\n\nleaf_df &lt;- cbind(leaf_5, leaf_20, leaf_40) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:3) %&gt;% \n  mutate(name = case_when(\n    name == \"leaf_5\" ~ \"n = 5\",\n    name == \"leaf_20\" ~ \"n = 20\",\n    name == \"leaf_40\" ~ \"n = 40\"\n  ),\n  name = fct_relevel(name, \"n = 5\", \"n = 20\", \"n = 40\"))\n\nleaf_df %&gt;% \n  filter(name == \"n = 20\") %&gt;% \n  ggplot() +\n  geom_histogram(aes(x = value),\n                 color = \"cornflowerblue\",\n                 fill = \"cornflowerblue\",\n                 alpha = 0.8) +\n  geom_vline(xintercept = mean(leaf_pop),\n             linetype = 2,\n             linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 280)) +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        strip.text = element_text(size = 18)) +\n  labs(x = \"Mean leaf length (cm)\") +\n  facet_wrap(~name, ncol = 1) \n\n\n\n\n\n\n\n\n\nCode\nggplot(leaf_df) +\n  geom_histogram(aes(x = value),\n                 color = \"cornflowerblue\",\n                 fill = \"cornflowerblue\",\n                 alpha = 0.8) +\n  geom_vline(xintercept = mean(leaf_pop),\n             linetype = 2,\n             linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 280)) +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.line.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        strip.text = element_text(size = 18)) +\n  labs(x = \"Mean leaf length (cm)\") +\n  facet_wrap(~name, ncol = 1) \n\n\n\n\n\n\n\n\n\n\n\nresampling confidence intervals\n\n\nCode\nleaf_20_ci &lt;- cbind(leaf_20, leaf_20_sd) %&gt;% \n  as_tibble() %&gt;% \n  mutate(ci_low = leaf_20 - -qt(p = 0.05/2, df = 19)*leaf_20_sd/sqrt(20),\n         ci_high = leaf_20 + -qt(p = 0.05/2, df = 19)*leaf_20_sd/sqrt(20),\n         iter = rownames(.)) %&gt;% \n  mutate(color = case_when(\n    ci_low &lt;= mean(leaf_pop) & ci_high &gt;= mean(leaf_pop) ~ \"yes\",\n    TRUE ~ \"no\"\n  ),\n  color = fct_relevel(color, \"yes\", \"no\"))\n\n# selecting 8 resamples to plot\nleaf_20_ci_sample &lt;- leaf_20_ci %&gt;% \n  group_by(color) %&gt;% \n  sample_n(4) %&gt;% \n  ungroup() %&gt;% \n  mutate(iter = fct_inorder(iter))\n\nleaf_20_ci_sample\n\n\n# A tibble: 8 × 6\n  leaf_20 leaf_20_sd ci_low ci_high iter  color\n    &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;\n1    4.90      0.429   4.70    5.10 158   yes  \n2    4.86      0.443   4.66    5.07 108   yes  \n3    4.97      0.429   4.77    5.17 712   yes  \n4    4.75      0.459   4.53    4.96 298   yes  \n5    4.71      0.432   4.51    4.91 500   no   \n6    4.75      0.369   4.58    4.92 983   no   \n7    5.28      0.483   5.06    5.51 824   no   \n8    5.22      0.450   5.00    5.43 973   no   \n\n\nCode\nggplot(data = leaf_20_ci_sample, aes(x = leaf_20, y = iter, color = color)) +\n  geom_vline(xintercept = mean(leaf_pop),\n             lty = 2) +\n  geom_pointrange(aes(xmin = ci_low, xmax = ci_high)) +\n  scale_color_manual(values = c(\"yes\" = \"darkgreen\", \"no\" = \"orange\")) +\n  scale_x_continuous(limits = c(mean(leaf_pop)*0.85, mean(leaf_pop)*1.15)) +\n  scale_y_discrete(limits = rev) +\n  theme(axis.title.y = element_blank(),\n        axis.line.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) +\n  theme(legend.position = \"none\") +\n  labs(x = \"Leaf length (cm)\")\n\n\n\n\n\n\n\n\n\n\n\n\nplotting standard error\n\n\nCode\nenframe(leaves) %&gt;% \n  mutate(group = \"Sample\") %&gt;% \n  ggplot(aes(x = group, y = value)) +\n  geom_point(position = position_jitter(width = 0.2, height = 0, seed = 1),\n             shape = 21,\n             alpha = 0.8) +\n  geom_point(aes(x = group, y = mean(value)),\n             color = \"cornflowerblue\",\n             size = 4) +\n  geom_errorbar(aes(ymin = mean(value) - sd(value)/sqrt(20), \n                    ymax = mean(value) + sd(value)/sqrt(20),\n                    width = 0.2),\n                color = \"cornflowerblue\",\n                linewidth = 1) +\n  labs(y = \"Leaf length (cm)\") +\n  theme(axis.title.x = element_blank())\n\n\n\n\n\n\n\n\n\n\n\ncalculating CI using function\n\n\nCode\nHmisc::smean.cl.normal(leaves)\n\n\n    Mean    Lower    Upper \n4.844110 4.578826 5.109393 \n\n\nCode\nggplot2::mean_cl_normal(leaves)\n\n\n        y     ymin     ymax\n1 4.84411 4.578826 5.109393\n\n\n\n\nplotting with “dry” trees\n\n\nCode\nenframe(leaves) %&gt;% \n  mutate(group = \"Sample\") %&gt;% \n  ggplot() +\n  geom_point(aes(x = group, y = value),\n             position = position_jitter(width = 0.2, height = 0, seed = 1),\n             shape = 21,\n             alpha = 0.8) +\n  geom_point(aes(x = group, y = mean(value)),\n             color = \"cornflowerblue\",\n             size = 3) +\n  geom_errorbar(data = leaf_conflev %&gt;% filter(conflev == 0.95) %&gt;% mutate(group = \"Sample\"),\n                aes(x = group, ymin = lower, ymax = upper),\n                width = 0,\n                color = \"cornflowerblue\",\n                size = 1) +\n  geom_pointrange(data = data.frame(group = \"Dry\", mean = 3.2, lower = 3.0, upper = 3.4),\n                  aes(x = group, y = mean, ymin = lower, ymax = upper),\n                  color = \"firebrick\",\n                  size = 1,\n                  linewidth = 1) +\n  labs(y = \"Leaf length (cm)\") +\n  theme(axis.title.x = element_blank())"
  },
  {
    "objectID": "lecture/lecture_week-02.html#hypothesis-testing-z-distribution",
    "href": "lecture/lecture_week-02.html#hypothesis-testing-z-distribution",
    "title": "Week 2 figures - Lectures 3 and 4",
    "section": "3. Hypothesis testing: z-distribution",
    "text": "3. Hypothesis testing: z-distribution\nExample: You’re told that the mean weight of a coast live oak acorn is \\(2.1 g\\). You question that claim. You then choose to randomly sample 30 acorns and calculate the sample mean: \\(\\bar{y} = 2.6 g\\). You also (miraculously) know the population standard deviation: \\(\\sigma = 0.3 g\\).\nDo you have evidence to refute this claim?\nFirst, store some numbers:\n\n\nCode\nacorn_mean &lt;- 2.1\nacorn_sd &lt;- 0.45\nsample_mean &lt;- 2.2\n\n\nPlotting the acorn population distribution:\n\n\nCode\nmin &lt;- acorn_mean-(3*acorn_sd)\nmax &lt;- acorn_mean+(3*acorn_sd)\n\nacorn_pop_hist &lt;- data.frame(x = min:max) %&gt;% \n  ggplot(aes(x)) +\n  stat_function(geom = \"line\", \n                n = 1000, \n                fun = dnorm, \n                args = list(mean = acorn_mean, sd = acorn_sd), \n                linewidth = 2, \n                color = \"darkgoldenrod\") +\n  geom_vline(xintercept = acorn_mean, \n             linetype = 2, \n             linewidth = 2) +\n  scale_x_continuous(breaks = c(acorn_mean-3*acorn_sd,\n                                acorn_mean-2*acorn_sd, \n                                acorn_mean-acorn_sd,\n                                acorn_mean, \n                                acorn_mean+acorn_sd,\n                                acorn_mean+2*acorn_sd,\n                                acorn_mean+3*acorn_sd),\n                     limits = c(min, max)) +\n  labs(x = \"Acorn mass (g)\") +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank())\n\nacorn_pop_hist\n\n\n\n\n\n\n\n\n\nAnd with the sample mean:\n\n\nCode\npop_with_sample &lt;- acorn_pop_hist +\n  geom_vline(xintercept = sample_mean, \n             color = \"tomato3\",\n             linewidth = 2)\npop_with_sample\n\n\n\n\n\n\n\n\n\nAnd with a sample mean at least that different:\n\n\nCode\npop_with_sample +\n  geom_vline(xintercept = acorn_mean - (sample_mean - acorn_mean), \n             color = \"tomato3\",\n             linewidth = 2)\n\n\n\n\n\n\n\n\n\nWe can calculate a z-score using the formula:\n\\[\n\\begin{align}\nz &= \\frac{\\bar{y} - \\mu}{\\sigma/\\sqrt{n}} \\\\\n&= \\frac{2.2 - 2.10}{0.45/\\sqrt{30}} \\\\\n&= 1.22\n\\end{align}\n\\]\nIn this version of the z-score formula, the number of observations \\(n\\) is included; technically, the one from before also included \\(n\\), but since we were only choosing one individual and asking about the probability of selecting that individual, \\(\\sqrt{n} = 1\\) so it cancelled out.\n\n\nCode\nacorn_z &lt;- (sample_mean - acorn_mean)/(acorn_sd/sqrt(30))\nacorn_z\n\n\n[1] 1.217161\n\n\nCode\npnorm(acorn_z, mean = 0, sd = 1, lower.tail = FALSE)\n\n\n[1] 0.1117714\n\n\nWe can plot the z-scores against each other:\n\n\nCode\ndata.frame(x = -3:3) %&gt;% \n  ggplot(aes(x)) +\n  stat_function(geom = \"area\",\n                fun = dnorm,\n                args = list(mean = 0, sd = 1),\n                xlim = c(1.96, 3),\n                fill = \"lightgrey\") +\n  stat_function(geom = \"area\",\n                fun = dnorm,\n                args = list(mean = 0, sd = 1),\n                xlim = c(-3, -1.96),\n                fill = \"lightgrey\") +\n  geom_linerange(x = 1.96, ymin = 0, ymax = 0.06) +\n  geom_linerange(x = -1.96, ymin = 0, ymax = 0.06) +\n  geom_linerange(x = acorn_z, linetype = 2, linewidth = 2,\n                 ymin = 0, ymax = 0.18) +\n  geom_linerange(x = -acorn_z, linetype = 2, linewidth = 2,\n                 ymin = 0, ymax = 0.18) +\n  stat_function(geom = \"line\", \n                n = 1000, \n                fun = dnorm, \n                args = list(mean = 0, sd = 1), \n                linewidth = 2, \n                color = \"darkgoldenrod\") +\n  scale_x_continuous(breaks = seq(-3, 3, by = 1)) +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 0.45)) +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank()) +\n  labs(x = \"Z\")"
  },
  {
    "objectID": "lecture/lecture_week-02.html#one-vs-two-tailed-figure",
    "href": "lecture/lecture_week-02.html#one-vs-two-tailed-figure",
    "title": "Week 2 figures - Lectures 3 and 4",
    "section": "4. one vs two tailed figure",
    "text": "4. one vs two tailed figure\nIn a one-tailed test (directional, greater or lesser), all the significance is in one tail of the distribution. In a two-tailed test (not directional, different from), the significance is split between two tails of the distribution.\n\n\nCode\ntwo &lt;- ggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(3, 5), fill = \"darkgrey\") +\n  geom_linerange(aes(x = 3, ymin = 0, ymax = 0.032), linewidth = 1, lty = 2, color = \"#000000\") +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(-5, -3), fill = \"darkgrey\") +\n  geom_linerange(aes(x = -3, ymin = 0, ymax = 0.032), linewidth = 1, lty = 2, color = \"#000000\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  theme_void() +\n  theme(panel.grid = element_blank())\n\none &lt;- ggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(2, 5), fill = \"darkgrey\") +\n  geom_linerange(aes(x = 2, ymin = 0, ymax = 0.063), linewidth = 1, lty = 2, color = \"#000000\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  theme_void() +\n  theme(panel.grid = element_blank())\n\none + two"
  },
  {
    "objectID": "lecture/lecture_week-07.html",
    "href": "lecture/lecture_week-07.html",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(flextable)\nlibrary(modelsummary)\nlibrary(gtsummary)\nlibrary(readxl)\nlibrary(here)\nlibrary(janitor)\n\n# analysis\nlibrary(car)\nlibrary(performance)\nlibrary(broom)"
  },
  {
    "objectID": "lecture/lecture_week-07.html#set-up",
    "href": "lecture/lecture_week-07.html#set-up",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(flextable)\nlibrary(modelsummary)\nlibrary(gtsummary)\nlibrary(readxl)\nlibrary(here)\nlibrary(janitor)\n\n# analysis\nlibrary(car)\nlibrary(performance)\nlibrary(broom)"
  },
  {
    "objectID": "lecture/lecture_week-07.html#math",
    "href": "lecture/lecture_week-07.html#math",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "1. Math",
    "text": "1. Math\n\na. Residuals\nResiduals are the difference between the actual observed value (\\(y_i\\)) and the model prediction (\\(\\hat{y}\\)) at some value of \\(x\\).\n\\[\nresidual = y_i - \\hat{y}\n\\]\nOrdinary least squares minimizes the sum of squares of the residuals.\n\n\nb. Model equations\nOLS gives you an equation for a line.\n$$ \\[\\begin{align}\ny &= b + mx \\\\\n\ny &= \\beta_0 + \\beta_1x + \\epsilon \\\\\n\n\\end{align}\\] $$ \\(\\beta\\) terms (“betas”) are often referred to as “model coefficients”.\n\n\nc. Mathematical hypothesis\nStatistically, the hypotheses are:\nH_0_: the predictor variable does not predict the response\nH_A_: the predictor variable does predict the response\nMathematically, you might express that as:\n\\[\nH_0: \\beta_1 = 0  \\\\\nH_A: \\beta_1 \\neq 0\n\\]\n\n\nd. R2\n\\[\n\\begin{align}\nR^2 &= 1 - \\frac{\\sum_{i = 1}^{n}(y_i - \\hat{y})^2}{\\sum_{i = 1}^{n}(y_i - \\bar{y})^2} \\\\\n&= 1 - \\frac{SS_{residuals}}{SS_{total}}\n\\end{align}\n\\]\n\n\ne. Pearson’s correlation"
  },
  {
    "objectID": "lecture/lecture_week-07.html#formula-for-pearsons-correlation",
    "href": "lecture/lecture_week-07.html#formula-for-pearsons-correlation",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "formula for Pearson’s correlation",
    "text": "formula for Pearson’s correlation\n\\[\nr = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum(x_i-\\bar{x})^2}\\sqrt{\\sum(y_i - \\bar{y})^2}}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-07.html#test-statistic-for-pearson-correlation",
    "href": "lecture/lecture_week-07.html#test-statistic-for-pearson-correlation",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "test statistic for pearson correlation",
    "text": "test statistic for pearson correlation\n\\[\n\\begin{align}\nt &= \\frac{r\\sqrt{n - 2}}{\\sqrt{1-r^2}} \\\\\ndf &= n -2\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-07.html#r2",
    "href": "lecture/lecture_week-07.html#r2",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "2. R2",
    "text": "2. R2\n\n\nCode\ndf &lt;- tibble(\n  x = seq(from = 1, to = 20, by = 1),\n  r2_1 = 3*x + 1,\n  r2_between = runif(n = 20, min = 1, max = 5)*x + runif(n = 20, min = 1, max = 5),\n  r2_0 = runif(n = 20, min = 1, max = 20)\n)\n\nlm(r2_1 ~ x, data = df) |&gt; \n  summary()\n\n\n\nCall:\nlm(formula = r2_1 ~ x, data = df)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-3.676e-15 -1.312e-15 -5.240e-17  8.432e-16  7.220e-15 \n\nCoefficients:\n             Estimate Std. Error   t value Pr(&gt;|t|)    \n(Intercept) 1.000e+00  1.142e-15 8.757e+14   &lt;2e-16 ***\nx           3.000e+00  9.532e-17 3.147e+16   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.458e-15 on 18 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 9.905e+32 on 1 and 18 DF,  p-value: &lt; 2.2e-16\n\n\nCode\nggplot(df,\n       aes(x = x,\n           y = r2_1)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\nCode\nlm(r2_between ~ x, data = df) |&gt; \n  summary()\n\n\n\nCall:\nlm(formula = r2_between ~ x, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-22.344  -8.201   0.994   9.517  32.971 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5.0684     6.6511   0.762  0.45591    \nx             2.5942     0.5552   4.672  0.00019 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.32 on 18 degrees of freedom\nMultiple R-squared:  0.5481,    Adjusted R-squared:  0.523 \nF-statistic: 21.83 on 1 and 18 DF,  p-value: 0.0001896\n\n\nCode\nggplot(df,\n       aes(x = x,\n           y = r2_between)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\",\n              se = FALSE)\n\n\n\n\n\n\n\n\n\nCode\nlm(r2_0 ~ x, data = df) |&gt; \n  summary()\n\n\n\nCall:\nlm(formula = r2_0 ~ x, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.2426 -1.7958  0.6555  1.7988  6.0232 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5.0045     1.6667   3.003 0.007641 ** \nx             0.6143     0.1391   4.415 0.000334 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.588 on 18 degrees of freedom\nMultiple R-squared:  0.5199,    Adjusted R-squared:  0.4932 \nF-statistic: 19.49 on 1 and 18 DF,  p-value: 0.0003342\n\n\nCode\nggplot(df,\n       aes(x = x,\n           y = r2_0)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\",\n              se = FALSE)"
  },
  {
    "objectID": "lecture/lecture_week-07.html#red-abalone-example",
    "href": "lecture/lecture_week-07.html#red-abalone-example",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "3. Red abalone example",
    "text": "3. Red abalone example\nThis example is inspired in by Hamilton et al. 2022.\nWe work with the linear model using the real data in class, but it’s hard to see the difference in diagnostic plots between a “good” vs “bad” linear model with that data set.\nThis is the fake data generated to compare different diagnostic plots.\n\na. generating the data\n\n\nCode\nset.seed(666)\nabalone &lt;- tibble(\n  temperature = seq(from = 10, to = 18, by = 1),\n  growth1 = runif(length(temperature), min = -0.7, max = -0.63)*temperature + runif(length(temperature), min = 15, max = 17),\n  growth2 = runif(length(temperature), min = -0.7, max = -0.63)*temperature + runif(length(temperature), min = 15, max = 17),\n  growth3 = runif(length(temperature), min = -0.7, max = -0.63)*temperature + runif(length(temperature), min = 15, max = 17)\n) |&gt; \n  pivot_longer(cols = growth1:growth3,\n               names_to = \"rep\",\n               values_to = \"growth\") |&gt; \n  mutate(growth = round(growth, digits = 1)) |&gt; \n  select(temperature, growth) |&gt; \n  rename(x = temperature,\n         y = growth)\n\n# look at your data:\nhead(abalone, 10)\n\n\n# A tibble: 10 × 2\n       x     y\n   &lt;dbl&gt; &lt;dbl&gt;\n 1    10   9.1\n 2    10   9.6\n 3    10   9.7\n 4    11   9  \n 5    11   8.8\n 6    11   8.8\n 7    12   7.5\n 8    12   9.1\n 9    12   8.5\n10    13   6.3\n\n\nCode\nggplot(data = abalone,\n       aes(x = x,\n           y = y)) +\n  geom_point() \n\n\n\n\n\n\n\n\n\nSeems like there is a linear relationship between temperature and abalone growth. As temperature increases, abalone growth decreases.\n\n\nb. fitting a model\n\n\nCode\nabalone_model &lt;- lm(\n  y ~ x,\n  data = abalone\n)\n\n# just checking DHARMa residuals just in case\nDHARMa::simulateResiduals(abalone_model, plot = TRUE)\n\n\n\n\n\n\n\n\n\nObject of Class DHARMa with simulated residuals based on 250 simulations with refit = FALSE . See ?DHARMa::simulateResiduals for help. \n \nScaled residual values: 0.328 0.604 0.656 0.62 0.548 0.472 0.228 0.976 0.716 0.052 0.496 0.528 0.128 0.132 0.92 0.352 0.684 0.152 0.98 0.764 ...\n\n\nCode\n# base R residuals\npar(mfrow = c(2, 2))\nplot(abalone_model)\n\n\n\n\n\n\n\n\n\n\n\nc. looking at model coefficients\n\n\nCode\nsummary(abalone_model)\n\n\n\nCall:\nlm(formula = y ~ x, data = abalone)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.15370 -0.50093  0.06019  0.34491  1.24630 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 16.40926    0.69633   23.57  &lt; 2e-16 ***\nx           -0.69722    0.04891  -14.25 1.65e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6562 on 25 degrees of freedom\nMultiple R-squared:  0.8904,    Adjusted R-squared:  0.8861 \nF-statistic: 203.2 on 1 and 25 DF,  p-value: 1.65e-13\n\n\nCode\n# common way of representing model summaries\n# from flextable package\nflextable::as_flextable(abalone_model)\n\n\nEstimateStandard Errort valuePr(&gt;|t|)(Intercept)16.4090.69623.5650.0000***x-0.6970.049-14.2540.0000***Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05Residual standard error: 0.6562 on 25 degrees of freedomMultiple R-squared: 0.8904, Adjusted R-squared: 0.8861F-statistic: 203.2 on 25 and 1 DF, p-value: 0.0000\n\n\nCode\n# better table\nflextable::as_flextable(abalone_model) |&gt; \n  set_formatter(values = list(\"p.value\" = function(x){ # special function to represent p &lt; 0.001\n    z &lt;- scales::label_pvalue()(x)\n    z[!is.finite(x)] &lt;- \"\"\n    z\n  }))\n\n\nEstimateStandard Errort valuePr(&gt;|t|)(Intercept)16.4090.69623.565&lt;0.001***x-0.6970.049-14.254&lt;0.001***Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05Residual standard error: 0.6562 on 25 degrees of freedomMultiple R-squared: 0.8904, Adjusted R-squared: 0.8861F-statistic: 203.2 on 25 and 1 DF, p-value: 0.0000\n\n\nCode\n# somewhat more customizable way\n# from modelsummary package\nmodelsummary(abalone_model)\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  16.409\n                \n                \n                  \n                  (0.696)\n                \n                \n                  x\n                  -0.697\n                \n                \n                  \n                  (0.049)\n                \n                \n                  Num.Obs.\n                  27\n                \n                \n                  R2\n                  0.890\n                \n                \n                  R2 Adj.\n                  0.886\n                \n                \n                  AIC\n                  57.8\n                \n                \n                  BIC\n                  61.7\n                \n                \n                  Log.Lik.\n                  -25.899\n                \n                \n                  F\n                  203.189\n                \n                \n                  RMSE\n                  0.63\n                \n        \n      \n    \n\n\n\nCode\n# better table\nmodelsummary(list(\"Abalone model\" = abalone_model), # naming the model\n             fmt = 2, # rounding digits to 2 decimal places\n             estimate = \"{estimate} [{conf.low}, {conf.high}] ({p.value})\", # customizing appearance\n             statistic = NULL, # not displaying standard error\n             gof_omit = 'DF|AIC|BIC|Log.Lik.|RMSE') # taking out some extraneous info\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Abalone model\n              \n        \n        \n        \n                \n                  (Intercept)\n                  16.41 [14.98, 17.84] (&lt;0.01)\n                \n                \n                  x\n                  -0.70 [-0.80, -0.60] (&lt;0.01)\n                \n                \n                  Num.Obs.\n                  27\n                \n                \n                  R2\n                  0.890\n                \n                \n                  R2 Adj.\n                  0.886\n                \n                \n                  F\n                  203.189\n                \n        \n      \n    \n\n\n\nCode\n# using gtsummary package\ntbl_regression(abalone_model,\n               intercept = TRUE)\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\n(Intercept)\n16\n15, 18\n&lt;0.001\n\n\nx\n-0.70\n-0.80, -0.60\n&lt;0.001\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nCode\n# more customizing\ntbl_regression(abalone_model, # model object\n               intercept = TRUE) |&gt; # show the intercept\n  as_flex_table() # turn it into a flextable (easier to save)\n\n\nCharacteristicBeta95% CIp-value(Intercept)1615, 18&lt;0.001x-0.70-0.80, -0.60&lt;0.001Abbreviation: CI = Confidence Interval\n\n\n\n\nCode\nanova(abalone_model)\n\n\nAnalysis of Variance Table\n\nResponse: y\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nx          1 87.501  87.501  203.19 1.65e-13 ***\nResiduals 25 10.766   0.431                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nd. visualizing the model\n\n\nCode\nmodel_preds &lt;- ggpredict(\n  abalone_model,\n  terms = \"x\"\n)\n\n# look at the output:\nmodel_preds\n\n\n# Predicted values of y\n\n x | Predicted |     95% CI\n---------------------------\n10 |      9.44 | 8.96, 9.92\n11 |      8.74 | 8.34, 9.14\n12 |      8.04 | 7.71, 8.37\n13 |      7.35 | 7.07, 7.62\n14 |      6.65 | 6.39, 6.91\n15 |      5.95 | 5.67, 6.23\n16 |      5.25 | 4.92, 5.58\n18 |      3.86 | 3.38, 4.34\n\n\nCode\nggpredict(abalone_model, \n          terms = \"x[18]\")\n\n\n# Predicted values of y\n\n x | Predicted |     95% CI\n---------------------------\n18 |      3.86 | 3.38, 4.34\n\n\nCode\n# plotting without 95% CI\nggplot(abalone, # using the actual data\n       aes(x = x, # x-axis\n           y = y)) + # y-axis\n  geom_point(color = \"cornflowerblue\", # each point is an individual abalone\n             size = 3) +\n  \n  # model prediction: actual model line\n  geom_line(data = model_preds, # model prediction table\n            aes(x = x, # x-axis\n                y = predicted), # y-axis\n            linewidth = 1)  # line width\n\n\n\n\n\n\n\n\n\nCode\n# plotting\nggplot(abalone, # using the actual data\n       aes(x = x, # x-axis\n           y = y)) + # y-axis\n  \n  # plot the data first\n  # each point is an individual abalone\n  geom_point(color = \"cornflowerblue\",\n             size = 3) + \n  \n  # model prediction: 95% CI\n  geom_ribbon(data = model_preds, # model prediction table\n              aes(x = x, # x-axis\n                  y = predicted, # y-axis\n                  ymin = conf.low, # lower bound of 95% CI\n                  ymax = conf.high), # upper bound of 95% CI\n              alpha = 0.2) + # transparency) \n  \n  # model prediction: actual model line\n  geom_line(data = model_preds, # model prediction table\n            aes(x = x, # x-axis\n                y = predicted), # y-axis\n            linewidth = 1) # line width\n\n\n\n\n\n\n\n\n\nCode\n# compare with:\nggplot(abalone,\n       aes(x = x,\n           y = y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\n\n\ne. outliers\n\n\nCode\nabalone |&gt; \n  mutate(outlier = ifelse(row_number() %in% c(19, 21, 27), \"yes\", \"no\")) |&gt; \n  ggplot(aes(x = x,\n             y = y)) +\n  geom_point(aes(color = outlier), \n             size = 3) + \n  geom_line(data = model_preds,\n            aes(x = x,\n                y = predicted),\n            linewidth = 1) +\n  scale_color_manual(values = c(\"yes\" = \"red\", \"no\" = \"cornflowerblue\")) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nCode\n# new abalone data frame\nabalone2 &lt;- abalone |&gt; \n  slice(-c(19, 21, 27))\n\nabalone_model2 &lt;- lm(y ~ x,\n                    data = abalone2)\n\nsummary(abalone_model2)\n\n\n\nCall:\nlm(formula = y ~ x, data = abalone2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.01641 -0.44359  0.08359  0.34163  1.05272 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 16.81772    0.60270   27.90  &lt; 2e-16 ***\nx           -0.73087    0.04336  -16.85 4.61e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.537 on 22 degrees of freedom\nMultiple R-squared:  0.9281,    Adjusted R-squared:  0.9249 \nF-statistic: 284.1 on 1 and 22 DF,  p-value: 4.606e-14\n\n\nCode\nmodel_preds2 &lt;- ggpredict(abalone_model2, terms = \"x\")\n\nggplot(data = abalone2,\n       aes(x = x,\n           y = y)) +\n  geom_point(color = \"cornflowerblue\",\n             size = 3) +\n  geom_line(data = model_preds2,\n            aes(x = x,\n                y = predicted), \n            linewidth = 1)\n\n\n\n\n\n\n\n\n\n\n\nf. actual data\nData from: Hamilton et al. 2022. Aquaculture. “Integrated multi-trophic aquaculture mitigates the effects of ocean acidification: Seaweeds raise system pH and improve growth of juvenile abalone.”\nThank you to Scott for being willing to share this data!\n\n\nCode\nabalone &lt;- read_xlsx(here(\"data\", \"Abalone IMTA_growth and pH.xlsx\")) |&gt; \n  clean_names()\n\n# creating clean dataset\nabalone_clean &lt;- abalone |&gt; # start with abalone object\n  # select columns of interest\n  select(mean_p_h, change_in_area_mm2_d_1_25, recirculation_treatment) |&gt; \n  # rename columns\n  rename(ph = mean_p_h, \n         change_in_area = change_in_area_mm2_d_1_25,\n         recirculation = recirculation_treatment) |&gt; \n  # recod recirculation\n  mutate(recirculation = case_when(\n    recirculation == 0 ~ \"0% recirculation\",\n    recirculation == 0.3 ~ \"30% recirculation\",\n    recirculation == 0.65 ~ \"65% recirculation\"\n  ))\n\n# base layer: ggplot\nggplot(data = abalone_clean,\n       aes(x = ph,\n           y = change_in_area)) +\n  # first layer: points representing abalones\n  geom_point(size = 4,\n             stroke = 1,\n             fill = \"firebrick3\",\n             shape = 21)\n\n\n\n\n\n\n\n\n\nCode\nabalone_clean |&gt; \n  select(ph, change_in_area) |&gt; \n  slice_sample(n = 5)\n\n\n# A tibble: 5 × 2\n     ph change_in_area\n  &lt;dbl&gt;          &lt;dbl&gt;\n1  7.95           5.40\n2  8.23           5.74\n3  8.15           5.48\n4  8.14           6.02\n5  7.95           5.47\n\n\nCode\nabalone_model &lt;- lm(\n  change_in_area ~ ph,  # formula: change in area as a function of pH\n  data = abalone_clean  # data frame: abalone_clean\n)\n\nDHARMa::simulateResiduals(abalone_model) |&gt; \n  plot()\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))   # creating a 2x2 grid\nplot(abalone_model)    # plot diagnostic plots\n\n\n\n\n\n\n\n\n\nCode\n# more information about the model\nsummary(abalone_model)\n\n\n\nCall:\nlm(formula = change_in_area ~ ph, data = abalone_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.42714 -0.29282  0.08769  0.21258  0.43965 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) -18.5010     6.1601  -3.003  0.01488 * \nph            2.9827     0.7596   3.926  0.00348 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3063 on 9 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.6314,    Adjusted R-squared:  0.5905 \nF-statistic: 15.42 on 1 and 9 DF,  p-value: 0.003477\n\n\nCode\n# creating a new object called abalone_preds\nabalone_preds &lt;- ggpredict(\n  abalone_model,      # model object\n  terms = \"ph\"        # predictor (in quotation marks)\n)\n\n# display the predictions\nabalone_preds\n\n\n# Predicted values of change_in_area\n\n  ph | Predicted |     95% CI\n-----------------------------\n7.94 |      5.19 | 4.83, 5.54\n7.95 |      5.21 | 4.86, 5.55\n8.06 |      5.53 | 5.30, 5.76\n8.10 |      5.67 | 5.46, 5.88\n8.10 |      5.67 | 5.46, 5.88\n8.14 |      5.77 | 5.55, 5.98\n8.15 |      5.81 | 5.59, 6.04\n8.33 |      6.36 | 5.92, 6.80\n\n\nCode\n# find predicted growth at ph = 7.9\nggpredict(\n  abalone_model,\n  terms = \"ph[7.9]\"\n)\n\n\n# Predicted values of change_in_area\n\n  ph | Predicted |     95% CI\n-----------------------------\n7.90 |      5.06 | 4.65, 5.48\n\n\nCode\n# find predicted growth at ph = 7.9\nggpredict(\n  abalone_model,\n  terms = \"ph[8.23]\"\n)\n\n\n# Predicted values of change_in_area\n\n  ph | Predicted |     95% CI\n-----------------------------\n8.23 |      6.05 | 5.75, 6.34\n\n\nCode\n# find predicted growth at ph = 8\nggpredict(\n  abalone_model,\n  terms = \"ph[8]\"\n)\n\n\n# Predicted values of change_in_area\n\nph | Predicted |     95% CI\n---------------------------\n 8 |      5.36 | 5.08, 5.64\n\n\nCode\n# model summary in a neat table\nas_flextable(abalone_model)\n\n\nEstimateStandard Errort valuePr(&gt;|t|)(Intercept)-18.5016.160-3.0030.0149  *ph2.9830.7603.9260.0035 **Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05Residual standard error: 0.3063 on 9 degrees of freedomMultiple R-squared: 0.6314, Adjusted R-squared: 0.5905F-statistic: 15.42 on 9 and 1 DF, p-value: 0.0035\n\n\nCode\n# model summary in a neat table\ntbl_regression(abalone_model,\n               intercept = TRUE,\n               label = list(`(Intercept)` = \"Intercept\", \n                            `ph` = \"pH\")) |&gt; \n  as_flex_table() \n\n\nCharacteristicBeta95% CIp-valueIntercept-19-32, -4.60.015pH3.01.3, 4.70.003Abbreviation: CI = Confidence Interval\n\n\nCode\n# look at the column names\ncolnames(abalone_preds)\n\n\n[1] \"x\"         \"predicted\" \"std.error\" \"conf.low\"  \"conf.high\" \"group\"    \n\n\nCode\n# look at the \"class\" (i.e. \"type\") of object\nclass(abalone_preds)\n\n\n[1] \"ggeffects\"  \"data.frame\"\n\n\nCode\n# base layer: ggplot\n# using clean data frame\nggplot(data = abalone_clean,\n       aes(x = ph,\n           y = change_in_area)) +\n  # first layer: points representing abalones\n  geom_point(size = 4,\n             stroke = 1,\n             fill = \"firebrick3\",\n             shape = 21) +\n  # second layer: ribbon representing confidence interval\n  # using predictions data frame\n  geom_ribbon(data = abalone_preds,\n              aes(x = x,\n                  y = predicted,\n                  ymin = conf.low,\n                  ymax = conf.high),\n              alpha = 0.1) +\n  # third layer: line representing model predictions\n  # using predictions data frame\n  geom_line(data = abalone_preds,\n            aes(x = x,\n                y = predicted),\n            linewidth = 1) +\n  # axis labels\n  labs(x = \"pH\", \n       y = expression(\"Change in shell area (\"*mm^{2}~d^-1*\")\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = abalone_clean,\n       aes(x = ph,\n           y = change_in_area)) +\n  # first layer: points representing abalones\n  geom_point(size = 4,\n             stroke = 1,\n             fill = \"firebrick3\",\n             shape = 21) +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "lecture/lecture_week-07.html#exponential-growth-example",
    "href": "lecture/lecture_week-07.html#exponential-growth-example",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "4. Exponential growth example",
    "text": "4. Exponential growth example\nTo compare with abalone example\n\n\nCode\ndf_ex &lt;- tibble(\n  x = seq(from = 10, to = 18, length = 27),\n  y = c(15, 15, 15, \n        15, 14.3, 14.2, \n        14.1, 14, 13.9,\n        13.9, 13.8, 13.7,\n        13.2, 13.1, 13,\n        12.5, 11.1, 10,\n        9.9, 7, 5,\n        3, 1.7, 1,\n        0.5, 0.3, 0.1)\n) \n\nlm_ex &lt;- lm(y ~ x, data = df_ex)\n\nsummary(lm_ex)\n\n\n\nCall:\nlm(formula = y ~ x, data = df_ex)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.2540 -2.0605 -0.4009  2.3533  3.6288 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  38.5833     2.6772   14.41 1.29e-13 ***\nx            -2.0329     0.1885  -10.79 6.82e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.347 on 25 degrees of freedom\nMultiple R-squared:  0.8231,    Adjusted R-squared:  0.816 \nF-statistic: 116.3 on 1 and 25 DF,  p-value: 6.823e-11\n\n\nCode\nggplot(data = df_ex,\n       aes(x = x,\n           y = y)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nCode\nlm_pred &lt;- ggpredict(lm_ex, terms = ~x)\n\nex_plot_noline &lt;- ggplot(df_ex, aes(x= x, y = y)) +\n  geom_point(size = 3, color = \"orange\") +\n  theme_classic() +\n  theme(text = element_text(size = 14))\n\nex_plot_noline\n\n\n\n\n\n\n\n\n\nCode\nex_plot &lt;- ggplot(df_ex, aes(x= x, y = y)) +\n  geom_point(size = 3, color = \"orange\") +\n  geom_line(data = lm_pred, aes(x = x, y = predicted), linewidth = 1) +\n  theme(text = element_text(size = 14)) \n\nex_plot\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\nplot(lm_ex)\n\n\n\n\n\n\n\n\n\nCode\nDHARMa::simulateResiduals(lm_ex) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# if using quarto, don't label chunk with a table... so weird\nanova_tbl &lt;- broom::tidy(anova(model1)) |&gt; \n  mutate(across(where(is.numeric), ~ round(.x, digits = 2))) |&gt; \n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\"\n  )) \n\nflextable(anova_tbl) |&gt; \n  set_header_labels(term = \"Term\", \n                    df = \"Degrees of freedom\", \n                    sumsq = \"Sum of squares\", \n                    meansq = \"Mean squares\", \n                    statistic = \"F-statistic\", \n                    p.value = \"p-value\") |&gt; \n  set_table_properties(layout = \"autofit\", width = 0.8)"
  },
  {
    "objectID": "lecture/lecture_week-07.html#model-summary",
    "href": "lecture/lecture_week-07.html#model-summary",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "model summary",
    "text": "model summary\n\n\nCode\nsummary(lm_ex)\n\n\n\nCall:\nlm(formula = y ~ x, data = df_ex)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2756.1  -660.5   226.3   843.2  1081.0 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   9431.3     1111.3   8.486 3.16e-09 ***\nx            -1642.0      156.5 -10.492 3.30e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1023 on 28 degrees of freedom\nMultiple R-squared:  0.7972,    Adjusted R-squared:   0.79 \nF-statistic: 110.1 on 1 and 28 DF,  p-value: 3.298e-11"
  },
  {
    "objectID": "lecture/lecture_week-07.html#model-plots",
    "href": "lecture/lecture_week-07.html#model-plots",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "model plots",
    "text": "model plots\n\n\nCode\nlm_pred &lt;- ggpredict(lm_ex, terms = ~x)\n\nex_plot_noline &lt;- ggplot(df_ex, aes(x= x, y = y)) +\n  geom_point(shape = 17, size = 3, color = \"orange\") +\n  theme_classic() +\n  theme(text = element_text(size = 14))\n\nex_plot &lt;- ggplot(df_ex, aes(x= x, y = y)) +\n  geom_point(shape = 17, size = 3, color = \"orange\") +\n  geom_line(data = lm_pred, aes(x = x, y = predicted), linewidth = 1) +\n  theme_classic() +\n  theme(text = element_text(size = 14))"
  },
  {
    "objectID": "lecture/lecture_week-10.html",
    "href": "lecture/lecture_week-10.html",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(flextable)\nlibrary(GGally)\nlibrary(equatiomatic)\n\n# data\nlibrary(palmerpenguins)\n\n# analysis\nlibrary(car)\nlibrary(performance)\nlibrary(broom)\nlibrary(DHARMa)\nlibrary(MuMIn)\nlibrary(lmtest)"
  },
  {
    "objectID": "lecture/lecture_week-10.html#simple-linear-regression",
    "href": "lecture/lecture_week-10.html#simple-linear-regression",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "simple linear regression",
    "text": "simple linear regression\n\\[\nE[y_i] = a + bx_i\n\\]\n\\[\nvar[y_i] = s^2\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#generalized-form",
    "href": "lecture/lecture_week-10.html#generalized-form",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "generalized form:",
    "text": "generalized form:\n\\[\nE[y_i] = a + bx_i\n\\]\n\\[\nvar[y_i] = v(E[y_i])\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#random-component",
    "href": "lecture/lecture_week-10.html#random-component",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "random component",
    "text": "random component\n\\[\nY_i \\sim N(\\mu_i, \\sigma^2)\n\\]\n\\[\nY_i \\sim Normal(\\mu_i, \\sigma^2)\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#systematic-component",
    "href": "lecture/lecture_week-10.html#systematic-component",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "systematic component",
    "text": "systematic component\n\\[\n\\eta_i = \\sum^{p-1}_{n = 0}\\beta_jx_{ij}\n\\]\n\\[\n\\mu_i = \\beta_0 + \\beta x_i\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#link",
    "href": "lecture/lecture_week-10.html#link",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "link",
    "text": "link\n\\[\n\\eta = g(\\mu_i)\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#random",
    "href": "lecture/lecture_week-10.html#random",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "random",
    "text": "random\n\\[\nE(Y) = p\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#systematic",
    "href": "lecture/lecture_week-10.html#systematic",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "systematic",
    "text": "systematic"
  },
  {
    "objectID": "lecture/lecture_week-10.html#link-1",
    "href": "lecture/lecture_week-10.html#link-1",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "link",
    "text": "link\n\\[\n\\eta = g(p) = log(\\frac{p_i}{1 - p_i})\n\\]\n\\[\nlog(\\frac{p_i}{1 - p_i}) = \\beta_0 + \\beta_1 x_i\n\\]\n\\[\nY_i \\sim Binomial(p_i)\n\\]\n\\[\n\\eta = logit(p_i) = log(\\frac{p_i}{1 - p_i})\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-05.html",
    "href": "lecture/lecture_week-05.html",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\n\n# data\nlibrary(palmerpenguins)\n\n# analysis\nlibrary(car)\nlibrary(effectsize)"
  },
  {
    "objectID": "lecture/lecture_week-05.html#set-up",
    "href": "lecture/lecture_week-05.html#set-up",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\n\n# data\nlibrary(palmerpenguins)\n\n# analysis\nlibrary(car)\nlibrary(effectsize)"
  },
  {
    "objectID": "lecture/lecture_week-05.html#math",
    "href": "lecture/lecture_week-05.html#math",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "1. Math",
    "text": "1. Math\n\na. sum of squares\nAmong groups:\n\\[\n\\sum^k_{i = 1}\\sum^n_{j = 1}(\\bar{y_i} - \\bar{y})^2\n\\]\nwhere k is the number of groups, i is ith group, n is the number of observations per group, j is the jth observation. \\(\\bar{y_i}\\) is the mean of group i, while \\(\\bar{y}\\) is the grand mean (of all samples pooled together).\nWithin groups:\n\\[\n\\sum^k_{i = 1}\\sum^n_{j = 1}(y_{ij} - \\bar{y_i})^2\n\\]\nwhere \\(y_{ij}\\) is the jth observation in the ith group, and \\(\\bar{y_i}\\) is the mean of group i.\nTotal sum of squares:\n\\[\n\\sum^k_{i = 1}\\sum^n_{j = 1}(y_{ij} - \\bar{y})^2\n\\]\nwhere \\(y_{ij}\\) is the jth observation in the ith group, and \\(\\bar{y}\\) is the grand mean.\n\n\nb. mean squares\nAmong groups:\n\\[\n\\frac{SS_{among \\ group}}{k - 1}\n\\]\nWithin groups:\n\\[\n\\frac{SS_{within \\ group}}{n - k}\n\\]\n\n\nc. F-ratio/F-statistic\n\\[\n\\frac{MS_{among \\ group}}{MS_{within \\ group}}\n\\]\nPut another way, the F-ratio is the ratio of among group variance to within group variance. If the among group variance is larger than within group variance, the F-ratio is large, and therefore the probability of among group variance being equal to within group variance is small. Thus, you would reject the null hypothesis if the F-ratio is large.\n\n\nd. η squared\n\\[\n\\eta^2 = \\frac{SS_{among \\ group}}{SS_{among \\ group} + SS_{within \\ group}}\n\\] ### e. U statistic\n\\[\n\\begin{align}\nU_1 &= \\Sigma R_1 - n_1(n_1 + 1)/2 = 17 - 5(5+1)/2 = 2 \\\\\nU_2 &= \\Sigma R_2 - n_2(n_2 + 1)/2 = 38 - 5(5+1)/2 = 23\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-05.html#warm-up-code-for-a-figure",
    "href": "lecture/lecture_week-05.html#warm-up-code-for-a-figure",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "2. Warm up: code for a figure",
    "text": "2. Warm up: code for a figure\n\n\nCode\n# random sample of 10 rows from data frame\nsample_n(chickwts, 10) %&gt;% \n  arrange(feed)\n\n\n   weight      feed\n1     108 horsebean\n2     179 horsebean\n3     227 horsebean\n4     148   linseed\n5     257   linseed\n6     258  meatmeal\n7     248   soybean\n8     199   soybean\n9     295 sunflower\n10    334 sunflower\n\n\nCode\nggplot(data = chickwts,           # data frame: chickwts\n       aes(x = feed,              # x-axis: feed type\n           y = weight,            # y-axis: chick weight\n           fill = feed)) +        # fill by feed type  \n  geom_boxplot() +                # creates a boxplot\n  geom_jitter(height = 0,         # prevents jitter from moving points along y-axis\n              width = 0.2) +      # narrows spread of jitter along x-axis\n  theme(legend.position = \"none\") # removes legend"
  },
  {
    "objectID": "lecture/lecture_week-05.html#analysis-of-variance",
    "href": "lecture/lecture_week-05.html#analysis-of-variance",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "3. Analysis of variance",
    "text": "3. Analysis of variance\nCentral question: How does bill length differ between penguin species?\n\na. Exploratory data visualization\n\n\nCode\npenguins_jitter &lt;- ggplot(data = penguins,\n                          aes(x = species,\n                              y = bill_length_mm,\n                              color = species)) +\n  geom_jitter(width = 0.2,\n              height = 0,\n              shape = 21) +\n  scale_color_manual(values = c(\"#209c90\", \"#018ca9\", \"#27c839\")) +\n  labs(x = \"Species\",\n       y = \"Bill length (mm)\") +\n  theme(legend.position = \"none\")\n\npenguins_jitter\n\n\n\n\n\n\n\n\n\n\n\nb. histogram and qq plots\n\n\nCode\nhist &lt;- ggplot(data = penguins,\n       aes(x = bill_length_mm,\n           fill = species)) +\n  geom_histogram(bins = 14,\n                 color = \"black\") +\n  scale_fill_manual(values = c(\"#209c90\", \"#018ca9\", \"#27c839\")) +\n  scale_y_continuous(expand = c(0, 0)) +\n  facet_wrap(~ species, scales = \"free\", ncol = 1) +\n  labs(x = \"Bill length (mm)\",\n       y = \"Count\") +\n  theme(legend.position = \"none\",\n        strip.background = element_rect(color = \"white\"),\n        strip.text = element_text(size = 20))\n\nqq &lt;- ggplot(data = penguins,\n       aes(sample = bill_length_mm)) +\n  geom_qq_line() +\n  geom_qq(aes(color = species)) +\n  scale_color_manual(values = c(\"#209c90\", \"#018ca9\", \"#27c839\")) +\n  facet_wrap(~ species, scales = \"free\", ncol = 1) +\n  labs(x = \"Theoretical quantile\",\n       y = \"Value\") +\n  theme(legend.position = \"none\",\n        strip.background = element_rect(color = \"white\"),\n        strip.text = element_text(size = 20))\n\nhist + qq\n\n\n\n\n\n\n\n\n\n\n\nc. Shapiro-Wilk normality test\nGeneral: Is the response variable normally distributed?\nExample: Is bill length normally distributed?\n\n\nCode\n# first, wrangle\nadelie &lt;- penguins %&gt;% \n  filter(species == \"Adelie\") %&gt;% \n  pull(bill_length_mm)\n\nchinstrap &lt;- penguins %&gt;% \n  filter(species == \"Chinstrap\") %&gt;% \n  pull(bill_length_mm)\n\ngentoo &lt;- penguins %&gt;% \n  filter(species == \"Gentoo\") %&gt;% \n  pull(bill_length_mm)\n\n# then, do the shapiro-wilk test\nshapiro.test(adelie)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  adelie\nW = 0.99336, p-value = 0.7166\n\n\nCode\nshapiro.test(chinstrap)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  chinstrap\nW = 0.97525, p-value = 0.1941\n\n\nCode\nshapiro.test(gentoo)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  gentoo\nW = 0.97272, p-value = 0.01349\n\n\n\n\nd. Levene test of variances\nGeneral: Are the group variances equal?\nExample: Are the species variances equal?\n\n\nCode\nleveneTest(bill_length_mm ~ species,\n           data = penguins)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)\ngroup   2  2.2425 0.1078\n      339               \n\n\n\n\nCode\npenguins |&gt; \n  drop_na(bill_length_mm) |&gt; \n  group_by(species) |&gt; \n  summarize(variance = var(bill_length_mm, na.rm = TRUE),\n            n = length(bill_length_mm)) \n\n\n# A tibble: 3 × 3\n  species   variance     n\n  &lt;fct&gt;        &lt;dbl&gt; &lt;int&gt;\n1 Adelie        7.09   151\n2 Chinstrap    11.2     68\n3 Gentoo        9.50   123\n\n\n\n\ne. analysis of variance\n\n\nCode\n# do the actual test\n# model object stored as `penguins_anova`\npenguins_anova &lt;- aov(bill_length_mm ~ species,\n                      data = penguins)\n\n# output of the test\npenguins_anova\n\n\nCall:\n   aov(formula = bill_length_mm ~ species, data = penguins)\n\nTerms:\n                 species Residuals\nSum of Squares  7194.317  2969.888\nDeg. of Freedom        2       339\n\nResidual standard error: 2.959853\nEstimated effects may be unbalanced\n2 observations deleted due to missingness\n\n\nCode\n# more information\nsummary(penguins_anova)\n\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nspecies       2   7194    3597   410.6 &lt;2e-16 ***\nResiduals   339   2970       9                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2 observations deleted due to missingness\n\n\n\n\nf. post hoc test\nWhich group comparisons are different?\n\n\nCode\nTukeyHSD(penguins_anova)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = bill_length_mm ~ species, data = penguins)\n\n$species\n                      diff       lwr        upr     p adj\nChinstrap-Adelie 10.042433  9.024859 11.0600064 0.0000000\nGentoo-Adelie     8.713487  7.867194  9.5597807 0.0000000\nGentoo-Chinstrap -1.328945 -2.381868 -0.2760231 0.0088993\n\n\n\n\ng. effect size\n\n\nCode\neta_squared(penguins_anova)\n\n\n# Effect Size for ANOVA\n\nParameter | Eta2 |       95% CI\n-------------------------------\nspecies   | 0.71 | [0.67, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\n\n\nh. example of writing\nWithout the stats: Our results suggest a difference in bill length between species, with a large effect of species. Species differed in bill length, and pairwise comparisons between species showed that all three species differed from each other. Generally, Adelie penguins tend to have shorter bills than Chinstrap and Gentoo penguins. Gentoo penguins tend to have shorter bills than Chinstrap penguins.\nWith the stats: Our results suggest a difference in bill length between species, with a large (\\(\\eta^2\\) = 0.71) effect of species. Species differed in bill length (one-way ANOVA, F(2, 339) = 410.6, p &lt; 0.001, \\(\\alpha\\) = 0.05), and pairwise comparisons between species showed that all three species differed from each other. Generally, Adelie penguins tend to have 10.0 mm shorter bills than Chinstrap (Tukey HSD, p &lt; 0.001, 95% confidence interval: [9.0, 11.1] mm) penguins and 8.7 mm shorter than Gentoo (Tukey HSD, p &lt; 0.001, 95% confidence interval: [7.9, 9.6] mm) penguins. Gentoo penguins tend to have 1.3 mm shorter bills than Chinstrap penguins (Tukey HSD, p = 0.008, 95% confidence interval: [0.3, 2.4] mm).\n\n\ni. a “finalized” figure\n\n\nCode\nggplot(data = penguins,\n       aes(x = species,\n           y = bill_length_mm,\n           color = species)) +\n  geom_jitter(width = 0.2,\n              height = 0,\n              shape = 21,\n              alpha = 0.4) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_cl_normal,\n               size = 0.8,\n               linewidth = 1) +\n  scale_color_manual(values = c(\"#209c90\", \"#018ca9\", \"#27c839\")) +\n  labs(x = \"Species\",\n       y = \"Bill length (mm)\") +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "lecture/lecture_week-05.html#non-parametric-tests",
    "href": "lecture/lecture_week-05.html#non-parametric-tests",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "4. Non parametric tests",
    "text": "4. Non parametric tests\n\na. Mann-Whitney U\n\n\nCode\nwilcox_df &lt;- cbind(Sample1 = c(1.1, 2.4, 1.8, 0.4, 1.6), \n                   Sample2 = c(5.4, 3.1, 2.3, 1.9, 4.2)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = Sample1:Sample2) %&gt;% \n  rename(sample = name) %&gt;% \n  arrange(sample)\n\nwilcox_df\n\n\n# A tibble: 10 × 2\n   sample  value\n   &lt;chr&gt;   &lt;dbl&gt;\n 1 Sample1   1.1\n 2 Sample1   2.4\n 3 Sample1   1.8\n 4 Sample1   0.4\n 5 Sample1   1.6\n 6 Sample2   5.4\n 7 Sample2   3.1\n 8 Sample2   2.3\n 9 Sample2   1.9\n10 Sample2   4.2\n\n\nCode\nwilcox.test(value ~ sample,\n            data = wilcox_df)\n\n\n\n    Wilcoxon rank sum exact test\n\ndata:  value by sample\nW = 2, p-value = 0.03175\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nb. Wilcoxon signed-rank\n\n\nCode\n# for a comparison of one group against a theoretical median\nwilcox.test(Sample1, mu = theoretical)\n\n# for a comparison of two groups\nwilcox.test(value ~ sample,\n            data = wilcox_df, \n            paired = TRUE)\n\n\n\n\nc. Kruskal-Wallis\n\n\nCode\nkruskal_df &lt;- cbind(Sample1 = round(rnorm(n = 5, mean = 4, sd = 1), 1), \n                    Sample2 = round(rnorm(n = 5, mean = 6, sd = 1), 1),\n                    Sample3 = round(rnorm(n = 5, mean = 8, sd = 1), 1)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = Sample1:Sample3) %&gt;% \n  rename(sample = name) %&gt;% \n  arrange(sample)\n\nrank_by_hand &lt;- kruskal_df %&gt;% \n  arrange(value) %&gt;% \n  rownames_to_column(\"ranks\") %&gt;% \n  mutate(ranks = as.numeric(ranks)) %&gt;% \n  group_by(sample) %&gt;% \n  reframe(sum_ranks = sum(ranks))\n\nR1 &lt;- rank_by_hand[1, 2]\nR2 &lt;- rank_by_hand[2, 2]\nR3 &lt;- rank_by_hand[3, 2]\nn &lt;- 15\nn1 &lt;- 5\nn2 &lt;- 5\nn3 &lt;- 5\n\nrstatix::kruskal_test(value ~ sample,\n             data = kruskal_df)\n\n\n# A tibble: 1 × 6\n  .y.       n statistic    df       p method        \n* &lt;chr&gt; &lt;int&gt;     &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;         \n1 value    15      10.9     2 0.00439 Kruskal-Wallis\n\n\nCode\nkruskal.test(value ~ sample,\n             data = kruskal_df)\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  value by sample\nKruskal-Wallis chi-squared = 10.859, df = 2, p-value = 0.004386\n\n\nCode\n#((12 * STATISTIC / (n * (n + 1)) - 3 * (n + 1)) / (1 - sum(TIES^3 - TIES) / (n^3 - n)))\n\n(12/(n*(n+1)))*((R1^2)/n1 + (R2^2)/n2 + (R3^2)/n3) - 3*(n + 1)\n\n\n  sum_ranks\n1     10.82\n\n\nCode\nrstatix::kruskal_effsize(value ~ sample,\n                         data = kruskal_df)\n\n\n# A tibble: 1 × 5\n  .y.       n effsize method  magnitude\n* &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;ord&gt;    \n1 value    15   0.738 eta2[H] large    \n\n\nCode\nrstatix::dunn_test(value ~ sample,\n                         data = kruskal_df)\n\n\n# A tibble: 3 × 9\n  .y.   group1  group2     n1    n2 statistic       p   p.adj p.adj.signif\n* &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1 value Sample1 Sample2     5     5      2.05 0.0399  0.0799  ns          \n2 value Sample1 Sample3     5     5      3.26 0.00112 0.00336 **          \n3 value Sample2 Sample3     5     5      1.20 0.228   0.228   ns"
  },
  {
    "objectID": "lecture/lecture_week-09.html",
    "href": "lecture/lecture_week-09.html",
    "title": "Week 9 figures - Lecture 16",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(here)\nlibrary(janitor)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(flextable)\nlibrary(GGally)\n\n# data\nlibrary(palmerpenguins)\n\n# analysis\nlibrary(car)\nlibrary(performance)\nlibrary(broom)\nlibrary(DHARMa)\nlibrary(MuMIn)\nlibrary(lmtest)\nlibrary(equatiomatic)\nCode\ndrought_exp &lt;- read_xlsx(path = here(\"data\", \n                                     \"Valliere_etal_EcoApps_Data.xlsx\"),\n                         sheet = \"First Harvest\")\n\n# cleaning\ndrought_exp_clean &lt;- drought_exp %&gt;% \n  clean_names() %&gt;% # nicer column names\n  mutate(species_name = case_when( # adding column with species scientific names\n    species == \"ENCCAL\" ~ \"Encelia californica\", # bush sunflower\n    species == \"ESCCAL\" ~ \"Eschscholzia californica\", # California poppy\n    species == \"PENCEN\" ~ \"Penstemon centranthifolius\", # Scarlet bugler\n    species == \"GRICAM\" ~ \"Grindelia camporum\", # great valley gumweed\n    species == \"SALLEU\" ~ \"Salvia leucophylla\", # Purple sage\n    species == \"STIPUL\" ~ \"Nasella pulchra\", # Purple needlegrass\n    species == \"LOTSCO\" ~ \"Acmispon glaber\" # deerweed\n  )) %&gt;% \n  relocate(species_name, .after = species) %&gt;% # moving species_name column after species\n  mutate(water_treatment = case_when( # adding column with full treatment names\n    water == \"WW\" ~ \"Well watered\",\n    water == \"DS\" ~ \"Drought stressed\"\n  )) %&gt;% \n  relocate(water_treatment, .after = water) # moving water_treatment column after water"
  },
  {
    "objectID": "lecture/lecture_week-09.html#variance-inflation-factor",
    "href": "lecture/lecture_week-09.html#variance-inflation-factor",
    "title": "Week 9 figures - Lecture 16",
    "section": "variance inflation factor",
    "text": "variance inflation factor\nThe VIF for the \\(j^{th}\\) predictor is:\n\\[\nVIF_j = \\frac{1}{1-R\n^2_j}\n\\]\nwhere \\(R^2_J\\) is the \\(R^2\\) value obtained by a model with the \\(j^{th}\\) predictor as a response and the rest of the predictors as predictors.\n\n\nCode\nggpairs(drought_exp_clean, # data frame\n        columns = c(\"leaf_dry_weight_g\", # columns to visualize\n                    \"sla\", \n                    \"shoot_g\", \n                    \"root_g\"), \n        upper = list(method = \"pearson\")) + # calculating Pearson correlation coefficient\n  theme_bw() + # cleaner theme\n  theme(panel.grid = element_blank()) # getting rid of gridlines"
  },
  {
    "objectID": "lecture/lecture_week-09.html#no-interaction",
    "href": "lecture/lecture_week-09.html#no-interaction",
    "title": "Week 9 figures - Lecture 16",
    "section": "no interaction",
    "text": "no interaction\n\n\nCode\nfrog_num &lt;- 30\nset.seed(666)\nfrogs &lt;- tibble(\n  weight = c(\n    round(rnorm(n = frog_num, mean = 5, sd = 0.35), 2),\n    round(rnorm(n = frog_num, mean = 5, sd = 0.35), 2)\n  ),\n  color = c(\n    rep(\"green\", frog_num),\n    rep(\"blue\", frog_num)\n  )\n) %&gt;% \n  mutate(toxicity = case_when(\n    color == \"green\" ~ round(rnorm(n = frog_num, mean = 2, sd = 0.1), 2)*weight - 5,\n    color == \"blue\" ~ round(rnorm(n = frog_num, mean = 2, sd = 0.1), 2)*weight - 3\n  ))\n\nggplot(data = frogs,\n       aes(x = weight,\n           y = toxicity,\n           color = color)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nCode\nfrog_mod &lt;- lm(toxicity ~ weight + color,\n               data = frogs)\n\nsimulateResiduals(frog_mod) %&gt;% plot()\n\n\n\n\n\n\n\n\n\nCode\nsummary(frog_mod)\n\n\n\nCall:\nlm(formula = toxicity ~ weight + color, data = frogs)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.38164 -0.30495  0.01705  0.32444  1.34105 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -1.8311     0.8863  -2.066   0.0434 *  \nweight        1.7407     0.1747   9.966 4.26e-14 ***\ncolorgreen   -1.9444     0.1311 -14.834  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4992 on 57 degrees of freedom\nMultiple R-squared:  0.8713,    Adjusted R-squared:  0.8668 \nF-statistic: 192.9 on 2 and 57 DF,  p-value: &lt; 2.2e-16\n\n\nCode\nggpredict(frog_mod,\n          terms = c(\"weight [all]\",\n                    \"color\")) %&gt;% \n  plot(show_data = TRUE, \n       limit_range = TRUE) +\n  scale_color_manual(values = c(\"green\" = \"darkgreen\", \n                                \"blue\" = \"blue\")) +\n  scale_fill_manual(values = c(\"green\" = \"darkgreen\", \n                                \"blue\" = \"blue\")) +\n  theme_classic() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "lecture/lecture_week-09.html#with-interaction",
    "href": "lecture/lecture_week-09.html#with-interaction",
    "title": "Week 9 figures - Lecture 16",
    "section": "with interaction",
    "text": "with interaction\n\n\nCode\nset.seed(666)\nfrogs &lt;- tibble(\n  weight = c(\n    round(rnorm(n = frog_num, mean = 5, sd = 0.35), 2),\n    round(rnorm(n = frog_num, mean = 5, sd = 0.35), 2)\n  ),\n  color = c(\n    rep(\"green\", frog_num),\n    rep(\"blue\", frog_num)\n  )\n) %&gt;% \n  mutate(toxicity = case_when(\n    color == \"green\" ~ round(rnorm(n = frog_num, mean = -2, sd = 0.1), 2)*weight + 15,\n    color == \"blue\" ~ round(rnorm(n = frog_num, mean = 2, sd = 0.1), 2)*weight - 7\n  ))\n\nggplot(data = frogs,\n       aes(x = weight,\n           y = toxicity,\n           color = color,\n           shape = color)) +\n  geom_point(size = 3,\n             alpha = 0.8) +\n  # scale_x_continuous(limits = c(0, 7)) +\n  scale_color_manual(values = c(\"green\" = \"darkgreen\", \n                                \"blue\" = \"blue\")) \n\n\n\n\n\n\n\n\n\nCode\nfrog_mod1 &lt;- lm(toxicity ~ weight + color, # no interaction\n               data = frogs)\n\nfrog_mod2 &lt;- lm(toxicity ~ weight * color, # interaction\n               data = frogs)\n\nsimulateResiduals(frog_mod1) %&gt;% plot() # no interaction\n\n\n\n\n\n\n\n\n\nCode\nsimulateResiduals(frog_mod2) %&gt;% plot() # interaction\n\n\n\n\n\n\n\n\n\nCode\nsummary(frog_mod1) # no interaction\n\n\n\nCall:\nlm(formula = toxicity ~ weight + color, data = frogs)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.78880 -0.67346 -0.02757  0.54386  2.35344 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   7.6209     1.5994   4.765 1.34e-05 ***\nweight       -0.9243     0.3152  -2.933  0.00483 ** \ncolorgreen    2.0470     0.2365   8.655 5.69e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9008 on 57 degrees of freedom\nMultiple R-squared:  0.6272,    Adjusted R-squared:  0.6141 \nF-statistic: 47.94 on 2 and 57 DF,  p-value: 6.135e-13\n\n\nCode\nsummary(frog_mod2) # interaction\n\n\n\nCall:\nlm(formula = toxicity ~ weight * color, data = frogs)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.36733 -0.31151  0.01057  0.35051  1.39586 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        -6.5225     1.5382  -4.240 8.44e-05 ***\nweight              1.8777     0.3042   6.172 7.96e-08 ***\ncolorgreen         23.0841     1.8689  12.352  &lt; 2e-16 ***\nweight:colorgreen  -4.2056     0.3727 -11.285 4.78e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5023 on 56 degrees of freedom\nMultiple R-squared:  0.8861,    Adjusted R-squared:   0.88 \nF-statistic: 145.3 on 3 and 56 DF,  p-value: &lt; 2.2e-16\n\n\nCode\nmodel.sel(frog_mod1, # no interaction\n          frog_mod2) # interaction\n\n\nModel selection table \n           (Int) clr       wgh clr:wgh df  logLik  AICc delta\nfrog_mod2 -6.523   + 1.000e+00       +  5 -41.749  94.6  0.00\nfrog_mod1  7.621   + 1.162e-15          4 -77.329 163.4 68.78\nModels ranked by AICc(x) \n\n\nCode\nggpredict(frog_mod2,\n          terms = c(\"weight [all]\",\n                    \"color\")) %&gt;% \n  plot(show_data = TRUE, \n       limit_range = TRUE) +\n  scale_color_manual(values = c(\"green\" = \"darkgreen\", \n                                \"blue\" = \"blue\")) +\n  scale_fill_manual(values = c(\"green\" = \"darkgreen\", \n                                \"blue\" = \"blue\")) +\n  theme_classic() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\ncalculating slopes (very hacky):\n\n\nCode\npredictions &lt;- ggpredict(frog_mod2,\n          terms = c(\"weight [all]\",\n                    \"color\")) %&gt;% \n  group_by(group) %&gt;% \n  filter(predicted %in% c(max(predicted), min(predicted))) %&gt;% \n  arrange(group)\n\npredictions\n\n\n# A tibble: 4 × 6\n# Groups:   group [2]\n      x predicted std.error conf.low conf.high group\n  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;\n1  4.22      6.74     0.175    6.39       7.09 green\n2  5.75      3.18     0.203    2.77       3.58 green\n3  4.22      1.40     0.268    0.864      1.94 blue \n4  5.75      4.27     0.232    3.81       4.74 blue \n\n\nCode\n# solve for slopes\ngreen_slope &lt;- (pluck(predictions, 2, 2) - pluck(predictions, 2, 1))/(pluck(predictions, 1, 2) - pluck(predictions, 1, 1))\ngreen_slope\n\n\n[1] -2.327946\n\n\nCode\nblue_slope &lt;- (pluck(predictions, 2, 4) - pluck(predictions, 2, 3))/(pluck(predictions, 1, 4) - pluck(predictions, 1, 3))\nblue_slope  \n\n\n[1] 1.877666\n\n\nCode\n# solve for intercepts\ngreen_intercept &lt;- pluck(predictions, 2, 2) - (green_slope*pluck(predictions, 1, 2))\ngreen_intercept\n\n\n[1] 16.56161\n\n\nCode\nblue_intercept &lt;- pluck(predictions, 2, 4) - (blue_slope*pluck(predictions, 1, 4))\nblue_intercept \n\n\n[1] -6.522534\n\n\nCode\nggpredict(frog_mod2,\n          terms = c(\"weight [5]\",\n                    \"color\"))\n\n\n# Predicted values of toxicity\n\ncolor: green\n\nweight | Predicted |     95% CI\n-------------------------------\n     5 |      4.92 | 4.73, 5.11\n\ncolor: blue\n\nweight | Predicted |     95% CI\n-------------------------------\n     5 |      2.87 | 2.68, 3.05\n\n\nCode\ngreen_slope*5 + green_intercept\n\n\n[1] 4.921879\n\n\nCode\nblue_slope*5 + blue_intercept\n\n\n[1] 2.865798"
  },
  {
    "objectID": "lecture/lecture_week-08.html",
    "href": "lecture/lecture_week-08.html",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(flextable)\nlibrary(GGally)\n\n# data\nlibrary(palmerpenguins)\n\n# analysis\nlibrary(car)\nlibrary(performance)\nlibrary(broom)\nlibrary(DHARMa)\nlibrary(MuMIn)\nlibrary(gtsummary)"
  },
  {
    "objectID": "lecture/lecture_week-08.html#sum-of-squares-for-linear-regression",
    "href": "lecture/lecture_week-08.html#sum-of-squares-for-linear-regression",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "sum of squares for linear regression",
    "text": "sum of squares for linear regression\n\nregression (or model)\n\\[\nSS_{reg} = \\sum_{i = 1}^{n}(\\hat{y} - \\bar{y})^2\n\\]\n\n\nerror\n\\[\nSS_{err} = \\sum_{i = 1}^{n}(y_i - \\hat{y})^2\n\\]\n\n\ntotal\n\\[\nSS_{tot} = \\sum_{i = 1}^n(y_i - \\bar{y})\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-08.html#mean-square",
    "href": "lecture/lecture_week-08.html#mean-square",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "mean square",
    "text": "mean square\n\nregression\n\\[\nMS_{reg} = \\frac{SS_{reg}}{1}\n\\]\n\n\nerror\n\\[\nMS_{err} = \\frac{SS_{err}}{n - 2}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-08.html#f-statistic",
    "href": "lecture/lecture_week-08.html#f-statistic",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "F-statistic",
    "text": "F-statistic\n\\[\nF = \\frac{MS_{reg}}{MS_{err}}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-08.html#plant-growth-dummy-variable",
    "href": "lecture/lecture_week-08.html#plant-growth-dummy-variable",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "plant growth dummy variable",
    "text": "plant growth dummy variable\n\n\nCode\n# humidity units: %\n# plant growth: cm / week\n\nlow_col &lt;- \"#2176ae\"\nmedium_col &lt;- \"#fbb13c\"\nhigh_col &lt;- \"#fe6847\"\n\nn &lt;- 30\nset.seed(10)\nplant_df &lt;- tibble(\n  humidity = round(rnorm(n = n, mean = 60, sd = 15), 0),\n  low = humidity*rnorm(n = n, mean = 0.025, sd = 0.012) + 1,\n  medium = humidity*rnorm(n = n, mean = 0.025, sd = 0.015) + 1.5,\n  high = humidity*rnorm(n = n, mean = 0.025, sd = 0.017) + 2\n) %&gt;% \n  pivot_longer(cols = low:high,\n               names_to = \"fertilizer\", \n               values_to = \"growth\") %&gt;% \n  mutate(fertilizer = fct_relevel(fertilizer, \"low\", \"medium\", \"high\"))\n\n# gives you a random sample\nsample_n(plant_df, 10)\n\n\n# A tibble: 10 × 3\n   humidity fertilizer growth\n      &lt;dbl&gt; &lt;fct&gt;       &lt;dbl&gt;\n 1       71 high         3.01\n 2       42 high         1.90\n 3       58 medium       1.92\n 4       50 low          3.07\n 5       56 low          1.96\n 6       61 low          2.50\n 7       47 medium       4.24\n 8       54 low          2.86\n 9       77 low          3.93\n10       39 medium       1.99\n\n\nCode\n# look at the structure\nstr(plant_df)\n\n\ntibble [90 × 3] (S3: tbl_df/tbl/data.frame)\n $ humidity  : num [1:90] 60 60 60 57 57 57 39 39 39 51 ...\n $ fertilizer: Factor w/ 3 levels \"low\",\"medium\",..: 1 2 3 1 2 3 1 2 3 1 ...\n $ growth    : num [1:90] 1.17 1.89 3.08 2.37 2.53 ...\n\n\nCode\nggplot(data = plant_df,\n       aes(x = humidity,\n           y = growth)) +\n  geom_point() \n\n\n\n\n\n\n\n\n\nCode\nggplot(data = plant_df,\n       aes(x = fertilizer,\n           y = growth,\n           color = fertilizer)) +\n  geom_jitter(width = 0.2,\n              height = 0,\n              alpha = 0.3) +\n  stat_summary(fun.data = mean_cl_normal,\n               geom = \"pointrange\",\n               size = 1,\n               linewidth = 1) +\n  scale_color_manual(values = c(low_col, medium_col, high_col)) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nCode\nplant_df %&gt;% \n  group_by(fertilizer) %&gt;% \n  summarize(mean = mean(growth))\n\n\n# A tibble: 3 × 2\n  fertilizer  mean\n  &lt;fct&gt;      &lt;dbl&gt;\n1 low         2.25\n2 medium      2.82\n3 high        3.51\n\n\nCode\nplant_df %&gt;% \n  summarize(mean = mean(growth))\n\n\n# A tibble: 1 × 1\n   mean\n  &lt;dbl&gt;\n1  2.86\n\n\nCode\nplant_lm &lt;- lm(growth ~ humidity + fertilizer,\n               data = plant_df)\n\n# am i broken because i can't look at anything other than dharma residuals\nsimulateResiduals(plant_lm) %&gt;% plot()\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\nplot(plant_lm)\n\n\n\n\n\n\n\n\n\nCode\nggpredict(plant_lm,\n          terms = c(\"humidity\",\n                    \"fertilizer\")) %&gt;% \n  plot(show_data = TRUE) +\n  scale_color_manual(values = c(low_col, medium_col, high_col)) +\n  scale_fill_manual(values = c(low_col, medium_col, high_col)) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nCode\nggpredict(plant_lm,\n          terms = c(\"humidity\")) %&gt;% \n  plot(show_data = TRUE) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nCode\nggpredict(lm(growth ~ humidity, data = plant_df),\n          terms = \"humidity\") %&gt;% \n  plot(show_data = TRUE) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nCode\nsummary(plant_lm)\n\n\n\nCall:\nlm(formula = growth ~ humidity + fertilizer, data = plant_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.7361 -0.5220  0.1129  0.5353  1.6649 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      1.280788   0.390802   3.277  0.00151 ** \nhumidity         0.017697   0.006615   2.675  0.00894 ** \nfertilizermedium 0.573791   0.207205   2.769  0.00688 ** \nfertilizerhigh   1.264891   0.207205   6.105 2.88e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8025 on 86 degrees of freedom\nMultiple R-squared:  0.3411,    Adjusted R-squared:  0.3182 \nF-statistic: 14.84 on 3 and 86 DF,  p-value: 7.19e-08\n\n\nCode\nsummary(lm(growth ~ humidity, data = plant_df))\n\n\n\nCall:\nlm(formula = growth ~ humidity, data = plant_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.7902 -0.7698 -0.0693  0.5993  1.9402 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 1.893683   0.440513   4.299 4.42e-05 ***\nhumidity    0.017697   0.007833   2.259   0.0263 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9502 on 88 degrees of freedom\nMultiple R-squared:  0.05483,   Adjusted R-squared:  0.04409 \nF-statistic: 5.105 on 1 and 88 DF,  p-value: 0.02633\n\n\nCode\ntbl_regression(plant_lm,\n               label = list(humidity = \"Humidity (%)\",\n                            fertilizer = \"Fertilizer treatment\")) |&gt; \n  as_flex_table() \n\n\nCharacteristicBeta95% CIp-valueHumidity (%)0.020.00, 0.030.009Fertilizer treatmentlow——medium0.570.16, 0.990.007high1.30.85, 1.7&lt;0.001Abbreviation: CI = Confidence Interval"
  },
  {
    "objectID": "lecture/lecture_week-08.html#generating-data",
    "href": "lecture/lecture_week-08.html#generating-data",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "generating data",
    "text": "generating data\n\n\nCode\nset.seed(666)\nfrog_n &lt;- 87\n\nfrog_df &lt;- tibble(\n  weight = (round(rnorm(n = frog_n, mean = 3, sd = 0.1), 2)),\n  blue = round(rnorm(n = frog_n, mean = 2.5, sd = 0.09)*(round(rnorm(n = frog_n, mean = 3, sd = 0.1), 2)), 2),\n  green = round(rnorm(n = frog_n, mean = 3, sd = 0.05)*(round(rnorm(n = frog_n, mean = 3, sd = 0.1), 2)), 2),\n  red = round(rnorm(n = frog_n, mean = 2.3, sd = 0.05)*(round(rnorm(n = frog_n, mean = 3, sd = 0.1), 2)), 2)\n) %&gt;% \n  pivot_longer(cols = blue:red,\n               names_to = \"color\",\n               values_to = \"toxicity\")\n\ndf &lt;- cbind(\n  # predictor variables\n  # color = sample(x = c(\"blue\", \"green\", \"red\"), size = frog_n, replace = TRUE, prob = c(0.3, 0.3, 0.3)),\n  weight = (round(rnorm(n = frog_n, mean = 3, sd = 0.1), 2))\n  #pattern = sample(x = c(\"striped\", \"spotted\", \"none\"), size = frog_n, replace = TRUE, prob = c(0.3, 0.3, 0.3))\n) %&gt;%\n  as_tibble() %&gt;%\n  mutate(toxicity = round(rnorm(n = frog_n, mean = 1.5, sd = 0.06)*weight, 3)) %&gt;%\n  mutate(color = case_when(\n    between(toxicity, 2.5, 4.4) ~ \"blue\",\n    between(toxicity, 4.4, 4.6) ~ \"green\",\n    between(toxicity, 4.6, 5.5) ~ \"red\"\n  )) %&gt;% \n  mutate(toxicity = case_when(\n    color == \"blue\" ~ round(rnorm(n = frog_n, mean = 2.5, sd = 0.09)*weight, 3),\n    color == \"green\" ~ round(rnorm(n = frog_n, mean = 3, sd = 0.05)*weight, 3),\n    color == \"red\" ~ round(rnorm(n = frog_n, mean = 2.3, sd = 0.05)*weight, 3)\n  )) %&gt;% \n  mutate(color = as_factor(color),\n         color = fct_relevel(color, \"red\", \"blue\", \"green\"))\n\n\n# df &lt;- cbind(\n#   color = sample(x = c(\"blue\", \"green\", \"red\"), size = frog_n, replace = TRUE, prob = c(0.3, 0.3, 0.3))\n# ) %&gt;% \n#   as_tibble() %&gt;% \n#   mutate(weight = (round(rnorm(n = frog_n, mean = 3.5, sd = 0.1), 2))) %&gt;% \n#   mutate(toxicity = case_when(\n#     color == \"blue\" ~ round(rnorm(n = frog_n, mean = 3, sd = 0.4)*weight, 2),\n#     color == \"green\" ~ round(rnorm(n = frog_n, mean = 2, sd = 0.5)*weight, 2),\n#     color == \"red\" ~ round(rnorm(n = frog_n, mean = 1, sd = 0.03)*weight, 2)\n#   ))"
  },
  {
    "objectID": "lecture/lecture_week-08.html#plotting-data",
    "href": "lecture/lecture_week-08.html#plotting-data",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "plotting data",
    "text": "plotting data\n\n\nCode\nblue_col &lt;- \"cornflowerblue\"\ngreen_col &lt;- \"darkgreen\"\nred_col &lt;- \"maroon\"\n\nstriped_col &lt;- \"grey1\"\nspotted_col &lt;- \"grey50\"\nnone_col &lt;- \"grey80\"\n\nggplot(data = frog_df, aes(x = color, y = toxicity, color = color, fill = color)) +\n  geom_jitter(width = 0.2, height = 0, alpha = 0.3) +\n  scale_color_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  scale_fill_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  stat_summary(geom = \"pointrange\", \n               fun = mean, \n               fun.min = function(x) mean(x) - sd(x), \n               fun.max = function(x) mean(x) + sd(x), \n               shape = 21, \n               size = 1) +\n #  geom_point(position = position_jitter(width = 0.2, height = 0, seed = 666), alpha = 0.3) +\n  labs(title = \"Color\") +\n  theme(legend.position = \"none\",\n        axis.title.x = element_blank(),\n        text = element_text(size = 22))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = frog_df, aes(x = weight, y = toxicity)) +\n  geom_point() +\n  # geom_smooth(method = \"lm\") +\n  labs(title = \"Weight\") +\n  theme(legend.position = \"none\",\n        axis.title.x = element_blank(),\n        text = element_text(size = 22))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = frog_df, aes(x = weight, y = toxicity, color = color)) +\n  geom_point() +\n  scale_color_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Weight\")\n\n\n\n\n\n\n\n\n\nCode\nhead(df, 10)\n\n\n# A tibble: 10 × 3\n   weight toxicity color\n    &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;\n 1   3.18     8.29 blue \n 2   3.02     9.24 green\n 3   3.01     8.75 green\n 4   3.07     7.24 red  \n 5   2.98     7.47 blue \n 6   2.94     8.89 green\n 7   2.95     7.26 blue \n 8   2.91     7.25 blue \n 9   2.95     6.61 red  \n10   3.06     8.96 green"
  },
  {
    "objectID": "lecture/lecture_week-08.html#model",
    "href": "lecture/lecture_week-08.html#model",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "model",
    "text": "model\n\n\nCode\nmodel1 &lt;- lm(toxicity ~ weight + color, \n             data = frog_df)\n\nmodel2 &lt;- lm(toxicity ~ weight * color, \n             data = frog_df)\n\nsimulateResiduals(model1, plot = TRUE)\n\n\n\n\n\n\n\n\n\nObject of Class DHARMa with simulated residuals based on 250 simulations with refit = FALSE . See ?DHARMa::simulateResiduals for help. \n \nScaled residual values: 0.804 0.556 0.336 0.376 0.5 0.56 0.076 0.74 0.308 0.008 0.416 0.828 0.684 0.204 0.272 0.66 0.172 0.208 0.604 0.708 ...\n\n\nCode\nsimulateResiduals(model2, plot = TRUE)\n\n\n\n\n\n\n\n\n\nObject of Class DHARMa with simulated residuals based on 250 simulations with refit = FALSE . See ?DHARMa::simulateResiduals for help. \n \nScaled residual values: 0.82 0.536 0.336 0.42 0.436 0.572 0.076 0.74 0.3 0.012 0.368 0.84 0.628 0.256 0.244 0.692 0.144 0.212 0.58 0.752 ...\n\n\nCode\ncheck_model(model2)\n\n\n\n\n\n\n\n\n\nCode\ntestOutliers(model2)\n\n\n\n\n\n\n\n\n\n\n    DHARMa outlier test based on exact binomial test with approximate\n    expectations\n\ndata:  model2\noutliers at both margin(s) = 1, observations = 261, p-value = 0.7287\nalternative hypothesis: true probability of success is not equal to 0.007968127\n95 percent confidence interval:\n 9.699839e-05 2.116127e-02\nsample estimates:\nfrequency of outliers (expected: 0.00796812749003984 ) \n                                           0.003831418"
  },
  {
    "objectID": "lecture/lecture_week-08.html#diagnostics",
    "href": "lecture/lecture_week-08.html#diagnostics",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "diagnostics",
    "text": "diagnostics\n\n\nCode\npar(mfrow = c(2, 2))\nplot(model1)\n\n\n\n\n\n\n\n\n\nCode\nplot(model2)"
  },
  {
    "objectID": "lecture/lecture_week-08.html#model-summary",
    "href": "lecture/lecture_week-08.html#model-summary",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "model summary",
    "text": "model summary\n\n\nCode\nsummary(model1)\n\n\n\nCall:\nlm(formula = toxicity ~ weight + color, data = frog_df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.90113 -0.21865 -0.00068  0.22588  0.90229 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  7.71921    0.58381  13.222   &lt;2e-16 ***\nweight      -0.07811    0.19467  -0.401    0.689    \ncolorgreen   1.48908    0.05049  29.490   &lt;2e-16 ***\ncolorred    -0.56874    0.05049 -11.263   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.333 on 257 degrees of freedom\nMultiple R-squared:  0.8733,    Adjusted R-squared:  0.8718 \nF-statistic: 590.6 on 3 and 257 DF,  p-value: &lt; 2.2e-16\n\n\nCode\nsummary(model2)\n\n\n\nCall:\nlm(formula = toxicity ~ weight * color, data = frog_df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.91522 -0.22141 -0.00686  0.21240  0.87930 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         8.2941     1.0119   8.196 1.21e-14 ***\nweight             -0.2702     0.3379  -0.800    0.425    \ncolorgreen          0.1204     1.4311   0.084    0.933    \ncolorred           -0.9248     1.4311  -0.646    0.519    \nweight:colorgreen   0.4573     0.4778   0.957    0.339    \nweight:colorred     0.1189     0.4778   0.249    0.804    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3337 on 255 degrees of freedom\nMultiple R-squared:  0.8738,    Adjusted R-squared:  0.8713 \nF-statistic: 353.1 on 5 and 255 DF,  p-value: &lt; 2.2e-16\n\n\nCode\nmodel.sel(model1, model2)\n\n\nModel selection table \n       (Int) clr   wgh clr:wgh df  logLik  AICc delta\nmodel1 7.719   + 0.832          5 -81.355 172.9   0.0\nmodel2 8.294   + 0.168       +  7 -80.851 176.1   3.2\nModels ranked by AICc(x) \n\n\nCode\nggpredict(model1,\n          terms = c(\"weight [2:4 by = 0.01]\", \n                    \"color\")) %&gt;% \n  plot(show_data = TRUE,\n       limit_range = TRUE) +\n  scale_color_manual(values = c(\"green\" = green_col, \n                                \"red\" = red_col, \n                                \"blue\" = blue_col)) +\n  scale_fill_manual(values = c(\"green\" = green_col, \n                               \"red\" = red_col, \n                               \"blue\" = blue_col)) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nCode\nggpredict(model2,\n          terms = c(\"weight [2:4 by = 0.01]\", \n                    \"color\")) %&gt;% \n  plot(show_data = TRUE,\n       limit_range = TRUE) +\n  scale_color_manual(values = c(\"green\" = green_col, \n                                \"red\" = red_col, \n                                \"blue\" = blue_col)) +\n  scale_fill_manual(values = c(\"green\" = green_col, \n                               \"red\" = red_col, \n                               \"blue\" = blue_col)) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\\[\n\\hat{y}_h \\pm t_{(1-\\alpha/2, n-2)}*\\sqrt{MSE*(\\frac{1}{n}+\\frac{(x_h-\\bar{x})^2}{\\sum(x_i-\\bar{x})^2})}\n\\]\n\\[\nMSE = \\frac{\\sum(y_i-\\hat{y})^2}{n}\n\\]\n\n\nCode\ntidy(model2, conf.int = TRUE, conf.level = 0.95)\n\n\n# A tibble: 6 × 7\n  term              estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)          8.29      1.01     8.20   1.21e-14    6.30     10.3  \n2 weight              -0.270     0.338   -0.800  4.25e- 1   -0.936     0.395\n3 colorgreen           0.120     1.43     0.0841 9.33e- 1   -2.70      2.94 \n4 colorred            -0.925     1.43    -0.646  5.19e- 1   -3.74      1.89 \n5 weight:colorgreen    0.457     0.478    0.957  3.39e- 1   -0.484     1.40 \n6 weight:colorred      0.119     0.478    0.249  8.04e- 1   -0.822     1.06 \n\n\n\n\nCode\nmodel_summary &lt;- summary(model2)\nc(\"lower\" = model_summary$coef[2,1] - qt(0.975, df = model_summary$df[2]) * model_summary$coef[2, 2],\n  \"upper\" = model_summary$coef[2,1] + qt(0.975, df = model_summary$df[2]) * model_summary$coef[2, 2])\n\n\n     lower      upper \n-0.9355103  0.3951563 \n\n\nConfidence interval for a single coefficient: in words: estimate plus or minus the t-value at your confidence level * standard error"
  },
  {
    "objectID": "lecture/lecture_week-04.html",
    "href": "lecture/lecture_week-04.html",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\n\n# cohen's d\nlibrary(effectsize)\n\n# power\nlibrary(pwr)"
  },
  {
    "objectID": "lecture/lecture_week-04.html#set-up",
    "href": "lecture/lecture_week-04.html#set-up",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\n\n# cohen's d\nlibrary(effectsize)\n\n# power\nlibrary(pwr)"
  },
  {
    "objectID": "lecture/lecture_week-04.html#math",
    "href": "lecture/lecture_week-04.html#math",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "1. Math",
    "text": "1. Math\n\na. Cohen’s d\n\\[\nCohen's \\; d = \\frac{\\bar{y_A} - \\bar{y_B}}{\\sqrt{(s^2_A + s^2_B)/2}}\n\\]\n\n\nb. Cohen’s d with separated SD\n\\[\nCohen's \\; d = \\frac{\\bar{y_A} - \\bar{y_B}}{\\sqrt{\\frac{(n_A - 1)\\times s^2_A + (n_B - 1)\\times s^2_B}{n_A + n_B - 2}}}\n\\]\n\n\nb. confidence interval for two-sample t-test\n\\[\nCI = (\\bar{y_A} - \\bar{y_B}) \\pm t \\times \\sqrt{\\frac{(n_A - 1)s_A^2 + (n_B - 1)s_B^2}{n_A+n_B-2}} \\times \\sqrt{\\frac{1}{n_A}+\\frac{1}{n_B}}\n\\]\n\n\nc. test statistic for paired t-test\n\\[\nt_s = \\frac{\\bar{y}_d - \\mu_0}{s_d - \\sqrt{n}}\n\\]\n\n\nd. standard error for two-sample t-test\nIf variances are not equal:\n\\[\nSE_{\\bar{y_A} - \\bar{y_B}} = \\sqrt{\\frac{s_A^2}{n_A}+\\frac{s_B^2}{n_B}}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-04.html#interpret-this-output",
    "href": "lecture/lecture_week-04.html#interpret-this-output",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "2. Interpret this output",
    "text": "2. Interpret this output\nYou have two raised beds in which you’re growing tomatoes. One bed is in the sun, but the other is in shade. You want to know if the weight of the tomatoes is different between beds. You measure 33 tomatoes from each bed.\n\n\nCode\ntomatoes &lt;- cbind(sunny = rnorm(n = 33, mean = 150, sd = 20),\n                  shaded = rnorm(n = 33, mean = 130, sd = 10)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"sun_level\", values_to = \"weight_g\")\n\nggplot(data = tomatoes,\n       aes(x = sun_level,\n           y = weight_g)) +\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\n\nCode\nvar.test(weight_g ~ sun_level,\n         data = tomatoes)\n\n\n\n    F test to compare two variances\n\ndata:  weight_g by sun_level\nF = 0.24646, num df = 32, denom df = 32, p-value = 0.0001527\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1217225 0.4990146\nsample estimates:\nratio of variances \n         0.2464575 \n\n\nCode\nt.test(weight_g ~ sun_level,\n       data = tomatoes,\n       var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  weight_g by sun_level\nt = -6.6939, df = 46.87, p-value = 2.412e-08\nalternative hypothesis: true difference in means between group shaded and group sunny is not equal to 0\n95 percent confidence interval:\n -33.27431 -17.89509\nsample estimates:\nmean in group shaded  mean in group sunny \n            127.4624             153.0471"
  },
  {
    "objectID": "lecture/lecture_week-04.html#power-analysis",
    "href": "lecture/lecture_week-04.html#power-analysis",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "3. Power analysis",
    "text": "3. Power analysis\n\n\nCode\n# higher power\npwr.t.test(n = NULL, d = 0.7, sig.level = 0.05, power = 0.95)\n\n\n\n     Two-sample t test power calculation \n\n              n = 54.01938\n              d = 0.7\n      sig.level = 0.05\n          power = 0.95\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nCode\n# lower power\npwr.t.test(n = NULL, d = 0.7, sig.level = 0.05, power = 0.80)\n\n\n\n     Two-sample t test power calculation \n\n              n = 33.02457\n              d = 0.7\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group"
  },
  {
    "objectID": "lecture/lecture_week-04.html#write-about-this-result",
    "href": "lecture/lecture_week-04.html#write-about-this-result",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "4. Write about this result",
    "text": "4. Write about this result\nYou have two worm compost bins: one in which you throw citrus peels, and the other in which you don’t. You’re curious to see if the citrus worms are bigger than the non-citrus worms. You measure 34 worms from each bin and find this result:\n\n\nCode\nworms &lt;- cbind(citrus = rnorm(n = 34, mean = 140, sd = 20),\n               non_citrus = rnorm(n = 34, mean = 160, sd = 15)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"compost_bin\", values_to = \"weight_g\")\n\nggplot(data = worms,\n       aes(x = compost_bin,\n           y = weight_g)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nCode\nvar.test(weight_g ~ compost_bin,\n         data = worms)\n\n\n\n    F test to compare two variances\n\ndata:  weight_g by compost_bin\nF = 1.005, num df = 33, denom df = 33, p-value = 0.9886\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.5019252 2.0123262\nsample estimates:\nratio of variances \n          1.005006 \n\n\nCode\nt.test(weight_g ~ compost_bin,\n       data = worms,\n       var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  weight_g by compost_bin\nt = -7.2003, df = 66, p-value = 7.126e-10\nalternative hypothesis: true difference in means between group citrus and group non_citrus is not equal to 0\n95 percent confidence interval:\n -32.57036 -18.42879\nsample estimates:\n    mean in group citrus mean in group non_citrus \n                135.7626                 161.2622"
  },
  {
    "objectID": "lecture/lecture_week-04.html#effect-size-examples",
    "href": "lecture/lecture_week-04.html#effect-size-examples",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "5. Effect size examples",
    "text": "5. Effect size examples\n\na. large sample size, small difference\n\\[\n\\bar{y_a} - \\bar{y_b}\n\\]\n\n\nCode\nset.seed(1)\ndata &lt;- cbind(a = rnorm(n = 100, mean = 10, sd = 2), \n               b = rnorm(n = 100, mean = 11, sd = 2)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"group\", values_to = \"value\") %&gt;% \n  group_by(group)\n\nset.seed(1)\nlarge &lt;- data %&gt;% \n  slice_sample(n = 40)\n\nggplot(data = large,\n       aes(x = group,\n           y = value)) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_se) +\n  scale_y_continuous(limits = c(5, 16)) \n\n\n\n\n\n\n\n\n\nCode\nt.test(value ~ group,\n       data = large,\n       var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  value by group\nt = -2.9666, df = 78, p-value = 0.003996\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -2.1892413 -0.4308888\nsample estimates:\nmean in group a mean in group b \n       9.819199       11.129264 \n\n\nCode\nset.seed(1)\nsmall &lt;- data %&gt;% \n  slice_sample(n = 20)\n\nggplot(data = small,\n       aes(x = group,\n           y = value)) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_se) +\n  scale_y_continuous(limits = c(5, 16)) \n\n\n\n\n\n\n\n\n\nCode\nt.test(value ~ group,\n       data = small,\n       var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  value by group\nt = -1.5737, df = 38, p-value = 0.1238\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -1.9408171  0.2431029\nsample estimates:\nmean in group a mean in group b \n       10.23925        11.08811 \n\n\nCode\nset.seed(1)\n\nsmall &lt;- cbind(a = MASS::mvrnorm(n = 10, mu = 16.5, Sigma = 2, empirical = TRUE),\n               b = MASS::mvrnorm(n = 10, mu = 17, Sigma = 2, empirical = TRUE)) %&gt;% \n  as.data.frame() %&gt;% \n  rename(\"a\" = \"V1\", \"b\" = \"V2\") %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"group\", values_to = \"value\")\n# small &lt;- cbind(a = rnorm(n = 10, mean = 14, sd = 3), \n#                b = rnorm(n = 10, mean = 17, sd = 3)) %&gt;% \n#   as_tibble() %&gt;% \n#   pivot_longer(cols = 1:2, names_to = \"group\", values_to = \"value\")\nggplot(data = small,\n       aes(x = group,\n           y = value)) +\n  geom_point(size = 3,\n             shape = 21,\n             aes(color = group),\n             position = position_jitter(\n               width = 0.15,\n               height = 0,\n               seed = 10\n             )) +\n  stat_summary(geom = \"point\",\n               fun = mean,\n               color = \"red\",\n               size = 4) +\n  # scale_y_continuous(limits = c(5, 16),\n  #                    breaks = c(6, 9, 12, 15)) +\n  scale_color_manual(values = c(\"darkblue\", \"darkgreen\")) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = small,\n       aes(x = value)) +\n  geom_density(aes(fill = group),\n               alpha = 0.4)\n\n\n\n\n\n\n\n\n\nCode\nt.test(value ~ group,\n       data = small,\n       var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  value by group\nt = -0.79057, df = 18, p-value = 0.4395\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -1.8287398  0.8287398\nsample estimates:\nmean in group a mean in group b \n           16.5            17.0 \n\n\nCode\ncohens_d(value ~ group,\n         data = small,\n         pooled_sd = FALSE)\n\n\nCohen's d |        95% CI\n-------------------------\n-0.35     | [-1.23, 0.54]\n\n- Estimated using un-pooled SD.\n\n\nCode\nset.seed(1)\nlarge &lt;- cbind(a = MASS::mvrnorm(n = 100, mu = 16.5, Sigma = 2, empirical = TRUE),\n               b = MASS::mvrnorm(n = 100, mu = 17, Sigma = 2, empirical = TRUE)) %&gt;% \n  as.data.frame() %&gt;% \n  rename(\"a\" = \"V1\", \"b\" = \"V2\") %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"group\", values_to = \"value\")\nggplot(data = large,\n       aes(x = group,\n           y = value)) +\n  geom_point(size = 3,\n             shape = 21,\n             aes(color = group),\n             position = position_jitter(\n               width = 0.15,\n               height = 0,\n               seed = 10\n             )) +\n  stat_summary(geom = \"point\",\n               fun = mean,\n               color = \"red\",\n               size = 4) +\n\n  # scale_y_continuous(limits = c(5, 16),\n  #                    breaks = c(6, 9, 12, 15)) +\n  scale_color_manual(values = c(\"darkblue\", \"darkgreen\")) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = large,\n       aes(x = value)) +\n  geom_histogram(aes(fill = group),\n               alpha = 0.4)\n\n\n\n\n\n\n\n\n\nCode\nt.test(value ~ group,\n       data = large,\n       var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  value by group\nt = -2.5, df = 198, p-value = 0.01323\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -0.8944035 -0.1055965\nsample estimates:\nmean in group a mean in group b \n           16.5            17.0 \n\n\nCode\ncohens_d(value ~ group,\n         data = large,\n         pooled_sd = FALSE)\n\n\nCohen's d |         95% CI\n--------------------------\n-0.35     | [-0.63, -0.07]\n\n- Estimated using un-pooled SD.\n\n\n\n\nb. needlegrass example\n\n\nCode\nset.seed(1)\nneedlegrass &lt;- cbind(ungrazed = rnorm(n = 35, mean = 82, sd = 6), \n                     grazed = rnorm(n = 35, mean = 74, sd = 5)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"plot_type\", values_to = \"height_cm\")\n\n# boxplot\nggplot(data = needlegrass,\n       aes(x = plot_type,\n           y = height_cm,\n           color = plot_type)) +\n  geom_boxplot(outliers = FALSE,\n               linewidth = 1) +\n  geom_point(position = position_jitter(\n    width = 0.1, \n    height = 0.1,\n    seed = 10\n  ),\n  alpha = 0.4,\n  size = 1) +\n    scale_color_manual(values = c(\"darkgreen\", \"cornflowerblue\")) \n\n\n\n\n\n\n\n\n\nCode\n# plot without all the adjustments\nggplot(data = needlegrass,\n       aes(x = plot_type,\n           y = height_cm,\n           color = plot_type)) +\n  geom_point(position = position_jitter(width = 0.1, height = 0, seed = 10),\n             alpha = 0.2) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_cl_normal) \n\n\n\n\n\n\n\n\n\nCode\n# \"finalized\" plot\nggplot(data = needlegrass,\n       aes(x = plot_type,\n           y = height_cm,\n           color = plot_type)) +\n  geom_point(position = position_jitter(width = 0.1, height = 0, seed = 10),\n             alpha = 0.2) +\n  scale_color_manual(values = c(\"darkgreen\", \"cornflowerblue\")) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_cl_normal,\n               size = 1,\n               linewidth = 1) +\n  labs(x = \"Plot type\",\n       y = \"Height (cm)\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nDoing a t-test:\n\n\nCode\nvar.test(height_cm ~ plot_type,\n       data = needlegrass)\n\n\n\n    F test to compare two variances\n\ndata:  height_cm by plot_type\nF = 0.72641, num df = 34, denom df = 34, p-value = 0.3559\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.366669 1.439115\nsample estimates:\nratio of variances \n         0.7264149 \n\n\nCode\nt.test(height_cm ~ plot_type,\n       data = needlegrass)\n\n\n\n    Welch Two Sample t-test\n\ndata:  height_cm by plot_type\nt = -5.9471, df = 66.334, p-value = 1.127e-07\nalternative hypothesis: true difference in means between group grazed and group ungrazed is not equal to 0\n95 percent confidence interval:\n -9.720197 -4.834401\nsample estimates:\n  mean in group grazed mean in group ungrazed \n              75.18323               82.46053 \n\n\nCode\nvect &lt;- dt(x = seq(from = -10, to = 10, by = 0.5), df = 66.334) %&gt;% \n  enframe()\n\nggplot(data = vect,\n       aes(x = name,\n           y = value)) +\n  geom_line() +\n  geom_vline(xintercept = -5.9471)\n\n\n\n\n\n\n\n\n\nCohen’s d:\n\n\nCode\n# pooled SD\ncohens_d(height_cm ~ plot_type,\n       data = needlegrass)\n\n\nCohen's d |         95% CI\n--------------------------\n-1.42     | [-1.94, -0.89]\n\n- Estimated using pooled SD.\n\n\nCode\n# unpooled SD\ncohens_d(height_cm ~ plot_type,\n       data = needlegrass, \n       pooled_sd = FALSE)\n\n\nCohen's d |         95% CI\n--------------------------\n-1.42     | [-1.94, -0.89]\n\n- Estimated using un-pooled SD.\n\n\nCode\n# by hand\nneedlegrass_sum &lt;- needlegrass %&gt;% \n  group_by(plot_type) %&gt;% \n  reframe(\n    mean = mean(height_cm),\n    var = var(height_cm),\n    n = length(height_cm)\n  )\n\nya &lt;- pluck(needlegrass_sum, 2, 1)\nyb &lt;- pluck(needlegrass_sum, 2, 2)\nvara &lt;- pluck(needlegrass_sum, 3, 1)\nvarb &lt;- pluck(needlegrass_sum, 3, 2)\nna &lt;- pluck(needlegrass_sum, 4, 1)\nnb &lt;- pluck(needlegrass_sum, 4, 2)\n\n# by hand\n\n(ya - yb)/sqrt((vara + varb)/2)\n\n\n[1] -1.421636\n\n\nCode\n(ya - yb)/sqrt(\n  ((na - 1)*vara + (nb - 1)*varb)/(na + nb - 2)\n)\n\n\n[1] -1.421636"
  },
  {
    "objectID": "lecture/lecture_week-04.html#good-and-bad-results-statements",
    "href": "lecture/lecture_week-04.html#good-and-bad-results-statements",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "6. good and bad results statements",
    "text": "6. good and bad results statements\n\n\nCode\nmanaged &lt;- rnorm(n = 33, mean = 5, sd = 1) %&gt;% \n  enframe() %&gt;% \n  mutate(treatment = \"managed\")\nnonintervention &lt;- rnorm(n = 30, mean = 7, sd = 1) %&gt;% \n  enframe() %&gt;% \n  mutate(treatment = \"non-intervention\") \npools &lt;- rbind(managed, nonintervention) %&gt;% \n  select(treatment, value) %&gt;% \n  rename(temp = value)\nvar.test(temp ~ treatment,\n         data = pools)\n\n\n\n    F test to compare two variances\n\ndata:  temp by treatment\nF = 1.287, num df = 32, denom df = 29, p-value = 0.4953\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.6197933 2.6377877\nsample estimates:\nratio of variances \n          1.286962 \n\n\nCode\nt.test(temp ~ treatment,\n       data = pools)\n\n\n\n    Welch Two Sample t-test\n\ndata:  temp by treatment\nt = -11.206, df = 60.948, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group managed and group non-intervention is not equal to 0\n95 percent confidence interval:\n -2.558536 -1.783706\nsample estimates:\n         mean in group managed mean in group non-intervention \n                      4.952439                       7.123560 \n\n\nCode\ncohens_d(temp ~ treatment,\n       data = pools)\n\n\nCohen's d |         95% CI\n--------------------------\n-2.81     | [-3.51, -2.10]\n\n- Estimated using pooled SD.\n\n\nStatement: Our data suggest a difference in water temperature between managed (n = 33) and non-intervention (i.e. control, n = 30) vernal pools, with a strong (Cohen’s d = 2.19) effect of management.\nTemperatures in managed pools were different from those in non-intervention pools (two-tailed two-sample t-test, t(60.9) = -8.7, p &lt; 0.001, ⍺ = 0.05); on average, managed pools were 5.3 °C, while control pools were 7.1 °C."
  },
  {
    "objectID": "lecture/lecture_week-04.html#qqhistograms",
    "href": "lecture/lecture_week-04.html#qqhistograms",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "7. QQ/histograms",
    "text": "7. QQ/histograms\n\n\nCode\nset.seed(666)\ndata1 &lt;- rnorm(n = 30, mean = 15, sd = 2) |&gt; \n  enframe()\n\nggplot(data = data1,\n       aes(x = value)) +\n  geom_histogram(bins = 6,\n                 fill = \"cornflowerblue\",\n                 color = \"black\") +\n  scale_y_continuous(expand = c(0, 0))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = data1,\n       aes(sample = value)) +\n  geom_qq_line(color = \"black\") +\n  geom_qq(color = \"cornflowerblue\",\n          size = 4)\n\n\n\n\n\n\n\n\n\nCode\nset.seed(666)\ndata2 &lt;- rgamma(n = 30, shape = 0.5) |&gt; \n  enframe()\n\nggplot(data = data2,\n       aes(x = value)) +\n  geom_histogram(bins = 6,\n                 fill = \"orange\",\n                 color = \"black\") +\n  scale_y_continuous(expand = c(0, 0))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = data2,\n       aes(sample = value)) +\n  geom_qq_line(color = \"black\") +\n  geom_qq(color = \"orange\",\n          size = 4)"
  },
  {
    "objectID": "lecture/lecture_week-06.html",
    "href": "lecture/lecture_week-06.html",
    "title": "Week 6 figures - Lecture 11",
    "section": "",
    "text": "\\[\n\\begin{align}\n\\chi^2 &= \\sum\\frac{(O - E)^2}{E} \\\\\n&= \\frac{55 - 47.2}{47.2} +...+\\frac{45-31.9}{31.9} \\\\\n&= 15.276\n\\end{align}\n\\]\n\n\n\n\\[\n\\begin{align}\nexpected &= \\frac{row \\, total \\times column \\, total}{table \\, total} \\\\\n&= \\frac{126 \\times 118}{315} \\\\\n&= 47.2\n\\end{align}\n\\]\n\n\n\n\\[\ndf = (number\\;of\\;rows - 1) \\times (number\\;of\\;columns - 1)\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-06.html#math",
    "href": "lecture/lecture_week-06.html#math",
    "title": "Week 6 figures - Lecture 11",
    "section": "",
    "text": "\\[\n\\begin{align}\n\\chi^2 &= \\sum\\frac{(O - E)^2}{E} \\\\\n&= \\frac{55 - 47.2}{47.2} +...+\\frac{45-31.9}{31.9} \\\\\n&= 15.276\n\\end{align}\n\\]\n\n\n\n\\[\n\\begin{align}\nexpected &= \\frac{row \\, total \\times column \\, total}{table \\, total} \\\\\n&= \\frac{126 \\times 118}{315} \\\\\n&= 47.2\n\\end{align}\n\\]\n\n\n\n\\[\ndf = (number\\;of\\;rows - 1) \\times (number\\;of\\;columns - 1)\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-06.html#code",
    "href": "lecture/lecture_week-06.html#code",
    "title": "Week 6 figures - Lecture 11",
    "section": "2. Code",
    "text": "2. Code\n\na. data\n\n\nCode\n# creating matrix of survey results\nsurvey &lt;- matrix(\n  c(55, 38, 33, 41, 25, 29, 22, 27, 45),\n  nrow = 3,\n  ncol = 3,\n  byrow = TRUE,\n  dimnames = list(c(\"walking_distance\", \"driving_distance\", \"out_of_town\"),\n                  c(\"trails\", \"dog_access\", \"wildlife_viewing\"))\n)\n\n# displaying survey results\nsurvey\n\n\n                 trails dog_access wildlife_viewing\nwalking_distance     55         38               33\ndriving_distance     41         25               29\nout_of_town          22         27               45\n\n\n\n\nb. calculating critical value\n\n\nCode\ncritical_value &lt;- qchisq(p = 0.05, # probability (area under curve)\n                         df = 4, # degrees of freedom\n                         lower.tail = FALSE) # calculate boundary where 0.05 is to the right\n\ncritical_value\n\n\n[1] 9.487729\n\n\n\n\nc. calculating p-value\n\n\nCode\np_value &lt;- pchisq(q = 15.276, # test statistic\n       df = 4, # degrees of freedom\n       lower.tail = FALSE) # calculate probability (area under the curve) to the RIGHT of the test statistic\n\np_value\n\n\n[1] 0.004161711\n\n\n\n\nd. using chisq.test() function\n\n\nCode\nchisq.test(survey)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  survey\nX-squared = 15.276, df = 4, p-value = 0.004162"
  },
  {
    "objectID": "lecture/lecture_week-03.html",
    "href": "lecture/lecture_week-03.html",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\n\n# calculate effect size\nlibrary(effsize)\n\n# visualization\nlibrary(patchwork)"
  },
  {
    "objectID": "lecture/lecture_week-03.html#set-up",
    "href": "lecture/lecture_week-03.html#set-up",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\n\n# calculate effect size\nlibrary(effsize)\n\n# visualization\nlibrary(patchwork)"
  },
  {
    "objectID": "lecture/lecture_week-03.html#math",
    "href": "lecture/lecture_week-03.html#math",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "1. Math",
    "text": "1. Math\n\na. test statistic for one sample t-test\n\\[\nt = \\frac{\\bar{y} - \\mu}{s/\\sqrt{n}}\n\\]\n\n\nb. two sample t-test when variances are equal (Student’s)\n\\[\nt = \\frac{\\bar{y_A} - \\bar{y_B}}{s_p \\times \\sqrt{\\frac{1}{N_A + N_B}}}\n\\]\n\\[\ndf = (N_A - 1) + (N_B - 1)\n\\]\n\n\nc. when variances are not equal (Welch’s)\n\\[\nt = \\frac{\\bar{y_A} - \\bar{y_B}}{\\sqrt{\\frac{s_A^2}{N_A}+\\frac{s_B^2}{N_B}}}\n\\]\n\\[\ndf = \\frac{(\\frac{s_A^2}{N_A}+\\frac{S_B^2}{N_B})^2}{\\frac{(\\frac{s_A^2}{N_A})^2}{N_A-1}+\\frac{(\\frac{s_B^2}{N_B})^2}{N_B-1}}\n\\]\n\n\nd. test statistic for F test\n\\[\nF =  \\frac{s^2_A}{s^2_B}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-03.html#central-limit-theorem",
    "href": "lecture/lecture_week-03.html#central-limit-theorem",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "2. central limit theorem",
    "text": "2. central limit theorem\nIf you were to sample a bunch of times from any distribution (i.e. take many observations within a sample, take many observations in another sample), the mean values for each sample will be normally distributed. Kareem Carr has a nice explainer of how this works here.\n\n\nCode\n# randomly select 10000 numbers from a uniform distribution for the population\nuniform &lt;- runif(10000, min = 2, max = 8)\n\n# make a histogram for the population\nuniformdf &lt;- as.data.frame(uniform)\n\nggplot(uniformdf, aes(x = uniform)) +\n  geom_histogram(breaks = seq(2, 8, length.out = 41), fill = \"firebrick\", alpha = 0.7, color = \"firebrick\") +\n  geom_vline(xintercept = mean(uniform), linewidth = 2) +\n  annotate(\"text\", x = 4, y = 290, label = \"mean = 4.967\", size = 10) +\n  scale_x_continuous(breaks = seq(from = 2, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 305)) +\n  labs(x = \"Continuous value\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# for() loop to \nstore2 &lt;- c()\nstore5 &lt;- c()\nstore15 &lt;- c()\nstore30 &lt;- c()\nstore50 &lt;- c()\n\nfor(i in 1:100) {\n  \n  # sample 100x\n  store2[i] &lt;- mean(sample(uniform, 2, replace = FALSE))\n  store5[i] &lt;- mean(sample(uniform, 5, replace = FALSE))\n  store15[i] &lt;- mean(sample(uniform, 15, replace = FALSE))\n  store30[i] &lt;- mean(sample(uniform, 30, replace = FALSE))\n  store50[i] &lt;- mean(sample(uniform, 50, replace = FALSE))\n\n}\n\n\ndf &lt;- cbind(store2, store5, store15, store30, store50) %&gt;% \n  as.data.frame()\n  \nggplot(df) +\n  geom_histogram(aes(x = store2), bins = 10, alpha = 0.7, fill = \"chocolate1\", color = \"chocolate1\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store2)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store5), bins = 10, alpha = 0.7, fill = \"blue3\", color = \"blue3\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store5)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store15), bins = 12, alpha = 0.7, fill = \"darkorchid4\", color = \"darkorchid4\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store15)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store30), bins = 12, alpha = 0.7, fill = \"lightseagreen\", color = \"lightseagreen\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store30)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store50), bins = 12, alpha = 0.7, fill = \"violetred3\", color = \"violetred3\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store50)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))"
  },
  {
    "objectID": "lecture/lecture_week-03.html#z--vs-t-distribution",
    "href": "lecture/lecture_week-03.html#z--vs-t-distribution",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "3. z- vs t-distribution",
    "text": "3. z- vs t-distribution\n\na. comparison with normal\nt-distributions allow for more uncertainty around the tails.\n\n\nCode\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1, color = \"darkorange\") +\n  annotate(\"text\", x = 2.5, y = 0.4, label = \"normal\", color = \"darkorange\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#856F33\") +\n  annotate(\"text\", x = 3, y = 0.32, label = \"t-distribution (small n)\", color = \"#856F33\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 10), linewidth = 1, color = \"#56E9E7\") +\n  annotate(\"text\", x = 3, y = 0.37, label = \"t-distribution (large n)\", color = \"#56E9E7\", size = 6) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\n\n\nb. visual representation of significance and t-statistic\n\n\nCode\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 19), xlim = c(1.8, 5), fill = \"#0070c0\") +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 19), xlim = c(-5, -1.8), fill = \"#0070c0\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 19), linewidth = 1, color = \"#000000\") +\n  geom_hline(yintercept = 0) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.4)) +\n  theme_void() +\n  theme(panel.grid = element_blank(),\n        plot.margin = unit(c(1, 0, 0, 0), \"cm\"))"
  },
  {
    "objectID": "lecture/lecture_week-03.html#qqplot-examples",
    "href": "lecture/lecture_week-03.html#qqplot-examples",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "5. qqplot examples",
    "text": "5. qqplot examples\nWe use qqplots (quantile-quantile plots) to visually evaluate the normality of some variable. The x-axis is the “theoretical” quantile, and the y-axis is the “sample” quantile. If the points follow a 1:1 line, then the variable is normally distributed.\nThe New Haven temperature data is normally distributed:\n\n\nCode\nnhtemp_hist &lt;- as_tibble(nhtemp) %&gt;% \n  ggplot(aes(x = x)) +\n  geom_histogram(breaks = seq(47, 55, length.out = 9), fill = \"turquoise3\", color = \"#000000\") +\n  scale_x_continuous(breaks = seq(47, 55, length.out = 9), expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 23)) +\n  theme_classic() +\n  labs(x = \"Bins\", y = \"Count\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nnhtemp_qq &lt;- ggplot(as_tibble(nhtemp)) +\n  stat_qq(aes(sample = x), color = \"turquoise3\", size = 3) +\n  labs(x = \"Theoretical quantile\", y = \"Sample quantile\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nnhtemp_hist + nhtemp_qq\n\n\n\n\n\n\n\n\n\nThe sunspot data is not:\n\n\nCode\nsunspot_hist &lt;- as_tibble(sunspots) %&gt;% \n  ggplot(aes(x = x)) +\n  geom_histogram(breaks = round(seq(0, 260, length.out = 30)), fill = \"tomato2\", color = \"#000000\") +\n  scale_x_continuous(breaks = round(seq(0, 260, length.out = 30)), expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 480)) +\n  theme_classic() +\n  labs(x = \"Bins\", y = \"Count\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nsunspot_qq &lt;- ggplot(as_tibble(sunspots)) +\n  stat_qq(aes(sample = x), color = \"tomato2\", size = 3) +\n  theme_classic() +\n  labs(x = \"Theoretical quantile\", y = \"Sample quantile\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nsunspot_hist \n\n\n\n\n\n\n\n\n\nCode\nsunspot_qq"
  },
  {
    "objectID": "lecture/lecture_week-03.html#one-sample-t-test-example",
    "href": "lecture/lecture_week-03.html#one-sample-t-test-example",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "6. One sample t-test example",
    "text": "6. One sample t-test example\nThis is the creosote example from lecture.\n\ngenerating numbers\n\n\nCode\nset.seed(1)\ncreosote &lt;- rnorm(n = 41, mean = 1.8, sd = 0.3) %&gt;% \n  round(digits = 2) \n\n\n\n\nhistogram and qq plot\n\n\nCode\n# calculate the range\nrange &lt;- max(creosote) - min(creosote)\n\n# determine the number of observations\nobs &lt;- length(creosote)\n\n# calculate the number of bins using the Rice Rule\n# note that this doesn't come out to a whole number, so it's rounded\nbins &lt;- 2*(obs^(1/3)) %&gt;% \n  round(digits = 0)\n\n# calculate the width of the bin\nbinwidth &lt;- range/(bins - 1)\n\n# set up a sequence of numbers from 0 to 100\nseq &lt;- seq(from = 1, to = 11, by = 1)\n\n# calculate the axis breaks  \naxis_breaks &lt;- seq*binwidth + (binwidth/2)\n\n# round the axis breaks\naxis_breaks_rounded &lt;- round(axis_breaks, \n                             digits = 3)\n\nhist &lt;- creosote %&gt;% \n  enframe() %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(binwidth = binwidth,\n                 fill = \"#e3c922\",\n                 color = \"black\") +\n  scale_x_continuous(breaks = axis_breaks_rounded) +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 14)) +\n  labs(x = \"Creosote height (m)\",\n       y = \"Count\")\n\nqq &lt;- creosote %&gt;% \n  enframe() %&gt;% \n  ggplot(aes(sample = value)) +\n  geom_qq_line() +\n  geom_qq(color = \"#e3c922\",\n          size = 4,\n          alpha = 0.8) \n\nhist + qq\n\n\n\n\n\n\n\n\n\n\n\ncalculating a critical value\n\n\nCode\nt_critical &lt;- qt(p = 0.05/2, df = 40, lower.tail = FALSE)\nt_critical\n\n\n[1] 2.021075\n\n\n\n\ncalculating t-score\n“By hand”:\n\n\nCode\n# claimed mean\nmu &lt;- 3\n\n# number of observations\nn &lt;- length(creosote)\n\n# sample mean\nybar &lt;- mean(creosote)\n\n# sample standard deviation\ns &lt;- sd(creosote)\n\n# sample standard error\nse &lt;- s/sqrt(n)\n\n# t-score\nt &lt;- (ybar-mu)/se\n\nt\n\n\n[1] -28.56624\n\n\nUsing t.test()\n\n\nCode\nt.test(creosote, mu = 3)\n\n\n\n    One Sample t-test\n\ndata:  creosote\nt = -28.566, df = 40, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 3\n95 percent confidence interval:\n 1.743305 1.909378\nsample estimates:\nmean of x \n 1.826341 \n\n\nManually calculating p-value:\n\n\nCode\n# manually calculating p-value\n# two-tailed: multiply probability by 2\n# lower = FALSE: probability of the value being more than t\n2*pt(q = t, df = n - 1, lower = TRUE)\n\n\n[1] 3.158646e-28\n\n\n\n\nvisual representation of sample t-statistic vs t-critical\n\n\nCode\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(t_critical, 5), fill = \"darkgrey\") +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(-5, -t_critical), fill = \"darkgrey\") +\n  \n  annotate(geom = \"linerange\", x = t_critical, ymin = 0, ymax = 0.065, linewidth = 1, lty = 2, color = \"#000000\") +\n  annotate(geom = \"linerange\", x = -t_critical, ymin = 0, ymax = 0.065, linewidth = 1, lty = 2, color = \"#000000\") +\n  \n  # annotate(geom = \"linerange\", x = t, ymin = 0, ymax = 0.075, linewidth = 1, color = \"#000000\") +\n  # annotate(geom = \"linerange\", x = -t, ymin = 0, ymax = 0.075, linewidth = 1, color = \"#000000\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  theme_void() +\n  theme(panel.grid = element_blank(),\n        plot.margin = unit(c(1, 0, 0, 0), \"cm\"))"
  },
  {
    "objectID": "lecture/lecture_week-03.html#two-sample-t-test",
    "href": "lecture/lecture_week-03.html#two-sample-t-test",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "7. two-sample t-test",
    "text": "7. two-sample t-test\n\n\nCode\nex1 &lt;- ggplot(data.frame(x = -8:8), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 1, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 1), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nset.seed(2)\nx &lt;- rnorm(30, mean = 0, sd = 2)\ny &lt;- rnorm(30, mean = 1, sd = 2)\n\nt.test(x = x, y = y, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  x and y\nt = -0.78852, df = 58, p-value = 0.4336\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.6721807  0.7270662\nsample estimates:\nmean of x mean of y \n0.4573436 0.9299009 \n\n\nCode\n# 0.43\n\n\n\n\nCode\nex2 &lt;- ggplot(data.frame(x = -8:17), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 2, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 2), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nset.seed(1000000000)\nx &lt;- rnorm(30, mean = 0, sd = 2)\ny &lt;- rnorm(30, mean = 2, sd = 2)\n\nt.test(x = x, y = y, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  x and y\nt = -3.7904, df = 58, p-value = 0.0003603\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.7905631 -0.8617609\nsample estimates:\nmean of x mean of y \n0.1435745 1.9697364 \n\n\nCode\n# 0.6932\n\n\n\n\nCode\nex3 &lt;- ggplot(data.frame(x = -8:17), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 10, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 10), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nset.seed(100)\nx &lt;- rnorm(40, mean = 0, sd = 2)\ny &lt;- rnorm(40, mean = 10, sd = 2)\n\nt.test(x = x, y = y, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  x and y\nt = -21.69, df = 78, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -10.564878  -8.788488\nsample estimates:\nmean of x mean of y \n0.2003543 9.8770375 \n\n\nCode\n# p &lt; 0.001\n\n\n\n\nCode\nex1 + ex2 + ex3\n\n\n\n\n\n\n\n\n\n\nsame differences in means, different SD\n\n\nCode\nsmall &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 2), linewidth = 2, color = \"#0070C0\") +\n  geom_vline(aes(xintercept = 3), color = \"#0070C0\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nbig &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 0.5), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 0.5), linewidth = 2, color = \"#0070C0\") +\n  geom_vline(aes(xintercept = 3), color = \"#0070C0\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.8)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\ndiff &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 0.5), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 1.25), linewidth = 2, color = \"#0070C0\") +\n  geom_vline(aes(xintercept = 3), color = \"#0070C0\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.85)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nsmall / big / diff\n\n\n\n\n\n\n\n\n\n\n\nF-distribution\n\n\nCode\nggplot(data.frame(x = seq(from = 0, to = 4, by = 0.1)), aes(x)) +\n  stat_function(geom = \"line\", fun = df, args = list(df1 = 20, df2 = 20), color = \"#FF6B2B\", linewidth = 1, xlim = c(0, 4)) +\n  stat_function(geom = \"line\", fun = df, args = list(df1 = 5, df2 = 5), color = \"#0070C0\", linewidth = 1, xlim = c(0, 4)) +\n  stat_function(geom = \"line\", fun = df, args = list(df1 = 1, df2 = 5), linewidth = 1, xlim = c(0, 4)) +\n  annotate(\"text\", x = 1.5, y = 1, label = \"20, 20\", color = \"#FF6B2B\", size = 8) +\n  annotate(\"text\", x = -0.2, y = 0.5, label = \"5, 5\", color = \"#0070C0\", size = 8) +\n  annotate(\"text\", x = 0.5, y = 1.5, label = \"1, 5\", size = 8) + \n  scale_y_continuous(expand = c(0, 0)) +\n  theme(axis.text = element_blank(),\n        axis.line = element_blank(),\n        axis.ticks = element_blank(),\n        axis.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nF-distribution example\n\n\nCode\nset.seed(1)\nrats &lt;- rnorm(n = 20, mean = 178, sd = 43)\nset.seed(1)\nmice &lt;- rnorm(n = 20, mean = 120, sd = 20)\n\nmean(rats)\n\n\n[1] 186.1925\n\n\nCode\nmean(mice)\n\n\n[1] 123.8105\n\n\nCode\nvar(rats)\n\n\n[1] 1542.126\n\n\nCode\nvar(mice)\n\n\n[1] 333.6129\n\n\nCode\nvar(rats)/var(mice)\n\n\n[1] 4.6225\n\n\nCode\nvar.test(rats, mice)\n\n\n\n    F test to compare two variances\n\ndata:  rats and mice\nF = 4.6225, num df = 19, denom df = 19, p-value = 0.001619\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  1.829642 11.678519\nsample estimates:\nratio of variances \n            4.6225 \n\n\n\n\nCode\nt.test(rats, mice, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  rats and mice\nt = 6.4415, df = 38, p-value = 1.414e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 42.77708 81.98702\nsample estimates:\nmean of x mean of y \n 186.1925  123.8105 \n\n\nCode\nt.test(rats, mice, var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  rats and mice\nt = 6.4415, df = 26.853, p-value = 6.84e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 42.50629 82.25781\nsample estimates:\nmean of x mean of y \n 186.1925  123.8105 \n\n\n\n\nCode\n(mean(rats) - mean(mice))/sqrt((var(rats) + var(mice))/2)\n\n\n[1] 2.036988\n\n\n\n\nCode\ncohen.d(rats, mice)\n\n\n\nCohen's d\n\nd estimate: 2.036988 (large)\n95 percent confidence interval:\n   lower    upper \n1.248080 2.825895 \n\n\ntesting test statistic formula to compare against t-test from above:\n\n\nCode\nxa &lt;- mean(rats)\nxb &lt;- mean(mice)\n\nvara &lt;- var(rats)\nvarb &lt;- var(mice)\n\nnA &lt;- length(rats)\nnB &lt;- length(mice)\n\n(xa - xb)/sqrt((vara/nA)+(varb/nB))\n\n\n[1] 6.441521\n\n\nCode\n(nA - 1) + (nB - 1)\n\n\n[1] 38\n\n\nCode\n(((vara/nA)+(varb/nB))^2)/((vara/nA)^2/(nA-1)+(varb/nB)^2/(nB-1))\n\n\n[1] 26.85313"
  },
  {
    "objectID": "lecture/lecture_week-01.html",
    "href": "lecture/lecture_week-01.html",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\n\n# visualization\nlibrary(patchwork)"
  },
  {
    "objectID": "lecture/lecture_week-01.html#set-up",
    "href": "lecture/lecture_week-01.html#set-up",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\n\n# visualization\nlibrary(patchwork)"
  },
  {
    "objectID": "lecture/lecture_week-01.html#math",
    "href": "lecture/lecture_week-01.html#math",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "1. Math",
    "text": "1. Math\n\nsample mean\n\\[\n\\bar{y} = \\frac{1}{n}\\sum_{i = 1}^ny_i\n\\]\n\n\nsample variance\n\\[\ns^2 = \\frac{\\sum(y_i - \\bar{y})^2}{n - 1}\n\\]\n\n\nsample standard deviation\n\\[\ns = \\sqrt{\\frac{\\sum(y_i - \\bar{y})^2}{n - 1}}\n\\]\n\n\ncoefficient of variation\n\\[\nCV = \\frac{\\sigma}{\\mu}\n\\]\n\n\nz-score for selecting a single individual\n\\[\nz = \\frac{y_i - \\mu}{\\sigma}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-01.html#mean-and-median",
    "href": "lecture/lecture_week-01.html#mean-and-median",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "2. Mean and median",
    "text": "2. Mean and median\nFor data following a symmetrical distribution, the mean and median tend to be similar.\n\n\nCode\nset.seed(1)\nrnorm(n = 100, mean = 6, sd = 1) %&gt;% \n  as_tibble() %&gt;% \n  ggplot(aes(x = value)) +\n  geom_density() +\n  geom_vline(aes(xintercept = mean(value)), color = \"blue\") +\n  annotate(\"text\", x = 5.75, y = 0.5, label = \"mean\", color = \"blue\") +\n  geom_vline(aes(xintercept = median(value))) +\n  annotate(\"text\", x = 6.5, y  = 0.5, label = \"median\") +\n  scale_x_continuous(limits = c(2.5, 10)) +\n  scale_y_continuous(limits = c(0, 0.5)) +\n  labs(x = \"Sculpin lengths (cm)\") +\n  theme(axis.text.y = element_blank(),\n        axis.title.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nCode\nset.seed(10)\nsample(x = 1:10, \n       size = 100, \n       replace = TRUE,\n       prob = 10:1\n       #prob = 10:1\n       ) |&gt; \n  as_tibble() |&gt; \n  ggplot(aes(x = value)) +\n  geom_density() +\n  geom_vline(aes(xintercept = mean(value)),\n             color = \"blue\") +\n  geom_vline(aes(xintercept = median(value))) +\n  labs(x = \"Sculpin lengths (cm)\") +\n  theme(axis.text.y = element_blank(),\n        axis.title.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank())"
  },
  {
    "objectID": "lecture/lecture_week-01.html#range",
    "href": "lecture/lecture_week-01.html#range",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "3. Range",
    "text": "3. Range\n\n\nCode\nset.seed(1)\nnarrow &lt;- rnorm(n = 30, mean = 6, sd = 1) %&gt;% \n  as_tibble() %&gt;% \n  mutate(y = 0) %&gt;% \n  ggplot(aes(x = value, y = y)) +\n  geom_jitter(shape = 21) +\n  geom_point(aes(x = mean(value), y = 0), color = \"blue\", size = 3) +\n  scale_x_continuous(limits = c(0, 15)) +\n  scale_y_continuous(limits = c(-0.5, 0.5)) +\n  theme(axis.line.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.title.y = element_blank()) +\n  labs(x = \"Sculpin lengths (cm)\")\n# min: 3.78\n# max: 7.60\n\nset.seed(1)\nwide &lt;- rnorm(n = 30, mean = 6, sd = 2) %&gt;% \n  as_tibble() %&gt;% \n  mutate(y = 0) %&gt;% \n  ggplot(aes(x = value, y = y)) +\n  geom_jitter(shape = 21) +\n    geom_point(aes(x = mean(value), y = 0), color = \"blue\", size = 3) +\n  scale_x_continuous(limits = c(0, 15)) +\n  scale_y_continuous(limits = c(-0.5, 0.5)) +\n  theme(axis.line.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.title.y = element_blank()) +\n  labs(x = \"Sculpin lengths (cm)\")\n# min: 1.57\n# max: 9.19\n\nnarrow + wide\n\n\n\n\n\n\n\n\n\n\nHow would you describe this data?\n\n\nCode\nset.seed(1)\nex1 &lt;- rf(n = 100, df1 = 30, df2 = 10)\nmean(ex1)\n\n\n[1] 1.321259\n\n\nCode\nmedian(ex1)\n\n\n[1] 1.163362\n\n\nCode\nex1 %&gt;% \n  enframe() %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 9,\n                 color = \"#000000\",\n                 fill = \"orange\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  labs(x = \"Hermit crab shell length (cm)\")\n\n\n\n\n\n\n\n\n\nCode\nset.seed(1)\nex2 &lt;- rnorm(n = 100, mean = 25, sd = 5)\nmean(ex2)\n\n\n[1] 25.54444\n\n\nCode\nmedian(ex2)\n\n\n[1] 25.56955\n\n\nCode\nex2 %&gt;% \n  enframe() %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 9,\n                 color = \"#000000\",\n                 fill = \"darkgreen\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  labs(x = \"Octopus arm length (cm)\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#anemone-regression-example",
    "href": "lecture/lecture_week-01.html#anemone-regression-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "4. anemone regression example",
    "text": "4. anemone regression example\n\n\nCode\n# number of arms \narms &lt;- seq(from = 40, to = 100, by = 1)\n\n# diameter: anemones can be up to 8 cm long\nset.seed(10)\ndiam &lt;- rnorm(length(arms), mean = seq(from = 1, to = 5, length = length(arms)), sd = 1) \n\n# create a data frame\ndf &lt;- cbind(diam, arms) %&gt;% \n  as.data.frame()\n\nggplot(df, aes(x = arms, y = diam)) +\n  geom_point(size = 2) +\n  labs(x = \"Number of arms\", y = \"Diameter (cm)\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(df, aes(x = arms, y = diam)) +\n  geom_point(size = 2) +\n  # just using geom smooth for the purposes of visualization\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 2) +\n  labs(x = \"Number of arms\", y = \"Diameter (cm)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#histogram-example",
    "href": "lecture/lecture_week-01.html#histogram-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "5. histogram example",
    "text": "5. histogram example\nThe Rice rule guidelines for the calculating the number of bins in a histogram:\n\\[\nbins = 2n^{1/3}\n\\]\nwhere \\(n\\) is the number of observations. This is an example of a histogram that does follow the rice rule, where the bin number is 8.\n\n\nCode\nggplot(df, aes(x = diam)) +\n  scale_x_continuous(breaks = seq(from = 0, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 19), breaks = seq(from = 0, to = 18, by = 3)) +\n  geom_histogram(breaks = seq(from = 0, to = 8, by = 1), color = \"#000000\", fill = \"lightblue\") +\n  labs(x = \"Anemone diameter (cm)\", y = \"Count\") +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\nThese histograms do not, and it proves difficult to see the distribution:\n\n\nCode\nggplot(df, aes(x = diam)) +\n  scale_x_continuous(breaks = seq(from = 0, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 19), breaks = seq(from = 0, to = 18, by = 3)) +\n  geom_histogram(color = \"#000000\", fill = \"lightblue\") +\n  labs(x = \"Anemone diameter (cm)\", y = \"Count\") +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\nCode\nggplot(df, aes(x = diam)) +\n  scale_x_continuous(breaks = seq(from = 0, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_histogram(color = \"#000000\", fill = \"lightblue\", bins = 3) +\n  labs(x = \"Anemone diameter (cm)\", y = \"Count\") +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#jitter-plot-and-box-and-whisker-plot-example",
    "href": "lecture/lecture_week-01.html#jitter-plot-and-box-and-whisker-plot-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "6. jitter plot and box and whisker plot example",
    "text": "6. jitter plot and box and whisker plot example\n\n\nCode\nset.seed(1)\n\npretend_lengths &lt;- cbind(\n  juveniles = rnorm(20, mean = 2, sd = 0.5), \n  females = rnorm(20, mean = 8, sd = 1), \n  males = rnorm(20, mean = 4, sd = 1)\n) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:3)\n\nggplot(pretend_lengths, aes(x = name, y = value, color = name)) +\n  geom_jitter(width = 0.1, alpha = 0.8, size = 2) +\n  scale_color_manual(values = c(\"darkgreen\", \"cornflowerblue\", \"orange\")) +\n  labs(y = \"Weight (g)\") +\n  theme(axis.title.x = element_blank(),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(pretend_lengths, aes(x = name, y = value, color = name, fill = name)) +\n  geom_boxplot(alpha = 0.8) +\n  scale_color_manual(values = c(\"darkgreen\", \"cornflowerblue\", \"orange\")) +\n  scale_fill_manual(values = c(\"darkgreen\", \"cornflowerblue\", \"orange\")) +\n  labs(y = \"Weight (g)\") +\n  theme(axis.title.x = element_blank(),\n        legend.position = \"none\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#probability-mass-example",
    "href": "lecture/lecture_week-01.html#probability-mass-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "7. Probability mass example",
    "text": "7. Probability mass example\n\n\nCode\nggplot(data.frame(x = 1:55), aes(x)) +\n  stat_function(geom = \"bar\", n = 55, fun = dpois, args = list(lambda = 10), fill = \"coral\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.13)) +\n  coord_cartesian(xlim = c(0, 22)) +\n  labs(x = \"Mussel clump size (count)\", y = \"Probability mass\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#probability-density-example",
    "href": "lecture/lecture_week-01.html#probability-density-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "8. Probability density example",
    "text": "8. Probability density example\n\n\nCode\nggplot(data.frame(x = 1:20), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 10, sd = 2), linewidth = 1) +\n  stat_function(geom = \"area\", fun = dnorm, args = list(mean = 10, sd = 2), xlim = c(12, 14), fill = \"turquoise3\") +\n  geom_vline(xintercept = 12, lty = 2, color = \"grey\", linewidth = 1) +\n  geom_vline(xintercept = 14, lty = 2, color = \"grey\", linewidth = 1) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.22)) +\n  # coord_cartesian(xlim = c(0, 22)) +\n  labs(x = \"Individual mussel weight (g)\", y = \"Probability density\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#probability-distribution",
    "href": "lecture/lecture_week-01.html#probability-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "9. probability distribution",
    "text": "9. probability distribution\n\n\nCode\nset.seed(1)\nnormdist &lt;- rnorm(n = 100000, mean = 0, sd = 1) %&gt;% \n  as_tibble(rownames = \"x\")\n\nggplot(normdist) +\n  geom_histogram(aes(x = value, after_stat(density)), fill = \"white\", color = \"black\", bins = 100) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), color = \"blue\", linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#normal-distribution",
    "href": "lecture/lecture_week-01.html#normal-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "10. normal distribution",
    "text": "10. normal distribution\n\n\nCode\nggplot(data.frame(x = -10:25), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1, color = \"darkorange\") +\n  annotate(\"text\", x = 4.5, y = 0.4, label = \"\\U03BC = 0, \\U03C3 = 1\", color = \"darkorange\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 15, sd = 3), linewidth = 1, color = \"blue\") +\n  annotate(\"text\", x = 16, y = 0.15, label = \"\\U03BC = 15, \\U03C3 = 3\", color = \"blue\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 5, sd = 5), linewidth = 1, color = \"darkgreen\") +\n  annotate(\"text\", x = 7, y = 0.1, label = \"\\U03BC = 5, \\U03C3 = 5\", color = \"darkgreen\", size = 6) +\n  scale_x_continuous(breaks = seq(-10, 25, 5)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#z-score-calculation",
    "href": "lecture/lecture_week-01.html#z-score-calculation",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "11. z-score calculation",
    "text": "11. z-score calculation\n\nfigure\nWe’ll use \\(z = -1.23\\) for this example.\n\n\nCode\n# z-score\nq &lt;- -1.23\n\nggplot(data.frame(x = -4:4), aes(x)) +\n  # zscore\n  geom_linerange(x = q, ymin = 0, ymax = 0.19) +\n  # area under the curve\n  stat_function(geom = \"area\", fun = dnorm, args = list(mean = 0, sd = 1), xlim = c(-4, -1.23), fill = \"turquoise3\") +\n  # Z distribution curve\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1.5, color = \"darkorange\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.45)) +\n  theme(axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.title = element_blank(),\n        axis.line.y = element_blank())\n\n\n\n\n\n\n\n\n\n\n\ncalculation\n\n\nCode\npnorm(q, mean = 0, sd = 1)\n\n\n[1] 0.1093486\n\n\nYou can compare this with the Z-score table.\n\n\nchiton example\nWhat is the probability of selecting a chiton that is less than 6 ft long given a normally distributed population with \\(\\mu = 12\\) g with \\(\\sigma = 3\\) g?\n\n\nCode\n# calculate the z-score\nchiton_z &lt;- (6 - 12)/3\n  \n# calculate the probability under the curve\npnorm(chiton_z, mean = 0, sd = 1)\n\n\n[1] 0.02275013"
  },
  {
    "objectID": "lecture/lecture_week-01.html#rule",
    "href": "lecture/lecture_week-01.html#rule",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "12. 68-95-99.7 rule",
    "text": "12. 68-95-99.7 rule\nIn a normal distribution, 68% of values lie within 1 standard deviation of the mean, 95% within 2 standard deviations, and 99.7% within 3 standard deviations.\n\n\nCode\nlabels &lt;- c(\n  \"\", \"\\U03BC - 3\\U03C3\", \"\\U03BC - 2\\U03C3\", \"\\U03BC - \\U03C3\", \"\\U03BC\", \"\\U03BC + \\U03C3\", \"\\U03BC + 2\\U03C3\", \"\\U03BC + 3\\U03C3\", \"\"\n)\n\nggplot(data.frame(x = -4:4), aes(x)) +\n  geom_linerange(x = 1, ymin = 0, ymax = 0.24) +\n  geom_linerange(x = -1, ymin = 0, ymax = 0.24) +\n  geom_linerange(x = 2, ymin = 0, ymax = 0.055) +\n  geom_linerange(x = -2, ymin = 0, ymax = 0.055) +\n  geom_linerange(x = 3, ymin = 0, ymax = 0.005) +\n  geom_linerange(x = -3, ymin = 0, ymax = 0.005) +\n  geom_linerange(x = 0, ymin = 0, ymax = 0.399) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1.5, color = \"darkorange\") +\n  scale_x_continuous(labels = labels, breaks = seq(-4, 4, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.41)) +\n  labs(x = \"\") +\n  theme_classic() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 24),\n        axis.line.y = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks = element_blank())"
  },
  {
    "objectID": "lecture/lecture_week-01.html#students-t-distribution",
    "href": "lecture/lecture_week-01.html#students-t-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "13. Student’s t distribution",
    "text": "13. Student’s t distribution\n\n\nCode\nggplot(data.frame(x = -10:10), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#856F33\") +\n  annotate(\"text\", x = 3.5, y = 0.3, label = \"\\U03BD = 1\", color = \"#856F33\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 3), linewidth = 1, color = \"#E6821C\") + \n  annotate(\"text\", x = 3.5, y = 0.35, label = \"\\U03BD = 3\", color = \"#E6821C\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 5), linewidth = 1, color = \"#56E9E7\") +\n  annotate(\"text\", x = 3.5, y = 0.37, label = \"\\U03BD = 5\", color = \"#56E9E7\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 100), linewidth = 1, color = \"#04B37F\") +\n    annotate(\"text\", x = 3.5, y = 0.4, label = \"\\U03BD = 100\", color = \"#04B37F\", size = 6) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#uniform-distribution",
    "href": "lecture/lecture_week-01.html#uniform-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "14. Uniform distribution",
    "text": "14. Uniform distribution\n\n\nCode\nggplot(data.frame(x = 0:10), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dunif, args = list(min = 2, max = 8), linewidth = 1, color = \"firebrick4\") +\n  annotate(\"text\", x = 2, y = 0.172, label = \"a = 2\", color = \"firebrick4\", size = 6) + \n  annotate(\"text\", x = 8, y = 0.172, label = \"b = 8\", color = \"firebrick4\", size = 6) + \n  scale_x_continuous(breaks = seq(0, 10, 2)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(-0.001, 0.18)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#binomial-distribution",
    "href": "lecture/lecture_week-01.html#binomial-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "14. Binomial distribution",
    "text": "14. Binomial distribution\n\n\nCode\nggplot(data.frame(x = 1:20), aes(x)) +\n  stat_function(geom = \"line\", n = 20, fun = dbinom, args = list(size = 20, p = 0.1), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dbinom, args = list(size = 20, p = 0.1), color = \"#6D9929\", size = 3) +\n  annotate(\"text\", x = 5.5, y = 0.29, label = \"n = 20, p = 0.1\", color = \"#6D9929\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dbinom, args = list(size = 20, p = 0.4), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dbinom, args = list(size = 20, p = 0.4), color = \"#4A76E5\", size = 3) +\n  annotate(\"text\", x = 8, y = 0.2, label = \"n = 20, p = 0.4\", color = \"#4A76E5\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dbinom, args = list(size = 20, p = 0.7), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dbinom, args = list(size = 20, p = 0.7), color = \"#E67960\", size = 3) +\n  annotate(\"text\", x = 15, y = 0.21, label = \"n = 20, p = 0.7\", color = \"#E67960\", size = 6) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  labs(x = \"Number of successes\", y = \"Mass\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#poisson-distribution",
    "href": "lecture/lecture_week-01.html#poisson-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "15. Poisson distribution",
    "text": "15. Poisson distribution\n\n\nCode\nggplot(data.frame(x = 1:20), aes(x)) +\n  stat_function(geom = \"line\", n = 20, fun = dpois, args = list(lambda = 1), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dpois, args = list(lambda = 1), color = \"coral\", size = 4) +\n  annotate(\"text\", x = 3, y = 0.37, label = \"\\U03BB = 1\", color = \"coral\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dpois, args = list(lambda = 4), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dpois, args = list(lambda = 4), color = \"darkgreen\", size = 4) +\n  annotate(\"text\", x = 6, y = 0.2, label = \"\\U03BB = 4\", color = \"darkgreen\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dpois, args = list(lambda = 10), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dpois, args = list(lambda = 10), color = \"turquoise\", size = 4) +\n  annotate(\"text\", x = 14, y = 0.12, label = \"\\U03BB = 10\", color = \"turquoise\", size = 6) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Discrete value\", y = \"Mass\")"
  },
  {
    "objectID": "workshop/workshop-05_2025.html",
    "href": "workshop/workshop-05_2025.html",
    "title": "Coding workshop: Week 5",
    "section": "",
    "text": "Workshop dates: May 1 (Thursday), May 2 (Friday)"
  },
  {
    "objectID": "workshop/workshop-05_2025.html#summary",
    "href": "workshop/workshop-05_2025.html#summary",
    "title": "Coding workshop: Week 5",
    "section": "1. Summary",
    "text": "1. Summary\n\nPackages\n\ntidyverse\n\nlterdatasampler\n\nrstatix\n\ncar\n\n\n\nOperations\n\nNew functions\n\nmake sure a variable is a factor using as_factor()\ndo a Shapiro-Wilk test using shapiro.test()\n\ndo a Levene’s test using car::leveneTest()\n\ndo an ANOVA using aov()\n\nlook for more information from model results using summary()\n\ndo post-hoc Tukey test using TukeyHSD()\n\ncalculate effect size for ANOVA using rstatix::eta_squared()\n\ndo Kruskal-Wallis test using kruskal.test()\n\ndo Dunn’s test using rstatix::dunn_test()\n\ncalculate effect size for Kruskal-Wallis test using rstatix::kruskal_effsize()\n\n\n\nReview\n\nread in data using read_csv()\n\nchain functions together using |&gt;\n\nmodify columns using mutate()\n\nselect columns using select()\n\nrename columns using rename()\n\nvisualize data using ggplot()\n\ncreate histograms using geom_histogram()\n\nvisualize QQ plots using geom_qq() and geom_qq_line()\n\ncreate multi-panel plots using facet_wrap()\n\ngroup data using group_by()\n\nsummarize data using summarize()\n\n\n\n\nData sources\nThe Plum Island Ecosystem fiddler crab data is from lterdatasampler (data info here). The ramen ratings data set is a Tidy Tuesday dataset - see more about the data and its source here."
  },
  {
    "objectID": "workshop/workshop-05_2025.html#code",
    "href": "workshop/workshop-05_2025.html#code",
    "title": "Coding workshop: Week 5",
    "section": "2. Code",
    "text": "2. Code\n\n1. Packages\n\nlibrary(tidyverse)\nlibrary(lterdatasampler)\nlibrary(rstatix)\nlibrary(car)\n\n# for parametric tests\ndata(pie_crab)\n\n# for non-parametric tests\nramen_ratings &lt;- read_csv(\"ramen_ratings.csv\")\n\n\n\n2. Parametric tests\n\na. Cleaning and wrangling\n\nCreate a new object called pie_crab_clean.\nFilter to only include the following sites: Cape Cod, Virginia Coastal Reserve LTER, and Zeke’s Island NERR.\nMake sure site is a factor.\nSelect the columns of interest: site, name, and code.\nRename the column name to site_name and code to site_code.\n\n\npie_crab_clean &lt;- pie_crab |&gt; # start with the pie_crab dataset\n  filter(site %in% c(\"CC\", \"ZI\", \"VCR\")) |&gt; # filter for Cape Cod, Zeke's Island, Virginia Coastal\n  mutate(name = as_factor(name)) |&gt; # make sure site name is being read in as a factor\n  select(site, name, size) |&gt; # select columns of interest\n  rename(site_code = site, # rename site to be site_code\n         site_name = name) # rename name to be site_name\n\n# display some rows from the data frame\n# useful for showing a small part of the data frame\nslice_sample(pie_crab_clean, # data frame\n             n = 10) # number of rows to show\n\n# A tibble: 10 × 3\n   site_code site_name                      size\n   &lt;chr&gt;     &lt;fct&gt;                         &lt;dbl&gt;\n 1 CC        Cape Cod                      19.3 \n 2 ZI        Zeke's Island NERR             8.45\n 3 ZI        Zeke's Island NERR            12.7 \n 4 ZI        Zeke's Island NERR             9.87\n 5 ZI        Zeke's Island NERR            14.7 \n 6 CC        Cape Cod                      17.2 \n 7 CC        Cape Cod                      14.4 \n 8 ZI        Zeke's Island NERR            11.6 \n 9 VCR       Virginia Coastal Reserve LTER 15.9 \n10 CC        Cape Cod                      13.8 \n\n\n\n\nb. Quick summary\n\nCreate a new object called pie_crab_summary.\nCalculate the mean, variance, and sample size. Display the object.\n\n\n# creating a new object called pie_crab_summary\npie_crab_summary &lt;- pie_crab_clean |&gt; # starting with clean data frame\n  group_by(site_name) |&gt; # group by site\n  summarize(mean = mean(size), # calculate mean size\n            var = var(size), # calculate variance of size\n            n = length(size)) # calculate number of observations per site (sample size)\n\n# display pie_crab_summary\npie_crab_summary\n\n# A tibble: 3 × 4\n  site_name                      mean   var     n\n  &lt;fct&gt;                         &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 Zeke's Island NERR             12.1  4.04    35\n2 Virginia Coastal Reserve LTER  16.3  8.63    30\n3 Cape Cod                       16.8  4.22    27\n\n\n\n\nc. Exploring the data\nCreate a jitter plot with the mean crab size for each site.\n\n# base layer: ggplot\nggplot(pie_crab_clean, # use the clean data set\n       aes(x = site_name, # x-axis\n           y = size)) + # y-axis\n  # first layer: jitter (each point is an individual crab)\n  geom_jitter(height = 0, # don't jitter points vertically\n              width = 0.15) + # narrower jitter (easier to see)\n  # second layer: point representing mean\n  stat_summary(geom = \"point\", # geometry being plotted\n               fun = mean, # function (calculating the mean)\n               color = \"red\", # color to make it easier to see\n               size = 5) + # larger point size\n  theme_minimal() # cleaner plot theme\n\n\n\n\n\n\n\n\nIs there a difference in mean crab size between the three sites?\nYes, and Zeke’s Island NERR crabs tend to be smaller than those from Cape Cod or Virginia Coastal Reserve LTER.\n\n\nd. Check 1: normally distributed variable\n\nCreate a histogram of crab size.\nFacet your histogram so that you have 3 panels, with one panel for each site.\n\n\n# base layer: ggplot\nggplot(data = pie_crab_clean, \n       aes(x = size)) + # x-axis\n  # first layer: histogram\n  geom_histogram(bins = 9) + # number of bins from Rice Rule\n  # faceting by site_name: creating 3 different panels\n  facet_wrap(~ site_name) \n\n\n\n\n\n\n\n\n\nCreate a QQ plot of crab size.\nFacet your QQ plot so that you have 3 panels, with one panel for each site.\n\n\n# base layer: ggplot\nggplot(data = pie_crab_clean, \n       aes(sample = size)) + # y-axis\n  # first layer: QQ plot reference line\n  geom_qq_line(color = \"orange\") + \n  # second layer: QQ plot points (actual observations)\n  geom_qq() + \n  # faceting by site_name\n  facet_wrap(~ site_name, \n             scales = \"free\") # let axes vary between panels\n\n\n\n\n\n\n\n\nWhat are the outcomes of your visual checks?\nNot perfect (crab sizes from VCR LTER seem not normally distributed) but with large sample sizes for each group, this might not matter too much.\nDo Shapiro-Wilk tests:\n\ncc_crabs &lt;- pie_crab_clean |&gt; # use the original data set\n  filter(site_code == \"CC\") |&gt; # filter to only include Cape Cod\n  pull(size) # extract the size column as a vector\n\nvcr_crabs &lt;- pie_crab_clean |&gt; \n  filter(site_code == \"VCR\") |&gt; # filter to only include Virginia Coastal\n  pull(size)\n\nzi_crabs &lt;- pie_crab_clean |&gt; \n  filter(site_code == \"ZI\") |&gt; # filter to only include Zeke's Island\n  pull(size)\n\n# do the Shapiro-Wilk tests\nshapiro.test(cc_crabs)\n\n\n    Shapiro-Wilk normality test\n\ndata:  cc_crabs\nW = 0.93547, p-value = 0.09418\n\nshapiro.test(vcr_crabs)\n\n\n    Shapiro-Wilk normality test\n\ndata:  vcr_crabs\nW = 0.94447, p-value = 0.12\n\nshapiro.test(zi_crabs)\n\n\n    Shapiro-Wilk normality test\n\ndata:  zi_crabs\nW = 0.97446, p-value = 0.5766\n\n\nWhat are the outcomes of your statistical checks?\nWith Shapiro-Wilk normality tests, there seems to be no deviation from normality for Cape Cod crab sizes (W = 0.9, p = 0.09), VCR LTER crab sizes (W = 0.9, p = 0.12), or Zeke’s Island crab sizes (W = 1, p = 0.6).\n\n\ne. Check 2: equal variances\nDo a gut check: is the largest variance less than 4× the smallest variance?\n\n4.04*4 &gt; 8.63\n\n[1] TRUE\n\n\nUsing leveneTest() from car\n\n# do the Levene test\nleveneTest(\n  size ~ site_name, # formula: crab size as a function of site\n  data = pie_crab_clean # data frame\n)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value  Pr(&gt;F)   \ngroup  2  5.0233 0.00857 **\n      89                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat are the outcomes of your variance check?\nThere’s a deviation from homogeneity of variance (in other words, the variances are not equal), but since the largest variance is less than 4 times the smallest variance (and the sample sizes are large), this may still be ok.\n\n\nf. ANOVA\n\n# creating an object called crab_anova\ncrab_anova &lt;- aov(size ~ site_name, # formula\n                  data = pie_crab_clean) # data\n\n# gives more information\nsummary(crab_anova)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)    \nsite_name    2  442.2  221.10   39.56 5.1e-13 ***\nResiduals   89  497.4    5.59                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSummarize results: is there a difference in crab size between the three sites?\nThere is a difference in crab size between Cape Cod, Virginia Coastal Reserve LTER, and Zeke’s Island NERR (one-way ANOVA, F(2, 89) = 39.6, p &lt; 0.001, \\(\\alpha\\) = 0.05).\n\n\ng. Post-hoc: Tukey HSD\n\nTukeyHSD(crab_anova)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = size ~ site_name, data = pie_crab_clean)\n\n$site_name\n                                                      diff       lwr      upr\nVirginia Coastal Reserve LTER-Zeke's Island NERR 4.2719524  2.869912 5.673993\nCape Cod-Zeke's Island NERR                      4.7514709  3.308099 6.194843\nCape Cod-Virginia Coastal Reserve LTER           0.4795185 -1.015317 1.974354\n                                                     p adj\nVirginia Coastal Reserve LTER-Zeke's Island NERR 0.0000000\nCape Cod-Zeke's Island NERR                      0.0000000\nCape Cod-Virginia Coastal Reserve LTER           0.7255994\n\n\nWhich pairwise comparisons are actually different? Which ones are not different?\nZeke’s Island NERR and Cape Cod crabs are different, and Zeke’s Island NERR and Virginia Coastal Reserve LTER crabs are different. Virginial Coastal Reserve LTER and Cape Cod crabs are not different.\n\n\nh. effect size\nUsing eta_squared() from rstatix\n\neta_squared(crab_anova)\n\nsite_name \n0.4706113 \n\n\nWhat is the magnitude of the differences between sites in crab size?\nThere is a large difference in crab size between sites.\n\n\ni. Putting everything together\nWe found a large (\\(\\eta^2\\) = 0.47) difference between sites in mean crab size (one-way ANOVA, F(2, 89) = 39.6, p &lt; 0.001, \\(\\alpha\\) = 0.05). The smallest crabs were from Zeke’s Island NERR, which were on average 12.1 mm. Zeke’s Island crabs were 4.8 mm (95% CI: [3.3, 6.2] mm) smaller than crabs from Cape Cod (Tukey’s HSD: p &lt; 0.001) and 4.3 mm (95% CI: [2.9, 5.7] mm) smaller than crabs from Virginia Coastal Reserve LTER (Tukey’s HSD: p &lt; 0.001).\n\n\n\n3. Non-parametric tests\n\na. Clean and wrangle the data\n\nramen_ratings_clean &lt;- ramen_ratings |&gt; # use the ramen_ratings dataframe\n  filter(brand == \"Maruchan\") |&gt; # filter to only include Maruchan ramen\n  mutate(style = fct_relevel(style, \"Bowl\", \"Pack\", \"Tray\", \"Cup\")) # reorder style factor\n\n# look at the structure\nstr(ramen_ratings_clean)\n\ntibble [106 × 6] (S3: tbl_df/tbl/data.frame)\n $ review_number: num [1:106] 3176 3152 3141 3124 3111 ...\n $ brand        : chr [1:106] \"Maruchan\" \"Maruchan\" \"Maruchan\" \"Maruchan\" ...\n $ variety      : chr [1:106] \"Gotsumori Shio Yakisoba\" \"QTTA Curry Ramen\" \"Thai Red Curry Udon\" \"Kitsune Udon 40th Anniversary\" ...\n $ style        : Factor w/ 4 levels \"Bowl\",\"Pack\",..: 3 4 1 1 1 4 1 1 4 3 ...\n $ country      : chr [1:106] \"Japan\" \"Japan\" \"Japan\" \"Japan\" ...\n $ stars        : num [1:106] 5 5 5 4.5 4 4 3.75 2 2.5 2.5 ...\n\n\n\n\nb. Quick summary\n\n# create a new object called ramen_ratings_summary\nramen_ratings_summary &lt;- ramen_ratings_clean |&gt; # start with the cleaned data frame\n  # group by stle\n  group_by(style) |&gt; \n  # calculate the median\n  summarize(median = median(stars))\n\n# display the object\nramen_ratings_summary \n\n# A tibble: 4 × 2\n  style median\n  &lt;fct&gt;  &lt;dbl&gt;\n1 Bowl    4.25\n2 Pack    3.75\n3 Tray    3.75\n4 Cup     3.5 \n\n\n\n\nc. Make a boxplot to compare star ratings across ramen styles\n\n# base layer: ggplot\nggplot(data = ramen_ratings_clean, \n       aes(x = style, # x-axis\n           y = stars, # y-axis\n           color = style)) + # fill geoms by ramen style\n  # first layer: boxplot\n  geom_boxplot(color = \"darkgrey\", \n               outliers = FALSE) + # taking out outliers because they will be shown in the jitter\n  # second layer: jitter\n  geom_jitter(height = 0,\n              width = 0.1,\n              size = 2,\n              alpha = 0.6) +\n  # set custom colors\n  scale_color_manual(values = c(\"firebrick4\", \"orange\", \"gold\", \"darkgreen\")) + \n  # minimal theme\n  theme_minimal() + \n  # take out the legend\n  theme(legend.position = \"none\") \n\n\n\n\n\n\n\n\n\n\nd. Do the Kruskal-Wallis test\n\nkruskal.test(\n  stars ~ style, # formula: star ratings as a function of ramen style\n  data = ramen_ratings_clean # data frame\n)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  stars by style\nKruskal-Wallis chi-squared = 15.679, df = 3, p-value = 0.00132\n\n\nIs there a difference in ratings between ramen styles?\nRamen styles differ in ratings (Kruskal-Wallis rank sum test, \\(\\chi^2\\)(3) = 15.7, p = 0.0013).\n\n\ne. Do a Dunn’s post-hoc test\nUsing dunn_test() from rstatix\n\ndunn_test(\n  stars ~ style, # formula: star ratings as a function of ramen style\n  data = ramen_ratings_clean # data frame\n)\n\n# A tibble: 6 × 9\n  .y.   group1 group2    n1    n2 statistic        p   p.adj p.adj.signif\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1 stars Bowl   Pack      33    30    -2.61  0.00898  0.0449  *           \n2 stars Bowl   Tray      33    17    -2.54  0.0112   0.0449  *           \n3 stars Bowl   Cup       33    26    -3.70  0.000213 0.00128 **          \n4 stars Pack   Tray      30    17    -0.323 0.747    0.985   ns          \n5 stars Pack   Cup       30    26    -1.16  0.244    0.733   ns          \n6 stars Tray   Cup       17    26    -0.686 0.492    0.985   ns          \n\n\nWhich pairwise comparisons of ramen styles are different from each other?\nBowls and packs are different, bowls and trays are different, bowls and cups are different.\n\n\nf. Calculate an effect size\nUsing kruskal_effsize() from rstatix\n\nkruskal_effsize(\n  stars ~ style, # formula: star ratings as a function of ramen style\n  data = ramen_ratings_clean # data frame\n)\n\n# A tibble: 1 × 5\n  .y.       n effsize method  magnitude\n* &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;ord&gt;    \n1 stars   106   0.124 eta2[H] moderate \n\n\nWhat is the magnitude of the effect of ramen style on ratings?\nThere is a moderate (\\(\\eta^2\\) = 0.12) effect of ramen style on ratings.\n\n\ng. Putting everything together\nWe found a moderate (\\(\\eta^2\\) = 0.12) difference in ratings between ramen styles (Kruskal-Wallis rank sum test, \\(\\chi^2\\)(3) = 15.7, p = 0.0013). Bowl-style ramen had a median rating of 4.25 stars, which tended to be more highly rated than pack (Dunn’s post-hoc test: Holm adjusted p = 0.04, median rating = 3.75 stars), tray (Dunn’s post-hoc test: Holm adjusted p = 0.04, median rating = 3.75 stars), or cup style ramen (Dunn’s post-hoc test: Holm adjusted p = 0.0013, median rating = 3.5 stars)."
  },
  {
    "objectID": "workshop/workshop-03_2025.html",
    "href": "workshop/workshop-03_2025.html",
    "title": "Coding workshop: Week 3",
    "section": "",
    "text": "Workshop dates: April 17 (Thursday), April 18 (Friday)"
  },
  {
    "objectID": "workshop/workshop-03_2025.html#summary",
    "href": "workshop/workshop-03_2025.html#summary",
    "title": "Coding workshop: Week 3",
    "section": "1. Summary",
    "text": "1. Summary\n\nPackages\n\ntidyverse\n\nlterdatasampler\n\n\n\nOperations\n\nNew functions\n\ndisplay data from package using data()\n\nvisualize QQ plots using geom_qq() and geom_qq_line()\n\ncreate multi-panel plots using facet_wrap()\n\ncompare group variances using var.test()\n\ndo t-tests using t.test()\n\nmake rownames into a separate column using rownames_to_column()\n\nuse geom_pointrange() to show means and 95% CI\n\n\n\nReview\n\nchain functions together using |&gt;\n\nfiltering observations using filter()\n\nmanipulate columns using mutate() and case_when()\n\nvisualize data using ggplot()\n\ncreate boxplots using geom_boxplot() and show observation values using geom_jitter()\n\ncreate histograms using geom_histogram()\n\ngroup data using group_by()\n\nsummarize data using summarize()\n\n\n\n\nGeneral Quarto formatting tips\nYou can control the appearance of text, links, images, etc. using this guide.\n\n\nData source\nThe data on sugar maples is from the lterdatasampler package. The package developers (alumni of the Bren Masters of Environmental Data Science program!) curated a bunch of datasets from the LTER network into this package for teaching and learning. Read about the package here.\nThe source of the data is Hubbard Brook Experimental Forest. Read more about the data here."
  },
  {
    "objectID": "workshop/workshop-03_2025.html#code",
    "href": "workshop/workshop-03_2025.html#code",
    "title": "Coding workshop: Week 3",
    "section": "2. Code",
    "text": "2. Code\nRemember to set up an Rproject before starting!\n\n1. Set up\nInsert a code chunk below to read in your packages. Name the code chunk packages.\n\nlibrary(tidyverse)\nlibrary(lterdatasampler)\n\nBecause we are using data from the package lterdatasampler, we don’t need to use read_csv().\nInstead, we can use data() to make the data frame show up in the environment.\nInsert a code chunk below to display hbr_maples in the environment using data(\"hbr_maples\"). Name the code chunk data.\n\ndata(\"hbr_maples\")\n\n\n\n2. Cleaning and wrangling\nInsert a code chunk to:\n\ncreate a new object from hbr_maples called maples_2003\n\nfilter observations to only include the year 2003\n\nmutate the watershed column so that W1 is filled in as Calcium-treated\n\nName the code chunk data-cleaning.\n\nmaples_2003 &lt;- hbr_maples |&gt; # start with hbr_maples data frame\n  filter(year == \"2003\") |&gt; # filter to only include observations from 2003\n  mutate(watershed = case_when( # rename watersheds\n    watershed == \"Reference\" ~ \"Reference\",\n    watershed == \"W1\" ~ \"Calcium-treated\"\n  ))\n\n\n\n3. Exploratory data visualization\nInsert a code chunk to make a boxplot + jitter plot comparing stem lengths between watersheds. Remember to:\n\ncolor by watershed\n\ncontrol the jitter so that the points don’t move up and down the y-axis\n\nName the code chunk boxplot-and-jitter.\n\n# base layer: ggplot\nggplot(data = maples_2003, # starting data frame\n       aes(x = watershed, # x-axis\n           y = stem_length, # y-axis\n           color = watershed)) + # coloring by watershed\n  # first layer: boxplot\n  geom_boxplot() +\n  # second layer: jitter plot\n  geom_jitter(height = 0, # making sure points don't move along y-axis\n              width = 0.2) # narrowing width of jitter\n\n\n\n\n\n\n\n\n\n\n4. Checks for t-test assumptions\nInsert a code chunk to create a histogram. Name the code chunk histogram.\nUse facet_wrap() to create separate panels for each watershed.\n\nggplot(data = maples_2003, # starting data frame\n       aes(x = stem_length)) + # x-axis (no y-axis for histogram)\n  geom_histogram(bins = 6) + # number of bins from Rice Rule\n  facet_wrap(~watershed) # creating two panels to show watersheds separately\n\n\n\n\n\n\n\n\nInsert a code chunk to create a QQ plot. Name the code chunk qq-plot.\nUse facet_wrap() to create separate panels for each watershed.\n\n# base layer: ggplot call\nggplot(data = maples_2003, # starting data frame\n       aes(sample = stem_length)) + # y-axis for QQ plot (no x-axis for QQ plot)\n  # first layer: QQ reference line \n  geom_qq_line(color = \"blue\") + # showing this in blue so it's easier to see\n  # second layer: QQ plot\n  geom_qq() + \n  # creating \"facets\"\n  facet_wrap(~watershed) # show watersheds separately\n\n\n\n\n\n\n\n\nCheck in: using histograms and QQ plots, does stem length seem to be normally distributed?\nYes, because the histogram looks symmetrical, and the QQ plot points follow a straight line.\nNext, we’ll check our variances. We can make sure we know where the F test results are coming from by calculating the variance ratios ourselves.\n\n# calculate variances\nstem_length_var &lt;- maples_2003 |&gt; # starting data frame\n  group_by(watershed) |&gt; # group by watershed\n  summarize(variance = var(stem_length)) # calculate variances\n\n# calculate variance ratio (use this number to double check against results of var.test)\n205.7026/194.3021\n\n[1] 1.058674\n\n\nInsert a code chunk to check the variances using var.test(). Name the code chunk F-test.\nIn the function var.test(), enter the arguments for:\n\nthe formula\n\nthe data\n\n\n# doing F test of equal variances\nvar.test(\n  stem_length ~ watershed, # formula: response variable ~ grouping variable\n  data = maples_2003 # data: maples_2003 data frame\n)\n\n\n    F test to compare two variances\n\ndata:  stem_length by watershed\nF = 1.0587, num df = 119, denom df = 119, p-value = 0.7563\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.7378244 1.5190473\nsample estimates:\nratio of variances \n          1.058674 \n\n\nRemember that this variance test is an F test of equal variances. You are comparing the variance of one group with another.\nTo communicate about this, you could write something like:\nUsing an F test of equal variances, we determined that variances were (equal or not equal) (F ratio, F(num df, denom df) = F statistic, p-value).\nWe determined that group variances were (equal or not equal) (F ratio, F(num df, denom df) = F statistic, p-value).\nFill in the blank here:\nWe determined that group variances were equal (F ratio = 1.06, F(119, 119) = 1.06, p = 0.76).\n\n\n5. Doing a t-test\nInsert a code chunk to do a t-test. Name the code chunk t-test.\nIn the function t.test(), enter the arguments for:\n\nthe formula\n\nthe variances in var.equal =\n\nand the dataframe in data =\n\n\nt.test(\n  stem_length ~ watershed, # formula: response variable ~ grouping variable\n  var.equal = TRUE, # argument for equal/unequal variances (variances should be equal)\n  data = maples_2003 # data: maples_2003 data frame\n)\n\n\n    Two Sample t-test\n\ndata:  stem_length by watershed\nt = 3.7797, df = 238, p-value = 0.0001985\nalternative hypothesis: true difference in means between group Calcium-treated and group Reference is not equal to 0\n95 percent confidence interval:\n  3.304134 10.497532\nsample estimates:\nmean in group Calcium-treated       mean in group Reference \n                     87.88583                      80.98500 \n\n\n\n\n6. Communicating\n\na. visual communication\nWhen doing a t-test, remember that you are comparing means. To visualize the data in a way that reflects the values you are comparing (again, you are comparing means), you can visualize the means of each watershed with the standard deviation (spread), standard error (variation), or confidence interval (confidence).\nIn this example, we will show 95% confidence intervals.\nIn this code chunk, we are calculating the means and 95% confidence intervals. Name the code chunk ci-calculation.\n\nmaples_ci &lt;- maples_2003 |&gt; # start with the maples_2003 data frame\n  group_by(watershed) |&gt; # group by watershed\n  summarize(ci = mean_cl_normal(stem_length)) |&gt; # calculate the 95% CI\n  deframe() |&gt; # expand the data frame\n  rownames_to_column(\"watershed\") # make the data frame rownames a column called \"watershed\"\n\nBefore moving on, look at the maples_ci object to make sure you know what it contains.\nNote that this visualization uses two data frames. We use maples_2003 to show the underlying data using geom_jitter(), and maples_ci to show the mean and 95% CI.\n\n# base layer: ggplot with the x- and y-axes\nggplot(data = maples_2003, # using the maples_2003 data frame\n       aes(x = watershed, # x-axis\n           y = stem_length, # y-axis\n           color = watershed)) + # coloring points by watershed\n  # first layer: showing the underlying data\n  geom_jitter(height = 0, # no jitter in the vertical direction\n              width = 0.1, # smaller jitter in the horizontal direction\n              alpha = 0.4, # make the points more transparent\n              shape = 21) + # make the points open circles\n  # second layer: showing the summary (mean and 95% CI)\n  geom_pointrange(data = maples_ci, # using the maples_ci data frame\n                  aes(x = watershed, # x-axis\n                      y = y, # y-axis\n                      ymax = ymax, # upper bound of confidence interval\n                      ymin = ymin)) + # lower bound of confidence interval\n  labs(x = \"Watershed\", # labeling the axes\n       y = \"Stem length (cm)\") +\n  # figure customization\n  # Note: this is optional (but nice to do!)\n  scale_color_manual(values = c(\"Calcium-treated\" = \"darkorchid3\",\n                                \"Reference\" = \"tomato3\")) + # changing the point colors\n  theme_bw() + # using a theme\n  theme(legend.position = \"none\") # getting rid of the legend\n\n\n\n\n\n\n\n\n\n\nb. Writing\nSummarize the results of the t-test in one sentence. Before you do, make sure you know the:\n\ntype of test\n\nStudent’s t (note: this is because variances are equal)\n\nSample size\n\nn = 120 for calcium-treated, n = 120 for reference (240 total)\n\nsignificance level (\\(\\alpha\\))\n\n\\(\\alpha\\) = 0.05\n\ndegrees of freedom\n\n238 (note: 240 - 2 = 238)\n\nt-value (aka t-statistic)\n\n3.8\n\np-value\n\np &lt; 0.001 (don’t need to give exact number for anything below 0.001)\nWe found a significant difference in sugar maple stem lengths between calcium-treated (n = 120) and reference (n = 120) watersheds (Student’s t-test, t(238) = 3.8, p &lt; 0.001, \\(\\alpha\\) = 0.05).\nEND OF WORKSHOP 3"
  },
  {
    "objectID": "workshop/workshop-03_2025.html#extra-stuff",
    "href": "workshop/workshop-03_2025.html#extra-stuff",
    "title": "Coding workshop: Week 3",
    "section": "Extra stuff",
    "text": "Extra stuff\n\nWhy do we have to put in watershed == \"Reference\" ~ \"Reference\"?\nLet’s see what happens when you don’t include that:\n\nhbr_maples |&gt; # start with hbr_maples data frame\n  filter(year == \"2003\") |&gt; # filter to only include observations from 2003\n  mutate(watershed = case_when( # rename watersheds\n    # note that we're missing the \"Reference\" line of code here\n    watershed == \"W1\" ~ \"Calcium-treated\"\n  )) |&gt; \n  # including this to only display the first 6 rows of the data frame\n  head()\n\n# A tibble: 6 × 11\n   year watershed elevation transect sample stem_length leaf1area leaf2area\n  &lt;dbl&gt; &lt;chr&gt;     &lt;fct&gt;     &lt;fct&gt;    &lt;fct&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1  2003 &lt;NA&gt;      Low       R1       1             86.9     13.8      12.1 \n2  2003 &lt;NA&gt;      Low       R1       2            114       14.6      15.3 \n3  2003 &lt;NA&gt;      Low       R1       3             83.5     12.5       9.73\n4  2003 &lt;NA&gt;      Low       R1       4             68.1      9.97     10.1 \n5  2003 &lt;NA&gt;      Low       R1       5             72.1      6.84      5.48\n6  2003 &lt;NA&gt;      Low       R1       6             77.7      9.66      7.64\n# ℹ 3 more variables: leaf_dry_mass &lt;dbl&gt;, stem_dry_mass &lt;dbl&gt;,\n#   corrected_leaf_area &lt;dbl&gt;\n\n\nIn the watershed column, the mutate()/case_when() function replaced Reference with NA, which is a missing value.\nWhenever you use mutate()/case_when(), you have to explicitly name each value in the column you’re mutating.\nIf you want to keep values, you can insert the argument TRUE ~. Here’s what that code/output would look like:\n\nhbr_maples |&gt; # start with hbr_maples data frame\n  filter(year == \"2003\") |&gt; # filter to only include observations from 2003\n  mutate(watershed = case_when( # rename watersheds\n    watershed == \"W1\" ~ \"Calcium-treated\", # change all occurrences of W1 in the watershed column to be Calcium-treated\n    # note that this has to come LAST\n    TRUE ~ watershed # keep any values that are not explicitly named as the original value\n  )) |&gt; \n  # including this to only display the first 6 rows of the data frame\n  head()\n\n# A tibble: 6 × 11\n   year watershed elevation transect sample stem_length leaf1area leaf2area\n  &lt;dbl&gt; &lt;chr&gt;     &lt;fct&gt;     &lt;fct&gt;    &lt;fct&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1  2003 Reference Low       R1       1             86.9     13.8      12.1 \n2  2003 Reference Low       R1       2            114       14.6      15.3 \n3  2003 Reference Low       R1       3             83.5     12.5       9.73\n4  2003 Reference Low       R1       4             68.1      9.97     10.1 \n5  2003 Reference Low       R1       5             72.1      6.84      5.48\n6  2003 Reference Low       R1       6             77.7      9.66      7.64\n# ℹ 3 more variables: leaf_dry_mass &lt;dbl&gt;, stem_dry_mass &lt;dbl&gt;,\n#   corrected_leaf_area &lt;dbl&gt;\n\n\nIf you combine arguments where you are changing values (for example, watershed == \"W1\" ~ \"Calcium-treated\") with TRUE ~ column name, you can change values and keep the original values in the column.\n\n\nShapes in figures\nIn class, we used shape = 21 in the geom_point() call to make the points show up as open circles. By default, ggplot() uses shape = 16 for all geometries that include points.\nThis figure below shows the 26 options for shapes you can use in any plot with a point geometry.\nShapes 0-14 are only outlines (with a transparent fill). Shapes 15 - 20 are filled (no outline). This means you control them with color in the aes() function, and scale_color_() functions. These show up in pink in the plot below.\nShapes 21 - 25 include outlines and fills. You can manipulate both: you can change the outline using color and scale_color_() functions, and change the fill with fill and scale_fill_() functions. In the plot, outlines show up in pink and fills show up in yellow.\n\n\n\n\n\n\n\n\n\nCredit to Albert Kuo’s blog post for inspiring me to make my own reference figure, and Alex Phillips’s colorblind friendly schemes for the colors in the figure."
  },
  {
    "objectID": "workshop/workshop-07_2025.html",
    "href": "workshop/workshop-07_2025.html",
    "title": "Coding workshop: Week 7",
    "section": "",
    "text": "tidyverse\n\nhere\n\nggeffects\n\nflextable\n\n\n\n\n\n\n\norganize file paths using here()\n\nlook at data using str(), glimpse(), and class()\n\nconstruct a linear model using lm()\n\nvisualize model predictions using ggpredict()\n\nsaving image using ggsave()\n\ncalculating correlation using cor.test()\n\nplot model diagnostics using plot()\n\nplot model 95% CI using geom_ribbon()\n\nplot model predictions using geom_line()\n\n\n\n\n\nread in data using read_csv()\n\nvisualize data using ggplot()\n\ncreate scatterplot using geom_point()\n\n\n\n\n\nThe data from this workshop comes from two sources:\n\nHamilton et al. 2022. “Integrated multi-trophic aquaculture mitigates the effects of ocean acidification: Seaweeds raise system pH and improve growth of juvenile abalone.” https://doi.org/10.1016/j.aquaculture.2022.738571\nRamirez, A. 2024. Sonadora elevational plots: long-term monitoring of air temperature ver 877108. Environmental Data Initiative. https://doi.org/10.6073/pasta/6b66eecae3092d8f2340b5132dec38ab (Accessed 2025-05-14)."
  },
  {
    "objectID": "workshop/workshop-07_2025.html#summary",
    "href": "workshop/workshop-07_2025.html#summary",
    "title": "Coding workshop: Week 7",
    "section": "",
    "text": "tidyverse\n\nhere\n\nggeffects\n\nflextable\n\n\n\n\n\n\n\norganize file paths using here()\n\nlook at data using str(), glimpse(), and class()\n\nconstruct a linear model using lm()\n\nvisualize model predictions using ggpredict()\n\nsaving image using ggsave()\n\ncalculating correlation using cor.test()\n\nplot model diagnostics using plot()\n\nplot model 95% CI using geom_ribbon()\n\nplot model predictions using geom_line()\n\n\n\n\n\nread in data using read_csv()\n\nvisualize data using ggplot()\n\ncreate scatterplot using geom_point()\n\n\n\n\n\nThe data from this workshop comes from two sources:\n\nHamilton et al. 2022. “Integrated multi-trophic aquaculture mitigates the effects of ocean acidification: Seaweeds raise system pH and improve growth of juvenile abalone.” https://doi.org/10.1016/j.aquaculture.2022.738571\nRamirez, A. 2024. Sonadora elevational plots: long-term monitoring of air temperature ver 877108. Environmental Data Initiative. https://doi.org/10.6073/pasta/6b66eecae3092d8f2340b5132dec38ab (Accessed 2025-05-14)."
  },
  {
    "objectID": "workshop/workshop-07_2025.html#code",
    "href": "workshop/workshop-07_2025.html#code",
    "title": "Coding workshop: Week 7",
    "section": "2. Code",
    "text": "2. Code\nAll code is in this repository.\nAll GitHub/Git steps are in this guide. Videos to accompany this guide are on Canvas."
  },
  {
    "objectID": "workshop/workshop-01_2025.html",
    "href": "workshop/workshop-01_2025.html",
    "title": "Coding workshop: Week 1",
    "section": "",
    "text": "Workshop dates: April 3 (Thursday), April 4 (Friday)"
  },
  {
    "objectID": "workshop/workshop-01_2025.html#summary",
    "href": "workshop/workshop-01_2025.html#summary",
    "title": "Coding workshop: Week 1",
    "section": "1. Summary",
    "text": "1. Summary\n\nPackages\n\ntidyverse\n\n\n\nOperations\n\ncalculations using mean() and median()\n\nread in data using read_csv()\n\nfilter data using filter()\n\ngroup data using group_by()\n\ncreate new column using mutate()\n\ncalculate summary statistics using summarize()\n\nchain functions together using |&gt;\n\nvisualize data using ggplot()\n\ncreate boxplots using geom_boxplot()\n\ncreate line plots (a type of scatterplot) using geom_point() and geom_line()\n\nlabel plots using labs()\n\n\n\nData source\nThis workshop’s data comes from National Parks Service Stats, which is the official repository for all data relating to national parks visits. Today, we are working with data from Channel Islands (unceded Chumash land), Death Valley (unceded Serrano and Cahuilla land), and Joshua Tree (unceded Shoshone, Kawaiisu, and Southern Paiute land). You can orient yourself on this map."
  },
  {
    "objectID": "workshop/workshop-01_2025.html#code",
    "href": "workshop/workshop-01_2025.html#code",
    "title": "Coding workshop: Week 1",
    "section": "2. Code",
    "text": "2. Code\n\n\n\n\n\n\nRemember to set up an Rproj file!\n\n\n\nIn class, before we started coding, we set up an Rproject for this folder of workshop materials for week 1. If you need help setting up an Rproject file, see the video on Canvas titled “Creating an Rproject” under the Week 1 module for help.\n\n\n\n1. Intro to scripts\nIn class, we use an R Script. It allows you to write your code (recipe) and run the code in the console (kitchen).\nR considers everything in the script as code to run. Try writing code to calculate the sum of 5 and 7 multiplied by 2.\nRun code by putting your cursor on the line and hitting Ctrl + Enter or Cmd + Enter.\n\n(5+7)*2 # basic math: adding and multiplying\n\n[1] 24\n\n\nEverything in colored text is considered code, and that is what R will run in the console. If you don’t want to run code, you can put a pound sign/hashtag at the beginning of the line. This is especially useful when you want to explain what your code is doing at each line in plain language.\nGo back up to the code you wrote to do the simple calculation and write a comment describing what the code is doing.\n\n\n2. Intro to objects\nIt’s often useful to save things called “objects.” These are stored numbers, lists of numbers, or anything else that appears in the “Environment” tab in the top right.\nTo save (aka store) an object, the general form is:\nobject name &lt;- what you want to store\nRead aloud, this is “object name, left arrow operator, what you want to store”.\nIn this code, we are creating an object called visits and storing a list of numbers: 31, 15, 20, 50.\nIn code, you know that something is a list if it is within a c() function (we’ll get to functions in the next section).\nWrite a comment at the end of this line describing what it does.\n\nvisits &lt;- c(31, 15, 20, 50) # saving a list of numbers as an object called visits\n\n\n\n3. Intro to functions\nR allows you to apply functions to do calculations, from simple to complex structures.\nLet’s say we want to find the mean of the numbers in visits. We could do the calculation by hand, or we could as R to do it for us.\nFunctions are really powerful tools in R. In this class, we’ll get comfortable learning new functions and applying them to different scenarios.\nIn this next line, we’ll calculate the mean of the numbers in visits using the function mean().\nAll functions take the general form function(). Read aloud, this is “function, parentheses”.\n\nmean(visits) # calculating mean of numbers in visits\n\n[1] 29\n\n\nWrite a comment at the end of the line so that you know what it is doing!\nThere is also a function for calculating the median, another measure of central tendency we talked about in class. You can probably guess what it is called!\n\nmedian(visits)\n\n[1] 25.5\n\n\n\n\n4. Intro to packages and data\nPackages are collections of functions that you can bring into R to use. You’ve already installed a package (using the install.packages() function) if you did the set up steps!\nToday (and most days), we’ll use the tidyverse package. The tidyverse is actually a package of packages, and they all have functions that are really useful for us to use in working with data and analyzing it.\nIn this next line, we’ll “read in the package” using the function library(). You only have to install a package once, but you have to read in a package every time you start a new script or restart R.\n\nlibrary(tidyverse)\n\nTo work with data, we can also “read it in” the way we would a package. Basically, we are getting the data into R for us to work with. The function we’ll use for that is read_csv(), which is from the tidyverse package.\n\nparks_visits &lt;- read_csv(\"parks_visits.csv\")\n\nWe’ve already looked at the data in Excel, but let’s make sure it’s actually in R.\nFirst, if you look at the “Environment” tab, you should see an object called park_visits.\n\n\n\n\n\n\nIs my data actually in R?\n\n\n\n\n\nIf you’re not sure if your data is in R, the first thing to check is the “Environment”. If you’ve read in everything correctly, you should see an object in there. If not, you know something is wrong!\n\n\n\nSecond, you can use the View() function to look at the actual data.\n\nView(parks_visits)\n\n\n\n5. cleaning and wranging\nLet’s say we want to figure out what the average (mean) number of visits is for Joshua Tree is across all years and months.\nFirst, you can filter by park to only include jtnp (or Joshua Tree) using the filter() function.\n\ndf1 &lt;- filter(parks_visits, # use the parks_visits data frame\n              park == \"jtnp\") # only include rows where `jtnp` is in the `park` column\n\nThen, you can calculate the mean monthly visits for Joshua Tree across all years using the summarize() and mean() functions.\n\ndf2 &lt;- summarize(df1, # use the df1 data frame\n                 mean_visits = mean(visits)) # calculate the mean number of visits\n\nThis can get tedious if you have a bunch of filtering and summarizing to do! So instead, we can use…\n\n\n6. an easier way to clean and wrangle\nYou can use what’s called a pipe operator to chain functions together. The keyboard shortcut for a pipe is Ctrl + Shift + M or Cmd + Shift + M.\n\n\n\n\n\n\nWhich pipe to use?\n\n\n\n\n\nIf you did the set up steps, you should see a pipe operator that looks like this: |&gt;.\nIf you don’t, you might see a pipe operator that looks like this: %&gt;%.\nThese both do the same thing, though the |&gt; is from baseR (or, a package of pre-loaded R functions and operators) and the %&gt;% is from the magrittr package in the tidyverse.\n\n\n\nWhen reading your code aloud, you can read the pipe as “and then”\n\n# create a new object called `jtnp`\njtnp &lt;- parks_visits |&gt; # start with the `parks_visits` data frame\n  filter(park == \"jtnp\") |&gt; # filter to only include Joshua tree\n  summarize(mean_visits = mean(visits)) # calculate the mean number of visits at Joshua Tree\n\n\n\n7. Visualizing data\nLet’s say we want to visualize the average monthly visits for Channel Islands, Joshua Tree, and Death Valley. We can use a boxplot to do that. Remember that a boxplot is an easy way to represent the central tendency (using the median) and spread (using quantiles) of a variable.\nBefore you move on, write your best guess for which park has, on average, the greatest number of visitors (out of these three).\nTo visualize the data, we’ll use ggplot() and its associated functions, which are all in the ggplot2 package in the tidyverse.\nThe main parts of creating a plot in ggplot() are:\n\nthe “global call”: you have to tell R that you want to use ggplot() by actually naming the function\n\nthe “aesthetics”: you have the tell R the data frame name (in this case, parks_visits) and what the x- and y-axes should be (using the aesthetics function called aes())\n\nthe “geometries”: this is the type of plot you are making. In this case, we’re using the function geom_boxplot() because we want to make a boxplot. Most geom_() functions are named after the plot they make.\n\n\n# 1. start with the global call\nggplot(data = parks_visits, # using the data frame parks_visits\n       aes(x = park, # 2. naming the aesthetics: the x-axis should be the 3 parks\n           y = visits)) + # the y-axis should be monthly visits\n  geom_boxplot() # 3. the plot should be a boxplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGetting a warning?\n\n\n\nWhen you run the code to create this figure, you will get a warning message that looks like this: Warning message: Removed 1 row containing non-finite outside the scale range (stat_boxplot()).\nThis means that there is a number missing in the data frame. Can you find it? (Hint: you’ll need to look at CNPS visit numbers from 2005).\nMissing data is often not a big deal - things happen during data collection! However, we do want to be aware of missing data when we analyze it. That’s why making visualizations is so important; it can help us identify gaps in the dataset if there are any.\n\n\nWhich park do you think receives, on average, the greatest number of visitors?\nWe can check that using math!\n\n\n8. Grouping data using group_by()\nIn the parks_visits data frame, there are 3 parks. We could do everything in section 5 for each park individually, or we could use a function called group_by() from the tidyverse. When you use group_by(), you are basically telling R, “there are groups in this dataset that I want you to pay attention to.”\n\nparks_summary &lt;- parks_visits |&gt; # start with the parks_visits data frame\n  group_by(park) |&gt; # group by each park\n  summarize(median_visits = median(visits, na.rm = TRUE)) # summarize the median number of visits\n\nparks_summary # display the final data frame\n\n# A tibble: 3 × 2\n  park  median_visits\n  &lt;chr&gt;         &lt;dbl&gt;\n1 cnps         25698 \n2 dvnp         84672.\n3 jtnp        144762.\n\n\n\n\n9. Cleaning, wrangling, and visualizing all together\nLet’s say we want to create a figure of total annual visits through time. That would mean we would need to add up all the monthly visits for a given park in a given year. We can take advantage of the functions we’ve gone through to do that work!\nWe’ll also add in a new function here: mutate(). mutate() is a function that allows you to add new columns or manipulate existing columns in a data frame. In this case, we’ll use mutate to do two things:\n\nadd a new column called park_name that has the full name of each park (instead of the abbreviation)\n\nadd a new column called visits_millions that calculates the annual number of visits in millions\n\n\nannual_visits &lt;- parks_visits |&gt; # start with the parks_visits data frame\n  group_by(park, year) |&gt; # group by park AND year\n  summarize(total_visits = sum(visits, na.rm = TRUE)) |&gt; # calculate total visits per year\n  mutate(park_name = case_when( # create a new column called park_name\n    park == \"cnps\" ~ \"Channel Islands\", # when cnps appears in the park column, fill in Channel Islands\n    park == \"dvnp\" ~ \"Death Valley\", # when dvnp appears in the park column, fill in Death Valley\n    park == \"jtnp\" ~ \"Joshua Tree\" # when jtnp appears in the park column, fill in Joshua Tree\n  )) |&gt; \n  mutate(visits_millions = total_visits/1000000) # add a new column called visits_millions, where the total visits are divided by 1000000\n\nNow, we can visualize the data in a line plot, which is a type of scatter plot except the points are connected with lines. We can do that using ggplot() again, but this time with two new “geometries”: geom_point() and geom_line().\nWe’ll also add some color to the plot to make it more interesting to look at!\nLastly, we’ll add in a new function called labs(), which allows us to change the labels on the axes and legend and add a title to the plot, to make things more clear.\n\nggplot(data = annual_visits, # use the annual_visits data frame\n       aes(x = year, # the x-axis should be year\n           y = visits_millions, # the y-axis should be visits in millions\n           color = park_name)) + # color all geometries by park_name\n  geom_point() + # adding points\n  geom_line() + # adding lines\n  labs(x = \"Year\", # relabelling the x-axis\n       y = \"Recreation visits (in millions)\", # and the y-axis\n       title = \"Joshua Tree receives more visits than Death Valley and Channel Islands\", # adding a title\n       color = \"Park name\") # relabelling the legend\n\n\n\n\n\n\n\n\nEND OF WORKSHOP 1"
  },
  {
    "objectID": "workshop/workshop-01_2025.html#extra-stuff",
    "href": "workshop/workshop-01_2025.html#extra-stuff",
    "title": "Coding workshop: Week 1",
    "section": "3. Extra stuff",
    "text": "3. Extra stuff\n\nKeyboard shortcut for &lt;-\nOn Macs, this is Opt + -. On Windows, this is Alt + -.\n\n\nApplying and changing colors in a ggplot() object\nIf you want your plot to have colors in it and/or control the colors, you will need two things in your code:\n\nto apply colors: in the aes() call, have color = or fill = for the column in your data frame that represents the colors\n\nto control colors: you can add on another layer (using the + operator) of scale_color_manual() or scale_fill_manual.\n\n\n\n\n\n\n\nWhat to use: color or fill?\n\n\n\n\n\nfill is appropriate for any shape that you are filling in (i.e. something with a boundary); for example, in the boxplot, you are filling in the rectangle shape of the box.\ncolor is appropriate for anything that’s not a shape; points and lines are typically what you would “color”.\nIt takes some intuition building to decide which to use, so don’t get discouraged if you try fill but realize it’s supposed to be color or vice versa.\n\n\n\nHere’s a demonstration of how that works for a boxplot, where the argument in the aes() call is fill and the function to control the colors is scale_fill_manual().\n\n\n\n\n\n\nWithout colors:\n\nggplot(data = parks_visits, \n       aes(x = park, \n           y = visits)) + \n  geom_boxplot() \n\n\n\n\n\n\n\n\n\nWith colors:\n\nggplot(data = parks_visits, \n       aes(x = park, \n           y = visits,\n           fill = park)) + \n  geom_boxplot() +\n  scale_fill_manual(values = c(\"cnps\" = \"deeppink3\",\n                               \"jtnp\" = \"seagreen3\",\n                               \"dvnp\" = \"steelblue4\"))\n\n\n\n\n\n\n\n\n\n\n\nHere’s a demonstration of how it works with a line plot, where the argument in the aes() call is color and the function to control the colors is scale_color_manual().\n\n\n\nWithout colors:\n\nggplot(data = annual_visits, \n       aes(x = year, \n           y = visits_millions,\n           group = park)) + # this is an extra argument to make sure there is one line per park\n  geom_point() + \n  geom_line() + \n  labs(x = \"Year\", \n       y = \"Recreation visits (in millions)\", \n       title = \"Joshua Tree receives more visits than Death Valley and Channel Islands\", \n       color = \"Park name\") \n\n\n\n\n\n\n\n\n\nWith colors:\n\nggplot(data = annual_visits,\n       aes(x = year, \n           y = visits_millions, \n           color = park_name)) + \n  geom_point() +\n  geom_line() + \n  labs(x = \"Year\", \n       y = \"Recreation visits (in millions)\", \n       title = \"Joshua Tree receives more visits than Death Valley and Channel Islands\", \n       color = \"Park name\") + \n  scale_color_manual(values = c(\"Channel Islands\" = \"deeppink3\",\n                                \"Joshua Tree\" = \"seagreen3\",\n                                \"Death Valley\" = \"steelblue4\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCareful about your labels!\n\n\n\n\n\nWhen naming the colors that you’ll assign to each value in a column, be sure that they match up with the column you typed in for your fill or color argument.\nFor example, the boxplot uses fill = park. The park column in the parks_visits data frame has three values: cnps, jtnp, and dvnp. That’s why the scale_fill_manual() function contains a list of values using the abbreviations.\nIn contrast, the line plot uses color = park_name. The park_name column in the annual_visits data frame has three values: Channel Islands, Joshua Tree, and Death Valley. Thus, the scale_color_manual() function contains a list of values using the full names.\n\n\n\n\n\nChoosing colors!\nGo down color rabbit holes! Some resources to do that:\n\nNamed colors in R: R has a bunch of built in color names, like steelblue3, violetred2, and darkorchid4.\n\nhex codes: more customizable colors come from hex codes, which are 6 digit alphanumeric codes that describe a color. For example, #FFFFFFF represents white, while #000000 represents black, and #3d85c6 is a nice blue.\n\ncolor palettes: if you want to change the colors but you don’t want to pick your own, you can use color palettes. These are collections of colors that people have put into packages for you to use in your plots. There are lots of interesting packages of palettes: a beyonce package that has a bunch of palettes from music videos/concerts, a vangogh package that has palettes from Van Gogh paintings, and much more. A package I developed with my friends is calecopal, which is a package of palettes inspired by California ecosystems."
  },
  {
    "objectID": "assignments/homework-03.html",
    "href": "assignments/homework-03.html",
    "title": "Homework 3",
    "section": "",
    "text": "Due on Wednesday 28 May at 11:59 PM\nRead the instructions carefully and make sure you have all the components on the checklist."
  },
  {
    "objectID": "assignments/homework-03.html#part-1.-set-up-tasks",
    "href": "assignments/homework-03.html#part-1.-set-up-tasks",
    "title": "Homework 3",
    "section": "Part 1. Set up tasks",
    "text": "Part 1. Set up tasks\n\nGitHub steps\n\nCreate a repository called ENVS-193DS_homework-03 on GitHub. Make sure you provide a brief description, make it public, and initialize with a README.\nEnable GitHub pages.\n\n\n\nRStudio/code/computer organization steps\n\nClone your repository to your computer.\nCommit and push the gitignore and .Rproj files with the commit message: initial commit.\nCreate two new folders in your ENVS-193DS_homework-03 folder: one for code and another for data.\nCreate a new Quarto or RMarkdown document for your homework submission in the code folder.\nAt the top of your document, include a link to your GitHub repository.\nDo all of your set up (reading in packages/data) at the top of your document. At minimum, you should have the following packages read in: tidyverse, here, and either gt or flextable. Other packages you may find useful would be janitor or readxl.\n\nThroughout the course of doing your homework, make at least 10 commits and pushes to the remote."
  },
  {
    "objectID": "assignments/homework-03.html#part-2.-problems",
    "href": "assignments/homework-03.html#part-2.-problems",
    "title": "Homework 3",
    "section": "Part 2. Problems",
    "text": "Part 2. Problems\n\nProblem 1. Personal data (30 points)\n\n\n\n\n\n\nNote\n\n\n\nBefore doing this problem, update your spreadsheet with your new observations. Save your data as a .csv or .xlsx in your data folder.\n\n\n\na. Data summarizing (5 points)\nIn 1-2 sentences, describe how you could summarize your data to compare your response variable between categories or groups of your choosing. For example, are you counting observations and comparing counts between groups? Are you taking the mean and comparing means between groups? Are you finding the maximum, minimum, range? Are you adding numbers together?\nBe sure to describe why comparing between the groups you chose is informative. For example, you might calculate the mean number of steps you take to compare between week days, but what about those weekdays is different (e.g. “I could calculate the mean number of steps I took to compare average step count between weekdays because I have more classes on Monday than on any other day of the week, so I think I walk more on Monday.”)\n\n\n\n\n\n\nTip\n\n\n\nTry committing and pushing your changes here! Write an informative commit message.\n\n\n\n\nb. Visualization (10 points)\nUsing the summary you described in part a, create a visualization of your data comparing your summarized response variable between groups. If you are calculating a mean or median, show the underlying data in addition to your summary.\nUse colors in your figure (that are not the default ggplot settings).\nMake sure your axis labels are full, readable text (not just your column names).\n\n\n\n\n\n\nNote\n\n\n\nSee From Data to Viz for new ideas for visualization.\n\n\n\n\n\n\n\n\nTip\n\n\n\nTry committing and pushing your changes here! Write an informative commit message.\n\n\n\n\nc. Caption (5 points)\nWrite a caption for your figure.\n\n\n\n\n\n\nTip\n\n\n\nTry committing and pushing your changes here! Write an informative commit message.\n\n\n\n\nd. Table presentation (10 points)\nUsing gt or flextable, create a table with the same data summary that you describe in part a and visualized in part b. For example, if you described and visualized means, make a table with means. If you need to, round any numbers to one decimal point.\nDisplay the output.\n\n\n\n\n\n\nTip\n\n\n\nTry rendering your document here! Commit and push your changes, then find the url to your rendered output (if you get stuck, see the video on Canvas and/or the Git/GitHub basics page under the “Resources” tab).\nDouble check that your rendered document looks the way you would expect (e.g. tables all correct, text is formatted correctly). If not, go back and fix any issues or ask for help.\n\n\n\n\n\nProblem 2. Affective visualization (24 points)\nIn this problem, you will create an affective visualization using your personal data in preparation for workshops during weeks 9 and 10.\nIn lecture, we talked about the three vertices of data visualization: 1) exploratory, 2) affective, and 3) communicative. We’ve done a lot of exploratory and communicative visualization, but have yet to think about affective visualization.\nWhen thinking of affective visualization, you can expand your ideas of what data visualization could be. Some examples of affective visualizations include:\n\nJill Pelto’s paintings\nLorraine Woodruff-Long’s warming strips quilt\nStefanie Posavec and Giorgia Lupi’s Dear Data project\nEnvironmental Graphiti\n\n\na. Describe in words what an affective visualization could look like for your personal data (3-5 sentences). (2 points)\n\n\n\n\n\n\nTip\n\n\n\nTry committing and pushing your changes here! Write an informative commit message.\n\n\n\n\nb. Create a sketch (on paper) of your idea. (2 points)\nInclude a photo of this sketch in your submission.\n\n\n\n\n\n\nTip\n\n\n\nTry committing and pushing your changes here! Write an informative commit message.\nDouble check your rendered URL to make sure the photo of your sketch shows up.\n\n\n\n\nc. Make a draft of your visualization. (12 points)\nFeel free to be creative with this! You do not have to do this in R. You could create a sculpture, painting, textile object, etc.\nIf you are making your visualization in R, show the annotated code and the output.\nIf you are making your visualization outside of R, include a photo of your visualization in your submission.\n\n\n\n\n\n\nTip\n\n\n\nTry committing and pushing your changes here! Write an informative commit message.\nIf you are including a photo, double check your rendered URL to make sure the photo of your draft shows up.\n\n\n\n\nd. Write an artist statement. (8 points)\nAn artist statement gives the audience context to understand your work. For each of the following points, write 1-2 sentences to address:\n\nthe content of your piece (what are you showing?)\nthe influences (what did techniques/artists/etc. did you find influential in creating your work?)\nthe form of your work (written code, watercolor, oil painting, etc.)\nyour process (how did you create your work?)\n\n\n\n\n\n\n\nTip\n\n\n\nTry committing and pushing your changes here! Write an informative commit message.\n\n\n\n\n\n\n\n\nThis is prep for workshop during week 9!\n\n\n\nDuring week 9, we will send time providing peer review for your affective visualization. If you turn in your homework next Wednesday, you will have a draft of your affective visualization that is ready for peer review.\n\n\n\n\n\nProblem 3. Statistical critique (36 points)\nAt this point, you have seen and created a lot of figures for this class. Revisit the paper you chose for your critique and your homework 2, where you described figures or tables in the text. Address the following in full sentences (3-4 sentences each).\nFor this section of your homework, you will be evaluated on the logic, conciseness, and nuance of your critique.\n\na. Revisit and summarize (6 points)\nWhat are the statistical tests the authors are using to address their main research question? (Note: you have already written about this in homework 2! Find that text and provide it again here!)\nInsert the figure or table you described in Homework 2 here.\n\n\n\n\n\n\nTip\n\n\n\nTry committing and pushing your changes here! Write an informative commit message.\n\n\n\n\nb. Visual clarity (10 points)\nIn 1-3 sentences, answer the question that best fits your paper.\nIf you inserted a figure in Part a: How clearly did the authors visually represent their statistics in figures? For example, are the x- and y-axes in a logical position? Do they show summary statistics (means and SE, for example) and/or model predictions, and if so, do they show the underlying data?\nIf you inserted a table in Part b: How clearly does the table represent the data underlying tests?\nIf you have neither: Critique another figure or table in the text for visual clarity (and insert a screenshot of that figure/table in your submission).\n\n\n\n\n\n\nTip\n\n\n\nTry committing and pushing your changes here! Write an informative commit message.\n\n\n\n\nc. Aesthetic clarity (10 points)\nIn 1-3 sentences, answer the question that best fits your paper.\nIf you inserted a figure in Part a: How well did the authors handle “visual clutter”? How would you describe the the data:ink ratio?\nIf you inserted a table in Part b: How well did the authors handle “visual clutter”? Is there any bolding/italic text to draw your eye to specific numbers?\nIf you have neither: Critique another figure or table in the text for aesthetic clarity (and insert a screenshot of that figure/table in your submission).\n\n\n\n\n\n\nTip\n\n\n\nTry committing and pushing your changes here! Write an informative commit message.\n\n\n\n\nd. Recommendations (can be longer than 4 sentences, 10 points)\nWhat recommendations would you make to make the figure or table better? What would you take out, add, or change? Provide explanations/justifications for each of your recommendations.\nAlternatively, if they did not represent their statistics in a figure, what kind of figure would you recommend to them? Describe the x- and y-axes, with any geometries and aesthetics (colors, etc.). Provide enough explanation such that someone would be able to create the figure you describe in code. Provide explanations/justifications for the figure you would recommend.\n\n\n\n\n\n\nTip\n\n\n\nTry committing and pushing your changes here! Write an informative commit message."
  },
  {
    "objectID": "assignments/homework-03.html#double-check-your-assignment",
    "href": "assignments/homework-03.html#double-check-your-assignment",
    "title": "Homework 3",
    "section": "Double check your assignment!",
    "text": "Double check your assignment!\nOn Canvas, you will submit two links:\n\nthe link to your GitHub repository (15 points)\nthe link to your rendered html (15 points)\n\nYour GitHub repository should:\n\nhave an informative README with the following sections filled out: General information, Data and file information, and Rendered output. See the repo you created for workshop 7 and workshop 8 for a reference. (15 points)\nhave separate folders for code and data. See workshops 7 and 8 for how to organize these folders. (15 points)\nshow at least 10 commits/pushes with a descriptive, concise commit message (a few words describing what changes you are committing) (15 points)\n\nYour rendered html should:\n\nbe organized and readable (for example: no messages, warnings, etc., text is formatted correctly with subscripts or mathematical notation where necessary, text and headers are clearly different) (8 points)\ninclude a floating table of contents (see code from workshop 7 and 8 for a reference in Quarto and RMarkdown) (5 points)\n\nAdditionally, your rendered html should include only the components listed below:\n\na set up chunk at the top of the document, where you have read in your packages and your data (and you should not have read in any packages or data anywhere else) (5 points)\nyour name, the title, and the date (3 points)\nall code with annotations (10 points)\n\nfor Problem 1:\n\nwritten responses for a\ncode with annotations and output for b\nwritten responses for c\ncode with annotations and output for d\n\nfor Problem 2:\n\nwritten responses for a\nimage for b\nimage and/or code with annotations and output for c\nwritten responses for d\n\nfor Problem 3:\n\nwritten response and image for a\nwritten response for b\n\nwritten response for c\n\nwritten response for d\n\nLastly, check out the rubric on Canvas to see the point breakdown in more detail.\n181 total points"
  },
  {
    "objectID": "assignments/choose-your-own_advanced-data-visualization.html",
    "href": "assignments/choose-your-own_advanced-data-visualization.html",
    "title": "Choose your own assignment - Advanced data visualization",
    "section": "",
    "text": "Due on Wednesday June 4 (week 10) at 11:59 PM"
  },
  {
    "objectID": "assignments/choose-your-own_advanced-data-visualization.html#description",
    "href": "assignments/choose-your-own_advanced-data-visualization.html#description",
    "title": "Choose your own assignment - Advanced data visualization",
    "section": "Description",
    "text": "Description\nData visualization is a huge part of data storytelling. It also happens to be one of the major topics within the R user community. In this assignment, you’ll create an infographic using your personal data project, drawing inspiration from other people’s code and visualizations. You’ll learn about how people share their code (namely using GitHub) and create data art. You’ll then create your own piece, starting from the beginning (a sketch on a piece of paper) to a finished product (a visualization made in R, compiled in Canva, Illustrator, or another platform of your choosing). In the process, you’ll learn how to use ggplot and related packages to create visualizations. All components of this assignment should be written and rendered/knitted using Quarto or RMarkdown.\n\nWhat is visual storytelling?\nAsking an audience to read a paragraph of text is hard, but asking people to look at an infographic is way easier. You can draw people in with a well-presented, aesthetically pleasing figure, and then present some information that they might be interested in.\nSome examples of infographics that incorporate icons, images, and data include:\n\nInformation is Beautiful’s Seaweed: food, fertilizer, feed, fuel\nInformation is Beautiful’s Snake Oil Supplements?\n\n\n\nWhere to find inspiration\nMany examples of cool visualizations come from #tidytuesday, a hashtag/movement for R user community members to come together and learn more about how to use R tools to visualize and tell stories about data. Each week, organizers post a data set that has been cleaned up and is ready for visualization. We’ve worked with Tidy Tuesday data in class before: fisheries and ramen."
  },
  {
    "objectID": "assignments/choose-your-own_advanced-data-visualization.html#components",
    "href": "assignments/choose-your-own_advanced-data-visualization.html#components",
    "title": "Choose your own assignment - Advanced data visualization",
    "section": "Components",
    "text": "Components\n\nPart 1. Understand the context\n\na. Choose 4-5 types of visualizations you might be able to make with your data.\nFind examples that might work with the kind of data you have, or could work with some wrangling (e.g. you would have to calculate a sum or a mean, or otherwise summarize your data). Make notes of these visualizations (somewhere you can refer back to).\nYou’re not going to be using all of the types of visualizations you choose, but you need to come up with a list that allows you to try stuff out (and throw it out, if things don’t work).\nPotential resources for this step (but you can and should find others):\n\nYan Holtz’s From Data to Viz and R Graph Gallery to figure out what kinds of figures you could make\nSam Csik’s “One workflow for building effective (and pretty) {ggplot2} data visualizations.” to see how you can adjust the ggplot aesthetics to make a good looking figure\nNguyen Chi Dung’s “Infographics Using R” for a basic example of what is possible in R\nR statistics for Political Science’s “Create infographics with the Irish leader dataset in R and Canva” to see how to integrate visualizations from R with design platforms like Canva\nDeepanshu Bhalla’s “Create Infographics with R” to see how you can use images and icons\nKrzysztof Joachimiak’s compilation of packages and more that add visual interest to plots\nElmera Azadpour et al.’s “Jazz up your ggplots!” to see what extensions to ggplot you can use to make more beautiful plots\n\n\n\nb. Find some examples of visualizations you like, and save them somewhere you can refer back to.\nScroll through the #tidytuesday hashtag on X to see what visualizations people are making with the weekly data sets (link).\nSome cool examples (not an exhaustive list):\n\nIjeamaka Anyene’s collection of visualizations\nAditya Dahiya’s visualization of National Science Foundation grants\nSteven Ponce’s visualization of racial and ethnic disparities in reproductive health research\nIfeoma Egbogah’s visualization of the Palmer Penguins dataset\nCédric Scherer’s visualization of the Palmer Penguins dataset (code here)\nVictor Gauto’s visualization of Dungeons & Dragons actions\nManasseh Oduor’s visualization of attendance at different higher education institutions\nGeorgios Karamanis’s visualization of Himalayan expedition data (code here)\nDan Oehm’s visualization of Pokémon attributes (code here)\nNicola Rennie’s visualization of word counts from The Simpsons\n\n\n\n\n\n\n\nWhat kinds of examples should I be looking for?\n\n\n\nThe most useful examples will be ones where people have shared their code on GitHub.\nThe best way to understand someone’s code is to run it yourself. You can do this by forking and cloning the repository to your machine (as we did in workshop), or by copy/pasting the script into your computer. If you choose the second option, you may have to do some adjustment to file paths to get the script to read in the data correctly.\n\n\n\n\n\nPart 2. Your assignment\n\nRequirements\nYour infographic should have a clear narrative flow, demonstrating that you know how to tell a story (about yourself!) using data visualization.\nAll visualization components must be done in R. When you compile your visualizations into an infographic (with background colors, text boxes, titles, etc.) you can use Canva, Illustrator, PowerPoint, Slides, etc.\nYour infographic should have at least 3 data visualizations (i.e. figures that show some kind of data or numbers):\n\n1 visualization that we’ve discussed in class (jitter plot, boxplot, scatterplot, line plot)\n\n1 visualization that is new (as in, a visualization we haven’t covered in class)\n\n1 visualization that we’ve discussed or is new (choose what makes sense for your data)\n\nYou should also incorporate at least 2 add-ons from the following list:\n\ncustom annotations and arrows with geom_curve\nshapes with ggimage or fontawesome\ncustom fonts using showtext\n\nYour final infographic should have:\n\na title\nyour name\ntext descriptions for each figure describing what the main takeaway/message/pattern is\ninformation about your data\n\nhow long you have been collecting it\nhow many observations you have\nthe date of the most recent observation\n\n\nIn addition to incorporating these requirements, you will be graded on:\n\ncorrect, logical visualizations for the data you have (are you presenting the data accurately?)\nclear, concise communication about your data using visualization and text descriptions of patterns or messages\ninteresting and compelling aesthetic presentation to tell a clear visual story across your visualizations\n\nIn your final submission, you will also include a write-up (details below).\n\n\na. Update your data entry.\nEnter all the data you have.\nIf you get more observations as you’re completing this assignment (and you should), you need to update your figures to use your most recent data set.\n\n\nb. Sketch your visualization.\nUse colored pencils, highlighters, markers, etc. to represent the axes, images, text, titles, etc. of your infographic. Do not do this in code.\nIncorporate elements you liked from the visualizations you found in part 1 and clearly mark where they came from (using a footnote or direct annotation).\n\n\n\n\n\n\nOptional check-in here!\n\n\n\nIf you want to check in with An, you can turn in this sketch (as a photo or screenshot) by the 21st of May.\nThis check-in is optional. However, if you choose to do the check-in, the more detail you have on your sketch, the more thorough feedback you will receive.\n\n\n\n\nc. Code up your visualizations!\nCreate a GitHub repo for this assignment.\nClone the repo to your computer.\nOrganize your data and code into separate folders.\nCreate a .qmd or .Rmd file to code your visualizations.\nYour file should have:\n\na title\nyour name\nthe date\na set up code chunk\nsection headers for each visualization and your final write up (at the end)\nthe code and output for each visualization, including any summarizing or wrangling steps you had to take\ncode to save each visualization you make (as a .png, .pdf, .jpg, or other file)\na write-up (again at the end of your document)\n\nAll code should be annotated (see An if you are unclear about what counts as annotation).\n\n\nd. Arrange your visualizations using the design platform of your choosing.\nIncorporate color, text, etc. as needed to make your infographic visually interesting and compelling.\n\n\n\n\n\n\nRequired check-in here!\n\n\n\nThere is a required check-in for this assignment due on the 28th of May so that you can get directed feedback on your progress so far.\nFor the required check-in, you should have the basic components of your visualizations completed (you don’t have to have things finalized with the right colors, aesthetics, or add-ons) and you should have arranged all of your visualizations into a single infographic with at least a title.\n\n\n\n\ne. Write about your process\nIn the “write-up” section of your file, address the following points in 1-3 sentences each:\n\nGeneral information about design and visualization\n\nWhat patterns are you highlighting in each visualization? Why?\nOutside of the data visualization, what aesthetic choices (e.g. color, font, arrangement) did you make and why? In what way do your choices contribute to a compelling or interesting narrative?\n\n\n\nSources and process\n\nFor each visualization, describe what examples inspired that visualization (cite the author)\nDescribe your coding process, for example (not the only options for this prompt): did you have to clean up/summarize the data before you started? Which geoms did you start with? What geoms did you end up using, and why?\nDescribe the tools you used: other people’s code? Google/StackOverflow? ChatGPT (with examples of prompts)?"
  },
  {
    "objectID": "assignments/choose-your-own_advanced-data-visualization.html#checklist",
    "href": "assignments/choose-your-own_advanced-data-visualization.html#checklist",
    "title": "Choose your own assignment - Advanced data visualization",
    "section": "Checklist",
    "text": "Checklist\nFor your final submission, you only need to submit the link to GitHub repo where your materials for this specific assignment are (make sure it is public!).\nYour GitHub repository should include:\n\nyour .qmd or .Rmd with all your code\nyour rendered/knitted file in .html format\nyour final infographic\norganized files (separate folders for data, code, and images - so your code should incorporate use of the here package)\na README with a links to the .html file (be sure to enable GitHub pages) and the final infographic\n\nAdditionally, you should be committing and pushing changes throughout your completion of this assignment. Thus, you should make sure that you have at least 10 commits/pushes with informative commit messages."
  },
  {
    "objectID": "assignments/homework-01.html",
    "href": "assignments/homework-01.html",
    "title": "Homework 1",
    "section": "",
    "text": "Due on Wednesday April 16 (Week 3) at 11:59 PM\nRead these instructions before starting your homework and follow them carefully. See the end of this assignment for a checklist of components that your assignment must have at minimum (i.e. to earn at least partial credit). Only submit the items in that list, in the order requested."
  },
  {
    "objectID": "assignments/homework-01.html#part-1.-tasks",
    "href": "assignments/homework-01.html#part-1.-tasks",
    "title": "Homework 1",
    "section": "Part 1. Tasks",
    "text": "Part 1. Tasks\n\n\n\n\n\n\nNote\n\n\n\nYou will not need to submit any materials for tasks, but you are expected to complete the material/steps.\n\n\n\nTask 1. Set up your folders and .Rproj file\n\na. Create a new folder for this homework assignment within your ENVS-193DS folder.\nWithin the ENVS-193DS folder you set up, create a new folder for Homework 1. Name it whatever you want (a logical name could be homework-01).\n\n\nb. Download the files from Canvas\nDownload the homework files from Canvas into your homework folder on your computer. This includes:\n\nthe homework template\n\nglacial_volume_loss.csv\n\nglacial_volume_loss_copy.csv\n\n\n\nc. Create an Rproject for this homework assignment\nCreate an Rproj file within your homework-01 folder. If you need help with this, watch the “Creating an Rproject” video on Canvas.\n\n\n\nTask 2. Set up your code.\nAt the top of the template (or your own Quarto doc):\n\nLoad the tidyverse package.\n\nRead in data file 1 using read_csv(“glacial_volume_loss_copy.csv”) and store that as an object named glaciers.\n\n\n\nTask 3. Read about metadata from NOAA’s National Centers for Environmental Information\nRead the overview page on metadata here to understand what metadata is.\nThen, click through to the “Introduction to Metadata” page (under “Learn”) and read the questions that you should be able to answer with metadata.\n\nYou are now ready to start your homework!"
  },
  {
    "objectID": "assignments/homework-01.html#part-2.-problems-code-and-figures",
    "href": "assignments/homework-01.html#part-2.-problems-code-and-figures",
    "title": "Homework 1",
    "section": "Part 2. Problems, code, and figures",
    "text": "Part 2. Problems, code, and figures\n\nProblem 1. Measures of central tendency and data spread (11 points)\nAfter this winter’s rains, you’ve developed a new interest in slender salamanders (Batrachoseps spp.) You’ve collected the following lengths (in centimeters) for salamanders:\n\\[\n4.6, 4.4, 6.2, 5.2, 3.7, 6.0, 3.9, 4.6, 2.7\n\\]\n\nIn one sentence, categorize this data set: what type of data did you collect, and why is it that type? (2 points)\n\nCalculate the sample mean. Express your answer with the correct units and round to 1 decimal point. (3 points)\n\nCalculate the sample variance. Express your answer with the correct units and round to 1 decimal point. (3 points)\n\nCalculate the sample standard deviation. Express your answer with the correct units and round to 1 decimal point. (3 points)\n\n\n\nProblem 2. Visualizing data (50 points)\nIn this problem, you’ll work with data collected by the National Snow and Ice Data Center on glacial mass and sea level rise.\nBefore you start this problem, read about the data here.\nQuestions:\n\nOpen up the two data files (glacial_volume_loss_copy.csv and glacial_volume_loss.csv) in Excel (or another program, if you use something different). Look at the files side-by-side. In one sentence, explain how the data files are different. (2 points)\nUsing the “Introduction to Metadata” information from Task 3, choose one question from the examples for “Who”, “What”, “Why”, “Where”, “When” and “How”. For example, there are 5 examples under “How”; you should choose one of those examples to address.\n\nAnswer the questions you chose using the information in the User Guide on the data page.\nEach response should have the “question” (who, what, why, where, when, how), the example (“Who collected and processed the data?”), and your response. Format each as:\n\nWho: Who collected and processed the data? [insert response here]\n\nWhat: What are the data about? [insert response here]\n\nWhy: Why were the data collected? [insert response here]\n\nWhere: Where are the data located? [insert response here]\n\nand so on. You should have one response for each question and example. (18 points)\n\n\n\n\n\n\nChoose the examples that are most relevant to the dataset!\n\n\n\n\n\nNot all the examples from Task 3 will be relevant to this dataset. Read the examples and choose the most relevant ones based on what you learn about the dataset from the metadata and the user guide from the National Snow and Ice Data Center.\n\n\n\n\n\n\n\n\n\nBefore you start parts c and d\n\n\n\n\n\nOn paper, sketch out the axes for the histogram and the scatterplot. Label the axes, and write down the columns in the data frame you will need to use to make the figures. Draw the bars of the histogram and the points of the scatterplot.\nBy doing this before you code up your figure, you’ll be able to gain some intuition for what your figure should look like. You can then check your work against what you thought based on your drawing.\n\n\n\n\nCreate a histogram of annual sea level rise using ggplot(). Label the x- and y-axes. (16 points)\n\nCreate a scatterplot of cumulative sea level rise through time (year on the x-axis, cumulative sea level rise on the y-axis) using ggplot(). Label the x- and y-axes. (14 points)\n\n\n\nProblem 3. Personal data (36 points total)\nThis quarter, you’ll collect data from your own life to see how data science concepts are part of your daily existence. For this homework assignment, you’ll come up with two ideas for data collection. The data you collect:\n\nhas to be something you can get at least 30 observations on by week 10 (e.g. minutes to get from ENVS 193DS to your next class, not number of shark views per week)\n\nhas to be something that you could actually remember to write down (e.g. liters of water consumed in a day, not time spent on tiktok)\n\nhas to be be shaped by a question\n\nhas to include variables that would be appropriate to share with the class\n\nFor each idea you have (remember you have to come up with two ideas), you should:\n\narticulate a question (2 points each)\n\ndescribe your response variable (i.e. your variable of interest) (2 points each)\n\ndescribe your predictor variable (2 points each)\n\ndescribe what variables you should measure or record that indicate the time of the observation (for example: date or time of day) (2 points each)\ndescribe 4 additional variables you think you should measure or record that could also influence your response variable (2 points each)\n\ndescribe what type of data all your variables are with units (2 points each)\n\ndescribe the sources of your data (e.g. phone step tracker, screen time tracker, self) (2 points each)\n\ndescribe when you would take down data for an observation (2 points each)\n\ndesign a data sheet with some example data: what are the columns and what are the rows? (2 points each)\n\n\n\n\n\n\n\nNeed an example? Here’s An’s.\n\n\n\n\n\n\nQuestion: Do I go on longer runs on non-work days?\n\nMy response variable is length of run, measured in miles.\n\nMy predictor variable is work day (yes or no).\n\nI would record the date and time of day.\n\nduration, average pace, cadence, temperature, elevation, type of run, run location, hydration level\n\n\n\n\ndate (yyyy-mm-dd): continuous\n\ntime of day (hh:mm, 24 hour time): continuous\n\nduration (mm:ss): continuous\n\nlength (miles): continuous\n\naverage pace (min/mile): continuous\n\ncadence (steps/min): continuous\n\ntemperature (F): continuous\n\nelevation (feet): continuous\n\ntype of run (road, trail, mix): categorical\n\nrun location (neighborhood, front country, NCOS, other): categorical\n\nhydration level (&gt; 2 L, between 1-2 L, less than 1 L): categorical\n\nwork day (yes/no): binary categorical\n\n\nDate, time of day, duration, length, average pace, cadence, temperature, and elevation are all variables that I could get from Strava (a running tracking app). The 4 additional variables that I could not get from Strava and could influence the length of my run are: type of run, run location, hydration level, and work day. I would assign these categories myself.\nI would record my data after every run.\n\n\n\n\n\n\n\n\n\n\n\nWhen can I start collecting data?\n\n\n\n\n\nAn will give you feedback and recommendations for what to pursue for this project on Canvas on Thursday the 17th of April - Friday the 18th of April. That means that you should be able to start collecting data by the end of week 3, if not sooner.\n\n\n\n\n\nProblem 4. Setting up statistical critique (6 points)\nThroughout the quarter, you’ll engage in a critique of statistical methods for a published paper. Some methods are appropriate for the data and research questions, and some are not. You’ll be the judge.\nFor this homework assignment, you will find 3 candidate papers for your critique. Find 3 papers that speak to your interests - the paper could be on human health, plant restoration, agroecology, or more. Anything you might be interested in within the realm of environmental studies is fair game. Not all 3 papers have to be on the same topic.\n\nFor each paper, read the Abstract to get a general sense of what the paper is about. Then, read the Methods section, looking for information on statistical analysis. A paper is a good choice if it includes one of these terms (or something similar) in the analysis description:\n\nt-test\n\nAnalysis of variance (ANOVA)\n\nMann-Whitney U\n\nKruskal-Wallis\n\nWilcoxon rank sum\n\nLinear model or linear regression\n\nSpearman correlation\n\nPearson correlation\n\nlogistic regression\n\nGeneralized linear mixed effect model\n\nOnce you’ve verified that your paper includes at least one of the above listed terms, find the digital object identifier (DOI), which is a unique identifier in the form of a URL for a paper. You will know it is a DOI if it has doi.org somewhere in the URL.\n\nOnce you find the DOI for your paper, add it to the Google form. Repeat this for all three papers. (3 points)\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want to see what other people have chosen, see the class responses here.\n\n\n\nIn your homework document, list the papers in alphabetical order by author last name. (3 points)\nYour citations should take the form:\nLast name, first name, et al. Year. “Paper title.” Journal title volume:issue.\nExample:\nSanford, E., et al. 2019. “Widespread shifts in the coastal biota of northern California during the 2014–2016 marine heatwaves.” Scientific Reports 9:4216."
  },
  {
    "objectID": "assignments/homework-01.html#double-check-your-assignment",
    "href": "assignments/homework-01.html#double-check-your-assignment",
    "title": "Homework 1",
    "section": "Double check your assignment!",
    "text": "Double check your assignment!\nYour assignment should:\n\ninclude your name, the title, and the date (3 points)\n\ninclude all code with annotations (5 points)\n\nbe organized and readable (5 points)\n\nbe uploaded to Canvas as a single PDF (2 points)\n\nYour responses should include:\n\nwork and written responses for Problem 1\n\nwritten responses, annotated code, and figure outputs for Problem 2\n\nwritten responses for Problem 3\n\nwritten responses (3 paper citations) for Problem 4\n\nAdditionally, you should:\n\npaste 3 DOIs for the papers you’re interested in in the Google form\n\nLastly, check out the rubric on Canvas to see the point breakdown in more detail.\n118 points total"
  },
  {
    "objectID": "assignments/homework-01.html#frequently-asked-questions",
    "href": "assignments/homework-01.html#frequently-asked-questions",
    "title": "Homework 1",
    "section": "Frequently Asked Questions",
    "text": "Frequently Asked Questions\n\nI’m having trouble rendering to PDF. What can I do?\nYou could either install all the additional things R is asking for you to install, or you can render to a word doc instead (change pdf in the top part of the document to docx) and save that doc as a PDF.\n\n\nI don’t know how to insert an image into a Quarto document. How do I do that?\nHere is a resource for Quarto. If you rendered your Quarto file to a word document, you can insert an image into that word document the same way you would with any other word doc.\n\n\nWhere is the feedback for problem 4?\nIt is in the google sheet."
  },
  {
    "objectID": "assignments/reflection-01.html",
    "href": "assignments/reflection-01.html",
    "title": "Reflection 1",
    "section": "",
    "text": "Due on Sunday April 6 (Week 1) at 11:59 PM\nIn this assignment, you’ll introduce yourself and come up with a plan for what you’d like to get out of the class and roughly outline what you’d like to accomplish over the course of the quarter. You’ll continue visiting the goals you set for yourself in this assignment throughout the quarter, so it’s worth it to be as clear and specific as you can."
  },
  {
    "objectID": "assignments/reflection-01.html#components",
    "href": "assignments/reflection-01.html#components",
    "title": "Reflection 1",
    "section": "Components",
    "text": "Components\n\nA brief introduction\n\nyour name\n\nyour major\nyour year\n\npronouns (only if you feel comfortable sharing)\n\n\n\n\n\n\n\nNote\n\n\n\nFor each prompt below, respond in 1-3 sentences.\n\n\n\n\nSome questions about school and life\n\nWhy are you taking this class?\n\nWhat do you hope to get out of this class?\n\nIf you have a career in mind, how does this course apply to your future career, if at all?\n\nWhat do you wish your instructors knew about you, but don’t?\n\n\n\nSome questions about the way you like to learn\n\nWhat kinds of assignments, skills, or behaviors have you felt most comfortable with/enjoy from past classes? Why do you enjoy them?\n\nHow confident do you feel in your statistics skills (however you want to interpret that)? Why?\n\nHow confident do you feel in your coding skills (again, however you want to interpret that)? Why?\n\nWhat have you struggled with in the past in math or statistics courses? Why?\n\nOf the courses you’re taking this quarter, which do you expect to be the most challenging? Most demanding?\n\nWhich learning goals from the syllabus are you most excited about?\n\nWhat other learning goals do you have for the course?\n\nMost importantly, how do you plan on accomplishing your learning goals for this course?\n\n\n\n\n\n\n\nNote\n\n\n\nBe specific here! Instead of writing, “I will complete homework assignments” or “I will study”, you can make these more specific strategies: “I will use the homework assignments as opportunities for practice. I will communicate with classmates for help after trying…”"
  },
  {
    "objectID": "assignments/reflection-02.html",
    "href": "assignments/reflection-02.html",
    "title": "Reflection 2",
    "section": "",
    "text": "Due on Wednesday May 14 (week 7) at 11:59 PM\nIn this assignment, you’ll reflect on your own progress in the course up until this point.\nReread your responses to reflection 1 and the feedback on Canvas. Then, address the following questions in 2-3 sentences each."
  },
  {
    "objectID": "assignments/reflection-02.html#components",
    "href": "assignments/reflection-02.html#components",
    "title": "Reflection 2",
    "section": "Components",
    "text": "Components\n\nHow have you progressed towards your learning goals for this course? Specifically, how do you know that you’ve made progress (for example, have you grown more confident in coding, have you applied statistics to new scenarios)?\nWhat skills are you proud of developing and/or building on in the last 7 weeks?\nLooking forward, how have your learning goals changed? Have they stayed the same?\nHave you learned anything into which you want to dive more deeply? Have you done so? If yes, what did you learn?\nFill out the anonymous survey linked in the assignment description on Canvas, and answer the question at the end of the survey."
  },
  {
    "objectID": "assignments/reflection-02.html#checklist",
    "href": "assignments/reflection-02.html#checklist",
    "title": "Reflection 2",
    "section": "Checklist",
    "text": "Checklist\nYour reflection should:\n\naddress at least the 5 topics above (but please feel free to expand on these if you would like)\n\nbe uploaded to Canvas by 11:59 PM on Wednesday May 14 in PDF format"
  },
  {
    "objectID": "assignments/choose-your-own_quarto-website.html",
    "href": "assignments/choose-your-own_quarto-website.html",
    "title": "Choose your own assignment - Quarto website",
    "section": "",
    "text": "Due on Wednesday June 4 (week 10) at 11:59 PM"
  },
  {
    "objectID": "assignments/choose-your-own_quarto-website.html#description",
    "href": "assignments/choose-your-own_quarto-website.html#description",
    "title": "Choose your own assignment - Quarto website",
    "section": "Description",
    "text": "Description\nIn this assignment, you’ll create your own personal website using Quarto. By the end of this assignment, you’ll have a website that you developed using data science tools. You’ll also see how Quarto pages fit together like a puzzle to create a finished website.\nWhy make a website at all? Having a website is a great way of developing a digital portfolio of your skills and interests. Read Elizabeth Pearson’s “4 Reasons Having a Personal Website Will Help Your Career” for more.\nHow does making a website using Quarto actually work? In class, we use Quarto markdown documents to write code with text, then render the document into the format we want (usually .pdf or .docx). One major benefit to using Quarto + Rprojects is that 1) Quarto renders to .html and 2) Quarto can render a bunch of Qmd files in a single project to create a website.\nWhy make a website using Quarto? It’s a great way of demonstrating your skills to the data science community to show that you have some competency in knowing how Quarto documents work together."
  },
  {
    "objectID": "assignments/choose-your-own_quarto-website.html#components",
    "href": "assignments/choose-your-own_quarto-website.html#components",
    "title": "Choose your own assignment - Quarto website",
    "section": "Components",
    "text": "Components\n\nPart 1. Understand the context\n\na. Look at a Quarto website for some ideas regarding structure and content\nSome examples of personal Quarto websites include:\n\npast 193DS students (from Spring 2024): Evelyn Bermudez, Owen Choy, Dylan Freebairn-Smith, Ada Chibueze, Aidan Robertson, Brooke Ryan\nprofessionals: Meghan Harris, Jadey Ryan, Bea Milz, Sam Shanny-Csik\nthe instructors’ sites: Thuy-Tien, An\n\n\n\n\n\n\n\nTip\n\n\n\nIf you see a feature on someone’s Quarto website that you want to implement, go to their GitHub repository for the site to see how they made it. For example, Sam Shanny-Csik has a map of all the hikes she logged using Strava, which is an embedded product from a dashboard she created. The repository for Sam’s website is here, and the Strava dashboard is here.\n\n\n\n\n\nPart 2. Your assignment\n\nRequirements\nYour website should have at least the following pages:\n\na landing page with a\n\nphoto\nbrief bio (education, work, etc.)\n\nan about me page, which should include\n\nat least 3 photos (can be of you or other things: pets, food, places)\nat least 3 sections (of whatever you want to share about yourself)\n\na project page with\n\nat least one post with code, its output, and writing about what you’re doing and why\nat least one post with project or paper description (from a job, research project, class)\n\nanother page (a free for all)\n\ncould be about anything (hobbies, interests, etc.)\nmust be organized with section headers\nmust have photos or visuals of some kind\n\na resume or CV\n\ncan be a page itself or a PDF\n\n\nAdditionally, you need to include all of the following add-ons/customizations:\n\nsomewhere on your website, there should be an interactive figure or map (examples of how to do that here)\nchange the theme of your website from the default (here’s a list of Quarto themes)\nchange the CSS and/or SASS defaults for the theme to colors, fonts, etc. of your choice (here’s a tutorial for how to do that).\n\nFor your final submission (on Canvas), you will also submit a write-up of your process (details below).\n\n\na. List the “pages” you want to include on your website with section headers.\nDo this in a word doc or in Google docs. Do not code this.\nFor your project page, you could format using blog posts. You can enhance these with citations, figures, etc. to fill them out. Alternatively, you could use the blog post format to highlight classes you’ve taken to show you’ve developed skills in whatever those classes are about (for example, literary criticism, GIS, visual art). Note: you can have multiple pages in “blog” format - see Sam Csik’s personal website where the “talks & workshops”, “courses”, “projects”, and “posts” pages are all “blogs”.\nThroughout your website, you could also have photo galleries to share any visual media you might have - illustration, photography, etc.\n\n\n\n\n\n\nOptional check-in here!\n\n\n\nIf you want to check in with An, you can turn in this outline by the 21st of May.\nThis check-in is optional. However, if you choose to do the check-in, the more detail you have on your sketch, the more thorough feedback you will receive.\n\n\n\n\nb. Make your website following your outline.\nFollow these directions written by Sam Shanny-Csik (from above!). Read the directions before you start.\n\n\n\n\n\n\nRequired check-in here!\n\n\n\nThere is a required check-in for this assignment due on the 28th of May so that you can get directed feedback on your progress so far.\nFor the required check-in, you should have all the pages created for your website (landing page, about me page, project page, free for all page, resume/CV), but you do not have to have anything filled in yet.\n\n\n\n\nc. Fill out your website.\nInclude text, photos, etc.\n\n\nd. Write about your process.\nRespond to the following prompts with 1-3 sentences each:\n\nWhat was hard about this?\nWhat was easy?\nWhat was new to you?\nWhat was familiar to you?\nHow did following the tutorial go for you?\nWhich examples did you find most useful? Be specific about the components of your website that you copied from other people (e.g. I saw a photo gallery on this person’s website, so I created a gallery of…)."
  },
  {
    "objectID": "assignments/choose-your-own_quarto-website.html#checklist",
    "href": "assignments/choose-your-own_quarto-website.html#checklist",
    "title": "Choose your own assignment - Quarto website",
    "section": "Checklist",
    "text": "Checklist\nYour submission should include\n\nA link to the GitHub repository where your website is held\n\nA link to your actual website\n\nYour write up (as text in the Canvas submission)\n\nAdditionally, you should be committing and pushing changes throughout your completion of this assignment. Thus, you should make sure that you have at least 10 commits/pushes with informative commit messages."
  },
  {
    "objectID": "resources/using-github.html",
    "href": "resources/using-github.html",
    "title": "Git/GitHub basics",
    "section": "",
    "text": "Note\n\n\n\nIn class, we will create a GitHub repository and fork a repository. We might not get to GitHub pages or collaborating."
  },
  {
    "objectID": "resources/using-github.html#why-are-we-using-gitgithub",
    "href": "resources/using-github.html#why-are-we-using-gitgithub",
    "title": "Git/GitHub basics",
    "section": "Why are we using Git/GitHub?",
    "text": "Why are we using Git/GitHub?\nGit and GitHub allow us to do a few important things in data science:\n\nkeep track of different versions of our work (so that old work is never lost forever)\n\nstore our work remotely (so that if our computers die, we still have access to our stuff)\n\nreuse other people’s work (so that we can reproduce their work and also repurpose for our own needs)\n\ncollaborate with others (so that you’re not emailing, texting, etc. code back and forth)\n\nSee Horst and Lowndes, “GitHub for supporting, reusing, contributing, and failing safely.” for a broad overview of how Git/GitHub work together, and Jenny Brian’s “Excuse me, do you have a moment to talk about version control? for more."
  },
  {
    "objectID": "resources/using-github.html#what-is-the-difference-between-git-and-github",
    "href": "resources/using-github.html#what-is-the-difference-between-git-and-github",
    "title": "Git/GitHub basics",
    "section": "What is the difference between Git and GitHub?",
    "text": "What is the difference between Git and GitHub?\nGit is what tracks your changes (and allows you to have version control), while GitHub is a cloud hosting service for those changes. We use both together."
  },
  {
    "objectID": "resources/using-github.html#operations",
    "href": "resources/using-github.html#operations",
    "title": "Git/GitHub basics",
    "section": "Operations",
    "text": "Operations\n\n\n\n\n\n\nTip\n\n\n\nIf you’re having trouble seeing any screenshots, click the image to make it bigger.\n\n\n\n\n\n\n\n\nDefinitions\n\n\n\n\nrepo: short for “repository”, think of this as a folder\n\nremote: your repository on GitHub (in the cloud)\n\nclone: essentially making a local copy (i.e. a copy on your computer) of a remote repo\n\ncommit: track the changes you’ve made using Git (on your computer only)\n\npush: push the changes you’ve committed to GitHub (now in the cloud)\n\npull: pull changes from GitHub to your computer\n\nfork: create a copy of someone else’s repo on GitHub\n\n\n\n\nCreating a repository and using Git/GitHub\n\n1. Create a repository.\nGo to the GitHub homepage.\nClick the green “New” button.\n\n\n\n2. Fill information about your new repository.\nThis includes the name, a description, whether it is public or private (keep your repository public for now).\nAdditionally, initialize your repository with a README. It is very important to start your remote repository with a file, and GitHub does it for you by creating a file called README.md.\nA README file describes what is in the whole repository (code, data, etc). See the README resource for more details about what it is, but for now remember to always initialize your repository with a README.\n\n\n\n3. Clone your repo to your computer.\nWhen you are “cloning”, you are essentially making a local copy (i.e. on your computer) of your remote.\nDo this by clicking the green “Code” button and copying the url that shows up.\n\nThen, create a new project in RStudio.\nSelect “Version Control”.\n\nThen, select “Git”.\n\nPaste the clone url into the first box.\nKeep your cursor in that box, then hit the Tab key. The new project directory name should automatically fill in.\n\n\n\n\n\n\n\nDirectory names\n\n\n\nIt is very important that your remote and local repositories have the same name. The easiest way to ensure this is by not typing anything into the second box. Paste the url into the first box, then hit Tab.\n\n\nThen, select the folder on your computer where you are keeping all your repositories for Git/GitHub. If you created a folder called “Git” or “GitHub” in your root directory, use that folder. This is something that you only have to do once; for each subsequent repo you clone from GitHub, the file path will be automatically filled in.\nAfter you have created your repository, a new RStudio window will open.\nVerify that the clone has worked by seeing that you have:\n\na project (should be the same as the directory name)\n\nthe “Git” tab\n\na .gitignore file (a file that tells git which files to ignore when tracking changes)\n\n\n\n\n4. Make changes to your repository.\nCreate a new Quarto document.\nType in some code.\nSave your document.\nOpen up the Git tab in the top right. You should see your new .qmd file along with any other new files (the .gitignore and the .Rproj file.).\n\n\n\n5. Commit your changes.\nIn the Status column, you will see two yellow question marks. This means that the files are new, and git isn’t tracking them yet.\nCheck the boxes next to each file, which turns the two yellow question marks to a green “A” for “added”.\nClick “Commit”. A new screen will pop up that looks like this:\n\nIf you click through each file in the top left pane, you will see the changes to the file in the lower pane.\nThe top right pane is where your commit message goes.\nCommit messages accompany each git commit and push. They should describe the changes to the file since the last version. They’re best as short phrases describing the changes. For a first commit/push, you could just write something like “initial commit”, as in the example.\nWrite a commit message, then hit “Commit”.\nYou should see a window that shows your commit message and a summary of the file changes.\n\nCongratulations! Your files are now being tracked by git.\n\n\n6. Push your changes.\nYour file is now being tracked, but it’s not on GitHub yet.\nTo get your files on GitHub, push the commit. To do this, click the “Push” button. You should see a window that looks like this:\n\nDouble check that your push to GitHub by looking back at your remote. Refresh the repository page.\nYou should see your new files in the repository, and your commit message showing up next to the files that you changed.\n\nCongratulations! Your files are now on GitHub.\n\n\n7. Make more changes.\nVersion control only works if you actually use it. That means you should commit and push with each change you make. The frequency of committing/pushing you do depends on you. Some people are totally commit-happy and commit/push with every chunk of code they write; you might find it more reasonable to commit/push after each coding session.\nEvery time you make a change, your modified file will show up in the “Git” tab with a blue M for “modified”. The process for changes is the same as for new files:\n\nClick the check box,\n\nhit “Commit”,\n\nfill in a commit message,\n\ncommit,\n\nthen push.\n\nIn the commit window, you’ll see any modified files with changes highlighted in green, as before.\n\n\n\n\nForking\nForking is the process by which you can copy and reuse another person’s code. Imagine having a meal with someone else, and using your fork to take something from the other person’s plate. You can then do whatever you want with the food you’ve taken: eat it, mix it with other things, etc. This is the idea behind forking.\n\n1. Navigate to the repository you want to fork.\nYou should see a button to “Fork” in the top right.\n\n\n\n2. Create the fork\nClick “Fork”. You’ll be led to a screen to “Create a new fork”.\nYou can rename the repo if you want, or write a new description. You’ll also copy the main branch.\n\nYou will have to wait for a bit.\nOnce it’s done, you should see a screen that looks like a normal repo with some indications that you have forked someone else’s repo:\n\nunder the repo name, you will see “forked from” another repo.\n\na message saying “This branch is up to date with…”\n\n\n\n\n3. Clone the repo.\nThis is the same process as cloning your own repo.\nClick the green “Code” button and copy the url that shows up.\nThen, create a new project in RStudio.\nSelect “Version Control”.\nPaste the url you copied and hit tab.\nMake sure that you are creating a project as a subdirectory of your git/github folder.\n\n\n\n4. Work in the repo.\nThis is the same as working in your own repo: write code, make changes, commit and push them.\nYour changes will only be saved to your forked repo, not to the original repo. Thus, you are reusing people’s code and writing new code without overwriting their work.\n\n\n5. Incorporate upstream changes (if there are any)\nThe original repo is “upstream” of your fork. Sometimes, there are upstream changes to the original repo that you want to incorporate into your fork.\nIf there are upstream changes you want to have in your fork, then sync your fork by hitting the “Sync fork” button.\n\nThese changes will now be in your remote, but not in your local.\nGo back to RStudio and open the Git tab. Click “Pull” to get the changes into your computer.\n\n\n\n\nUsing GitHub Pages to display rendered .html output\n\n\n\n\n\n\nTip\n\n\n\nFor the rest of the assignments in this class (Homework 3, choose your own assignment (generative art and advanced data visualization), and final), you will submit a link to your rendered .html document on a GitHub repository.\nBe sure you are comfortable with doing this! Please ask for help if you are not!\n\n\n\nSet up\nMake sure your Quarto document is set to render to .html.\nYou can change this in the YAML (the part of the document at the very beginning between two sets of three dashes ---). The YAML line is: format: html.\n\n\n1. Render your document.\nWhen you render your Quarto document, you should see the rendered output pop up in the viewer pane (the bottom right).\nYou should also see new files show up in the Git pane: the .html version of your Quarto document, and a folder ending in _files/ that has all the related code for the .html file.\n\nWhen you click the checkbox for the _files/ folder, you will see a bunch of new files being added. This is normal!\n\n\n\n2. Commit and push these files.\nSame as above: write a brief commit message.\n\n\n\n3. Set up GitHub pages in your remote.\nNavigate to Settings &gt; Pages in your GitHub repo.\nUnder “Build and deployment”, choose the main branch in the root folder to enable GitHub pages.\n\nHit “Save”. If successful, you should see a blue banner at the top: “GitHub Pages source saved”.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are making a website, this step will be slightly different in that you’ll choose a different folder when setting up GitHub Pages. Be sure to follow Sam’s instructions!\n\n\nBack in the main page for your repo, you’ll see two new icons: a yellow dot next to your most recent commit, and a “Deployment” section on the right with “github-pages” in it.\n\nEventually, these will turn green, meaning that your GitHub pages set up is complete.\n\n\n4. Look at your deployment.\nClick on the github-pages link under “Deployment”.\nYou should see a screen that has the url to your page and the most recent commit message as a deployment message.\n\nMake a note of the url. It should be something along the lines of your-github-username.github.io/your-repository-name.\nClick on the url. It should take you to a pretty bare page:\n\nThis is the rendered version of your README.\n\n\n5. Find the url for your rendered .html.\nEvery rendered document in your repository is now accessible to anyone with the url to your GitHub pages. This means that you can share your rendered output without a file, just a link.\nThe link to your repo on GitHub pages is different from your repo on GitHub. This is the usual naming scheme:\n\n\nImage from Halina Do-Linh, Camila Vargas Poulsen, Samantha Csik, Daphne Virlar-Knight. 2023. coreR Course. NCEAS Learning Hub.\n\nBut first, you need to find your file.\nRendered document urls take the form: your-github-username.github.io/your-repository-name/[whatever folders the file is in]/the-file-name.html.\nIn this example, the url for the rendered .html is https://an-bui.github.io/new-repository/test-document.html. This means that test-document.html is in the root folder (i.e. is not in any subfolders) in new-repository.\n\nNavigate to that url. You should see your rendered document as a webpage!\n\n\n\n\n\n\n\nDo not fall for localhost!\n\n\n\nWhen you first render your document, you can open it up in a browser. It will look like a webpage, but the “url” will include something like localhost:. This is not a real url! It is temporary and not shareable. If you’re unsure you’re looking at the right thing, check the url. If it looks like an actual url, then you have it right.\n\n\n\n\n6. Save your url somewhere.\nThe best way to do this is to put a link somewhere in the README of your repo. For example, the README for this example repo includes the url to the rendered .html.\n\n\n\nBrowsing your remote repo\nGitHub allows you to easily browse the history of your repository. Think of this as time travel!\n\n1. Find your commit history\nEach commit/push you make to your repo gets stored in your commit history. The commit history is a list of all the commits you’ve made.\nFind your commit history in your repo. It should look like an arrow in a circle with the number of commits you’ve made. Click this.\n\n\n\n2. Browse your commit history\nYou can see the list of all commits you’ve made.\nTo see the details of a particular commit, click on the commit message.\nThis will lead you to a screen that displays the old verson on the left and what was added in that particular commit on the right.\n\n\n\n3. Browse your repository\nBack in the commit history, you have the option to browse your repository at the time of that commit (!!!).\n\nIf you click the &lt;&gt; button, it will take you back to the repository at the time of that commit. You can navigate the same way you would in a regular repository.\n\nThe url with the long code at the end indicates that you are browsing an old version of your repo.\n\n\n\n\n\n\nGitHub for failing safely\n\n\n\nThe time travel aspect of GitHub is one of the best reasons to use GitHub. If you are committing/pushing your changes regularly, you will have each version of your repository saved in the cloud. These versions are all easily browsable. If you’ve deleted something and you decide you want it back, then you can go back and get it. Nothing is gone forever, and that’s a good thing when you’re changing your code, working with others, and adding more to your work.\n\n\n\n\n\nCollaborating\nAnother powerful way to use GitHub is to work with other people. You can add collaborators to a repository and they can commit/push changes just like you can, and you can pull each others changes to your respective computers.\n\n\n\n\n\n\nWorking together\n\n\n\nGitHub is a powerful tool to collaborate, but it doesn’t replace good communication with collaborators. When working with someone else in the same repo, be sure to communicate with each other about what you’re doing, what part of the document you’re going to be working in, etc. This requires you to actually reach out and contact them - so do it!\n\n\n\n1. Add collaborators to your repo.\nIn your GitHub repo, navigate to Settings &gt; Collaborators.\n\nFind your collaborator by searching for their GitHub username.\nSelect their username.\n\nHit the green “Add … to this repository” button.\nIf successful, you should see the other person listed as a collaborator and a blue banner that says “… has been added as a collaborator on this repository.”.\n\n\n\n2. For the collaborators\nYou will receive an email with an invitation to the repo. Accept the invitation.\nYou should then see something like “you have push access to this repository”. That means you can work out of this repo and commit/push changes as though it was your own.\nClone this repo to your computer.\n\n\n3. Make changes, commit, push.\nSame as above!\n\n\n4. View changes to the repo.\nWhen your collaborator has made changes in the repo, you will see them on the remote.\n\nYou can also see the history of changes by clicking the “Commits” button.\n\n\n\n5. Incorporate changes\nYou and your collaborator will be working out of the same repo. That means that you can pull each others’ changes to your respective computers.\n\n\n\n\n\n\nPulling best practice\n\n\n\nWhen collaborating with others, it is best practice to pull often. If you’re starting up a coding session, pull any changes. Before you commit/push changes, pull more changes.\nThis prevents situations called “merge conflicts” which can range from easily fixable to extremely frustrating. See a guide to navigating merge conflicts here.\nOne easy way to avoid merge conflicts is to make sure that you and your collaborator are working on different parts of the document, or on different documents entirely. Once you’re both done with your respective parts, incorporate everything into one document.\n\n\nPull changes by hitting “Pull” in the Git tab.\n\nA window should pop up with a summary of changes, additions, deletions, etc. that you are pulling from the remote.\n\nYou will then see the changes on your computer!\n\nYou can keep working in your document as usual. You can also edit your collaborator’s work. For example, maybe you needed to add some comments to the code to annotate it, or maybe you need to change one of their functions to something new. Whatever it might be, be sure to continue communicating with your collaborators so that everyone is on the same page."
  },
  {
    "objectID": "resources/git-configuration.html",
    "href": "resources/git-configuration.html",
    "title": "Git/GitHub Part 1: prechecks",
    "section": "",
    "text": "“Git” (pronounced with a hard “g”, as in “give”) is the software that tracks versions of files on your computer. “GitHub” (also pronounced with a hard “g”) is the hosting platform that holds all versions of files tracked by Git.\n\n\n\nYou NEED to know where the difference between files on your actual, physical computer vs files held on OneDrive or iCloud. Git will not work properly with files on OneDrive or iCloud (in short, the cloud syncing does not work with version control).\nFor every folder you track with Git, you have to make sure it is not on OneDrive or iCloud.\nOne easy way make sure that your folders are on your actual computer (again, not on OneDrive or iCloud) is to create a folder called git or github outside of cloud folders. On my (An’s) computer (which is a Mac), the file path to this folder is Macintosh HD &gt; Users &gt; An &gt; github.\nWith Macs: your root directory is usually Macintosh HD.\nWith Windows: your root directory is the C: drive.\n\n\n\nYou are going to run into problems down the line (when we use Git/GitHub in class) if you do not set this up correctly. PLEASE give yourself time to read the directions and follow the steps exactly as they are laid out. Additionally, reach out to An/Thuy-Tien/Grace for individual help with any of these steps.\n\n\n\nWe are going to start using Git/GitHub in class during week 7 (Thursday the 15th of May and Friday the 16th of May). You can get help in:\n\ndrop-in hours (Wednesday the 7th, Friday the 9th, Wednesday the 14th, Thursday the 15th)\nin workshop on Thursday the 8th or Friday the 9th (come to any workshop meeting, you don’t have to come to the one you’re enrolled in)\n\n\n\n\nAgain, we are going to start using Git/GitHub in class during week 7. If you do not set things up correctly on your own AND/OR if you do not get help during workshop or drop-in, we will not stop to help you.\nYOU NEED TO SET EVERYTHING UP CORRECTLY BEFORE WEEK 7 WORKSHOP."
  },
  {
    "objectID": "resources/git-configuration.html#git-vs-github",
    "href": "resources/git-configuration.html#git-vs-github",
    "title": "Git/GitHub Part 1: prechecks",
    "section": "",
    "text": "“Git” (pronounced with a hard “g”, as in “give”) is the software that tracks versions of files on your computer. “GitHub” (also pronounced with a hard “g”) is the hosting platform that holds all versions of files tracked by Git."
  },
  {
    "objectID": "resources/git-configuration.html#do-not-track-files-in-folders-on-onedrive-or-icloud",
    "href": "resources/git-configuration.html#do-not-track-files-in-folders-on-onedrive-or-icloud",
    "title": "Git/GitHub Part 1: prechecks",
    "section": "",
    "text": "You NEED to know where the difference between files on your actual, physical computer vs files held on OneDrive or iCloud. Git will not work properly with files on OneDrive or iCloud (in short, the cloud syncing does not work with version control).\nFor every folder you track with Git, you have to make sure it is not on OneDrive or iCloud.\nOne easy way make sure that your folders are on your actual computer (again, not on OneDrive or iCloud) is to create a folder called git or github outside of cloud folders. On my (An’s) computer (which is a Mac), the file path to this folder is Macintosh HD &gt; Users &gt; An &gt; github.\nWith Macs: your root directory is usually Macintosh HD.\nWith Windows: your root directory is the C: drive."
  },
  {
    "objectID": "resources/git-configuration.html#stay-calm-and-do-not-panic",
    "href": "resources/git-configuration.html#stay-calm-and-do-not-panic",
    "title": "Git/GitHub Part 1: prechecks",
    "section": "",
    "text": "You are going to run into problems down the line (when we use Git/GitHub in class) if you do not set this up correctly. PLEASE give yourself time to read the directions and follow the steps exactly as they are laid out. Additionally, reach out to An/Thuy-Tien/Grace for individual help with any of these steps."
  },
  {
    "objectID": "resources/git-configuration.html#opportunities-to-get-help-before-we-start-using-gitgithub-in-class",
    "href": "resources/git-configuration.html#opportunities-to-get-help-before-we-start-using-gitgithub-in-class",
    "title": "Git/GitHub Part 1: prechecks",
    "section": "",
    "text": "We are going to start using Git/GitHub in class during week 7 (Thursday the 15th of May and Friday the 16th of May). You can get help in:\n\ndrop-in hours (Wednesday the 7th, Friday the 9th, Wednesday the 14th, Thursday the 15th)\nin workshop on Thursday the 8th or Friday the 9th (come to any workshop meeting, you don’t have to come to the one you’re enrolled in)"
  },
  {
    "objectID": "resources/git-configuration.html#in-class-technical-difficulties",
    "href": "resources/git-configuration.html#in-class-technical-difficulties",
    "title": "Git/GitHub Part 1: prechecks",
    "section": "",
    "text": "Again, we are going to start using Git/GitHub in class during week 7. If you do not set things up correctly on your own AND/OR if you do not get help during workshop or drop-in, we will not stop to help you.\nYOU NEED TO SET EVERYTHING UP CORRECTLY BEFORE WEEK 7 WORKSHOP."
  },
  {
    "objectID": "resources/git-configuration.html#create-a-github-account",
    "href": "resources/git-configuration.html#create-a-github-account",
    "title": "Git/GitHub Part 1: prechecks",
    "section": "1. Create a GitHub account",
    "text": "1. Create a GitHub account\nIf you don’t have one already, create a GitHub account.\nUse your personal email, not your ucsb.edu email (because you will lose access to that email once you graduate)."
  },
  {
    "objectID": "resources/git-configuration.html#check-that-you-have-git-on-your-computer",
    "href": "resources/git-configuration.html#check-that-you-have-git-on-your-computer",
    "title": "Git/GitHub Part 1: prechecks",
    "section": "2. Check that you have git on your computer",
    "text": "2. Check that you have git on your computer\nOpen RStudio. Open the Terminal.\nIf you are on a Mac, type which git and hit Enter.\nIf you are using a Windows machine, type where git and hit Enter.\n\n\n\n\n\n\nTip\n\n\n\nClick on any screenshot to make it bigger!\n\n\n\nYou should see something pop up that looks like a file path. It might look slightly different from this example, which is ok.\nIf you do not see a file path, you’ll need to install git: https://git-scm.com/downloads\n\n\n\n\n\n\nNote\n\n\n\nMost Macs come with git pre-installed. If you are using a Mac and you do not get a file path when you run which git, email An."
  },
  {
    "objectID": "resources/git-configuration.html#set-your-username-and-email",
    "href": "resources/git-configuration.html#set-your-username-and-email",
    "title": "Git/GitHub Part 1: prechecks",
    "section": "3. Set your username and email",
    "text": "3. Set your username and email\nIn the Terminal, type git config --global user.name \"your-username-here\" (replace your-username-here) with your actual user name. Hit Enter.\n\n\n\n\n\n\nPay attention to spaces, dashes, and all punctuation!!!\n\n\n\nNone of the steps in the Terminal will work without the right spaces, dashes, etc.\n\n\nThen (still in the Terminal), type git config --global user.email your-email-here (replace your-email-here) with your email. No quotation marks around your email!\nThen (again, still in the Terminal), type git config --list --global. You should see your user name under the user.name field, and your email under the user.email field."
  },
  {
    "objectID": "resources/resubmissions.html",
    "href": "resources/resubmissions.html",
    "title": "How to resubmit an assignment",
    "section": "",
    "text": "You can submit one (1) request for resubmission for either of the following assignments:\n\nyour midterm\nyour choose your own assignment (a Quarto website or an advanced data visualization)"
  },
  {
    "objectID": "resources/resubmissions.html#assignments-eligible-for-resubmission",
    "href": "resources/resubmissions.html#assignments-eligible-for-resubmission",
    "title": "How to resubmit an assignment",
    "section": "",
    "text": "You can submit one (1) request for resubmission for either of the following assignments:\n\nyour midterm\nyour choose your own assignment (a Quarto website or an advanced data visualization)"
  },
  {
    "objectID": "resources/resubmissions.html#format-for-resubmission-request",
    "href": "resources/resubmissions.html#format-for-resubmission-request",
    "title": "How to resubmit an assignment",
    "section": "Format for resubmission request",
    "text": "Format for resubmission request\nEmail An with the subject line “ENVS 193DS resubmission” along with the title of the assignment you are resubmitting.\nWrite your request for resubmission in a separate PDF.\nFor each component that you want to redo for the possibility of getting points back, you will need to articulate (in 1-2 sentences, the shorter, the better):\n\nwhat you got wrong\nwhat you need to do to fix it\nwhy that fix would improve the quality of your work (independently of the grade you received)\n\nFor example, if you got points off for x-axis labels on a plot that were overlapping, a reasonable request would be:\nProblem 2a\n\nMy x-axis labels for Problem 2a were overlapping.\nI need to either spread out the x-axis or fix the way I read in the data to make sure the columns are correct (so that the date column is read in as a date rather than a character).\nMaking sure the x-axis labels don’t overlap improves the figure because it would be more readable."
  },
  {
    "objectID": "resources/resubmissions.html#after-you-submit-your-request-to-resubmit",
    "href": "resources/resubmissions.html#after-you-submit-your-request-to-resubmit",
    "title": "How to resubmit an assignment",
    "section": "After you submit your request to resubmit",
    "text": "After you submit your request to resubmit\nAn will review your request for resubmission and either confirm or deny the request (if denied, you will be told how to improve your request prior to receiving approval).\nOnce you get the ok from An, you will have a week to resubmit your assignment.\nNote that An will regrade your whole assignment. There is no guarantee of a better grade."
  },
  {
    "objectID": "resources/using-virtual-machine.html",
    "href": "resources/using-virtual-machine.html",
    "title": "Using the virtual machine",
    "section": "",
    "text": "1. What is the virtual machine?\nFor this class, we have a virtual machine: it allows you to run R and RStudio in a browser (e.g. Google Chrome, Safari, Firefox). Find the virtual machine here!\nThe benefits of using the virtual machine are plenty:\n\nyou don’t have to download R, RStudio, and Quarto\n\nthe versions of all the software you need are updated\n\nthe packages you need for the class are already installed\n\nyou can download everything you’ve worked on\n\nand more!\nThe one con is that you do need to be connected to the internet. But compared to the benefits, this is hopefully not a major hurdle.\nBasically, if you’re having any issues with your versions of R, RStudio, or Quarto, try running your code on the virtual machine.\n\n\n2. Logging in and opening things up\nOnce you open up the virtual machine, you’ll be asked to log in. Use your UCSB email to do that. You should then get a screen that looks like this:\n Click RStudio.\nYou should then see a screen that looks exactly like an RStudio screen!\n\n\n\n3. Setting up\nIf you’re opening this up for the first time, do task 4 in the Getting set up guide: Change your settings.\nAdditionally, you’ll want to set up a new folder for your ENVS 193DS materials. Make a new folder called ENVS-193DS by clicking on the “Folder” button in the Files tab in the bottom right.\n\n\n\n4. Getting files into the machine\nDownload the zipped file of workshop materials from Canvas. Hit the Upload button (yellow arrow pointing up against a white paper). You should see a window that looks like this:\n\nHit Choose file and select the .zip file.\nThe machine will automatically unzip the file and create a new folder with all the file contents.\n\n\n\n5. Creating and using Rprojects\nWe’re going to create a lot of Rprojects in this class to get used to it. You can create a project in an existing directory (aka folder) in the same way that you would in the desktop version of RStudio. Go to the button in the top left that says Project: (None) and click. Hit New Project.\n Then, select the “Existing Directory” option.\n\nChoose the directory you want to create a project in. Once you click “Browse”, you’ll see a box that looks like this:\n\nDouble click the folders until you get to the one you want (in this example, I went from ENVS-193DS &gt; ENVS-193DS_workshop-01).\nYou can confirm that you chose the right folder once you hit “Choose”:\n\nHit “Create Project”.\nYou should now see the new Rproject in two locations: 1) in the upper right corner and 2) in the list of files in your directory.\n\nOnce you’re done working in your project, you can close the project by going to Project &gt; Close Project.\n\nIf you need to open your project again, navigate to the folder using the Files tab in the bottom right corner. Click on the .Rproj file. You will then see a window that looks like this:\n\nHit “Yes” to open the project.\n\n\n6. Downloading your files\nIf you want to hold onto your files on your computer (for example, once the class ends), you can download a whole directory. Click on the folder you want to download and go to More &gt; Export in the lower right pane.\n\nThe machine will download the whole folder as a .zip file, which you can then unzip on your computer."
  },
  {
    "objectID": "lecture.html",
    "href": "lecture.html",
    "title": "Lecture visualizations",
    "section": "",
    "text": "Order By\n       Default\n         \n          Lecture date - Oldest\n        \n         \n          Lecture date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nLecture date\n\n\n\n\n\n\nWeek 1 figures - Lectures 1 and 2\n\n\nMar 31, 2025\n\n\n\n\n\nWeek 2 figures - Lectures 3 and 4\n\n\n\nApr 7, 2025\n\n\n\n\n\n\nWeek 3 figures - Lectures 5 and 6\n\n\n\nApr 14, 2025\n\n\n\n\n\nWeek 4 figures - Lectures 7 and 8\n\n\nApr 21, 2025\n\n\n\n\nWeek 5 figures - Lectures 9 and 10\n\n\nApr 28, 2025\n\n\n\n\nWeek 6 figures - Lecture 11\n\n\nMay 5, 2025\n\n\n\n\nWeek 7 figures - Lectures 12 and 13\n\n\nMay 12, 2025\n\n\n\n\nWeek 8 figures - Lectures 14 and 15\n\n\nMay 19, 2025\n\n\n\n\nWeek 9 figures - Lecture 16\n\n\nMay 28, 2025\n\n\n\n\nWeek 10 figures - Lectures 17 and 18\n\n\nMay 28, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]