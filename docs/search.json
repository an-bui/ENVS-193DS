[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nFinalizing plots\n\n\ntips for making your plots readable and professional\n\n\n\n\nClear communication = interpretable stats\n\n\nCommunicating about statistical results, a few ways\n\n\n\n\nGit/GitHub basics\n\n\ncloning, committing, pushing, forking, pulling\n\n\n\n\nWriting an informative README\n\n\nmaking sure people know what they’re looking at\n\n\n\n\nUsing the virtual machine\n\n\nGeneral use\n\n\n\n\nCitations in RStudio\n\n\nusing the visual editor to add citations using a DOI\n\n\n\n\nSetting up GitHub pages\n\n\nsimple options to turn your repository into a website\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "weekly-materials/week01.html",
    "href": "weekly-materials/week01.html",
    "title": "Week 1 materials",
    "section": "",
    "text": "Lecture\n [Slides]  [Slides with annotations]  Lecture figures\n\n\nWorkshop\n\n\nAssignments\n\n\n\n\n\n\nCitationBibTeX citation:@online{bui2024,\n  author = {Bui, An},\n  title = {Week 1 Materials},\n  date = {2024-04-01},\n  url = {https://spring-2024.envs-193ds.com/weekly-materials/week01},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2024. “Week 1 Materials.” April 1, 2024. https://spring-2024.envs-193ds.com/weekly-materials/week01."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to ENVS 193DS, Spring 2024!",
    "section": "",
    "text": "Artwork by @allison_horst\n\n\nCourse description\nEnvironmental scientists use data to understand the world around them. In this class, we’ll learn about the tools used in environmental science and beyond to work with, analyze, and communicate about data.\nBy the end of the quarter, students will be able to:\n1. Describe basic concepts of probability and statistics\n2. Identify appropriate statistical analyses to test hypotheses\n3. Conduct statistical analyses and visualize data using the R programming language\n4. Implement best practices for reproducible analysis and collaborative work\n5. Interpret and contextualize statistical results in general concepts from environmental studies\n\n\nInstructional team\n\n\n\nInstructor: An Bui\nEmail: an_bui [at] ucsb.edu\nDrop-in hours: Wednesdays 3:30 - 5:30 PM\nDrop-in location: At the tables outside the UCen 1st floor (facing the lagoon)\nMore about me: an-bui.com\n\n\n\n\nTA: Caitlin Nordheim-Maestas\nEmail: caitlinnordheim [at] ucsb.edu\nDrop-in hours: Tuesdays 9:30 - 10:30 AM\nDrop-in location: Noble Hall 2201\nMore about me: cnordheim-maestas.github.io\n\n\n\nAcknowledgements\nI took much of my inspiration for this course from Allison Horst’s Environmental Data Science and Statistics course, Sam Sambado’s Biometry course, and Sam Csik’s Data Visualization and Communication course."
  },
  {
    "objectID": "resources/adding-citations.html",
    "href": "resources/adding-citations.html",
    "title": "Citations in RStudio",
    "section": "",
    "text": "Note: my understanding is that this works in Quarto and RMarkdown. But give it a try!\n\n1. Use the visual editor.\n\n\n\n2. Insert a citation.\nNavigate to Insert &gt; Citation.\n\n\n\n3. Find the paper DOI.\nDOI stands for Digital Object Identifier. It’s essentially a permanent identification number for papers, databases, etc. Pretty much all papers have a DOI, and they’re usually at the top of the page somewhere. Copy the text after the “https://doi.org/” part (that’s the DOI).\n\n\n\n4. Insert the DOI into the citation box in RStudio.\nSelect “From DOI”. Paste the DOI into the box and hit “Search”. The paper title, author, and other information should pop up.\nAt the bottom of the box, there will be an option to create a references.bib file. This is the file where all your citations will live. Note: it is important that the references.bib file is in the same folder as your script - this will happen automatically, but it’s good to double check!\nMake sure “In-text” is checked. Hit “Insert”.\n\n\n\n5. Marvel at your citation!\nOnce you look back at your script, you should see 1) something like @authorname in the text where you wanted to insert your citation, 2) bibliography: references.bib in the YAML, and 3) a references.bib file in the folder where your script is. In your script, put that citation in brackets. This is what it looks like in the visual editor:\n\nAnd in the source editor:\n\n\n\n6. Render your document.\nWhenever you’re ready, you can render/knit your document. It should have your citation in parentheses and the citation for the paper at the bottom of the page.\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{bui2023,\n  author = {Bui, An},\n  title = {Citations in {RStudio}},\n  date = {2023-06-01},\n  url = {https://an-bui.github.io/ES-193DS-W23/resources/adding-citations.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2023. “Citations in RStudio.” June 1, 2023. https://an-bui.github.io/ES-193DS-W23/resources/adding-citations.html."
  },
  {
    "objectID": "resources/using-virtual-machine.html",
    "href": "resources/using-virtual-machine.html",
    "title": "Using the virtual machine",
    "section": "",
    "text": "1. What is the virtual machine?\nFor this class, we have a virtual machine: it allows you to run R and RStudio in a browser (e.g. Google Chrome, Safari, Firefox). Find the virtual machine here!\nThe benefits of using the virtual machine are plenty:\n\nyou don’t have to download R, RStudio, and Quarto\n\nthe versions of all the software you need are updated\n\nthe packages you need for the class are already installed\n\nyou can download everything you’ve worked on\n\nand more!\nThe one con is that you do need to be connected to the internet. But compared to the benefits, this is hopefully not a major hurdle.\nBasically, if you’re having any issues with your versions of R, RStudio, or Quarto, try running your code on the virtual machine.\n\n\n2. Logging in and opening things up\nOnce you open up the virtual machine, you’ll be asked to log in. Use your UCSB email to do that. You should then get a screen that looks like this:\n Click RStudio.\nYou should then see a screen that looks exactly like an RStudio screen!\n\n\n\n3. Setting up\nIf you’re opening this up for the first time, do task 3 in the Getting set up guide: Change your workspace save settings.\n\n\n4. Getting files into the machine\nDownload the zipped file of workshop materials from Canvas. Hit the Upload button (yellow arrow pointing up against a white paper). You should see a window that looks like this:\n\nHit Choose file and select the .zip file.\nThe machine will automatically unzip the file and create a new folder with all the file contents.\n\n\n\n5. Creating a project\nWe’re going to create a lot of Rprojects in this class to get used to it. You can create a project in an existing directory (aka folder) in the same way that you would in the desktop version of RStudio. Go to the button in the top left that says Project: (None) and click. Hit New Project.\n Then, select the “Existing Directory” option.\n\nYou should now see the new Rproject in two locations: 1) in the upper left and 2) in the list of files in your directory.\n\n\n\n6. Downloading your files\nIf you want to hold onto your files on your computer, you can download a whole directory. Click on the folder you want to download and go to More &gt; Export in the lower right pane.\n\nThe machine will download the whole folder as a .zip file, which you can then unzip on your computer."
  },
  {
    "objectID": "resources/finalizing-plots.html",
    "href": "resources/finalizing-plots.html",
    "title": "Finalizing plots",
    "section": "",
    "text": "Data visualization is a huge part of data storytelling, one of the core parts of being a data scientist. This is especially relevant to environmental science: you’re responsible for communicating not just about the environment, but what evidence (i.e. data) supports your claim. Therefore, it is crucial that environmental scientists communicate about their data clearly and effectively.\nIn this class, your plots will be assessed using three (very broad) criteria:\n1. accuracy: is your plot accurately and truthfully representing the data?\n2. clarity: is your plot clearly representing a pattern, relationship, message?\n3. aesthetics: does your plot look good?"
  },
  {
    "objectID": "resources/finalizing-plots.html#non-negotiable-if-you-are-missing-these-you-will-not-get-full-credit-for-your-plot",
    "href": "resources/finalizing-plots.html#non-negotiable-if-you-are-missing-these-you-will-not-get-full-credit-for-your-plot",
    "title": "Finalizing plots",
    "section": "Non-negotiable (if you are missing these, you will not get full credit for your plot)",
    "text": "Non-negotiable (if you are missing these, you will not get full credit for your plot)\n\nAxes must have complete labels with units (very few exceptions to this)\n\nfor example: body_mass_g should be “Body mass (g)”\n\nIf plotting regression or correlation lines, underlying data must be displayed on plot in addition to predicted lines\n\nIn all other cases (for example, comparing means between groups), underlying data must be displayed on plot when possible\n\nConcise, descriptive title (if presented alone and not in a report)"
  },
  {
    "objectID": "resources/finalizing-plots.html#additional-points",
    "href": "resources/finalizing-plots.html#additional-points",
    "title": "Finalizing plots",
    "section": "Additional points",
    "text": "Additional points\n\nlogical start and end values of x or y axes (these are usually by default in ggplot, but you should double check)\nif gridlines aren’t useful to understand the data, remove them\nfigure background should be white (easier to see points)\ntext labels should be large enough to see/read clearly\nuse color sparingly and be aware of color-blind friendly palettes\nuse one font throughout a plot\nfigure fonts should match text font (for example, don’t use Arial in a figure when the rest of your text is in Times New Roman)\nmake sure your plot size and aspect ratio renders correctly\n\nIn general, the simpler you can make a plot, the better."
  },
  {
    "objectID": "resources/finalizing-plots.html#bar-chart",
    "href": "resources/finalizing-plots.html#bar-chart",
    "title": "Finalizing plots",
    "section": "Bar chart",
    "text": "Bar chart\n\n\nCode\npenguins %&gt;% \n  group_by(island, species) %&gt;% \n  count() %&gt;% \n  ggplot(aes(x = species, y = n)) +\n  geom_col() +\n  labs(title = \"penguins\") +\n  facet_wrap(~island)\n\n\n\n\n\n\n\n\n\nWhy is this bad?\n- gap between bottom of bars and x-axis\n- meaningless y axis\n- gray background against gray bars and black text is hard to see\n- gridlines don’t do much\n\n\nCode\npenguins %&gt;% \n  group_by(island, species) %&gt;% \n  count() %&gt;% \n  ggplot(aes(x = island, y = n)) +\n  # fill = fills in the shape, color = controls the outline\n  geom_col(fill = \"darkgrey\", color = \"#000000\") +\n  # expand takes away the gap at the bottom and at the top of the plot\n  # limits sets the limits of the axis\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 130)) +\n  # change titles to be meaningful\n  labs(title = \"Penguin counts differ across species and islands\",\n       x = \"Island\", \n       y = \"Penguin count\") +\n  # one of the built-in themes in ggplot\n  theme_bw() +\n  theme(# changing text sizes\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14),\n        strip.text = element_text(size = 14),\n        # getting rid of gridlines\n        panel.grid = element_blank(),\n        # making the subplot titles (aka strips) have a transparent background\n        strip.background = element_blank(),\n        # making the plot title bigger and centering it\n        plot.title = element_text(size = 20, hjust = 0.5),\n        plot.title.position = \"plot\",\n        text = element_text(family = \"Times\")\n        ) +\n  facet_wrap(~species)\n\n\n\n\n\n\n\n\n\nWhy is this better?\n- text is bigger\n- gridlines are gone\n- easier to see columns agains background\n- complete axes\n- grayscale color scheme (good for printing out and paper reports in black and white)"
  },
  {
    "objectID": "resources/finalizing-plots.html#bonus-plot-lollipop-plot",
    "href": "resources/finalizing-plots.html#bonus-plot-lollipop-plot",
    "title": "Finalizing plots",
    "section": "Bonus plot: lollipop plot",
    "text": "Bonus plot: lollipop plot\nOne way to represent discrete (i.e. count) variables is to make a lollipop plot. This cuts down on visual clutter, as the bars in a bar chart are thick and take up a lot of space, but lollipop plots show the same thing but with smaller shapes.\n\n\nCode\npenguins %&gt;% \n  group_by(island, species) %&gt;% \n  count() %&gt;% \n  ggplot(aes(x = island, \n             y = n)) +\n  # fill = fills in the shape, color = controls the outline\n  geom_point(size = 3) +\n  geom_segment(aes(y = 0,\n                   yend = n)) +\n  \n  # expand takes away the gap at the bottom and at the top of the plot\n  # limits sets the limits of the axis\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 130)) +\n  # change titles to be meaningful\n  labs(title = \"Penguin counts differ across species and islands\",\n       x = \"Island\", \n       y = \"Penguin count\") +\n  # one of the built-in themes in ggplot\n  theme_bw() +\n  theme(# changing text sizes\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14),\n        strip.text = element_text(size = 14),\n        # getting rid of gridlines\n        panel.grid = element_blank(),\n        # making the subplot titles (aka strips) have a transparent background\n        strip.background = element_blank(),\n        # making the plot title bigger and centering it\n        plot.title = element_text(size = 20, hjust = 0.5),\n        plot.title.position = \"plot\",\n        text = element_text(family = \"Times\")\n        ) +\n  facet_wrap(~species)"
  },
  {
    "objectID": "resources/finalizing-plots.html#scatterplot",
    "href": "resources/finalizing-plots.html#scatterplot",
    "title": "Finalizing plots",
    "section": "Scatterplot",
    "text": "Scatterplot\n\n\nCode\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nWhy is this bad?\n- grey background, black dots\n- hides some meaningful variation across species (for example, we know that Gentoo penguins tend to be bigger than Adelie and Chinstrap)\n- axes are meaningless\n- small text size\n- points likely overlap, so some parts of the data are hidden\n\n\nCode\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, color = species, shape = species)) +\n  geom_point(size = 3, alpha = 0.7) +\n  # specify color scheme\n  scale_color_manual(values = c(\"darkorange\", \"cornflowerblue\", \"darkgreen\")) +\n  # meaningful titles\n  labs(title = \"Larger penguins tend to have longer flippers\",\n       x = \"Body mass (g)\", \n       y = \"Flipper length (mm)\",\n       # have to specify color and shape separately (based on color and shape in aes() call)\n       color = \"Penguin species\", shape = \"Penguin species\") +\n  # another ggplot built-in theme\n  theme_classic() +\n  theme(# putting legend in plot area\n        legend.position = c(0.85, 0.2),\n        # legend text sizes\n        legend.text = element_text(size = 14),\n        legend.title = element_text(size = 14),\n        # text size, position, and font adjustment\n        axis.text = element_text(size = 14), \n        axis.title = element_text(size = 16),\n        plot.title = element_text(size = 18, hjust = 0.5),\n        plot.title.position = \"plot\",\n        text = element_text(family = \"Garamond\")\n    )\n\n\n\n\n\n\n\n\n\nWhy is this better?\n- white background, no grid lines\n- points are shaped and colored by species, so you can easily see the differences between groups\n- transparency shows overlapping points\n- complete axis labels\n- text is larger and font is changed\n- legend is in plot area (if there’s space to do this, generally good)"
  },
  {
    "objectID": "resources/finalizing-plots.html#boxplot-and-jitter",
    "href": "resources/finalizing-plots.html#boxplot-and-jitter",
    "title": "Finalizing plots",
    "section": "boxplot and jitter",
    "text": "boxplot and jitter\n\n\nCode\nggplot(data = penguins, aes(x = species, y = body_mass_g)) +\n  # fill the boxplot shape using the species column\n  # make the boxplots narrower\n  geom_boxplot(aes(fill = species), width = 0.2) +\n  # fill the violin shape using the species column: every species has a different color\n  # alpha argument: makes the violin shape more transparent (scale of 0 to 1)\n  geom_jitter(aes(color = species), alpha = 0.5) +\n  # specify the colors you want to use for each species\n  scale_color_manual(values = c(\"#F56A56\", \"#3D83F5\", \"#A9A20B\")) +\n  scale_fill_manual(values = c(\"#F56A56\", \"#3D83F5\", \"#A9A20B\")) +\n  # relabel the axis titles, plot title, and caption\n  labs(x = \"Penguin species\", y = \"Body mass (g)\",\n       title = \"Gentoo penguins tend to be heavier than Adelie or Chinstrap\",\n       caption = \"Data source: {palmerpenguins}, \\n Horst AM, Hill AP, Gorman KB.\") +\n  # themes built in to ggplot\n  theme_bw() +\n  # other theme adjustments\n  theme(legend.position = \"none\", \n        axis.title = element_text(size = 13),\n        axis.text = element_text(size = 12),\n        plot.title = element_text(size = 14),\n        plot.caption = element_text(face = \"italic\"),\n        text = element_text(family = \"Times New Roman\"),\n        panel.grid = element_blank())\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "resources/using-github.html",
    "href": "resources/using-github.html",
    "title": "Git/GitHub basics",
    "section": "",
    "text": "Git and GitHub allow us to do a few important things in data science:\n\nkeep track of different versions of our work (so that old work is never lost forever)\n\nstore our work remotely (so that if our computers die, we still have access to our stuff)\n\nreuse other people’s work (so that we can reproduce their work and also repurpose for our own needs)\n\ncollaborate with others (so that you’re not emailing, texting, etc. code back and forth)\n\nSee Horst and Lowndes, “GitHub for supporting, reusing, contributing, and failing safely.” for a broad overview of how Git/GitHub work together, and Jenny Brian’s “Excuse me, do you have a moment to talk about version control? for more."
  },
  {
    "objectID": "resources/using-github.html#why-are-we-using-gitgithub",
    "href": "resources/using-github.html#why-are-we-using-gitgithub",
    "title": "Git/GitHub basics",
    "section": "",
    "text": "Git and GitHub allow us to do a few important things in data science:\n\nkeep track of different versions of our work (so that old work is never lost forever)\n\nstore our work remotely (so that if our computers die, we still have access to our stuff)\n\nreuse other people’s work (so that we can reproduce their work and also repurpose for our own needs)\n\ncollaborate with others (so that you’re not emailing, texting, etc. code back and forth)\n\nSee Horst and Lowndes, “GitHub for supporting, reusing, contributing, and failing safely.” for a broad overview of how Git/GitHub work together, and Jenny Brian’s “Excuse me, do you have a moment to talk about version control? for more."
  },
  {
    "objectID": "resources/using-github.html#what-is-the-difference-between-git-and-github",
    "href": "resources/using-github.html#what-is-the-difference-between-git-and-github",
    "title": "Git/GitHub basics",
    "section": "What is the difference between Git and GitHub?",
    "text": "What is the difference between Git and GitHub?\nGit is what tracks your changes (and allows you to have version control), while GitHub is a cloud hosting service for those changes. We use both together."
  },
  {
    "objectID": "resources/using-github.html#operations",
    "href": "resources/using-github.html#operations",
    "title": "Git/GitHub basics",
    "section": "Operations",
    "text": "Operations\n\n\n\n\n\n\nTip\n\n\n\nIf you’re having trouble seeing any screenshots, click the image to make it bigger.\n\n\n\n\n\n\n\n\nDefinitions\n\n\n\n\nrepo: short for “repository”, think of this as a folder\n\nremote: your repository on GitHub (in the cloud)\n\nclone: essentially making a local copy (i.e. a copy on your computer) of a remote repo\n\ncommit: track the changes you’ve made using Git (on your computer only)\n\npush: push the changes you’ve committed to GitHub (now in the cloud)\n\npull: pull changes from GitHub to your computer\n\nfork: create a copy of someone else’s repo on GitHub\n\n\n\n\nCreating a repository and using Git/GitHub\n\n1. Create a repository.\nGo to the GitHub homepage.\nClick the green “New” button.\n\n\n\n2. Fill information about your new repository.\nThis includes the name, a description, whether it is public or private (keep your repository public for now).\nAdditionally, initialize your repository with a README. It is very important to start your remote repository with a file, and GitHub does it for you by creating a file called README.md. See the README resource for more details about what it is, but for now remember to always initialize your repository with a README.\n\n\n\n3. Clone your repo to your computer.\nWhen you are “cloning”, you are essentially making a local copy (i.e. on your computer) of your remote.\nDo this by clicking the green “Code” button and copying the url that shows up.\n\nThen, create a new project in RStudio.\nSelect “Version Control”.\n\nThen, select “Git”.\n\nPaste the clone url into the first box.\nKeep your cursor in that box, then hit the Tab key. The new project directory name should automatically fill in.\n\n\n\n\n\n\n\nDirectory names\n\n\n\nIt is very important that your remote and local repositories have the same name. The easiest way to ensure this is by not typing anything into the second box. Paste the url into the first box, then hit Tab.\n\n\nThen, select the folder on your computer where you are keeping all your repositories for Git/GitHub. If you created a folder called “Git” or “GitHub” in your root directory, use that folder. This is something that you only have to do once; for each subsequent repo you clone from GitHub, the file path will be automatically filled in.\nAfter you have created your repository, a new RStudio window will open.\nVerify that the clone has worked by seeing that you have:\n\na project (should be the same as the directory name)\n\nthe “Git” tab\n\na .gitignore file (a file that tells git which files to ignore when tracking changes)\n\n\n\n\n4. Make changes to your repository.\nCreate a new Quarto document.\nType in some code.\nSave your document.\nOpen up the Git tab in the top right. You should see your new .qmd file along with any other new files (the .gitignore and the .Rproj file.).\n\n\n\n5. Commit your changes.\nIn the Status column, you will see two yellow question marks. This means that the files are new, and git isn’t tracking them yet.\nCheck the boxes next to each file, which turns the two yellow question marks to a green “A” for “added”.\nClick “Commit”. A new screen will pop up that looks like this:\n\nIf you click through each file in the top left pane, you will see the changes to the file in the lower pane.\nThe top right pane is where your commit message goes.\nCommit messages accompany each git commit and push. They should describe the changes to the file since the last version. They’re best as short phrases describing the changes. For a first commit/push, you could just write something like “initial commit”, as in the example.\nWrite a commit message, then hit “Commit”.\nYou should see a window that shows your commit message and a summary of the file changes.\n\nCongratulations! Your files are now being tracked by git.\n\n\n6. Push your changes.\nYour file is now being tracked, but it’s not on GitHub yet.\nTo get your files on GitHub, push the commit. To do this, click the “Push” button. You should see a window that looks like this:\n\nDouble check that your push to GitHub by looking back at your remote. Refresh the repository page.\nYou should see your new files in the repository, and your commit message showing up next to the files that you changed.\n\nCongratulations! Your files are now on GitHub.\n\n\n7. Make more changes.\nVersion control only works if you actually use it. That means you should commit and push with each change you make. The frequency of committing/pushing you do depends on you. Some people are totally commit-happy and commit/push with every chunk of code they write; you might find it more reasonable to commit/push after each coding session.\nEvery time you make a change, your modified file will show up in the “Git” tab with a blue M for “modified”. The process for changes is the same as for new files:\n\nClick the check box,\n\nhit “Commit”,\n\nfill in a commit message,\n\ncommit,\n\nthen push.\n\nIn the commit window, you’ll see any modified files with changes highlighted in green, as before.\n\n\n\n\nUsing GitHub Pages to display rendered .html output\n\n\n\n\n\n\nTip\n\n\n\nFor the rest of the assignments in this class (Homework 3, choose your own assignment (generative art and advanced data visualization), and final), you will submit a link to your rendered .html document on a GitHub repository.\nBe sure you are comfortable with doing this! Please ask for help if you are not!\n\n\n\nSet up\nMake sure your Quarto document is set to render to .html.\nYou can change this in the YAML (the part of the document at the very beginning between two sets of three dashes ---). The YAML line is: format: html.\n\n\n1. Render your document.\nWhen you render your Quarto document, you should see the rendered output pop up in the viewer pane (the bottom right).\nYou should also see new files show up in the Git pane: the .html version of your Quarto document, and a folder ending in _files/ that has all the related code for the .html file.\n\nWhen you click the checkbox for the _files/ folder, you will see a bunch of new files being added. This is normal!\n\n\n\n2. Commit and push these files.\nSame as above: write a brief commit message.\n\n\n\n3. Set up GitHub pages in your remote.\nNavigate to Settings &gt; Pages in your GitHub repo.\nUnder “Build and deployment”, choose the main branch in the root folder to enable GitHub pages.\n\nHit “Save”. If successful, you should see a blue banner at the top: “GitHub Pages source saved”.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are making a website, this step will be slightly different in that you’ll choose a different folder when setting up GitHub Pages. Be sure to follow Sam’s instructions!\n\n\nBack in the main page for your repo, you’ll see two new icons: a yellow dot next to your most recent commit, and a “Deployment” section on the right with “github-pages” in it.\n\nEventually, these will turn green, meaning that your GitHub pages set up is complete.\n\n\n4. Look at your deployment.\nClick on the github-pages link under “Deployment”.\nYou should see a screen that has the url to your page and the most recent commit message as a deployment message.\n\nMake a note of the url. It should be something along the lines of your-github-username.github.io/your-repository-name.\nClick on the url. It should take you to a pretty bare page:\n\nThis is the rendered version of your README.\n\n\n5. Find the url for your rendered .html.\nEvery rendered document in your repository is now accessible to anyone with the url to your GitHub pages. This means that you can share your rendered output without a file, just a link.\nThe link to your repo on GitHub pages is different from your repo on GitHub. This is the usual naming scheme:\n\n\nImage from Halina Do-Linh, Camila Vargas Poulsen, Samantha Csik, Daphne Virlar-Knight. 2023. coreR Course. NCEAS Learning Hub.\n\nBut first, you need to find your file.\nRendered document urls take the form: your-github-username.github.io/your-repository-name/[whatever folders the file is in]/the-file-name.html.\nIn this example, the url for the rendered .html is https://an-bui.github.io/new-repository/test-document.html. This means that test-document.html is in the root folder (i.e. is not in any subfolders) in new-repository.\n\nNavigate to that url. You should see your rendered document as a webpage!\n\n\n\n\n\n\n\nDo not fall for localhost!\n\n\n\nWhen you first render your document, you can open it up in a browser. It will look like a webpage, but the “url” will include something like localhost:. This is not a real url! It is temporary and not shareable. If you’re unsure you’re looking at the right thing, check the url. If it looks like an actual url, then you have it right.\n\n\n\n\n6. Save your url somewhere.\nThe best way to do this is to put a link somewhere in the README of your repo. For example, the README for this example repo includes the url to the rendered .html.\n\n\n\nForking\nForking is the process by which you can copy and reuse another person’s code. Imagine having a meal with someone else, and using your fork to take something from the other person’s plate. You can then do whatever you want with the food you’ve taken: eat it, mix it with other things, etc. This is the idea behind forking.\n\n1. Navigate to the repository you want to fork.\nYou should see a button to “Fork” in the top right.\n\n\n\n2. Create the fork\nClick “Fork”. You’ll be led to a screen to “Create a new fork”.\nYou can rename the repo if you want, or write a new description. You’ll also copy the main branch.\n\nYou will have to wait for a bit.\nOnce it’s done, you should see a screen that looks like a normal repo with some indications that you have forked someone else’s repo:\n\nunder the repo name, you will see “forked from” another repo.\n\na message saying “This branch is up to date with…”\n\n\n\n\n3. Clone the repo.\nThis is the same process as cloning your own repo.\nClick the green “Code” button and copy the url that shows up.\nThen, create a new project in RStudio.\nSelect “Version Control”.\nPaste the url you copied and hit tab.\nMake sure that you are creating a project as a subdirectory of your git/github folder.\n\n\n\n4. Work in the repo.\nThis is the same as working in your own repo: write code, make changes, commit and push them.\nYour changes will only be saved to your forked repo, not to the original repo. Thus, you are reusing people’s code and writing new code without overwriting their work.\n\n\n5. Incorporate upstream changes (if there are any)\nThe original repo is “upstream” of your fork. Sometimes, there are upstream changes to the original repo that you want to incorporate into your fork.\nIf there are upstream changes you want to have in your fork, then sync your fork by hitting the “Sync fork” button.\n\nThese changes will now be in your remote, but not in your local.\nGo back to RStudio and open the Git tab. Click “Pull” to get the changes into your computer.\n\n\n\n\nCollaborating\nAnother powerful way to use GitHub is to work with other people. You can add collaborators to a repository and they can commit/push changes just like you can, and you can pull each others changes to your respective computers.\n\n\n\n\n\n\nWorking together\n\n\n\nGitHub is a powerful tool to collaborate, but it doesn’t replace good communication with collaborators. When working with someone else in the same repo, be sure to communicate with each other about what you’re doing, what part of the document you’re going to be working in, etc. This requires you to actually reach out and contact them - so do it!\n\n\n\n1. Add collaborators to your repo.\nIn your GitHub repo, navigate to Settings &gt; Collaborators.\n\nFind your collaborator by searching for their GitHub username.\nSelect their username.\n\nHit the green “Add … to this repository” button.\nIf successful, you should see the other person listed as a collaborator and a blue banner that says “… has been added as a collaborator on this repository.”.\n\n\n\n2. For the collaborators\nYou will receive an email with an invitation to the repo. Accept the invitation.\nYou should then see something like “you have push access to this repository”. That means you can work out of this repo and commit/push changes as though it was your own.\nClone this repo to your computer.\n\n\n3. Make changes, commit, push.\nSame as above!\n\n\n4. View changes to the repo.\nWhen your collaborator has made changes in the repo, you will see them on the remote.\n\nYou can also see the history of changes by clicking the “Commits” button.\n\n\n\n5. Incorporate changes\nYou and your collaborator will be working out of the same repo. That means that you can pull each others’ changes to your respective computers.\n\n\n\n\n\n\nPulling best practice\n\n\n\nWhen collaborating with others, it is best practice to pull often. If you’re starting up a coding session, pull any changes. Before you commit/push changes, pull more changes.\nThis prevents situations called “merge conflicts” which can range from easily fixable to extremely frustrating. See a guide to navigating merge conflicts here.\nOne easy way to avoid merge conflicts is to make sure that you and your collaborator are working on different parts of the document, or on different documents entirely. Once you’re both done with your respective parts, incorporate everything into one document.\n\n\nPull changes by hitting “Pull” in the Git tab.\n\nA window should pop up with a summary of changes, additions, deletions, etc. that you are pulling from the remote.\n\nYou will then see the changes on your computer!\n\nYou can keep working in your document as usual. You can also edit your collaborator’s work. For example, maybe you needed to add some comments to the code to annotate it, or maybe you need to change one of their functions to something new. Whatever it might be, be sure to continue communicating with your collaborators so that everyone is on the same page.\n\n\n\nBrowsing your remote repo\nGitHub allows you to easily browse the history of your repository. Think of this as time travel!\n\n1. Find your commit history\nEach commit/push you make to your repo gets stored in your commit history. The commit history is a list of all the commits you’ve made.\nFind your commit history in your repo. It should look like an arrow in a circle with the number of commits you’ve made. Click this.\n\n\n\n2. Browse your commit history\nYou can see the list of all commits you’ve made.\nTo see the details of a particular commit, click on the commit message.\nThis will lead you to a screen that displays the old verson on the left and what was added in that particular commit on the right.\n\n\n\n3. Browse your repository\nBack in the commit history, you have the option to browse your repository at the time of that commit (!!!).\n\nIf you click the &lt;&gt; button, it will take you back to the repository at the time of that commit. You can navigate the same way you would in a regular repository.\n\nThe url with the long code at the end indicates that you are browsing an old version of your repo.\n\n\n\n\n\n\nGitHub for failing safely\n\n\n\nThe time travel aspect of GitHub is one of the best reasons to use GitHub. If you are committing/pushing your changes regularly, you will have each version of your repository saved in the cloud. These versions are all easily browsable. If you’ve deleted something and you decide you want it back, then you can go back and get it. Nothing is gone forever, and that’s a good thing when you’re changing your code, working with others, and adding more to your work."
  },
  {
    "objectID": "assignments/optional-problem-03.html",
    "href": "assignments/optional-problem-03.html",
    "title": "OPTIONAL practice problem - Make an ugly plot",
    "section": "",
    "text": "Why make an ugly plot?\nMaking ugly things is a good way of getting over the barrier of getting to something good - sometimes you just need to get something down on paper (or code, as it were) to get started.\nThe only issue is that there are lots of little things to tweak in ggplot() or any other code to make a visualization, and it can be hard to parse all the little components when you’re trying to make a good figure you can put in a presentation or report or paper.\nHowever, if you’ve made an ugly plot, you will likely have already learned about all the components in a ggplot object that you can control.\n\n\nProblem\nTake the visualization you made for Workshop 4 and make it ugly. If you feel compelled to do so, post it on the discussion forum on Canvas so that everyone can marvel at your ugly plot!\n\n\nStarting out\nThis is a figure using the Trash Wheel data set from Workshop 4.\n\n# read in packages\nlibrary(tidyverse)\n\n# read in data\ntrashwheel &lt;- read_csv(here::here(\"workshop\", \"data\", \"trashwheel.csv\"))\n\nI’m going to start with a basic plot with date on the x-axis and weight on the y-axis. I’ll also create lines and points representing the trash collected by each trash wheel.\n\ntrash_plot &lt;- ggplot(data = trashwheel,      # use the trash wheel data frame\n                     aes(x = date,           # put date on the x-axis\n                         y = weight,         # put weight on the y-axis\n                         color = name)) +    # color everything by the name of the trash wheel\n  geom_point() +                             # make a layer of points\n  geom_line() +                              # make a layer of lines\n  theme(legend.position = \"bottom\") +        # put the legend on the bottom\n  facet_wrap(~ name)                         # separate the trash wheels into different columns\n\ntrash_plot\n\n\n\n\n\n\n\n\nFrom this visualization, it seems that the original Mister Trash Wheel collects more trash in weight than the other trash wheels. What are the units of weight? Who knows!\n\n\nMaking things worse\nYou can play around with the theme() arguments to really make your ugly plot shine. If you add each argument one by one (for example, I added axis.title.x, looked at the output, then added axis.title.y and so forth), you can start to understand which argument goes with what part of the plot.\n\ntrash_plot +\n  theme(\n    \n    # axis adjustments\n    axis.title.x = element_text(angle = 180, family = \"Papyrus\"),\n    axis.title.y = element_text(angle = 60, family = \"Times New Roman\"),\n    axis.text.x = element_text(angle = 120, family = \"Garamond\"),\n    axis.text.y = element_text(color = \"lightblue\", angle = 180, family = \"Bradley Hand\"),\n    axis.ticks.y = element_line(color = \"red\"),\n    axis.ticks.x.bottom = element_line(color = \"limegreen\"),\n    axis.line.y = element_line(color = \"purple\"),\n    \n    # legend adjustments\n    legend.background = element_rect(fill = \"blue\"),\n    legend.direction = \"vertical\",\n    legend.title = element_text(color = \"white\", family = \"American Typewriter\"),\n    legend.text = element_text(color = \"pink\", family = \"Curlz MT\"),\n    \n    # panel adjustments\n    panel.background = element_rect(color = \"orange\", fill = \"darkred\"),\n    panel.grid.major.x = element_line(linetype = 3),\n    panel.grid.minor.x = element_line(linetype = 6, color = \"purple4\"),\n    panel.grid.minor.y = element_line(linetype = 5, color = \"orchid\"),\n    \n    # plot (as in, everything that's not the panel)\n    plot.background = element_rect(fill = \"#289793\"),\n    \n    # strips for the facet\n    strip.background = element_rect(fill = \"#809283\"),\n    strip.text = element_text(size = 14, family = \"Imprint MT Shadow\")\n    \n  )\n\n\n\n\n\n\n\n\nTake the plot you made in workshop and make it ugly. If you want to share your plot, post it on the discussion forum in Canvas!"
  },
  {
    "objectID": "assignments/optional-problem-02.html",
    "href": "assignments/optional-problem-02.html",
    "title": "OPTIONAL practice problem - One sample t-test",
    "section": "",
    "text": "In this optional problem, you’ll try a one-sample t-test in code. In lecture, we talked about the different values you’ll want to keep in mind: the tstatistic, the p-value, the tcritical, and the significance level (or \\(\\alpha\\))."
  },
  {
    "objectID": "assignments/optional-problem-02.html#description",
    "href": "assignments/optional-problem-02.html#description",
    "title": "OPTIONAL practice problem - One sample t-test",
    "section": "",
    "text": "In this optional problem, you’ll try a one-sample t-test in code. In lecture, we talked about the different values you’ll want to keep in mind: the tstatistic, the p-value, the tcritical, and the significance level (or \\(\\alpha\\))."
  },
  {
    "objectID": "assignments/optional-problem-02.html#creosote-heights",
    "href": "assignments/optional-problem-02.html#creosote-heights",
    "title": "OPTIONAL practice problem - One sample t-test",
    "section": "2. Creosote heights",
    "text": "2. Creosote heights\n\n\n\n\n\nYou overhear a conversation where someone makes a claim that creosote (Larrea tridentata) shrubs are 3 m tall. On your next walk through the desert, you decide to measure some shrubs (n = 40). From these 40 shrubs, you calculate the following summary statistics:\n\\[\n\\begin{align}\n\\bar{y} &= 1.8 m \\\\\ns &= 0.26 m\n\\end{align}\n\\]\nUsing your sample, you ask: how does my sample compare to the claim that I heard?\nFor this problem, use a 95% confidence level with the corresponding significance level for a two tailed test."
  },
  {
    "objectID": "assignments/optional-problem-02.html#steps",
    "href": "assignments/optional-problem-02.html#steps",
    "title": "OPTIONAL practice problem - One sample t-test",
    "section": "3. Steps",
    "text": "3. Steps\n\nDraw a t-distribution and label the tcritical and the significance level.\n\nCreate a script or Quarto document to work in.\n\nCopy/paste the code in the Set up code chunk into your script. Run the code.\n\nWrite your hypotheses in biological and statistical terms.\n\nCalculate the tstatistic using the test statistic formula for a one sample t-test.\n\nCalculate the tcritical using qt().\nCalculate the p-value for your test statistic using pt().\n\nDraw the tstatistic and p-value on your distribution from step 0. Take a moment to think: do you have evidence to suggest that creosote shrubs are not 3 m tall?\n\nUse t.test() to verify that your calculations from steps 3-5 are correct.\n\nIn one sentence, summarize your findings.\n\n\nSet up code\n\n# read in the tidyverse\nlibrary(tidyverse)\n\n# data\ncreosote &lt;- c(1.61, 1.86, 1.55, 2.28, 1.90, \n              1.55, 1.95, 2.02, 1.97, 1.71,\n              2.25, 1.92, 1.61, 1.14, 2.14, \n              1.79, 1.80, 2.08, 2.05, 1.98, \n              2.08, 2.03, 1.82, 1.20, 1.99,\n              1.78, 1.75, 1.36, 1.66, 1.93,\n              2.21, 1.77, 1.92, 1.78, 1.39,\n              1.68, 1.68, 1.78, 2.13, 2.03)"
  },
  {
    "objectID": "assignments/optional-problem-02.html#solution",
    "href": "assignments/optional-problem-02.html#solution",
    "title": "OPTIONAL practice problem - One sample t-test",
    "section": "3. Solution",
    "text": "3. Solution\n\n0. draw a t-distribution and label\nYou should do this by hand, but this is just here for reference.\n\n# calculating t-critical (need this for the plot)\nt_critical &lt;- qt(p = 0.05/2, df = 40 - 1, lower.tail = FALSE)\n\n# plotting the distribution\ntdist_plot &lt;- ggplot(data.frame(x = -5:5), aes(x)) +\n  \n  # first plotting the shaded areas under the curve (significance level)\n  # this is the area to the right\n  stat_function(geom = \"area\", \n                fun = dt, \n                args = list(df = 1), \n                xlim = c(t_critical, 30), \n                fill = \"darkgrey\") +\n  # this is the area to the left\n  stat_function(geom = \"area\", \n                fun = dt, \n                args = list(df = 1), \n                xlim = c(-30, -t_critical), \n                fill = \"darkgrey\") +\n  \n  # then, plotting the boundaries at the critical t value: 2.022\n  # this is the line on the right\n  annotate(geom = \"linerange\", \n           x = t_critical, \n           ymin = 0, \n           ymax = 0.065, \n           linewidth = 1, \n           lty = 2, \n           color = \"#000000\") +\n  # this is the line on the left\n  annotate(geom = \"linerange\", \n           x = -t_critical, \n           ymin = 0, \n           ymax = 0.065, \n           linewidth = 1, \n           lty = 2, \n           color = \"#000000\") +\n  \n  # lastly, plot the t-distribution\n  stat_function(geom = \"line\", \n                n = 1000, \n                fun = dt, \n                args = list(df = 1), \n                linewidth = 1, \n                color = \"#000000\") +\n  \n  # controlling plot aesthetics\n  scale_x_continuous(limits = c(-10, 10)) +\n  scale_y_continuous(expand = c(0, 0), \n                     limits = c(0, 0.32)) +\n  theme_void() +\n  theme(panel.grid = element_blank(),\n        plot.margin = unit(c(1, 0, 0, 0), \"cm\"))\n\ntdist_plot\n\n\n\n\n\n\n\n\nIn this plot, the dashed line is the tcritical, and the shaded areas are the significance level. They are split between the two tails because this is a two tailed test (not directional).\n\n\n3. Write your hypotheses in biological and statistical terms.\n\nBiological\nCreosote shrub height is different from the claim.\n\n\nStatistical\nH0: Mean creosote shrub height is 3 m.\nHA: Mean creosote shrub height is not 3 m.\n\n\n\n4. Calculate the t-statistic.\n\n# claimed mean\nmu &lt;- 3\n\n# number of observations\nn &lt;- length(creosote)\n\n# sample mean\nybar &lt;- mean(creosote)\n\n# sample standard deviation\ns &lt;- sd(creosote)\n\n# sample standard error\nse &lt;- s/sqrt(n)\n\n# t-score\nt &lt;- (ybar-mu)/se\n\nt\n\n[1] -27.84555\n\n\n\n\n5. Calculate tcritical\n\nt_critical &lt;- qt(p = 0.05/2, df = n - 1, lower.tail = FALSE)\n\nt_critical\n\n[1] 2.022691\n\n\n\n\n6. Calculate the p-value\n\n2*pt(q = t, df = n - 1, lower = TRUE)\n\n[1] 2.390222e-27\n\n\n\n\n7. Draw the tstatistic and p-value\n\ntdist_plot +\n\n  # this is the line on the right\n  annotate(geom = \"linerange\", \n           x = t, \n           ymin = 0, \n           ymax = 0.3, \n           linewidth = 1, \n           color = \"#239a89\") +\n  # this is the line on the left\n  annotate(geom = \"linerange\", \n           x = -t, \n           ymin = 0, \n           ymax = 0.3, \n           linewidth = 1, \n           color = \"#239a89\") +\n  scale_x_continuous(limits = c(-30, 30))\n\n\n\n\n\n\n\n\nIn this plot, the teal lines represent the tstatistic. They are way way way past the tcritical. I’m not plotting the p-value here, because I know for sure that the threshold has been met for me to think, “It’s so unlikely that these creosote shrubs come from a population with a mean height of 3 m that I actually think they came from a population with a different mean height.”\n\n\n8. Use t.test()\n\nt.test(creosote, mu = 3)\n\n\n    One Sample t-test\n\ndata:  creosote\nt = -27.846, df = 39, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 3\n95 percent confidence interval:\n 1.743134 1.913366\nsample estimates:\nmean of x \n  1.82825 \n\n\n\n\n9. Report your findings\nWe tested the hypothesis that creosote height was different from the claim of 3 m. We measured the height of 40 creosote shrubs and found a significant difference between our sample and the claim (two-tailed one sample t-test, t(39) = -27.8, p &lt; 0.001, \\(\\alpha\\) = 0.05).\n\n\n\n\n\n\nReporting your findings\n\n\n\nFor most tests, the information in the parentheses would be:\n(test, distribution(degrees of freedom) = test statistic, p-value, \\(\\alpha\\)).\nThis changes slightly based on the test, but this is the general form."
  },
  {
    "objectID": "assignments/optional-problem-01.html",
    "href": "assignments/optional-problem-01.html",
    "title": "OPTIONAL practice problem - Central Limit Theorem",
    "section": "",
    "text": "In this optional problem, you’ll test out the Central Limit Theorem by repeatedly “sampling” a population with a uniform distribution with sample sizes of n = 2, n = 15, and n = 30. You’ll create histograms of the sampling distributions (i.e. means from the samples you generate) to see how the spread of the sampling distribution gets narrower with increasing sample size."
  },
  {
    "objectID": "assignments/optional-problem-01.html#description",
    "href": "assignments/optional-problem-01.html#description",
    "title": "OPTIONAL practice problem - Central Limit Theorem",
    "section": "",
    "text": "In this optional problem, you’ll test out the Central Limit Theorem by repeatedly “sampling” a population with a uniform distribution with sample sizes of n = 2, n = 15, and n = 30. You’ll create histograms of the sampling distributions (i.e. means from the samples you generate) to see how the spread of the sampling distribution gets narrower with increasing sample size."
  },
  {
    "objectID": "assignments/optional-problem-01.html#general-guidance",
    "href": "assignments/optional-problem-01.html#general-guidance",
    "title": "OPTIONAL practice problem - Central Limit Theorem",
    "section": "2. General guidance",
    "text": "2. General guidance\nYou don’t have to follow these steps exactly (or at all), but this is a workflow that might make sense. Try it out on your own!\n\na. Steps\n\nCreate a script or Quarto document to work in.\n\nCopy/paste the code in the Set up code chunk into your script. Run the code.\n\nCalculate the population mean. Store this as an object.\n\nFind the function that allows you to “sample” from a vector of numbers. If you don’t know the function, one google search could be “r sample numbers”.\n\nResample (i.e. take a sample multiple times) 100 times from the population, taking a sample of n = 2 each time.\n\nCalculate the mean every time you take a sample. Store each mean in a list.\n\nCreate a histogram of your sample means using the list from step 6.\n\nRepeat steps 2-5 for n = 15, and n = 30.\n\n\n\n\n\n\n\nfor() loops\n\n\n\nDoing repetitive tasks like steps 5-6 can get tiresome. You probably do not want to sample and calculate a mean “by hand” 300 times. Instead, you can write what’s called a for() loop. One resource for writing for() loops is in the chapter on Iteration in R for Data Science. There are other resources out there too! Try finding one that you like.\n\n\n\n\nb. Set up code\n\n# read in the tidyverse\nlibrary(tidyverse)\n\n# set seed: makes sure the \"random\" generation comes up with the same combination of numbers every time\nset.seed(1)\n\n# generate 10000 numbers from a uniform distribution for the population\nuniform &lt;- runif(10000, min = 2, max = 8)\n\n# turn the vector into a data frame\nuniformdf &lt;- as.data.frame(uniform)\n\n# make a histogram for the population\nggplot(data = uniformdf, \n       aes(x = uniform)) +\n  geom_histogram(breaks = seq(2, 8, length.out = 41), \n                 fill = \"firebrick\", \n                 alpha = 0.7, \n                 color = \"firebrick\") +\n  geom_vline(xintercept = mean(uniform), \n             linewidth = 2) +\n  scale_x_continuous(breaks = seq(from = 2, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), \n                     limits = c(0, 305)) +\n  labs(x = \"Continuous value\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18))"
  },
  {
    "objectID": "assignments/optional-problem-01.html#solution",
    "href": "assignments/optional-problem-01.html#solution",
    "title": "OPTIONAL practice problem - Central Limit Theorem",
    "section": "3. Solution",
    "text": "3. Solution\n\na. Resampling using a for() loop\n\n# for() loop to sample 100x and calculate the mean\n\n# creating holding vectors\nstore2 &lt;- c()\nstore15 &lt;- c()\nstore30 &lt;- c()\n\nfor(i in 1:100) {\n  \n  # sample from the population, calculate the mean, store that mean in the vector\n  store2[i] &lt;- mean(sample(uniform, 2, replace = FALSE))\n  store15[i] &lt;- mean(sample(uniform, 15, replace = FALSE))\n  store30[i] &lt;- mean(sample(uniform, 30, replace = FALSE))\n\n}\n\n# double checking that the holding vectors actually have values in them\nhead(store2)\n\n[1] 5.274438 4.708106 5.089106 5.065707 4.728355 5.068479\n\nhead(store15)\n\n[1] 5.642239 4.914242 4.723196 5.237746 4.314470 5.602474\n\nhead(store30)\n\n[1] 5.432664 5.037553 5.165615 4.619024 4.573481 5.170263\n\n\n\n\nb. n = 2 histogram\nBefore plotting the histogram, I’ll put the output from the for() loop into a data frame.\n\n# putting everything together in a data frame (not necessary but nice to do)\ndf &lt;- cbind(store2, store15, store30) %&gt;% \n  as.data.frame()\n\nThen, I’ll plot the first histogram for n = 2.\n\n# making a histogram for n = 2\nggplot(data = df) +\n  # making a histogram\n  geom_histogram(aes(x = store2), \n                 bins = 10, \n                 alpha = 0.7, \n                 fill = \"chocolate1\", \n                 color = \"chocolate1\") +\n  # controlling the axes\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  # controlling plot aesthetics\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\n\nc. n = 15 histogram\n\n# histogram for n = 15\nggplot(data = df) +\n  # making a histogram\n  geom_histogram(aes(x = store15), \n                 bins = 12, \n                 alpha = 0.7, \n                 fill = \"darkorchid4\", \n                 color = \"darkorchid4\") +\n  # controlling the axes\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  # controlling plot aesthetics\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\n\nd. n = 30 histogram\n\n# histogram for n = 30\nggplot(data = df) +\n  # making a histogram\n  geom_histogram(aes(x = store30), \n                 bins = 12, \n                 alpha = 0.7, \n                 fill = \"lightseagreen\", \n                 color = \"lightseagreen\") +\n  # controlling the axes\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  # controlling plot aesthetics\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))"
  },
  {
    "objectID": "assignments/optional-problem-05.html",
    "href": "assignments/optional-problem-05.html",
    "title": "OPTIONAL practice problem - everything is a linear model",
    "section": "",
    "text": "Linear models share the same parametric base as ANOVAs (and t-tests!). This means that if you were to compare your results from an ANOVA to a linear model, you would see the same result.\nHowever, the presentation of those results is slightly different, so it’s not always obvious if you’re just looking at R output. For example, with a linear model, you would see the estimates for each level of a factor relative to a reference level. Compare this with an ANOVA, where you would see sum of squares, mean squares, F-statistic, and p-value.\nProve to yourself that ANOVAs are actually just linear models!"
  },
  {
    "objectID": "assignments/optional-problem-05.html#description",
    "href": "assignments/optional-problem-05.html#description",
    "title": "OPTIONAL practice problem - everything is a linear model",
    "section": "",
    "text": "Linear models share the same parametric base as ANOVAs (and t-tests!). This means that if you were to compare your results from an ANOVA to a linear model, you would see the same result.\nHowever, the presentation of those results is slightly different, so it’s not always obvious if you’re just looking at R output. For example, with a linear model, you would see the estimates for each level of a factor relative to a reference level. Compare this with an ANOVA, where you would see sum of squares, mean squares, F-statistic, and p-value.\nProve to yourself that ANOVAs are actually just linear models!"
  },
  {
    "objectID": "assignments/optional-problem-05.html#set-up",
    "href": "assignments/optional-problem-05.html#set-up",
    "title": "OPTIONAL practice problem - everything is a linear model",
    "section": "Set up",
    "text": "Set up\nInstall palmerpenguins if you don’t have it already. Read in the data using data(penguins).\nThe question we will ask is: How does body mass differ between penguin species?\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(car)\nlibrary(ggeffects)\n\ndata(penguins)"
  },
  {
    "objectID": "assignments/optional-problem-05.html#problem",
    "href": "assignments/optional-problem-05.html#problem",
    "title": "OPTIONAL practice problem - everything is a linear model",
    "section": "Problem",
    "text": "Problem\n\n1. Calculate the mean body masses and lower and upper bounds of the 95% CI around the mean for each penguins species.\n\npenguins %&gt;% \n  group_by(species) %&gt;% # group by species\n  reframe(mean = mean(body_mass_g, na.rm = TRUE), # calculating mean\n          se = sd(body_mass_g, na.rm = TRUE)/sqrt(length(body_mass_g)), # calculating SE\n          tval = qt(p = 0.05/2, df = length(body_mass_g), lower.tail = FALSE), # finding t-value\n          margin = se*tval, # calculating margin of error\n          conf_low = mean - margin, # calculating the lower bound of the CI\n          conf_high = mean + margin, # calculating the upper bound of the CI\n          var = var(body_mass_g, na.rm = TRUE) # also calculating variance here for efficiency\n          ) \n\n# A tibble: 3 × 8\n  species    mean    se  tval margin conf_low conf_high     var\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 Adelie    3701.  37.2  1.98   73.5    3627.     3774. 210283.\n2 Chinstrap 3733.  46.6  2.00   93.0    3640.     3826. 147713.\n3 Gentoo    5076.  45.3  1.98   89.6    4986.     5166. 254133.\n\n\n\n\n\n\n\n\nNote\n\n\n\nStop and think: keep in mind what those means and 95% CI around the means are!\n\n\n\n\n2. Create a figure with species on the x-axis and body mass on the y-axis, with means, 95% CIs, and the underlying data.\n\nggplot(data = penguins, # penguins data\n       aes(x = species, # x-axis\n           y = body_mass_g)) + # y-axis\n  geom_point(position = position_jitter(width = 0.2, # shake points left and right\n                                        height = 0), # not up and down\n             alpha = 0.2) + # transparency\n  stat_summary(geom = \"pointrange\", # plot means and CIs\n               fun.data = mean_cl_normal) # calculating mean and 95% confidence interval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nStop and think: do you think there’s a difference between species in body mass?\n\n\n\n\n3. Use ANOVA to determine the difference in body mass between penguin species.\nDo any assumption checks as needed.\nFirst, Levene’s test:\n\nleveneTest(body_mass_g ~ species, # formula\n           data = penguins) # data\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value   Pr(&gt;F)   \ngroup   2  5.1203 0.006445 **\n      339                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSignificantly different variances in body mass between species! But looking at the calculated variances, they are for practical purposes equal.\nVisually evaluating normality:\n\nggplot(data = penguins,\n       aes(sample = body_mass_g)) + # argument for a QQ plot\n  geom_qq_line(lty = 2, \n               color = \"grey\") + # adding a reference line\n  geom_qq() + # QQ\n  theme_classic() + # cleaner background, easier to see things\n  facet_wrap(~species)\n\n\n\n\n\n\n\n\nStatistically evaluating normality:\n\nadelie &lt;- penguins %&gt;% \n  filter(species == \"Adelie\") %&gt;% # filtering for Adelie\n  pull(body_mass_g) # pulling body mass as a vector\n\nshapiro.test(adelie)\n\n\n    Shapiro-Wilk normality test\n\ndata:  adelie\nW = 0.98071, p-value = 0.0324\n\nchinstrap &lt;- penguins %&gt;% \n  filter(species == \"Chinstrap\") %&gt;% # filtering for chinstrap\n  pull(body_mass_g)\n\nshapiro.test(chinstrap)\n\n\n    Shapiro-Wilk normality test\n\ndata:  chinstrap\nW = 0.98449, p-value = 0.5605\n\ngentoo &lt;- penguins %&gt;% \n  filter(species == \"Gentoo\") %&gt;% # filtering for Gentoo\n  pull(body_mass_g)\n\nshapiro.test(gentoo)\n\n\n    Shapiro-Wilk normality test\n\ndata:  gentoo\nW = 0.98593, p-value = 0.2336\n\n\nProbably ok.\n\npenguins_anova &lt;- aov(body_mass_g ~ species, # formula\n                      data = penguins) # data\n\n# show the ANOVA table: sums of squares, mean squares, f-statistic, p-value\nsummary(penguins_anova)\n\n             Df    Sum Sq  Mean Sq F value Pr(&gt;F)    \nspecies       2 146864214 73432107   343.6 &lt;2e-16 ***\nResiduals   339  72443483   213698                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2 observations deleted due to missingness\n\n\n\n\n\n\n\n\nNote\n\n\n\nStop and think: what is the result of your ANOVA?\n\n\nThen, do a post-hoc:\n\nTukeyHSD(penguins_anova)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = body_mass_g ~ species, data = penguins)\n\n$species\n                       diff       lwr       upr     p adj\nChinstrap-Adelie   32.42598 -126.5002  191.3522 0.8806666\nGentoo-Adelie    1375.35401 1243.1786 1507.5294 0.0000000\nGentoo-Chinstrap 1342.92802 1178.4810 1507.3750 0.0000000\n\n\n\n\n\n\n\n\nNote\n\n\n\nStop and think: what is the result of your post-hoc test?\n\n\n\n\n4. Use a linear model to determine the difference in body mass between penguin species.\n\npenguins_lm &lt;- lm(body_mass_g ~ species,\n                  data = penguins)\n\npar(mfrow = c(2, 2)) # displaying all diagnostic plots in 2x2 grid\nplot(penguins_lm) # diagnostic plots\n\n\n\n\n\n\n\nsummary(penguins_lm) # model estimates and information\n\n\nCall:\nlm(formula = body_mass_g ~ species, data = penguins)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1126.02  -333.09   -33.09   316.91  1223.98 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       3700.66      37.62   98.37   &lt;2e-16 ***\nspeciesChinstrap    32.43      67.51    0.48    0.631    \nspeciesGentoo     1375.35      56.15   24.50   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 462.3 on 339 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.6697,    Adjusted R-squared:  0.6677 \nF-statistic: 343.6 on 2 and 339 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nStop and think about this result.\n\nHow do the estimates compare to your calculated means?\n\nHow do the F-statistic, degrees of freedom, and p-value for the model compare to the ANOVA summary?\n\nWhat components of the ANOVA summary go into the R2?\n\n\n\nThen, get the model predictions:\n\nggpredict(penguins_lm, \n          terms = c(\"species\")) # only predictor in the model is species\n\n# Predicted values of body_mass_g\n\nspecies   | Predicted |           95% CI\n----------------------------------------\nAdelie    |   3700.66 | 3626.67, 3774.66\nChinstrap |   3733.09 | 3622.82, 3843.36\nGentoo    |   5076.02 | 4994.03, 5158.00\n\n\n\n\n\n\n\n\nNote\n\n\n\nStop and think: compare these with your calculated means and 95% CIs.\n\n\nThen, plot for good measure!\n\nggpredict(penguins_lm, # getting model predictions\n          terms = c(\"species\")) %&gt;% # only predictor is species\n  # quick option to plot from ggpredict\n  plot(show_data = TRUE, # show the underlying data\n       jitter = TRUE) # shake the points around a bit"
  },
  {
    "objectID": "assignments/choose-your-own_data-visualization.html",
    "href": "assignments/choose-your-own_data-visualization.html",
    "title": "Choose your own assignment - Advanced data visualization",
    "section": "",
    "text": "Due on Wednesday June 5 (week 10) at 11:59 PM"
  },
  {
    "objectID": "assignments/choose-your-own_data-visualization.html#description",
    "href": "assignments/choose-your-own_data-visualization.html#description",
    "title": "Choose your own assignment - Advanced data visualization",
    "section": "Description",
    "text": "Description\nData visualization is a huge part of data storytelling. It also happens to be one of the major topics within the R user community. In this assignment, you’ll dissect the making of a data visualization and create one of your own using data from your personal data project. You’ll learn about how people share their code (namely using GitHub) and create data art. You’ll then create your own piece, starting from the beginning (a sketch on a piece of paper) to a finished product (a visualization made in R). In the process, you’ll learn how to use ggplot and related packages to create visualizations. All components of this assignment should be written and rendered/knitted using Quarto or RMarkdown.\nWhat is #tidytuesday? #tidytuesday is a hashtag/movement for R user community members to come together and learn more about how to use R tools to visualize and tell stories about data. Each week, organizers post a data set that has been cleaned up and is ready for visualization. We’ve worked with Tidy Tuesday data in class before: fisheries, ramen, and UFOs.\nWhy care about visual storytelling? Asking an audience to read a paragraph of text is hard, but asking people to look at an infographic is way easier. You can draw people in with a well-presented, aesthetically pleasing figure, and then present some information that they might be interested in."
  },
  {
    "objectID": "assignments/choose-your-own_data-visualization.html#components",
    "href": "assignments/choose-your-own_data-visualization.html#components",
    "title": "Choose your own assignment - Advanced data visualization",
    "section": "Components",
    "text": "Components\n\nPart 1. Understand the context\n\n1. Learn about tidy tuesday.\n\nRead about tidytuesday from the rfordatascience organizers’ repo (link)\n\nScroll through the #tidytuesday hashtag on Twitter to see what visualizations people are making with the weekly data sets. (link)\n\n\n\n2. Dissect someone else’s visualization\n\nFor context, read Sam Csik’s “One workflow for building effective (and pretty) {ggplot2} data visualizations.”\n\nLook for a Tidy Tuesday visualization you like with public code in the #tidytuesday hashtag. This usually comes in the form of a link to GitHub, where you’ll find a script (with a .R suffix) with all the code to create the visualization.\n\nalternatively, you can look at people’s GitHub repositories for tidy tuesday. Some examples include:\n\nIjeamaka Anyene\n\nGeorgios Karamanis\n\nNicola Rennie (who also has an amazing app where she has displayed all her visualizations - see this here)\n\n\n\nChoose three visualizations you really like. In 8-10 sentences total, summarize\n\nThe packages used and what they do\n\nAny cleaning/summarizing steps\n\nThe structure of the final data frame\n\nThe geoms used and how they show up in the final visualization (for example, geom_line() in the script creates which lines in the output?)\nFinally, include\n\nA screenshot of the visualization and a link to the creator’s GitHub code\n\n\n\n\n\n\n\nTip\n\n\n\nThe best way to understand someone’s code, especially if they’ve put it on GitHub, is to run it yourself. You can do this by forking and cloning the repository to your machine (as we did in workshop), or by copy/pasting the script into your computer. If you choose the second option, you may have to do some adjustment to file paths to get the script to read in the data correctly.\n\n\n\n\n\nPart 2. Make your own visualization using your data.\n\na. Update the observations in your data entry.\n\n\nb. Decide on a type of visualization that best fits the data set.\nOne good option is From Data to Viz by Yan Holtz (link), which lists types of visualizations based on data types.\n\n\nc. Sketch your visualization on paper.\nUse colored pencils, highlighters, markers, etc. to represent the colors, axes, and other components of your visualization.\n\n\nd. Code up your sketch!\nAnnotate your code!\n\n\ne. Write about your process\nIn 8-10 sentences total, describe\n\nYour coding process (for example (not the only options for this prompt): did you have to clean up/summarize the data before you started? Which geoms did you start with?)\n\nHow you designed the visualization (for example (again, not the only options): how did you choose the colors, shapes, fonts, etc., and why?)\n\nWhat message does your visualization convey - basically, what is the main take away of the visualization you created?"
  },
  {
    "objectID": "assignments/choose-your-own_data-visualization.html#checklist",
    "href": "assignments/choose-your-own_data-visualization.html#checklist",
    "title": "Choose your own assignment - Advanced data visualization",
    "section": "Checklist",
    "text": "Checklist\nYour submission should include\n\nA link to the GitHub repository where your materials for this specific assignment are (make sure it is public!)\n\nA link to a rendered HTML document with navigation bar showing where each of the exercises/tutorials are\n\nYour rendered HTML document should include\n\nyour name, the title, and the date\n\nwritten responses to part 1 for all three visualizations you select\n\na photo of your sketch in part 2c\n\nannotated code and output for part 2d\n\nwritten response to part 2e\n\n\n\n\n\n\n\nNote\n\n\n\nNote: you can do this by making your GitHub repository connect to GitHub pages. Ask if you are unsure about how to do this."
  },
  {
    "objectID": "assignments/midterm.html",
    "href": "assignments/midterm.html",
    "title": "Midterm",
    "section": "",
    "text": "Due on Wednesday May 8 (Week 6) at 11:59 PM"
  },
  {
    "objectID": "assignments/midterm.html#description",
    "href": "assignments/midterm.html#description",
    "title": "Midterm",
    "section": "Description",
    "text": "Description\nIn this midterm, you will demonstrate your ability to synthesize lecture concepts and technical skills from workshop. At this point, you have the conceptual ideas you need (for example, what is the appropriate test to use if you want to compare groups?) and the technical skills you need (for example, summarizing data, visualizing data). You also have the investigative skills you need (for example, reading for tasks, googling!). You will use all these components to complete the midterm.\nThis midterm is open note, open internet, open everything; feel free to also talk with classmates and friends."
  },
  {
    "objectID": "assignments/midterm.html#problem-1.-test-choice-assumptions-and-communication-21-points",
    "href": "assignments/midterm.html#problem-1.-test-choice-assumptions-and-communication-21-points",
    "title": "Midterm",
    "section": "Problem 1. Test choice, assumptions, and communication (21 points)",
    "text": "Problem 1. Test choice, assumptions, and communication (21 points)\n\nSkills you will demonstrate\nIn this problem, you will demonstrate your ability to come up with an “analysis plan” by articulating what hypotheses you are testing, and what tests are appropriate for those hypotheses. You will also demonstrate your ability to interpret code output and synthesize the statistics in writing to ground the stats in biology for a scientific audience.\n\n\nDescription\nYou’re the manager of a reserve that burned in a major wildfire a year ago. Plants have started to grow back in some areas, but things still don’t look quite right. You wonder if the soil phosphorus content (expressed in parts per million, ppm) has something to do with how plants are (or are not) returning to burned areas. You want to compare soil phosphorus content in areas in the reserve with different burn histories: recently burned (within the last 2 years), historically burned (within the last 10 years), and unburned (not burned in the last 10 years).\n\n\nComponents\n\na. Hypotheses (2 points)\nState your hypothesis in statistical terms. (1-2 sentences)\n\n\nb. Tests (2 points)\nWhat kind of parametric statistical test could you use to test the null hypothesis? Justify your use of this test by describing why it is appropriate for the response and predictor variables you have. (1-2 sentences)\n\n\nc. Assumptions (3 points)\nWhat are the assumptions you would have to meet to use the test? (1-2 sentences)\n\n\nd. Alternate routes (2 points)\nIf your data did not meet the assumptions of this test, what other test(s) could you do? Justify your potential use of this test. (1-2 sentences)\n\n\ne. Exporatory data visualization (2 points)\nAfter coming up with your analysis plan (in parts a-d), you collect samples from all three areas of the reserve (n = 35 for each sample). To explore your data, you make the following graph:\n\n\n\n\n\n\n\n\n\nDescribe whether or not there could be a difference in phosphorus soil content between burned and unburned treatments. Use components from the figure to justify your description. (1-2 sentences)\n\n\nf. Normality (2 points)\nYou then make a QQ plot and test for normality.\nThis is your QQ plot:\n\n\n\n\n\n\n\n\n\nAnd this is your output of a test for normality:\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  historic_burn\nW = 0.97773, p-value = 0.684\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  recent_burn\nW = 0.96896, p-value = 0.4152\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  unburned\nW = 0.96529, p-value = 0.3273\n\n\nUsing the figure and the results from the test you ran, describe whether your variable is normally distributed enough. If you have evidence to suggest your variable is not normally distributed, describe why you could continue using a parametric test. (1-2 sentences)\n\n\ng. Variances (2 points)\nYou then calculate the variances for each group and run a test for equal variances.\nThis is the output for your calculation of variances:\n\n\n# A tibble: 3 × 2\n  treatment        var\n  &lt;chr&gt;          &lt;dbl&gt;\n1 historic_burn 0.0328\n2 recent_burn   0.0135\n3 unburned      0.0216\n\n\nAnd the output of your variance test:\n\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value  Pr(&gt;F)  \ngroup   2  4.1822 0.01796 *\n      102                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nUsing your calculated variances and output of the test you ran, describe whether your variances are equal enough. (1-2 sentences)\n\n\nh. Test and communication (6 points)\nYou run your statistical test. Following your test, you also decide to do a post-hoc analysis and calculate an effect size.\nThis is your test output:\n\n\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntreatment     2  2.242  1.1210   49.51 9.42e-16 ***\nResiduals   102  2.310  0.0226                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis is your post-hoc output:\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = p_ppm ~ treatment, data = soil_data)\n\n$treatment\n                                diff         lwr        upr   p adj\nrecent_burn-historic_burn  0.1624826  0.07692837  0.2480369 5.0e-05\nunburned-historic_burn    -0.1949605 -0.28051474 -0.1094062 1.2e-06\nunburned-recent_burn      -0.3574431 -0.44299738 -0.2718888 0.0e+00\n\n\nAnd this is your effect size output:\n\n\nFor one-way between subjects designs, partial eta squared is equivalent\n  to eta squared. Returning eta squared.\n\n\n# Effect Size for ANOVA\n\nParameter | Eta2 |       95% CI\n-------------------------------\ntreatment | 0.49 | [0.38, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nYou want to report your results to the other managers at the reserve. In 2-3 sentences, describe your results."
  },
  {
    "objectID": "assignments/midterm.html#problem-2.-reproducing-an-analysis-41-points",
    "href": "assignments/midterm.html#problem-2.-reproducing-an-analysis-41-points",
    "title": "Midterm",
    "section": "Problem 2. Reproducing an analysis (41 points)",
    "text": "Problem 2. Reproducing an analysis (41 points)\n\nSkills you will demonstrate\nIn environmental studies, open research means that researchers make their data and/or their code available for anyone to see. This means that anyone should be able to reproduce the analysis, even if they are not on the research team. In this problem, you will demonstrate your ability to read a paper to understand the context for a research study and its statistical analysis. You will then demonstrate your ability to take a data set and analyze it, using the researchers’ original analysis as a guide.\nWhen reproducing someone else’s analysis, you should be able to get the same exact results (for example: test statistics, summary statistics) that they do. When doing this problem, double check your work against the text/figures in the paper. Did you get it right?\n\n\nDescription\nYou will reproduce the analysis in Beheshti, K. M., K. Wasson, C. Angelini, B. R. Silliman, and B. B. Hughes. 2021. Long-term study reveals top-down effect of crabs on a California salt marsh. Ecosphere 12(8):e03703. 10.1002/ecs2.3703.\nRead all parts of the paper before starting this problem.\nYou will specifically recreate the components in this passage:\n\nIn trial (i) with pickleweed root only, there was less pickleweed root biomass in treatments (MT = 0.21, SDT = 0.07) than controls (MC = 0.34, SDC = 0.05), indicating crab consumption of roots (Fig. 6, Welch’s two-sample t-test; t(20.5) = 5.55, P &lt; 0.0001). In trial (ii) with algae only, there was less algal biomass in treatments (MT = 0.12, SDT = 0.11) than controls (MC = 0.33, SDC = 0.03), indicating crab consumption of algae (Fig. 6, Welch’s two-sample t-test; t(13.05) = 6.098, P &lt; 0.0001). Lastly, in trial (iii) with both algae and pickleweed offered simultaneously, treatments had less biomass than controls for both pickleweed roots (MT = 0.24, SDT = 0.07, and MC = 0.32, SDC = 0.03) and algae (MT = 0.08, SDT = 0.15, and MC = 0.28, SDC = 0.10), indicating that crabs consume pickleweed roots as well as algae when both are offered (Fig. 6, Welch’s two-sample t-test; pickleweed roots, t(11.03) = 3.00, P = 0.012; algae t(14.40) = 3.20, P = 0.006).\n\n\nGetting the data\nOnce you have read the paper, find the open research statement at the end of the paper. Navigate to the database using the link that is provided. Download the data into your midterm directory. To understand the data structure, read the README, which is a description of the data.\n\n\n\nComponents\n\na. Feeding trials (2 points)\nIn 1-2 sentences, explain why the authors conducted feeding trials and how they analyzed the data from their feeding trials.\n\n\nb. Comparisons (2 points)\nIn 1-2 sentences, explain the difference(s) between the three feeding trials.\n\n\nc. Response variable (2 points)\nIn 1-2 sentences, explain the biological interpretation of the difference in mean dry weight between control and treatments in the feeding trials. For example, if mean dry weight is lower in the treatment than the control, what would be your biological explanation for why that is the case?\n\n\nd. Reading in the data (2 points)\nLoad in the data and do any cleaning/wrangling steps you need.\n\n\ne. Summary statistics (8 points)\nCalculate the mean and standard deviation of:\n\npickleweed root biomass in control and treatment for trial (i)\n\nalgal biomass in control and treatment for trial (ii)\n\nboth pickleweed and algal biomass in control and treatment for trial (iii)\n\nDisplay your results.\n\n\nf. Welch’s t-tests (10 points)\nConduct Welch’s t-tests comparing biomasses between control and treatment in:\n\ntrial (i)\n\ntrial (ii)\n\ntrial (iii)\n\nDisplay the outputs for all 3 tests.\n\n\ng. Making a new figure (11 points)\nPlots like Figure 6 show means and whiskers (in this case, standard error), but do not show the data structure and can mask important information about the spread of the observations in each sample.\nMake a new figure for figure 6 that displays the mean and standard error (as in figure 6) but shows the underlying data. Finalize it.\nFor full credit:\n\ntake out the gridlines\n\njitter the underlying data horizontally but not vertically\n\ngive each type a different color that is different from the ggplot() default color\n\nmake the underlying data more transparent than the dot and whisker\n\nmake the dot and whisker larger than the underlying data\n\ntake out the legend\n\n\n\nh. Caption (4 points)\nWrite a caption for your figure in part i. Include a data citation, if appropriate."
  },
  {
    "objectID": "assignments/midterm.html#problem-3.-cleaning-wrangling-and-visualization-19-points",
    "href": "assignments/midterm.html#problem-3.-cleaning-wrangling-and-visualization-19-points",
    "title": "Midterm",
    "section": "Problem 3. Cleaning, wrangling, and visualization (19 points)",
    "text": "Problem 3. Cleaning, wrangling, and visualization (19 points)\n\nSkills you will demonstrate\nFigures are built on data; however, to make a figure, you need to understand the data structure and any cleaning, wrangling, or summarizing steps to create it. In this problem, you will demonstrate your ability to clean, wrangle, and/or summarize a data set to create a figure, using a final figure as a guide.\n\n\nDescription\nIn this problem, you will use the arc_weather dataset from lterdatasampler to recreate this figure.\n\nThe caption for the figure is as follows:\nFigure 1. Toolik Field Station is above freezing between May and September. Blue lines represent mean monthly air temperature for a given year (1988 - 2018), with lines becoming lighter with more recent years. Horizontal black dashed line at 0 °C for reference. Data source: Horst A, Brun J (2023). lterdatasampler: Educational Dataset Examples from the Long Term Ecological Research Program. R package version 0.1.1, https://CRAN.R-project.org/package=lterdatasampler.\nApproach:\nYou will need to clean/wrangle the data before making this figure. You should end up with mean monthly air temperature, calculated for each month in each year. Your final data frame could look something like this:\n\n\n\n\n\n\n\nTip\n\n\n\nNote that there are multiple ways of approaching the cleaning/wrangling steps and the visualization steps. There is no one “correct” approach, as long as you get to the right output.\n\n\n\n\nComponents\n\na. Initial cleaning, wrangling, and summarizing (6 points)\nWrite your code to create arc_weather_clean, a clean and wrangled data frame. Annotate each line of code.\nOnce you’re done, display the first 10 rows of your data frame using head(arc_weather_clean, 10) in your script.\n\n\n\n\n\n\nProblem prep - do this on scratch paper (not in your document)\n\n\n\nIn words (not code), write the list of functions/arguments that would get you to the final data frame. For example:\n\nCreate a data frame called arc_weather_clean. Start with arc_weather data frame, and then…\n\n[insert next step here], and then…\n\n[insert next step here], and then…\n\n[insert next step here], and then…\n\nand so on. Use these steps to guide the code you write. Code not working? Rewrite your steps on scratch paper and try again.\n\n\n\n\nb. Make the figure (13 points)\nWrite your code to recreate the figure. Display the output.\n\n\n\n\n\n\nProblem prep - do this on scratch paper (not in your document)\n\n\n\nMake a list of the arguments in the aes() call and any geom_() calls you will need to use. What are the x- and y-axes, and what do the colors represent?"
  },
  {
    "objectID": "assignments/midterm.html#problem-4.-personal-data-18-points",
    "href": "assignments/midterm.html#problem-4.-personal-data-18-points",
    "title": "Midterm",
    "section": "Problem 4. Personal data (18 points)",
    "text": "Problem 4. Personal data (18 points)\n\nSkills you will demonstrate\nUp until this point, we’ve created figures to represent data. In this problem, you will create a table to represent data from your personal data project. You will demonstrate your understanding of data summarizing (for example, calculating a mean, counting observations), installing/loading packages, and your ability to apply packages/functions to your own use.\nBefore doing this problem, update your spreadsheet with your new observations.\n\n\nComponents\n\na. Data summarizing (2 points)\nIn 1-2 sentences, describe how you could summarize your data to compare your response variable between a categorical predictor variable of your choosing. For example, are you counting observations and comparing counts between groups? Are you taking the mean and comparing means between groups?\n\n\nb. Visualization (6 points)\nUsing the summary you described in part a, create a visualization of your data comparing your summarized response variable between some categorical predictor variable. If you are calculating a mean or median, show the underlying data in addition to your summary. Display the output.\n\n\n\n\n\n\nNote\n\n\n\nSee From Data to Viz for new ideas for visualization.\n\n\n\n\nc. Caption (4 points)\nWrite a caption for your figure.\n\n\nd. Table presentation (6 points)\nUsing the flextable package (package info here, gallery of examples here), create a table with the same data summary that you describe in part a and visualized in part b. For example, if you described and visualized means, make a table with means. Display the output."
  },
  {
    "objectID": "assignments/midterm.html#checklist",
    "href": "assignments/midterm.html#checklist",
    "title": "Midterm",
    "section": "Checklist",
    "text": "Checklist\nYour submission should:\n\nInclude your name, the title (“Midterm”), and the date you turned in your midterm (3 points)\n\nInclude for Problem 1:\n\nwritten responses for a-h\n\n\nInclude for Problem 2:\n\nwritten responses for a-c\n\nfull work (R code and annotations), output, and written response for d-g\n\nwritten response for h\n\n\nInclude for Problem 3:\n\nfull work (R code and annotations) and output for a-b\n\n\nInclude for Problem 4:\n\nwritten response for a\n\nfull work (R code and annotations) and output for b\n\nwritten response for c\n\nfull work (R code and annotations) and output for d\n\n\nbe uploaded to Canvas as a single PDF (1 point)\n\nbe organized and readable: a rendered Quarto document without any messages/warnings and figure output formatted correctly (10 points)\n\n113 points total"
  },
  {
    "objectID": "assignments/getting-set-up.html",
    "href": "assignments/getting-set-up.html",
    "title": "Getting set up",
    "section": "",
    "text": "Optional check in due on Wednesday April 3 (Week 1) at 11:59 PM\nIn this class, we’ll be using R and RStudio to code up our statistical analyses. Walk through these steps to make sure you have both programs on your computer and that everything is working properly. You need to make sure these tasks are completed before workshop on Thursday.\n\n\n\n\n\n\nDo these set up steps as soon as possible!\n\n\n\nEveryone needs to do tasks 1 - 7. If you want to submit the optional check-in for Caitlin/An to verify that you’ve done things correctly, you can do task 8 and submit your screenshot on Canvas.\nIf you do not have R, RStudio, and Quarto installed and running, we cannot stop for you. Do this before class starts!\n\n\n\nTask 1. Install R, RStudio, and Quarto\nIf you already have both things installed, great. If not, follow these instructions:\n\nFor MacOS, do set up steps 1-3 here\n\nFor Windows, do set up steps 1-3 here\n\n\n\n\n\n\n\nInstalling Quarto\n\n\n\nIf you cannot install Quarto on your computer (because it doesn’t work with your operating system, etc.), that is fine - you just might have some differences between what we do in class and what you see on your own computer.\n\n\n\n\n\n\n\n\nUpdating existing programs\n\n\n\nYou may want to update your R and RStudio version if you haven’t used either in the last year or so. If not, some of the packages we use in the class might not work with your set up.\n\n\n\n\nTask 2. Open RStudio\nWhen we say we’re “using R” in the class, what we’re really using is RStudio, which is a graphical user interface (GUI) for R (the language). Basically, we’re never going to open up “R”, but we’ll always open up “RStudio”.\nOpen RStudio on your computer.\n\n\nTask 3. Change your workspace save settings\nWhen you’re using RStudio, you’ll get the option to “save your workspace” if you close out of the program. We’re going to make sure you don’t do that, because we want to make sure our code runs independently of any old information that was saved on your computer from RStudio.\nGo to Tools &gt; Global Options &gt; General and make sure that:\n\n“Restore .Rdata into workspace at startup” is unchecked\n\n“Save workspace to .RData on exit” is on “Never”\n\nHit “Apply”.\n\n\n\n\n\n\n\nTask 4. Change your color scheme\nYou don’t have to stick with the boring RStudio color scheme! Go to Appearance (from Tools &gt; Global Options) and choose an Editor Theme. Hit “Apply” to save it.\n\n\n\n\n\n\n\nTask 5. Test out installing a package\nPackages are the best part of using R. We’ll talk more about what packages are in workshop, but for now try installing a package. Go to your Console (the bottom left pane in the RStudio window), and type (or copy paste) install.packages(\"tidyverse\"). Hit Enter.\nYou should get a message that looks something like this:\n\n\n\n\n\n\n\n\n\n\n\nOperating system differences\n\n\n\nThe database that holds all these packages will automatically detect which version you need based on your operating system. Don’t worry if your output message doesn’t look exactly the same as the one here - just as long as you get something like “The downloaded binary packages are in…”, you’ve probably got the package installed.\n\n\n\n\nTask 6. Test out reading in a package\nNow you’ve installed a package, but you want to make sure you can actually run it. Again in the Console (the bottom left pane), type library(tidyverse) and hit Enter.\nYou should get a message that looks something like this:\n\n\n\n\n\n\n\nTask 7. Set up a folder on your computer for class materials\nUsing R/RStudio requires you to know how your computer is organized and where your files are. For now, we’ll want to set up a folder in your computer called ENVS-193DS (note no spaces in the folder name).\nAll operating systems are different, but make sure that your folder is not in the “iCloud” or “Google Drive” folders in your computer. Basically, you want to be sure that you can get from your “root” directory (i.e. your actual computer hard drive) to the folder you’re using.\nYou can check this using the file path, or the folders you would need to open to get to the folder called ENVS-193DS. One example for MacOS is below, where the file path is written out at the bottom of the pane:\n\n\n\n\n\n\n\nTask 8. Take a screenshot of your RStudio set up\nSo that the instructors can verify that you’ve gotten everything set up, take a screenshot of your RStudio window with the code for install.packages(\"tidyverse\") and library(tidyverse) in your Console and submit it to the portal on Canvas. Your screenshot should look something like this:\n\n\n\n\n\n\n\n\n\n\n\nDouble check your screenshot!\n\n\n\nMake sure that the messages in the orange box (above) are visible in your screenshot! Otherwise we will not be able to troubleshoot whatever issues you are having with installation (if you are actually having any)."
  },
  {
    "objectID": "assignments/homework-03.html",
    "href": "assignments/homework-03.html",
    "title": "Homework 3",
    "section": "",
    "text": "Due on Sunday June 2 at 11:59 PM\nRead the instructions carefully and make sure you have all the components on the checklist."
  },
  {
    "objectID": "assignments/homework-03.html#set-up",
    "href": "assignments/homework-03.html#set-up",
    "title": "Homework 3",
    "section": "Set up",
    "text": "Set up\nGitHub steps:\n\nFork the workshop 8 repo on GitHub (link coming soon).\n\nRename the repository to lastname-firstname_homework-03.\n\nRStudio/code steps:\n\nClone your repository to your computer.\n\nCreate a new Quarto document for your homework submission in the code folder.\n\nAt the top of your document, include a link to your repository.\n\nDo all of your set up (reading in packages/data) at the top of your document.\n\nThroughout the course of doing your homework, make at least 10 commits and pushes to the remote."
  },
  {
    "objectID": "assignments/homework-03.html#problems",
    "href": "assignments/homework-03.html#problems",
    "title": "Homework 3",
    "section": "Problems",
    "text": "Problems\n\nProblem 1. Multiple linear regression: model selection and construction (52 points)\nUse the information from the homework-starter-doc.qmd to do this problem.\n\na. Make a table or list of all the models from class and the last one you constructed on your own. Write a caption for your table. (8 points)\nCaption: table captions typically go above the table. Number the table and provide a title. Describe what is in the table (columns and rows).\nTable: In your table, each row should be a model with the model number (1, 2, 3, etc.) and the predictors for each model.\n\n\n\n\n\n\nDouble check your work!\n\n\n\nThere should be 6 models total (null model + 5 models with predictors).\n\n\n\n\nb. Write a 5-6 sentence “statistical methods” section. (8 points)\nYour answer should be in paragraph form and include:\n\nhow you addressed the central question(s) (i.e. to examine the influence of ____, ____, and ____ on _____, I…)\n\nhow you chose the final model (i.e. to determine the model that best described ____, I…)\n\nhow you visually determined that your final model conformed to the assumptions of a linear model (i.e. to evaluate linear model assumptions, I…)\n\n\n\nc. Make a visualization of the model predictions with underlying data for your “best” model. (20 points)\nShow and annotate all your code. For full credit:\n\nmake the underlying data more transparent than the model predictions\n\ndisplay species names in full (not as species codes like ENCCAL or ESCCAL)\n\ndisplay water treatment types in full (not as WW or DS)\n\nrepresent well-watered and drought stressed treatments with different colors\n\nuse colors that are not the default ggplot() colors\n\nfacet your plot by species\n\nremove the legend\n\nfinalize the plot\n\n\n\n\n\n\n\nNote\n\n\n\nMake sure that the only output is the visualization!\n\n\n\n\nd. Write a caption for your visualization. (6 points)\nInclude a data citation.\n\n\ne. Write a 3-4 sentence results section. (10 points)\nYour answer should be in paragraph form and address the following points:\n\nwhat predictors “best” described total mass (include model statistics here)?\n\non average, what differences did you find between water treatments?\n\non average, what differences did you find between species?\n\n\n\n\nProblem 2. Affective visualization (24 points)\nIn this problem, you will create an affective visualization using your personal data in preparation for workshop during week 10.\nIn lecture, we talked about the three vertices of data visualization: 1) exploratory, 2) affective, and 3) communicative. We’ve done a lot of exploratory and communicative visualization, but have yet to think about affective visualization.\nWhen thinking of affective visualization, you can expand your ideas of what data visualization could be. Some examples of affective visualizations include:\n\nJill Pelto’s paintings\n\nLorraine Woodruff-Long’s warming strips quilt\n\nStefanie Posavec and Giorgia Lupi’s Dear Data project\n\nBefore starting, update your spreadsheet of observations.\n\na. Describe in words what an affective visualization could look like for your personal data (3-5 sentences). (2 points)\n\n\nb. Create a sketch (on paper) of your idea. (2 points)\nInclude a photo of this sketch in your submission.\n\n\nc. Make a draft of your visualization. (12 points)\nFeel free to be creative with this! You do not have to do this in R. You could create a sculpture, painting, textile object, etc.\nIf you are making your visualization in R, show the annotated code and the output.\nIf you are making your visualization outside of R, include a photo of your visualization in your submission.\n\n\nd. Write an artist statement. (8 points)\nAn artist statement gives the audience context to understand your work. Write 4-5 sentences to address:\n\nthe content of your piece (what are you showing?)\n\nthe influences (what did techniques/artists/etc. did you find influential in creating your work?)\n\nthe form of your work (written code, watercolor, oil painting, etc.)\n\nyour process (how did you create your work?)\n\n\n\n\nProblem 3. Statistical critique (36 points)\nAt this point, you have seen and created a lot of figures for this class. Revisit the paper you chose for your critique and your homework 2, where you described figures or tables in the text. Address the following in full sentences (3-4 sentences each).\nFor this section of your homework, you will be evaluated on the logic, conciseness, and nuance of your critique.\n\na. Revisit and summarize (6 points)\nWhat are the statistical tests the authors are using to address their main research question?\nInsert the figure or table you described in Homework 2 here.\n\n\nb. Visual clarity (10 points)\nHow clearly did the authors visually represent their statistics in figures? For example, are the x- and y-axes in a logical position? Do they show summary statistics (means and SE, for example) and/or model predictions, and if so, do they show the underlying data?\n\n\nc. Aesthetic clarity (10 points)\nHow well did the authors handle “visual clutter”? How would you describe the the data:ink ratio?\n\n\nd. Recommendations (can be longer than 4 sentences, 10 points)\nWhat recommendations would you make to make the figure better? What would you take out, add, or change? Provide explanations/justifications for each of your recommendations.\nAlternatively, if they did not represent their statistics in a figure, what kind of figure would you recommend to them? Describe the x- and y-axes, with any geometries and aesthetics (colors, etc.). Provide enough explanation such that someone would be able to create the figure you describe in code. Provide explanations/justifications for the figure you would recommend.\n\n\n\nChecklist\nYour homework should\n\nInclude your name, the title (“Homework 3”), and the date you turned in the assignment (3 points)\n\nInclude for Problem 1:\n\na table for part a (if you made it in code, show the code and annotations)\nwritten response for part b\nfull work (code and annotations) and output for part c\nwritten response for part d\nwritten response for part e\n\nInclude for Problem 2:\n\nwritten response for part a\nphoto for part b\ncode and annotations or photo for part c\n\nwritten response for part d\n\nInclude for Problem 3:\n\nwritten responses for part a-d\nwritten responses for parts g-h\n\nbe uploaded to Canvas as a single PDF (1 point)\nbe organized and readable (10 points), meaning that\n\nyou are submitting a rendered PDF\n\nall messages and warnings are hidden\n\nall figures and tables are displayed correctly in the rendered PDF\n\nall code annotations are visible in the rendered PDF\n\nyou have a set up chunk at the beginning and each section only has the code corresponding to that specific section (for example, no reading in packages/data in the chunk to create a visualization)\n\n\nbe associated with a GitHub repository (15 points), meaning that\n\nyou have a link to your GitHub repository at the top of your document\n\nyou have committed/pushed at least 10 times over the course of completing your homework\n\nat least 10 of your commits/pushes contain a descriptive, concise commit message (a few words describing what changes you are committing)\n\n\n141 points"
  },
  {
    "objectID": "workshop/workshop-02_2024-04-11.html",
    "href": "workshop/workshop-02_2024-04-11.html",
    "title": "Coding workshop: Week 2",
    "section": "",
    "text": "tidyverse\n\njanitor\n\n\n\n\n\nread in data using read_csv()\n\nchain functions together using %&gt;%\n\nclean column names using clean_names()\n\ncreate new columns using mutate()\n\nselect columns using select()\n\nmake data frame longer using pivot_longer()\n\nrename columns using rename()\n\ngroup data using group_by()\n\nsummarize data using reframe()\n\ncalculate standard deviation using sd()\n\ncalculate t-values using qt()\n\nexpand data frames using deframe()\n\nvisualize data using ggplot()\n\ncreate histograms using geom_histogram()\n\nvisualize means and raw data using geom_point()\n\nvisualize standard deviation, standard error, and confidence intervals using geom_errorbar() and geom_pointrange()\n\n\n\n\nThis workshop’s data comes from Tidy Tuesday 2021-10-12, which was from OurWorldinData.org."
  },
  {
    "objectID": "workshop/workshop-02_2024-04-11.html#summary",
    "href": "workshop/workshop-02_2024-04-11.html#summary",
    "title": "Coding workshop: Week 2",
    "section": "",
    "text": "tidyverse\n\njanitor\n\n\n\n\n\nread in data using read_csv()\n\nchain functions together using %&gt;%\n\nclean column names using clean_names()\n\ncreate new columns using mutate()\n\nselect columns using select()\n\nmake data frame longer using pivot_longer()\n\nrename columns using rename()\n\ngroup data using group_by()\n\nsummarize data using reframe()\n\ncalculate standard deviation using sd()\n\ncalculate t-values using qt()\n\nexpand data frames using deframe()\n\nvisualize data using ggplot()\n\ncreate histograms using geom_histogram()\n\nvisualize means and raw data using geom_point()\n\nvisualize standard deviation, standard error, and confidence intervals using geom_errorbar() and geom_pointrange()\n\n\n\n\nThis workshop’s data comes from Tidy Tuesday 2021-10-12, which was from OurWorldinData.org."
  },
  {
    "objectID": "workshop/workshop-02_2024-04-11.html#code",
    "href": "workshop/workshop-02_2024-04-11.html#code",
    "title": "Coding workshop: Week 2",
    "section": "2. Code",
    "text": "2. Code\n\n1. Set up\n\n# load in packages\nlibrary(tidyverse)\nlibrary(janitor)\n\n\n# read in data\nglobal_catch &lt;- read_csv(\"global-fishery-catch-by-sector.csv\")\n\n\n\n2. Cleaning up\nThis chunk of code cleans the column names, converts catch to catch per million tons, selects columns, makes the data frame longer, and renames the columns.\n\nglobal_catch_clean &lt;- global_catch %&gt;% # use the global_catch data frame\n  clean_names() %&gt;% # clean up column names\n  mutate(artisanal = artisanal_small_scale_commercial/1000000,\n         industrial = industrial_large_scale_commercial/1000000) %&gt;% # convert catch/1000000\n  select(year, artisanal, industrial) %&gt;% # select columns \n  pivot_longer(cols = artisanal:industrial) %&gt;% # make the data frame longer\n  rename(catch_mil = value,\n         fishery_type = name) # rename columns\n\n\n\n3. Making a histogram\nThis chunk of code creates a histogram.\n\nggplot(data = global_catch_clean,\n       aes(x = catch_mil,\n           fill = fishery_type)) + # fill the histogram based on the fishery type\n  geom_histogram(bins = 9, # set the number of bins\n                 alpha = 0.6, # make the columns transparent\n                 color = \"black\", # make the border of the columns black\n                 position = \"identity\") + # make the columns sit on top of each other\n  scale_y_continuous(expand = c(0, 0), # get rid of the space between the x-axis and the columns\n                     limits = c(0, 35)) # define the y-axis limits\n\n\n\n\n\n\n\n\n\n\n4. Visualizing standard error and confidence intervals\n\na. Calculations\n\n# calculate the confidence interval \"by hand\"\nglobal_catch_summary &lt;- global_catch_clean %&gt;% \n  group_by(fishery_type) %&gt;% \n  reframe(mean = mean(catch_mil), # calculate the mean\n            n = length(catch_mil), # count the number of observations\n            df = n - 1, # calculate the degrees of freedom\n            sd = sd(catch_mil), # calculate the standard deviation\n            se = sd/sqrt(n), # calculate the standard error\n            tval = qt(p = 0.05/2, df = df, lower.tail = FALSE), # find the t value\n            margin = tval*se, # calculate the margin of error\n            ci_lower = mean - margin, # calculate the lower bound of the confidence interval\n            ci_higher = mean + margin # calculate the upper bound of the confidence interval\n          ) \n\nThis is what your data frame should look like:\n\nglobal_catch_summary\n\n# A tibble: 2 × 10\n  fishery_type  mean     n    df    sd    se  tval margin ci_lower ci_higher\n  &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 artisanal     15.2    61    60  4.26 0.545  2.00   1.09     14.1      16.3\n2 industrial    59.5    61    60 24.2  3.10   2.00   6.21     53.3      65.7\n\n\n\n\nb. Visualizations\nWe want to visualized standard error:\n\nggplot(data = global_catch_summary,\n       aes(x = fishery_type, \n           y = mean, \n           color = fishery_type)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymin = mean - se, # plot the standard error\n                    ymax = mean + se),\n                width = 0.1) +\n  labs(title = \"Standard error\")\n\n\n\n\n\n\n\n\nand the 95% confidence interval:\n\nggplot(data = global_catch_summary,\n       aes(x = fishery_type, \n           y = mean, \n           color = fishery_type)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymin = mean - margin, # plot the 95% confidence interval\n                    ymax = mean + margin),\n                width = 0) +\n  labs(title = \"95% confidence interval\")\n\n\n\n\n\n\n\n\n\n\n\n5. Extra stuff\n\na. Controlling boundaries in a histogram\nThe general steps to do this are:\n\ncalculate the range\n\ndetermine the number of observations\n\ncalculate the number of bins you want (then round to the nearest whole number)\n\ncalculate the width of each bin by taking the range and dividing it by the number of bins - 2 (if the number of bins is odd) or bins - 1 (if the number of bins is even)\n\ndefine the line breaks by creating a sequence of numbers, calculating the boundaries for each bin (and if necessary, rounding the boundaries)\n\n\n# calculate the range\nrange &lt;- max(global_catch_clean$catch_mil) - min(global_catch_clean$catch_mil)\n\n# determine the number of observations\nobs &lt;- nrow(global_catch_clean)\n\n# calculate the number of bins using the Rice Rule\n# note that this doesn't come out to a whole number, so it's rounded\nbins &lt;- 2*(obs^(1/3)) %&gt;% \n  round(digits = 0)\n\n# calculate the width of the bin\nbinwidth &lt;- range/(bins - 2)\n\n# set up a sequence of numbers from 0 to 100\nseq &lt;- seq(from = 0, to = 100, by = 1)\n\n# calculate the axis breaks  \naxis_breaks &lt;- seq*binwidth + (binwidth/2)\n\n# round the axis breaks\naxis_breaks_rounded &lt;- round(axis_breaks, \n                             digits = 1)\n\nThen you can make your histogram with the right line breaks:\n\nggplot(data = global_catch_clean,\n       aes(x = catch_mil,\n           fill = fishery_type)) +\n  geom_histogram(binwidth = binwidth, \n                 alpha = 0.6, \n                 color = \"black\", \n                 position = \"identity\") +\n  scale_x_continuous(breaks = axis_breaks_rounded) +\n  scale_y_continuous(expand = c(0, 0), \n                     limits = c(0, 35))\n\n\n\n\n\n\n\n\n\n\nb. plotting the confidence interval using stat_summary\n\nggplot(data = global_catch_clean,\n       aes(x = fishery_type, \n           y = catch_mil, \n           color = fishery_type)) +\n  stat_summary(fun.data = mean_cl_normal, \n               geom = \"pointrange\") +\n  labs(title = \"95% confidence interval using stat_summary\")\n\n\n\n\n\n\n\n\n\n\nc. calculating the confidence interval with ggplot::mean_cl_normal\n\n# use a function to calculate the confidence interval\nglobal_catch_ci &lt;- global_catch_clean %&gt;% \n  group_by(fishery_type) %&gt;% \n  summarize(ci = mean_cl_normal(catch_mil)) %&gt;% # calculate the CI using a function\n  deframe() # expand the data frame\n\n\n\nd. Visualizing standard deviation\n\n\n\n\n\n\nNote\n\n\n\nThis is the same code that you would use if you were making a plot where your whiskers = standard error or whiskers = confidence interval.\n\n\n\nggplot(data = global_catch_summary, # use the summary data frame\n       aes(x = fishery_type, \n           y = mean, \n           color = fishery_type)) + # color the points by fishery type\n  geom_point(size = 2) + # plot the mean\n  geom_errorbar(aes(ymin = mean - sd, # plot the standard deviation\n                    ymax = mean + sd),\n                width = 0.1) +\n  labs(title = \"Standard deviation\")\n\n\n\n\n\n\n\n\n\n\ne. Visualizing the confidence interval with the underlying data\n\nggplot(data = global_catch_clean,\n       aes(x = fishery_type, \n           y = catch_mil, \n           color = fishery_type)) +\n  geom_point(position = position_jitter(width = 0.05, \n                                        seed = 1),\n             alpha = 0.2) +\n  geom_pointrange(data = global_catch_summary,\n                  aes(x = fishery_type, \n                      y = mean, \n                      ymin = mean - margin, \n                      ymax = mean + margin)) +\n  scale_color_manual(values = c(\"artisanal\" = \"cornflowerblue\",\n                                \"industrial\" = \"orange\")) +\n  labs(x = \"Fishery type\",\n       y = \"Catch per million tonnes\",\n       title = \"Industrial fisheries catch more than artisanal fisheries\") +\n  theme_light()"
  },
  {
    "objectID": "workshop/workshop-01_2024-04-05.html",
    "href": "workshop/workshop-01_2024-04-05.html",
    "title": "Coding workshop: Week 1",
    "section": "",
    "text": "tidyverse\n\n\n\n\n\ncalculations using mean() and max()\n\nread in data using read_csv()\n\nfilter data using filter()\n\narrange data using arrange()\n\ncreate new column using mutate()\n\ngroup data using group_by()\n\ncount observations using count()\n\nchain functions together using %&gt;%\n\nvisualize data using ggplot()\n\ncreating points and lines using geom_point() and geom_line()\n\n\n\n\nThis workshop’s data comes from Tidy Tuesday 2023-06-20, which was from the National UFO Reporting Center and sunrise-sunset.org by Jon Harmon."
  },
  {
    "objectID": "workshop/workshop-01_2024-04-05.html#summary",
    "href": "workshop/workshop-01_2024-04-05.html#summary",
    "title": "Coding workshop: Week 1",
    "section": "",
    "text": "tidyverse\n\n\n\n\n\ncalculations using mean() and max()\n\nread in data using read_csv()\n\nfilter data using filter()\n\narrange data using arrange()\n\ncreate new column using mutate()\n\ngroup data using group_by()\n\ncount observations using count()\n\nchain functions together using %&gt;%\n\nvisualize data using ggplot()\n\ncreating points and lines using geom_point() and geom_line()\n\n\n\n\nThis workshop’s data comes from Tidy Tuesday 2023-06-20, which was from the National UFO Reporting Center and sunrise-sunset.org by Jon Harmon."
  },
  {
    "objectID": "workshop/workshop-01_2024-04-05.html#code",
    "href": "workshop/workshop-01_2024-04-05.html#code",
    "title": "Coding workshop: Week 1",
    "section": "2. Code",
    "text": "2. Code\n\n1. Intro to scripts\nIn class, we use an R Script. It allows you to write your code (recipe) and run the code in the console (kitchen).\nR considers everything in the script as code to run, so you can write comments in the R Script by putting a pound sign at the beginning of the line. This is especially useful when you want to explain what your code is doing at each line in plain language.\nTry writing a comment of your own in the line below.\n\n# This is a comment!\n\n\n\n2. Intro to functions\nR allows you to apply functions to do calculations, from simple to complex structures. Run code by putting your cursor on the line and hitting Ctrl + Enter or Cmd + Enter.\n\nmean(c(4, 5, 1, 2, 1))\n\n[1] 2.6\n\n\nYou can store things you want to use over and over again as objects.\n\nnumbers &lt;- c(4, 6, 2, 5, 3, 10)\n\nand then you can use those objects in functions.\n\nmax(numbers)\n\n[1] 10\n\n\n\n\n3. loading in packages and data\n\nlibrary(tidyverse)\n\n\nufo_sightings &lt;- read_csv(\"ufo_sightings.csv\")\n\n\nView(ufo_sightings)\n\n\n\n4. cleaning and wranging\nThese are all functions in the tidyverse that allow you to work with your data in R.\nFirst, you can filter by state to only include California.\n\ndf1 &lt;- filter(ufo_sightings, \n              state == \"CA\") \n\nThen, you can arrange the data frame by date.\n\ndf2 &lt;- arrange(df1,\n               reported_date_time)\n\nThen, you can make a new column just with the year.\n\ndf3 &lt;- mutate(df2,\n              extracted_year = year(reported_date_time)) \n\nThen, you can group the data frame by year and shape.\n\ndf4 &lt;- group_by(df3, \n                extracted_year, shape)\n\nThen, you can count the number of occurrences by year and shape.\n\ndf5 &lt;- count(df4) \n\nThen, you can filter the data frame by the shapes you’re interested in.\n\ndf6 &lt;- filter(df5, \n              shape %in% c(\"formation\", \"circle\", \"orb\", \"changing\", \"light\"))\n\n\n\n5. an easier way to clean and wrangle\nYou can use what’s called a pipe operator to chain functions together. The keyboard shortcut for a pipe is Ctrl + Shift + M or Cmd + Shift + M.\nWhen reading your code aloud, you can read the pipe as “and then”\n\nnew_mexico &lt;- ufo_sightings %&gt;% # use the ufo_sightings data frame\n  filter(state == \"NM\") %&gt;% # and then, filter by state to only include New Mexico\n  arrange(reported_date_time) %&gt;% # and then, arrange by date\n  mutate(extracted_year = year(reported_date_time)) %&gt;% # and then, create a new column for the year\n  group_by(extracted_year, shape) %&gt;% # and then, group by extracted_year and shape\n  count() # and then, count occurrences\n\n\n\n6. data visualization\n\nggplot(data = df6, \n       aes(x = extracted_year, \n           y = n,\n           color = shape)) +\n  geom_point() +\n  geom_line() +\n  labs(x = \"Year\",\n       y = \"Number of sightings\",\n       title = \"UFOs in California are mostly light\")"
  },
  {
    "objectID": "workshop/workshop-03_2024-04-18.html",
    "href": "workshop/workshop-03_2024-04-18.html",
    "title": "Coding workshop: Week 3",
    "section": "",
    "text": "tidyverse\n\nreadxl\n\njanitor\n\n\n\n\n\n\n\ncreate new columns based on data in existing columns using mutate() and case_when()\n\nvisualize QQ plots using geom_qq() and geom_qq_line()\n\ncreate multi-panel plots using facet_wrap()\n\ncreate jitter plots using position = position_jitter() within geom_point()\n\nvisualize summary statistics using stat_summary()\n\ncompare group variances using var.test()\n\ndo t-tests using t.test()\n\n\n\n\n\nread in data using read_csv()\n\nchain functions together using %&gt;%\n\nclean column names using clean_names()\n\nselect columns using select()\n\nmake data frame longer using pivot_longer()\n\nrename columns using rename()\n\ngroup data using group_by()\n\nsummarize data using reframe()\n\ncalculate standard deviation using sd()\n\ncalculate t-values using qt()\n\nvisualize data using ggplot()\n\ncreate histograms using geom_histogram()\n\nvisualize confidence intervals using geom_pointrange()\n\n\n\n\n\nIf you’re working in the source editor (as we did in class), you can control the appearance of text, links, images, etc. using this guide.\n\n\n\nThe bison data is a subsetted version of the bison weight data from Konza Prairie as presented in the lterdatasampler package (more about the data here). The Flint water data is from a massive citizen science sampling effort done in 2015 by the residents of Flint, Michigan - read more about this project here and download the data here."
  },
  {
    "objectID": "workshop/workshop-03_2024-04-18.html#summary",
    "href": "workshop/workshop-03_2024-04-18.html#summary",
    "title": "Coding workshop: Week 3",
    "section": "",
    "text": "tidyverse\n\nreadxl\n\njanitor\n\n\n\n\n\n\n\ncreate new columns based on data in existing columns using mutate() and case_when()\n\nvisualize QQ plots using geom_qq() and geom_qq_line()\n\ncreate multi-panel plots using facet_wrap()\n\ncreate jitter plots using position = position_jitter() within geom_point()\n\nvisualize summary statistics using stat_summary()\n\ncompare group variances using var.test()\n\ndo t-tests using t.test()\n\n\n\n\n\nread in data using read_csv()\n\nchain functions together using %&gt;%\n\nclean column names using clean_names()\n\nselect columns using select()\n\nmake data frame longer using pivot_longer()\n\nrename columns using rename()\n\ngroup data using group_by()\n\nsummarize data using reframe()\n\ncalculate standard deviation using sd()\n\ncalculate t-values using qt()\n\nvisualize data using ggplot()\n\ncreate histograms using geom_histogram()\n\nvisualize confidence intervals using geom_pointrange()\n\n\n\n\n\nIf you’re working in the source editor (as we did in class), you can control the appearance of text, links, images, etc. using this guide.\n\n\n\nThe bison data is a subsetted version of the bison weight data from Konza Prairie as presented in the lterdatasampler package (more about the data here). The Flint water data is from a massive citizen science sampling effort done in 2015 by the residents of Flint, Michigan - read more about this project here and download the data here."
  },
  {
    "objectID": "workshop/workshop-03_2024-04-18.html#code",
    "href": "workshop/workshop-03_2024-04-18.html#code",
    "title": "Coding workshop: Week 3",
    "section": "2. Code",
    "text": "2. Code\n\n1. Set up\n\n# read in packages\nlibrary(tidyverse)\n\n# Bison from Konza Prairie LTER\nknz_bison &lt;- read_csv(\"knz_bison.csv\")\n\n\n\n2. Cleaning the bison data\n\nknz_bison_clean &lt;- knz_bison %&gt;% \n  mutate(animal_sex = case_when(\n    animal_sex == \"F\" ~ \"female\",\n    animal_sex == \"M\" ~ \"male\"\n  ))\n\nThe data frame should look something like this:\n\nhead(knz_bison_clean)\n\n# A tibble: 6 × 8\n  data_code rec_year rec_month rec_day animal_code animal_sex animal_weight\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;              &lt;dbl&gt;\n1 CBH01         2011        10      27 O-101       female               316\n2 CBH01         2011        10      27 O-102       female               266\n3 CBH01         2011        10      27 O-103       male                 290\n4 CBH01         2011        10      27 O-104       male                 326\n5 CBH01         2011        10      27 O-105       male                 336\n6 CBH01         2011        10      27 O-106       male                 350\n# ℹ 1 more variable: animal_yob &lt;dbl&gt;\n\n\n\n\n3. Exploring the bison data\n\na. Histograms\n\nggplot(knz_bison_clean,\n       aes(x = animal_weight,\n           fill = animal_sex)) +\n  geom_histogram(bins = 9) +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 30)) +\n  facet_wrap(~animal_sex) +\n  theme_minimal() +\n  theme(legend.position = \"none\") \n\n\n\n\n\n\n\n\n\n\nb. QQ plots\n\nggplot(knz_bison_clean,\n       aes(sample = animal_weight,\n           color = animal_sex)) +\n  geom_qq() +\n  geom_qq_line() +\n  theme_bw() +\n  facet_wrap(~animal_sex)\n\n\n\n\n\n\n\n\n\n\nc. Jitter plots and dot and whisker\n\nggplot(knz_bison_clean,\n       aes(x = animal_sex,\n           y = animal_weight,\n           color = animal_sex)) +\n  geom_point(position = position_jitter(width = 0.1, \n                                        seed = 1),\n             alpha = 0.1) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_cl_normal) +\n  labs(x = \"Sex\",\n       y = \"Weight (pounds)\") +\n  theme_classic() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n3. t-test\n\na. check variances\n\nvar.test(animal_weight ~ animal_sex, \n         data = knz_bison_clean)\n\n\n    F test to compare two variances\n\ndata:  animal_weight by animal_sex\nF = 0.84041, num df = 71, denom df = 67, p-value = 0.4705\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.5212348 1.3505428\nsample estimates:\nratio of variances \n         0.8404117 \n\n\n\n\nb. do the t-test\n\nt.test(animal_weight ~ animal_sex, \n         data = knz_bison_clean,\n       var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  animal_weight by animal_sex\nt = -1.7396, df = 138, p-value = 0.08416\nalternative hypothesis: true difference in means between group female and group male is not equal to 0\n95 percent confidence interval:\n -33.028782   2.112115\nsample estimates:\nmean in group female   mean in group male \n            311.0417             326.5000 \n\n\n\n\nc. writing\nThere is no significant difference in weights between male and female bison calves (two-sample t-test, t(138) = -1.74, p = 0.08).\n\n\n\n4. Paired t-tests\n\na. read in data\n\n# read in packages here\nlibrary(readxl)\nlibrary(janitor)\n\n# Flint water lead data\nflint_pb &lt;- read_xlsx(\"Flint-Samples-WORKING-COPY.xlsx\", \n                      sheet = \"Samples from Flint Water homes\")\n\n\n\nb. clean and wrangle the data\n\nflint_pb_clean &lt;- flint_pb %&gt;%\n  clean_names() %&gt;% # clean names using janitor function\n  select(sample_id, pb_bottle_1_ppb_first_draw, pb_bottle_2_ppb_45_secs_flushing, pb_bottle_3_ppb_2_mins_flushing) %&gt;% # select columns of interest\n  pivot_longer(cols = pb_bottle_1_ppb_first_draw:pb_bottle_3_ppb_2_mins_flushing) %&gt;% # make data frame longer\n  rename(flushing_interval = name,\n         lead_ppb = value) %&gt;% # rename columns\n  mutate(flushing_interval = case_when(\n    flushing_interval == \"pb_bottle_1_ppb_first_draw\" ~ \"first\",\n    flushing_interval == \"pb_bottle_2_ppb_45_secs_flushing\" ~ \"45 seconds\",\n    flushing_interval == \"pb_bottle_3_ppb_2_mins_flushing\" ~ \"two minutes\"\n  )) %&gt;% # use mutate and case when to recode levels in flushing interval column\n  filter(flushing_interval != \"45 seconds\") # take out 45 seconds interval\n\n\n\nc. plot the data with confidence intervals\n\nggplot(flint_pb_clean,\n       aes(x = flushing_interval,\n           y = lead_ppb)) +\n  geom_point(position = position_jitter(width = 0.1, seed = 1),\n             alpha = 0.1,\n             shape = 21) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_cl_normal) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nd. Summarize the data\n\nflint_pb_summary &lt;- flint_pb_clean %&gt;% \n  group_by(flushing_interval) %&gt;% \n  reframe(mean = mean(lead_ppb),\n          n = length(lead_ppb),\n          sd = sd(lead_ppb),\n          se = sd/sqrt(n),\n          tval = qt(p = 0.05/2, df = n - 1, lower.tail = FALSE),\n          margin = tval*se,\n          ci_lower = mean - margin,\n          ci_higher = mean + margin)\n\n\n\ne. Do a paired t-test\n\nt.test(lead_ppb ~ flushing_interval, \n       data = flint_pb_clean,\n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  lead_ppb by flushing_interval\nt = 6.3748, df = 270, p-value = 7.891e-10\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 4.827963 9.142612\nsample estimates:\nmean difference \n       6.985288 \n\n\n\n\nf. Writing\nIn words: There was a significant difference in the amount of lead in parts per billion detected between samples collected immediately after turning the water on and after 2 minutes (paired t-test, t(270) = 6.37, p &lt; 0.001).\nOn average, samples collected after 2 minutes had lead levels of 10.6 ppb [95% CI: 8.07, 13.2], while samples collected immediately had lead levels of 3.66 ppb [95% CI: 2.40, 4.92]."
  },
  {
    "objectID": "lecture/lecture_week-01.html",
    "href": "lecture/lecture_week-01.html",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\n\n# visualization\nlibrary(patchwork)"
  },
  {
    "objectID": "lecture/lecture_week-01.html#set-up",
    "href": "lecture/lecture_week-01.html#set-up",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\n\n# visualization\nlibrary(patchwork)"
  },
  {
    "objectID": "lecture/lecture_week-01.html#math",
    "href": "lecture/lecture_week-01.html#math",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "1. Math",
    "text": "1. Math\n\nsample mean\n\\[\n\\bar{y} = \\frac{1}{n}\\sum_{i = 1}^ny_i\n\\]\n\n\nsample variance\n\\[\ns^2 = \\frac{\\sum(y_i - \\bar{y})^2}{n - 1}\n\\]\n\n\nsample standard deviation\n\\[\ns = \\sqrt{\\frac{\\sum(y_i - \\bar{y})^2}{n - 1}}\n\\]\n\n\ncoefficient of variation\n\\[\nCV = \\frac{\\sigma}{\\mu}\n\\]\n\n\nz-score for selecting a single individual\n\\[\nz = \\frac{y_i - \\mu}{\\sigma}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-01.html#mean-and-median",
    "href": "lecture/lecture_week-01.html#mean-and-median",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "2. Mean and median",
    "text": "2. Mean and median\nFor data following a symmetrical distribution, the mean and median tend to be similar.\n\n\nCode\nset.seed(1)\nrnorm(n = 40, mean = 6, sd = 1) %&gt;% \n  as_tibble() %&gt;% \n  ggplot(aes(x = value)) +\n  geom_density() +\n  geom_vline(aes(xintercept = mean(value)), color = \"blue\") +\n  annotate(\"text\", x = 5.75, y = 0.5, label = \"mean\", color = \"blue\") +\n  geom_vline(aes(xintercept = median(value))) +\n  annotate(\"text\", x = 6.5, y  = 0.5, label = \"median\") +\n  scale_x_continuous(limits = c(2.5, 10)) +\n  scale_y_continuous(limits = c(0, 0.5)) +\n  labs(x = \"Sculpin lengths (cm)\") +\n  theme(axis.text.y = element_blank(),\n        axis.title.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank())"
  },
  {
    "objectID": "lecture/lecture_week-01.html#range",
    "href": "lecture/lecture_week-01.html#range",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "3. Range",
    "text": "3. Range\n\n\nCode\nset.seed(1)\nnarrow &lt;- rnorm(n = 30, mean = 6, sd = 1) %&gt;% \n  as_tibble() %&gt;% \n  mutate(y = 0) %&gt;% \n  ggplot(aes(x = value, y = y)) +\n  geom_jitter(shape = 21) +\n  geom_point(aes(x = mean(value), y = 0), color = \"blue\", size = 3) +\n  scale_x_continuous(limits = c(0, 15)) +\n  scale_y_continuous(limits = c(-0.5, 0.5)) +\n  theme(axis.line.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.title.y = element_blank()) +\n  labs(x = \"Sculpin lengths (cm)\")\n# min: 3.78\n# max: 7.60\n\nset.seed(1)\nwide &lt;- rnorm(n = 30, mean = 6, sd = 2) %&gt;% \n  as_tibble() %&gt;% \n  mutate(y = 0) %&gt;% \n  ggplot(aes(x = value, y = y)) +\n  geom_jitter(shape = 21) +\n    geom_point(aes(x = mean(value), y = 0), color = \"blue\", size = 3) +\n  scale_x_continuous(limits = c(0, 15)) +\n  scale_y_continuous(limits = c(-0.5, 0.5)) +\n  theme(axis.line.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.title.y = element_blank()) +\n  labs(x = \"Sculpin lengths (cm)\")\n# min: 1.57\n# max: 9.19\n\nnarrow + wide\n\n\n\n\n\n\n\n\n\n\nHow would you describe this data?\n\n\nCode\nset.seed(1)\nex1 &lt;- rf(n = 100, df1 = 30, df2 = 10)\nmean(ex1)\n\n\n[1] 1.321259\n\n\nCode\nmedian(ex1)\n\n\n[1] 1.163362\n\n\nCode\nex1 %&gt;% \n  enframe() %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 9,\n                 color = \"#000000\",\n                 fill = \"orange\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  labs(x = \"Hermit crab shell length (cm)\")\n\n\n\n\n\n\n\n\n\nCode\nset.seed(1)\nex2 &lt;- rnorm(n = 100, mean = 25, sd = 5)\nmean(ex2)\n\n\n[1] 25.54444\n\n\nCode\nmedian(ex2)\n\n\n[1] 25.56955\n\n\nCode\nex2 %&gt;% \n  enframe() %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 9,\n                 color = \"#000000\",\n                 fill = \"darkgreen\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  labs(x = \"Octopus arm length (cm)\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#anemone-regression-example",
    "href": "lecture/lecture_week-01.html#anemone-regression-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "4. anemone regression example",
    "text": "4. anemone regression example\n\n\nCode\n# number of arms \narms &lt;- seq(from = 40, to = 100, by = 1)\n\n# diameter: anemones can be up to 8 cm long\nset.seed(10)\ndiam &lt;- rnorm(length(arms), mean = seq(from = 1, to = 5, length = length(arms)), sd = 1) \n\n# create a data frame\ndf &lt;- cbind(diam, arms) %&gt;% \n  as.data.frame()\n\nggplot(df, aes(x = arms, y = diam)) +\n  geom_point(size = 2) +\n  labs(x = \"Number of arms\", y = \"Diameter (cm)\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(df, aes(x = arms, y = diam)) +\n  geom_point(size = 2) +\n  # just using geom smooth for the purposes of visualization\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 2) +\n  labs(x = \"Number of arms\", y = \"Diameter (cm)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#histogram-example",
    "href": "lecture/lecture_week-01.html#histogram-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "5. histogram example",
    "text": "5. histogram example\nThe Rice rule guidelines for the calculating the number of bins in a histogram:\n\\[\nbins = 2n^{1/3}\n\\]\nwhere \\(n\\) is the number of observations. This is an example of a histogram that does follow the rice rule, where the bin number is 8.\n\n\nCode\nggplot(df, aes(x = diam)) +\n  scale_x_continuous(breaks = seq(from = 0, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 19), breaks = seq(from = 0, to = 18, by = 3)) +\n  geom_histogram(breaks = seq(from = 0, to = 8, by = 1), color = \"#000000\", fill = \"lightblue\") +\n  labs(x = \"Anemone diameter (cm)\", y = \"Count\") +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\nThese histograms do not, and it proves difficult to see the distribution:\n\n\nCode\nggplot(df, aes(x = diam)) +\n  scale_x_continuous(breaks = seq(from = 0, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 19), breaks = seq(from = 0, to = 18, by = 3)) +\n  geom_histogram(color = \"#000000\", fill = \"lightblue\") +\n  labs(x = \"Anemone diameter (cm)\", y = \"Count\") +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\nCode\nggplot(df, aes(x = diam)) +\n  scale_x_continuous(breaks = seq(from = 0, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_histogram(color = \"#000000\", fill = \"lightblue\", bins = 3) +\n  labs(x = \"Anemone diameter (cm)\", y = \"Count\") +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#jitter-plot-and-box-and-whisker-plot-example",
    "href": "lecture/lecture_week-01.html#jitter-plot-and-box-and-whisker-plot-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "6. jitter plot and box and whisker plot example",
    "text": "6. jitter plot and box and whisker plot example\n\n\nCode\nset.seed(1)\n\npretend_lengths &lt;- cbind(\n  juveniles = rnorm(20, mean = 2, sd = 0.5), \n  females = rnorm(20, mean = 8, sd = 1), \n  males = rnorm(20, mean = 4, sd = 1)\n) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:3)\n\nggplot(pretend_lengths, aes(x = name, y = value, color = name)) +\n  geom_jitter(width = 0.1, alpha = 0.8, size = 2) +\n  scale_color_manual(values = c(\"darkgreen\", \"cornflowerblue\", \"orange\")) +\n  labs(y = \"Weight (g)\") +\n  theme(axis.title.x = element_blank(),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(pretend_lengths, aes(x = name, y = value, color = name, fill = name)) +\n  geom_boxplot(alpha = 0.8) +\n  scale_color_manual(values = c(\"darkgreen\", \"cornflowerblue\", \"orange\")) +\n  scale_fill_manual(values = c(\"darkgreen\", \"cornflowerblue\", \"orange\")) +\n  labs(y = \"Weight (g)\") +\n  theme(axis.title.x = element_blank(),\n        legend.position = \"none\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#probability-mass-example",
    "href": "lecture/lecture_week-01.html#probability-mass-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "7. Probability mass example",
    "text": "7. Probability mass example\n\n\nCode\nggplot(data.frame(x = 1:55), aes(x)) +\n  stat_function(geom = \"bar\", n = 55, fun = dpois, args = list(lambda = 10), fill = \"coral\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.13)) +\n  coord_cartesian(xlim = c(0, 22)) +\n  labs(x = \"Mussel clump size (count)\", y = \"Probability mass\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#probability-density-example",
    "href": "lecture/lecture_week-01.html#probability-density-example",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "8. Probability density example",
    "text": "8. Probability density example\n\n\nCode\nggplot(data.frame(x = 1:20), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 10, sd = 2), linewidth = 1) +\n  stat_function(geom = \"area\", fun = dnorm, args = list(mean = 10, sd = 2), xlim = c(12, 14), fill = \"turquoise3\") +\n  geom_vline(xintercept = 12, lty = 2, color = \"grey\", linewidth = 1) +\n  geom_vline(xintercept = 14, lty = 2, color = \"grey\", linewidth = 1) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.22)) +\n  # coord_cartesian(xlim = c(0, 22)) +\n  labs(x = \"Individual mussel weight (g)\", y = \"Probability density\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#probability-distribution",
    "href": "lecture/lecture_week-01.html#probability-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "9. probability distribution",
    "text": "9. probability distribution\n\n\nCode\nset.seed(1)\nnormdist &lt;- rnorm(n = 100000, mean = 0, sd = 1) %&gt;% \n  as_tibble(rownames = \"x\")\n\nggplot(normdist) +\n  geom_histogram(aes(x = value, after_stat(density)), fill = \"white\", color = \"black\", bins = 100) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), color = \"blue\", linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#normal-distribution",
    "href": "lecture/lecture_week-01.html#normal-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "10. normal distribution",
    "text": "10. normal distribution\n\n\nCode\nggplot(data.frame(x = -10:25), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1, color = \"darkorange\") +\n  annotate(\"text\", x = 4.5, y = 0.4, label = \"\\U03BC = 0, \\U03C3 = 1\", color = \"darkorange\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 15, sd = 3), linewidth = 1, color = \"blue\") +\n  annotate(\"text\", x = 16, y = 0.15, label = \"\\U03BC = 15, \\U03C3 = 3\", color = \"blue\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 5, sd = 5), linewidth = 1, color = \"darkgreen\") +\n  annotate(\"text\", x = 7, y = 0.1, label = \"\\U03BC = 5, \\U03C3 = 5\", color = \"darkgreen\", size = 6) +\n  scale_x_continuous(breaks = seq(-10, 25, 5)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\")"
  },
  {
    "objectID": "lecture/lecture_week-01.html#z-score-calculation",
    "href": "lecture/lecture_week-01.html#z-score-calculation",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "11. z-score calculation",
    "text": "11. z-score calculation\n\nfigure\nWe’ll use \\(z = -1.23\\) for this example.\n\n\nCode\n# z-score\nq &lt;- -1.23\n\nggplot(data.frame(x = -4:4), aes(x)) +\n  # zscore\n  geom_linerange(x = q, ymin = 0, ymax = 0.19) +\n  # area under the curve\n  stat_function(geom = \"area\", fun = dnorm, args = list(mean = 0, sd = 1), xlim = c(-4, -1.23), fill = \"turquoise3\") +\n  # Z distribution curve\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1.5, color = \"darkorange\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.45)) +\n  theme(axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.title = element_blank(),\n        axis.line.y = element_blank())\n\n\n\n\n\n\n\n\n\n\n\ncalculation\n\n\nCode\npnorm(q, mean = 0, sd = 1)\n\n\n[1] 0.1093486\n\n\nYou can compare this with the Z-score table.\n\n\nchiton example\nWhat is the probability of selecting a chiton that is less than 6 ft long given a normally distributed population with \\(\\mu = 12\\) g with \\(\\sigma = 3\\) g?\n\n\nCode\n# calculate the z-score\nchiton_z &lt;- (6 - 12)/3\n  \n# calculate the probability under the curve\npnorm(chiton_z, mean = 0, sd = 1)\n\n\n[1] 0.02275013"
  },
  {
    "objectID": "lecture/lecture_week-01.html#rule",
    "href": "lecture/lecture_week-01.html#rule",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "12. 68-95-99.7 rule",
    "text": "12. 68-95-99.7 rule\nIn a normal distribution, 68% of values lie within 1 standard deviation of the mean, 95% within 2 standard deviations, and 99.7% within 3 standard deviations.\n\n\nCode\nlabels &lt;- c(\n  \"\", \"\\U03BC - 3\\U03C3\", \"\\U03BC - 2\\U03C3\", \"\\U03BC - \\U03C3\", \"\\U03BC\", \"\\U03BC + \\U03C3\", \"\\U03BC + 2\\U03C3\", \"\\U03BC + 3\\U03C3\", \"\"\n)\n\nggplot(data.frame(x = -4:4), aes(x)) +\n  geom_linerange(x = 1, ymin = 0, ymax = 0.24) +\n  geom_linerange(x = -1, ymin = 0, ymax = 0.24) +\n  geom_linerange(x = 2, ymin = 0, ymax = 0.055) +\n  geom_linerange(x = -2, ymin = 0, ymax = 0.055) +\n  geom_linerange(x = 3, ymin = 0, ymax = 0.005) +\n  geom_linerange(x = -3, ymin = 0, ymax = 0.005) +\n  geom_linerange(x = 0, ymin = 0, ymax = 0.399) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1.5, color = \"darkorange\") +\n  scale_x_continuous(labels = labels, breaks = seq(-4, 4, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.41)) +\n  labs(x = \"\") +\n  theme_classic() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 24),\n        axis.line.y = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks = element_blank())"
  },
  {
    "objectID": "lecture/lecture_week-01.html#students-t-distribution",
    "href": "lecture/lecture_week-01.html#students-t-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "13. Student’s t distribution",
    "text": "13. Student’s t distribution\n\n\nCode\nggplot(data.frame(x = -10:10), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#856F33\") +\n  annotate(\"text\", x = 3.5, y = 0.3, label = \"\\U03BD = 1\", color = \"#856F33\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 3), linewidth = 1, color = \"#E6821C\") + \n  annotate(\"text\", x = 3.5, y = 0.35, label = \"\\U03BD = 3\", color = \"#E6821C\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 5), linewidth = 1, color = \"#56E9E7\") +\n  annotate(\"text\", x = 3.5, y = 0.37, label = \"\\U03BD = 5\", color = \"#56E9E7\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 100), linewidth = 1, color = \"#04B37F\") +\n    annotate(\"text\", x = 3.5, y = 0.4, label = \"\\U03BD = 100\", color = \"#04B37F\", size = 6) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#uniform-distribution",
    "href": "lecture/lecture_week-01.html#uniform-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "14. Uniform distribution",
    "text": "14. Uniform distribution\n\n\nCode\nggplot(data.frame(x = 0:10), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dunif, args = list(min = 2, max = 8), linewidth = 1, color = \"firebrick4\") +\n  annotate(\"text\", x = 2, y = 0.172, label = \"a = 2\", color = \"firebrick4\", size = 6) + \n  annotate(\"text\", x = 8, y = 0.172, label = \"b = 8\", color = \"firebrick4\", size = 6) + \n  scale_x_continuous(breaks = seq(0, 10, 2)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(-0.001, 0.18)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#binomial-distribution",
    "href": "lecture/lecture_week-01.html#binomial-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "14. Binomial distribution",
    "text": "14. Binomial distribution\n\n\nCode\nggplot(data.frame(x = 1:20), aes(x)) +\n  stat_function(geom = \"line\", n = 20, fun = dbinom, args = list(size = 20, p = 0.1), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dbinom, args = list(size = 20, p = 0.1), color = \"#6D9929\", size = 3) +\n  annotate(\"text\", x = 5.5, y = 0.29, label = \"n = 20, p = 0.1\", color = \"#6D9929\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dbinom, args = list(size = 20, p = 0.4), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dbinom, args = list(size = 20, p = 0.4), color = \"#4A76E5\", size = 3) +\n  annotate(\"text\", x = 8, y = 0.2, label = \"n = 20, p = 0.4\", color = \"#4A76E5\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dbinom, args = list(size = 20, p = 0.7), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dbinom, args = list(size = 20, p = 0.7), color = \"#E67960\", size = 3) +\n  annotate(\"text\", x = 15, y = 0.21, label = \"n = 20, p = 0.7\", color = \"#E67960\", size = 6) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  labs(x = \"Number of successes\", y = \"Mass\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\"))"
  },
  {
    "objectID": "lecture/lecture_week-01.html#poisson-distribution",
    "href": "lecture/lecture_week-01.html#poisson-distribution",
    "title": "Week 1 figures - Lectures 1 and 2",
    "section": "15. Poisson distribution",
    "text": "15. Poisson distribution\n\n\nCode\nggplot(data.frame(x = 1:20), aes(x)) +\n  stat_function(geom = \"line\", n = 20, fun = dpois, args = list(lambda = 1), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dpois, args = list(lambda = 1), color = \"coral\", size = 4) +\n  annotate(\"text\", x = 3, y = 0.37, label = \"\\U03BB = 1\", color = \"coral\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dpois, args = list(lambda = 4), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dpois, args = list(lambda = 4), color = \"darkgreen\", size = 4) +\n  annotate(\"text\", x = 6, y = 0.2, label = \"\\U03BB = 4\", color = \"darkgreen\", size = 6) +\n  stat_function(geom = \"line\", n = 20, fun = dpois, args = list(lambda = 10), color = \"black\") +\n  stat_function(geom = \"point\", n = 20, fun = dpois, args = list(lambda = 10), color = \"turquoise\", size = 4) +\n  annotate(\"text\", x = 14, y = 0.12, label = \"\\U03BB = 10\", color = \"turquoise\", size = 6) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Discrete value\", y = \"Mass\")"
  },
  {
    "objectID": "lecture/lecture_week-03.html",
    "href": "lecture/lecture_week-03.html",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\n\n# calculate effect size\nlibrary(effsize)\n\n# visualization\nlibrary(patchwork)"
  },
  {
    "objectID": "lecture/lecture_week-03.html#set-up",
    "href": "lecture/lecture_week-03.html#set-up",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\n\n# calculate effect size\nlibrary(effsize)\n\n# visualization\nlibrary(patchwork)"
  },
  {
    "objectID": "lecture/lecture_week-03.html#math",
    "href": "lecture/lecture_week-03.html#math",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "1. Math",
    "text": "1. Math\n\na. test statistic for one sample t-test\n\\[\nt = \\frac{\\bar{y} - \\mu}{s/\\sqrt{n}}\n\\]\n\n\nb. two sample t-test when variances are equal (Student’s)\n\\[\nt = \\frac{\\bar{y_A} - \\bar{y_B}}{s_p \\times \\sqrt{\\frac{1}{N_A + N_B}}}\n\\]\n\\[\ndf = (N_A - 1) + (N_B - 1)\n\\]\n\n\nc. when variances are not equal (Welch’s)\n\\[\nt = \\frac{\\bar{y_A} - \\bar{y_B}}{\\sqrt{\\frac{s_A^2}{N_A}+\\frac{s_B^2}{N_B}}}\n\\]\n\\[\ndf = \\frac{(\\frac{s_A^2}{N_A}+\\frac{S_B^2}{N_B})^2}{\\frac{(\\frac{s_A^2}{N_A})^2}{N_A-1}+\\frac{(\\frac{s_B^2}{N_B})^2}{N_B-1}}\n\\]\n\n\nd. test statistic for F test\n\\[\nF =  \\frac{s^2_A}{s^2_B}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-03.html#central-limit-theorem",
    "href": "lecture/lecture_week-03.html#central-limit-theorem",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "2. central limit theorem",
    "text": "2. central limit theorem\nIf you were to sample a bunch of times from any distribution (i.e. take many observations within a sample, take many observations in another sample), the mean values for each sample will be normally distributed. Kareem Carr has a nice explainer of how this works here.\n\n\nCode\n# randomly select 10000 numbers from a uniform distribution for the population\nuniform &lt;- runif(10000, min = 2, max = 8)\n\n# make a histogram for the population\nuniformdf &lt;- as.data.frame(uniform)\n\nggplot(uniformdf, aes(x = uniform)) +\n  geom_histogram(breaks = seq(2, 8, length.out = 41), fill = \"firebrick\", alpha = 0.7, color = \"firebrick\") +\n  geom_vline(xintercept = mean(uniform), linewidth = 2) +\n  annotate(\"text\", x = 4, y = 290, label = \"mean = 4.967\", size = 10) +\n  scale_x_continuous(breaks = seq(from = 2, to = 8, by = 1)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 305)) +\n  labs(x = \"Continuous value\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# for() loop to \nstore2 &lt;- c()\nstore5 &lt;- c()\nstore15 &lt;- c()\nstore30 &lt;- c()\nstore50 &lt;- c()\n\nfor(i in 1:100) {\n  \n  # sample 100x\n  store2[i] &lt;- mean(sample(uniform, 2, replace = FALSE))\n  store5[i] &lt;- mean(sample(uniform, 5, replace = FALSE))\n  store15[i] &lt;- mean(sample(uniform, 15, replace = FALSE))\n  store30[i] &lt;- mean(sample(uniform, 30, replace = FALSE))\n  store50[i] &lt;- mean(sample(uniform, 50, replace = FALSE))\n\n}\n\n\ndf &lt;- cbind(store2, store5, store15, store30, store50) %&gt;% \n  as.data.frame()\n  \nggplot(df) +\n  geom_histogram(aes(x = store2), bins = 10, alpha = 0.7, fill = \"chocolate1\", color = \"chocolate1\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store2)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store5), bins = 10, alpha = 0.7, fill = \"blue3\", color = \"blue3\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store5)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store15), bins = 12, alpha = 0.7, fill = \"darkorchid4\", color = \"darkorchid4\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store15)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store30), bins = 12, alpha = 0.7, fill = \"lightseagreen\", color = \"lightseagreen\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store30)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  geom_histogram(aes(x = store50), bins = 12, alpha = 0.7, fill = \"violetred3\", color = \"violetred3\") +\n  coord_cartesian(xlim = c(2, 8), ylim = c(0, 30)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  geom_vline(xintercept = mean(store50)) +\n  geom_vline(xintercept = mean(uniform), color = \"red\") +\n  labs(x = \"Sample means\", y = \"Count\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        plot.margin = unit(c(0.5, 0.5, 0.1, 0.1), \"cm\"))"
  },
  {
    "objectID": "lecture/lecture_week-03.html#z--vs-t-distribution",
    "href": "lecture/lecture_week-03.html#z--vs-t-distribution",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "3. z- vs t-distribution",
    "text": "3. z- vs t-distribution\n\na. comparison with normal\nt-distributions allow for more uncertainty around the tails.\n\n\nCode\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"line\", n = 1000, fun = dnorm, args = list(mean = 0, sd = 1), linewidth = 1, color = \"darkorange\") +\n  annotate(\"text\", x = 2.5, y = 0.4, label = \"normal\", color = \"darkorange\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#856F33\") +\n  annotate(\"text\", x = 3, y = 0.32, label = \"t-distribution (small n)\", color = \"#856F33\", size = 6) +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 10), linewidth = 1, color = \"#56E9E7\") +\n  annotate(\"text\", x = 3, y = 0.37, label = \"t-distribution (large n)\", color = \"#56E9E7\", size = 6) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.42)) +\n  labs(x = \"Continuous value\", y = \"Density\") +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        text = element_text(family = \"Lato\")) \n\n\n\n\n\n\n\n\n\n\n\nb. visual representation of significance and t-statistic\n\n\nCode\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 19), xlim = c(1.8, 5), fill = \"#0070c0\") +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 19), xlim = c(-5, -1.8), fill = \"#0070c0\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 19), linewidth = 1, color = \"#000000\") +\n  geom_hline(yintercept = 0) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.4)) +\n  theme_void() +\n  theme(panel.grid = element_blank(),\n        plot.margin = unit(c(1, 0, 0, 0), \"cm\"))"
  },
  {
    "objectID": "lecture/lecture_week-03.html#qqplot-examples",
    "href": "lecture/lecture_week-03.html#qqplot-examples",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "5. qqplot examples",
    "text": "5. qqplot examples\nWe use qqplots (quantile-quantile plots) to visually evaluate the normality of some variable. The x-axis is the “theoretical” quantile, and the y-axis is the “sample” quantile. If the points follow a 1:1 line, then the variable is normally distributed.\nThe New Haven temperature data is normally distributed:\n\n\nCode\nnhtemp_hist &lt;- as_tibble(nhtemp) %&gt;% \n  ggplot(aes(x = x)) +\n  geom_histogram(breaks = seq(47, 55, length.out = 9), fill = \"turquoise3\", color = \"#000000\") +\n  scale_x_continuous(breaks = seq(47, 55, length.out = 9), expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 23)) +\n  theme_classic() +\n  labs(x = \"Bins\", y = \"Count\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nnhtemp_qq &lt;- ggplot(as_tibble(nhtemp)) +\n  stat_qq(aes(sample = x), color = \"turquoise3\", size = 3) +\n  labs(x = \"Theoretical quantile\", y = \"Sample quantile\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nnhtemp_hist + nhtemp_qq\n\n\n\n\n\n\n\n\n\nThe sunspot data is not:\n\n\nCode\nsunspot_hist &lt;- as_tibble(sunspots) %&gt;% \n  ggplot(aes(x = x)) +\n  geom_histogram(breaks = round(seq(0, 260, length.out = 30)), fill = \"tomato2\", color = \"#000000\") +\n  scale_x_continuous(breaks = round(seq(0, 260, length.out = 30)), expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 480)) +\n  theme_classic() +\n  labs(x = \"Bins\", y = \"Count\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nsunspot_qq &lt;- ggplot(as_tibble(sunspots)) +\n  stat_qq(aes(sample = x), color = \"tomato2\", size = 3) +\n  theme_classic() +\n  labs(x = \"Theoretical quantile\", y = \"Sample quantile\") +\n  theme(plot.margin = unit(c(0.1, 1, 0.1, 0.1), \"cm\")) \n\nsunspot_hist \n\n\n\n\n\n\n\n\n\nCode\nsunspot_qq"
  },
  {
    "objectID": "lecture/lecture_week-03.html#one-sample-t-test-example",
    "href": "lecture/lecture_week-03.html#one-sample-t-test-example",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "6. One sample t-test example",
    "text": "6. One sample t-test example\nThis is the creosote example from lecture.\n\ngenerating numbers\n\n\nCode\nset.seed(1)\ncreosote &lt;- rnorm(n = 41, mean = 1.8, sd = 0.3) %&gt;% \n  round(digits = 2) \n\n\n\n\nhistogram and qq plot\n\n\nCode\n# calculate the range\nrange &lt;- max(creosote) - min(creosote)\n\n# determine the number of observations\nobs &lt;- length(creosote)\n\n# calculate the number of bins using the Rice Rule\n# note that this doesn't come out to a whole number, so it's rounded\nbins &lt;- 2*(obs^(1/3)) %&gt;% \n  round(digits = 0)\n\n# calculate the width of the bin\nbinwidth &lt;- range/(bins - 1)\n\n# set up a sequence of numbers from 0 to 100\nseq &lt;- seq(from = 1, to = 11, by = 1)\n\n# calculate the axis breaks  \naxis_breaks &lt;- seq*binwidth + (binwidth/2)\n\n# round the axis breaks\naxis_breaks_rounded &lt;- round(axis_breaks, \n                             digits = 3)\n\nhist &lt;- creosote %&gt;% \n  enframe() %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(binwidth = binwidth,\n                 fill = \"#e3c922\",\n                 color = \"black\") +\n  scale_x_continuous(breaks = axis_breaks_rounded) +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 14)) +\n  labs(x = \"Creosote height (m)\",\n       y = \"Count\")\n\nqq &lt;- creosote %&gt;% \n  enframe() %&gt;% \n  ggplot(aes(sample = value)) +\n  geom_qq_line() +\n  geom_qq(color = \"#e3c922\",\n          size = 4,\n          alpha = 0.8) \n\nhist + qq\n\n\n\n\n\n\n\n\n\n\n\ncalculating a critical value\n\n\nCode\nt_critical &lt;- qt(p = 0.05/2, df = 40, lower.tail = FALSE)\nt_critical\n\n\n[1] 2.021075\n\n\n\n\ncalculating t-score\n“By hand”:\n\n\nCode\n# claimed mean\nmu &lt;- 3\n\n# number of observations\nn &lt;- length(creosote)\n\n# sample mean\nybar &lt;- mean(creosote)\n\n# sample standard deviation\ns &lt;- sd(creosote)\n\n# sample standard error\nse &lt;- s/sqrt(n)\n\n# t-score\nt &lt;- (ybar-mu)/se\n\nt\n\n\n[1] -28.56624\n\n\nUsing t.test()\n\n\nCode\nt.test(creosote, mu = 3)\n\n\n\n    One Sample t-test\n\ndata:  creosote\nt = -28.566, df = 40, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 3\n95 percent confidence interval:\n 1.743305 1.909378\nsample estimates:\nmean of x \n 1.826341 \n\n\nManually calculating p-value:\n\n\nCode\n# manually calculating p-value\n# two-tailed: multiply probability by 2\n# lower = FALSE: probability of the value being more than t\n2*pt(q = t, df = n - 1, lower = TRUE)\n\n\n[1] 3.158646e-28\n\n\n\n\nvisual representation of sample t-statistic vs t-critical\n\n\nCode\nggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(t_critical, 5), fill = \"darkgrey\") +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(-5, -t_critical), fill = \"darkgrey\") +\n  \n  annotate(geom = \"linerange\", x = t_critical, ymin = 0, ymax = 0.065, linewidth = 1, lty = 2, color = \"#000000\") +\n  annotate(geom = \"linerange\", x = -t_critical, ymin = 0, ymax = 0.065, linewidth = 1, lty = 2, color = \"#000000\") +\n  \n  # annotate(geom = \"linerange\", x = t, ymin = 0, ymax = 0.075, linewidth = 1, color = \"#000000\") +\n  # annotate(geom = \"linerange\", x = -t, ymin = 0, ymax = 0.075, linewidth = 1, color = \"#000000\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  theme_void() +\n  theme(panel.grid = element_blank(),\n        plot.margin = unit(c(1, 0, 0, 0), \"cm\"))"
  },
  {
    "objectID": "lecture/lecture_week-03.html#two-sample-t-test",
    "href": "lecture/lecture_week-03.html#two-sample-t-test",
    "title": "Week 3 figures - Lectures 5 and 6",
    "section": "7. two-sample t-test",
    "text": "7. two-sample t-test\n\n\nCode\nex1 &lt;- ggplot(data.frame(x = -8:8), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 1, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 1), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nset.seed(2)\nx &lt;- rnorm(30, mean = 0, sd = 2)\ny &lt;- rnorm(30, mean = 1, sd = 2)\n\nt.test(x = x, y = y, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  x and y\nt = -0.78852, df = 58, p-value = 0.4336\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.6721807  0.7270662\nsample estimates:\nmean of x mean of y \n0.4573436 0.9299009 \n\n\nCode\n# 0.43\n\n\n\n\nCode\nex2 &lt;- ggplot(data.frame(x = -8:17), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 2, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 2), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nset.seed(1000000000)\nx &lt;- rnorm(30, mean = 0, sd = 2)\ny &lt;- rnorm(30, mean = 2, sd = 2)\n\nt.test(x = x, y = y, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  x and y\nt = -3.7904, df = 58, p-value = 0.0003603\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.7905631 -0.8617609\nsample estimates:\nmean of x mean of y \n0.1435745 1.9697364 \n\n\nCode\n# 0.6932\n\n\n\n\nCode\nex3 &lt;- ggplot(data.frame(x = -8:17), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 10, sd = 2), linewidth = 2, color = \"#00A38D\") +\n  geom_vline(aes(xintercept = 10), color = \"#00A38D\", lty = 2, linewidth = 2) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nset.seed(100)\nx &lt;- rnorm(40, mean = 0, sd = 2)\ny &lt;- rnorm(40, mean = 10, sd = 2)\n\nt.test(x = x, y = y, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  x and y\nt = -21.69, df = 78, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -10.564878  -8.788488\nsample estimates:\nmean of x mean of y \n0.2003543 9.8770375 \n\n\nCode\n# p &lt; 0.001\n\n\n\n\nCode\nex1 + ex2 + ex3\n\n\n\n\n\n\n\n\n\n\nsame differences in means, different SD\n\n\nCode\nsmall &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 2), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 2), linewidth = 2, color = \"#0070C0\") +\n  geom_vline(aes(xintercept = 3), color = \"#0070C0\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.21)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nbig &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 0.5), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 0.5), linewidth = 2, color = \"#0070C0\") +\n  geom_vline(aes(xintercept = 3), color = \"#0070C0\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.8)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\ndiff &lt;- ggplot(data.frame(x = -6:9), aes(x)) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 0, sd = 0.5), linewidth = 2, color = \"#FF6B2B\") +\n  geom_vline(aes(xintercept = 0), color = \"#FF6B2B\", lty = 2, linewidth = 2) +\n  stat_function(geom = \"line\", n = 100, fun = dnorm, args = list(mean = 3, sd = 1.25), linewidth = 2, color = \"#0070C0\") +\n  geom_vline(aes(xintercept = 3), color = \"#0070C0\", lty = 2, linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.85)) +\n  theme_void() +\n  theme(plot.margin = unit(c(1, 1, 1, 1), \"cm\"))\n\nsmall / big / diff\n\n\n\n\n\n\n\n\n\n\n\nF-distribution\n\n\nCode\nggplot(data.frame(x = seq(from = 0, to = 4, by = 0.1)), aes(x)) +\n  stat_function(geom = \"line\", fun = df, args = list(df1 = 20, df2 = 20), color = \"#FF6B2B\", linewidth = 1, xlim = c(0, 4)) +\n  stat_function(geom = \"line\", fun = df, args = list(df1 = 5, df2 = 5), color = \"#0070C0\", linewidth = 1, xlim = c(0, 4)) +\n  stat_function(geom = \"line\", fun = df, args = list(df1 = 1, df2 = 5), linewidth = 1, xlim = c(0, 4)) +\n  annotate(\"text\", x = 1.5, y = 1, label = \"20, 20\", color = \"#FF6B2B\", size = 8) +\n  annotate(\"text\", x = -0.2, y = 0.5, label = \"5, 5\", color = \"#0070C0\", size = 8) +\n  annotate(\"text\", x = 0.5, y = 1.5, label = \"1, 5\", size = 8) + \n  scale_y_continuous(expand = c(0, 0)) +\n  theme(axis.text = element_blank(),\n        axis.line = element_blank(),\n        axis.ticks = element_blank(),\n        axis.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nF-distribution example\n\n\nCode\nset.seed(1)\nrats &lt;- rnorm(n = 20, mean = 178, sd = 43)\nset.seed(1)\nmice &lt;- rnorm(n = 20, mean = 120, sd = 20)\n\nmean(rats)\n\n\n[1] 186.1925\n\n\nCode\nmean(mice)\n\n\n[1] 123.8105\n\n\nCode\nvar(rats)\n\n\n[1] 1542.126\n\n\nCode\nvar(mice)\n\n\n[1] 333.6129\n\n\nCode\nvar(rats)/var(mice)\n\n\n[1] 4.6225\n\n\nCode\nvar.test(rats, mice)\n\n\n\n    F test to compare two variances\n\ndata:  rats and mice\nF = 4.6225, num df = 19, denom df = 19, p-value = 0.001619\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  1.829642 11.678519\nsample estimates:\nratio of variances \n            4.6225 \n\n\n\n\nCode\nt.test(rats, mice, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  rats and mice\nt = 6.4415, df = 38, p-value = 1.414e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 42.77708 81.98702\nsample estimates:\nmean of x mean of y \n 186.1925  123.8105 \n\n\nCode\nt.test(rats, mice, var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  rats and mice\nt = 6.4415, df = 26.853, p-value = 6.84e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 42.50629 82.25781\nsample estimates:\nmean of x mean of y \n 186.1925  123.8105 \n\n\n\n\nCode\n(mean(rats) - mean(mice))/sqrt((var(rats) + var(mice))/2)\n\n\n[1] 2.036988\n\n\n\n\nCode\ncohen.d(rats, mice)\n\n\n\nCohen's d\n\nd estimate: 2.036988 (large)\n95 percent confidence interval:\n   lower    upper \n1.248080 2.825895 \n\n\ntesting test statistic formula to compare against t-test from above:\n\n\nCode\nxa &lt;- mean(rats)\nxb &lt;- mean(mice)\n\nvara &lt;- var(rats)\nvarb &lt;- var(mice)\n\nnA &lt;- length(rats)\nnB &lt;- length(mice)\n\n(xa - xb)/sqrt((vara/nA)+(varb/nB))\n\n\n[1] 6.441521\n\n\nCode\n(nA - 1) + (nB - 1)\n\n\n[1] 38\n\n\nCode\n(((vara/nA)+(varb/nB))^2)/((vara/nA)^2/(nA-1)+(varb/nB)^2/(nB-1))\n\n\n[1] 26.85313"
  },
  {
    "objectID": "lecture/lecture_week-06.html",
    "href": "lecture/lecture_week-06.html",
    "title": "Week 6 figures - Lecture 11",
    "section": "",
    "text": "\\[\n\\begin{align}\n\\chi^2 &= \\sum\\frac{(O - E)^2}{E} \\\\\n&= \\frac{55 - 47.2}{47.2} +...+\\frac{45-31.9}{31.9} \\\\\n&= 15.276\n\\end{align}\n\\]\n\n\n\n\\[\n\\begin{align}\nexpected &= \\frac{row \\, total \\times column \\, total}{table \\, total} \\\\\n&= \\frac{126 \\times 118}{315} \\\\\n&= 47.2\n\\end{align}\n\\]\n\n\n\n\\[\ndf = (number\\;of\\;rows - 1) \\times (number\\;of\\;columns - 1)\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-06.html#math",
    "href": "lecture/lecture_week-06.html#math",
    "title": "Week 6 figures - Lecture 11",
    "section": "",
    "text": "\\[\n\\begin{align}\n\\chi^2 &= \\sum\\frac{(O - E)^2}{E} \\\\\n&= \\frac{55 - 47.2}{47.2} +...+\\frac{45-31.9}{31.9} \\\\\n&= 15.276\n\\end{align}\n\\]\n\n\n\n\\[\n\\begin{align}\nexpected &= \\frac{row \\, total \\times column \\, total}{table \\, total} \\\\\n&= \\frac{126 \\times 118}{315} \\\\\n&= 47.2\n\\end{align}\n\\]\n\n\n\n\\[\ndf = (number\\;of\\;rows - 1) \\times (number\\;of\\;columns - 1)\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-06.html#code",
    "href": "lecture/lecture_week-06.html#code",
    "title": "Week 6 figures - Lecture 11",
    "section": "2. Code",
    "text": "2. Code\n\na. data\n\n\nCode\n# creating matrix of survey results\nsurvey &lt;- matrix(\n  c(55, 38, 33, 41, 25, 29, 22, 27, 45),\n  nrow = 3,\n  ncol = 3,\n  byrow = TRUE,\n  dimnames = list(c(\"walking_distance\", \"driving_distance\", \"out_of_town\"),\n                  c(\"trails\", \"dog_access\", \"wildlife_viewing\"))\n)\n\n# displaying survey results\nsurvey\n\n\n                 trails dog_access wildlife_viewing\nwalking_distance     55         38               33\ndriving_distance     41         25               29\nout_of_town          22         27               45\n\n\n\n\nb. calculating critical value\n\n\nCode\ncritical_value &lt;- qchisq(p = 0.05, # probability (area under curve)\n                         df = 4, # degrees of freedom\n                         lower.tail = FALSE) # calculate boundary where 0.05 is to the right\n\ncritical_value\n\n\n[1] 9.487729\n\n\n\n\nc. calculating p-value\n\n\nCode\np_value &lt;- pchisq(q = 15.276, # test statistic\n       df = 4, # degrees of freedom\n       lower.tail = FALSE) # calculate probability (area under the curve) to the RIGHT of the test statistic\n\np_value\n\n\n[1] 0.004161711\n\n\n\n\nd. using chisq.test() function\n\n\nCode\nchisq.test(survey)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  survey\nX-squared = 15.276, df = 4, p-value = 0.004162"
  },
  {
    "objectID": "lecture/lecture_week-04.html",
    "href": "lecture/lecture_week-04.html",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\n\n# cohen's d\nlibrary(effectsize)\n\n# power\nlibrary(pwr)"
  },
  {
    "objectID": "lecture/lecture_week-04.html#set-up",
    "href": "lecture/lecture_week-04.html#set-up",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\n\n# cohen's d\nlibrary(effectsize)\n\n# power\nlibrary(pwr)"
  },
  {
    "objectID": "lecture/lecture_week-04.html#math",
    "href": "lecture/lecture_week-04.html#math",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "1. Math",
    "text": "1. Math\n\na. Cohen’s d\n\\[\nCohen's \\; d = \\frac{\\bar{y_A} - \\bar{y_B}}{\\sqrt{(s^2_A + s^2_B)/2}}\n\\]\n\n\nb. Cohen’s d with separated SD\n\\[\nCohen's \\; d = \\frac{\\bar{y_A} - \\bar{y_B}}{\\sqrt{\\frac{(n_A - 1)\\times s^2_A + (n_B - 1)\\times s^2_B}{n_A + n_B + 2}}}\n\\]\n\n\nb. confidence interval for two-sample t-test\n\\[\nCI = (\\bar{y_A} - \\bar{y_B}) \\pm t \\times \\sqrt{\\frac{(n_A - 1)s_A^2 + (n_B - 1)s_B^2}{n_A+n_B-2}} \\times \\sqrt{\\frac{1}{n_A}+\\frac{1}{n_B}}\n\\]\n\n\nc. test statistic for paired t-test\n\\[\nt_s = \\frac{\\bar{y}_d - \\mu_0}{s_d - \\sqrt{n}}\n\\]\n\n\nd. standard error for two-sample t-test\nIf variances are not equal:\n\\[\nSE_{\\bar{y_A} - \\bar{y_B}} = \\sqrt{\\frac{s_A^2}{n_A}+\\frac{s_B^2}{n_B}}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-04.html#interpret-this-output",
    "href": "lecture/lecture_week-04.html#interpret-this-output",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "2. Interpret this output",
    "text": "2. Interpret this output\nYou have two raised beds in which you’re growing tomatoes. One bed is in the sun, but the other is in shade. You want to know if the weight of the tomatoes is different between beds. You measure 33 tomatoes from each bed.\n\n\nCode\ntomatoes &lt;- cbind(sunny = rnorm(n = 33, mean = 150, sd = 20),\n                  shaded = rnorm(n = 33, mean = 130, sd = 10)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"sun_level\", values_to = \"weight_g\")\n\nggplot(data = tomatoes,\n       aes(x = sun_level,\n           y = weight_g)) +\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\n\nCode\nvar.test(weight_g ~ sun_level,\n         data = tomatoes)\n\n\n\n    F test to compare two variances\n\ndata:  weight_g by sun_level\nF = 0.2801, num df = 32, denom df = 32, p-value = 0.0005368\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1383397 0.5671384\nsample estimates:\nratio of variances \n         0.2801031 \n\n\nCode\nt.test(weight_g ~ sun_level,\n       data = tomatoes,\n       var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  weight_g by sun_level\nt = -5.0017, df = 48.622, p-value = 7.811e-06\nalternative hypothesis: true difference in means between group shaded and group sunny is not equal to 0\n95 percent confidence interval:\n -31.45432 -13.42087\nsample estimates:\nmean in group shaded  mean in group sunny \n            130.4776             152.9152"
  },
  {
    "objectID": "lecture/lecture_week-04.html#power-analysis",
    "href": "lecture/lecture_week-04.html#power-analysis",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "3. Power analysis",
    "text": "3. Power analysis\n\n\nCode\n# higher power\npwr.t.test(n = NULL, d = 0.7, sig.level = 0.05, power = 0.95)\n\n\n\n     Two-sample t test power calculation \n\n              n = 54.01938\n              d = 0.7\n      sig.level = 0.05\n          power = 0.95\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nCode\n# lower power\npwr.t.test(n = NULL, d = 0.7, sig.level = 0.05, power = 0.80)\n\n\n\n     Two-sample t test power calculation \n\n              n = 33.02457\n              d = 0.7\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group"
  },
  {
    "objectID": "lecture/lecture_week-04.html#write-about-this-result",
    "href": "lecture/lecture_week-04.html#write-about-this-result",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "4. Write about this result",
    "text": "4. Write about this result\nYou have two worm compost bins: one in which you throw citrus peels, and the other in which you don’t. You’re curious to see if the citrus worms are bigger than the non-citrus worms. You measure 34 worms from each bin and find this result:\n\n\nCode\nworms &lt;- cbind(citrus = rnorm(n = 34, mean = 140, sd = 20),\n               non_citrus = rnorm(n = 34, mean = 160, sd = 15)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"compost_bin\", values_to = \"weight_g\")\n\nggplot(data = worms,\n       aes(x = compost_bin,\n           y = weight_g)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nCode\nvar.test(weight_g ~ compost_bin,\n         data = worms)\n\n\n\n    F test to compare two variances\n\ndata:  weight_g by compost_bin\nF = 1.7687, num df = 33, denom df = 33, p-value = 0.1063\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.8833406 3.5415030\nsample estimates:\nratio of variances \n          1.768715 \n\n\nCode\nt.test(weight_g ~ compost_bin,\n       data = worms,\n       var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  weight_g by compost_bin\nt = -3.4216, df = 61.276, p-value = 0.001114\nalternative hypothesis: true difference in means between group citrus and group non_citrus is not equal to 0\n95 percent confidence interval:\n -25.035923  -6.567811\nsample estimates:\n    mean in group citrus mean in group non_citrus \n                144.1785                 159.9803"
  },
  {
    "objectID": "lecture/lecture_week-04.html#effect-size-examples",
    "href": "lecture/lecture_week-04.html#effect-size-examples",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "5. Effect size examples",
    "text": "5. Effect size examples\n\na. large sample size, small difference\n\n\nCode\nset.seed(1)\nsmall &lt;- cbind(a = rnorm(n = 10, mean = 10, sd = 2), \n               b = rnorm(n = 10, mean = 11, sd = 2)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"group\", values_to = \"value\")\nt.test(value ~ group,\n       data = small,\n       var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  value by group\nt = -1.4727, df = 18, p-value = 0.1581\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -2.9926364  0.5260676\nsample estimates:\nmean in group a mean in group b \n       10.26441        11.49769 \n\n\nCode\nset.seed(1)\nlarge &lt;- cbind(a = rnorm(n = 100, mean = 10, sd = 2), \n               b = rnorm(n = 100, mean = 11, sd = 2)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"group\", values_to = \"value\")\nt.test(value ~ group,\n       data = large,\n       var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  value by group\nt = -2.6906, df = 198, p-value = 0.007743\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -1.2245098 -0.1887085\nsample estimates:\nmean in group a mean in group b \n       10.21777        10.92438 \n\n\n\n\nb. needlegrass example\n\n\nCode\nset.seed(1)\nneedlegrass &lt;- cbind(ungrazed = rnorm(n = 35, mean = 80, sd = 10), \n                     grazed = rnorm(n = 35, mean = 74, sd = 5)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:2, names_to = \"plot_type\", values_to = \"height_cm\")\n\n# plot without all the adjustments\nggplot(data = needlegrass,\n       aes(x = plot_type,\n           y = height_cm,\n           color = plot_type)) +\n  geom_point(position = position_jitter(width = 0.1, height = 0, seed = 10),\n             alpha = 0.2) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_cl_normal) \n\n\n\n\n\n\n\n\n\nCode\n# \"finalized\" plot\nggplot(data = needlegrass,\n       aes(x = plot_type,\n           y = height_cm,\n           color = plot_type)) +\n  geom_point(position = position_jitter(width = 0.1, height = 0, seed = 10),\n             alpha = 0.2) +\n  scale_color_manual(values = c(\"darkgreen\", \"cornflowerblue\")) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_cl_normal,\n               size = 1,\n               linewidth = 1) +\n  labs(x = \"Plot type\",\n       y = \"Height (cm)\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nDoing a t-test:\n\n\nCode\nvar.test(height_cm ~ plot_type,\n       data = needlegrass)\n\n\n\n    F test to compare two variances\n\ndata:  height_cm by plot_type\nF = 0.26151, num df = 34, denom df = 34, p-value = 0.0001765\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1320008 0.5180813\nsample estimates:\nratio of variances \n         0.2615094 \n\n\nCode\nt.test(height_cm ~ plot_type,\n       data = needlegrass,\n       var.equal = FALSE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  height_cm by plot_type\nt = -3.2032, df = 50.644, p-value = 0.002351\nalternative hypothesis: true difference in means between group grazed and group ungrazed is not equal to 0\n95 percent confidence interval:\n -9.084836 -2.083807\nsample estimates:\n  mean in group grazed mean in group ungrazed \n              75.18323               80.76756 \n\n\nCohen’s d:\n\n\nCode\n# pooled SD\ncohens_d(height_cm ~ plot_type,\n       data = needlegrass)\n\n\nCohen's d |         95% CI\n--------------------------\n-0.77     | [-1.25, -0.28]\n\n- Estimated using pooled SD.\n\n\nCode\n# unpooled SD\ncohens_d(height_cm ~ plot_type,\n       data = needlegrass, \n       pooled_sd = FALSE)\n\n\nCohen's d |         95% CI\n--------------------------\n-0.77     | [-1.25, -0.27]\n\n- Estimated using un-pooled SD.\n\n\nCode\n# by hand\nneedlegrass_sum &lt;- needlegrass %&gt;% \n  group_by(plot_type) %&gt;% \n  reframe(\n    mean = mean(height_cm),\n    var = var(height_cm),\n    n = length(height_cm)\n  )\n\nya &lt;- pluck(needlegrass_sum, 2, 1)\nyb &lt;- pluck(needlegrass_sum, 2, 2)\nvara &lt;- pluck(needlegrass_sum, 3, 1)\nvarb &lt;- pluck(needlegrass_sum, 3, 2)\nna &lt;- pluck(needlegrass_sum, 4, 1)\nnb &lt;- pluck(needlegrass_sum, 4, 2)\n\n# by hand\n\n(ya - yb)/sqrt((vara + varb)/2)\n\n\n[1] -0.7657151\n\n\nCode\n(ya - yb)/sqrt(\n  ((na - 1)*vara + (nb - 1)*varb)/(na + nb - 2)\n)\n\n\n[1] -0.7657151"
  },
  {
    "objectID": "lecture/lecture_week-04.html#good-and-bad-results-statements",
    "href": "lecture/lecture_week-04.html#good-and-bad-results-statements",
    "title": "Week 4 figures - Lectures 7 and 8",
    "section": "6. good and bad results statements",
    "text": "6. good and bad results statements\n\n\nCode\nmanaged &lt;- rnorm(n = 33, mean = 5, sd = 1) %&gt;% \n  enframe() %&gt;% \n  mutate(treatment = \"managed\")\nnonintervention &lt;- rnorm(n = 30, mean = 7, sd = 1) %&gt;% \n  enframe() %&gt;% \n  mutate(treatment = \"non-intervention\") \npools &lt;- rbind(managed, nonintervention) %&gt;% \n  select(treatment, value) %&gt;% \n  rename(temp = value)\nvar.test(temp ~ treatment,\n         data = pools)\n\n\n\n    F test to compare two variances\n\ndata:  temp by treatment\nF = 1.287, num df = 32, denom df = 29, p-value = 0.4953\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.6197933 2.6377877\nsample estimates:\nratio of variances \n          1.286962 \n\n\nCode\nt.test(temp ~ treatment,\n       data = pools)\n\n\n\n    Welch Two Sample t-test\n\ndata:  temp by treatment\nt = -11.206, df = 60.948, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group managed and group non-intervention is not equal to 0\n95 percent confidence interval:\n -2.558536 -1.783706\nsample estimates:\n         mean in group managed mean in group non-intervention \n                      4.952439                       7.123560 \n\n\nCode\ncohens_d(temp ~ treatment,\n       data = pools)\n\n\nCohen's d |         95% CI\n--------------------------\n-2.81     | [-3.51, -2.10]\n\n- Estimated using pooled SD.\n\n\nStatement: Our data suggest a difference in water temperature between managed (n = 33) and non-intervention (i.e. control, n = 30) vernal pools, with a strong (Cohen’s d = 2.19) effect of management.\nTemperatures in managed pools were different from those in non-intervention pools (two-tailed two-sample t-test, t(60.9) = -8.7, p &lt; 0.001, ⍺ = 0.05); on average, managed pools were 5.3 °C, while control pools were 7.1 °C."
  },
  {
    "objectID": "lecture/lecture_week-08.html",
    "href": "lecture/lecture_week-08.html",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(flextable)\nlibrary(GGally)\n\n# data\nlibrary(palmerpenguins)\n\n# analysis\nlibrary(car)\nlibrary(performance)\nlibrary(broom)\nlibrary(DHARMa)\nlibrary(MuMIn)"
  },
  {
    "objectID": "lecture/lecture_week-08.html#sum-of-squares-for-linear-regression",
    "href": "lecture/lecture_week-08.html#sum-of-squares-for-linear-regression",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "sum of squares for linear regression",
    "text": "sum of squares for linear regression\n\nregression (or model)\n\\[\nSS_{reg} = \\sum_{i = 1}^{n}(\\hat{y} - \\bar{y})^2\n\\]\n\n\nerror\n\\[\nSS_{err} = \\sum_{i = 1}^{n}(y_i - \\hat{y})^2\n\\]\n\n\ntotal\n\\[\nSS_{tot} = \\sum_{i = 1}^n(y_i - \\bar{y})\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-08.html#mean-square",
    "href": "lecture/lecture_week-08.html#mean-square",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "mean square",
    "text": "mean square\n\nregression\n\\[\nMS_{reg} = \\frac{SS_{reg}}{1}\n\\]\n\n\nerror\n\\[\nMS_{err} = \\frac{SS_{err}}{n - 2}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-08.html#f-statistic",
    "href": "lecture/lecture_week-08.html#f-statistic",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "F-statistic",
    "text": "F-statistic\n\\[\nF = \\frac{MS_{reg}}{MS_{err}}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-08.html#generating-data",
    "href": "lecture/lecture_week-08.html#generating-data",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "generating data",
    "text": "generating data\n\n\nCode\nset.seed(666)\nfrog_n &lt;- 87\n\ndf &lt;- cbind(\n  # predictor variables\n  color = sample(x = c(\"blue\", \"green\", \"red\"), size = frog_n, replace = TRUE, prob = c(0.3, 0.3, 0.3)),\n  weight = (round(rnorm(n = frog_n, mean = 3, sd = 0.3), 2)),\n  pattern = sample(x = c(\"striped\", \"spotted\", \"none\"), size = frog_n, replace = TRUE, prob = c(0.3, 0.3, 0.3))\n) %&gt;% \n  as_tibble() %&gt;% \n  mutate(weight = as.numeric(weight),\n         color = as.factor(color),\n         pattern = as.factor(pattern)) %&gt;% \n  group_by(color, pattern) %&gt;% \n  # response variable\n  mutate(toxicity = case_when(\n    color == \"blue\" & pattern == \"striped\" ~ rnorm(n = length(color), mean = 5, sd = 1),\n    color == \"blue\" & pattern == \"spotted\" ~ rnorm(n = length(color), mean = 4, sd = 1),\n    color == \"green\" & pattern == \"striped\" ~ rnorm(n = length(color), mean = 4, sd = 1),\n    color == \"green\" & pattern == \"spotted\" ~ rnorm(n = length(color), mean = 3, sd = 1),\n    color == \"red\" ~ rnorm(n = length(color), mean = 6, sd = 1),\n    TRUE ~ rnorm(n = length(color), mean = 2, sd = 1)\n  )) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "lecture/lecture_week-08.html#plotting-data",
    "href": "lecture/lecture_week-08.html#plotting-data",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "plotting data",
    "text": "plotting data\n\n\nCode\nblue_col &lt;- \"cornflowerblue\"\ngreen_col &lt;- \"darkgreen\"\nred_col &lt;- \"maroon\"\n\nstriped_col &lt;- \"grey1\"\nspotted_col &lt;- \"grey50\"\nnone_col &lt;- \"grey80\"\n\nggplot(data = df, aes(x = color, y = toxicity, color = color, fill = color)) +\n  geom_jitter(width = 0.2, height = 0, alpha = 0.3) +\n  scale_color_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  scale_fill_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  stat_summary(geom = \"pointrange\", fun = mean, fun.min = function(x) mean(x) - sd(x), fun.max = function(x) mean(x) + sd(x), shape = 21, size = 1) +\n #  geom_point(position = position_jitter(width = 0.2, height = 0, seed = 666), alpha = 0.3) +\n  labs(title = \"Color\") +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        axis.title.x = element_blank(),\n        text = element_text(size = 22))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = df, aes(x = pattern, y = toxicity, shape = pattern)) +\n  geom_jitter(width = 0.2, height = 0, alpha = 0.3) +\n  # scale_color_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  # scale_fill_manual(values = c(\"striped\" = striped_col, \"spotted\" = spotted_col, \"none\" = none_col)) +\n  stat_summary(geom = \"pointrange\", fun = mean, fun.min = function(x) mean(x) - sd(x), fun.max = function(x) mean(x) + sd(x), size = 1) +\n  labs(title = \"Pattern\") +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        axis.title.x = element_blank(),\n        text = element_text(size = 22))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = df, aes(x = weight, y = toxicity)) +\n  geom_point() +\n  # geom_smooth(method = \"lm\") +\n  labs(title = \"Weight\") +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        axis.title.x = element_blank(),\n        text = element_text(size = 22))\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = df, aes(x = weight, y = toxicity, color = color)) +\n  geom_point() +\n  scale_color_manual(values = c(\"blue\" = blue_col, \"green\" = green_col, \"red\" = red_col)) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"Weight\")"
  },
  {
    "objectID": "lecture/lecture_week-08.html#model",
    "href": "lecture/lecture_week-08.html#model",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "model",
    "text": "model\n\n\nCode\nmodel &lt;- lm(toxicity ~ weight + color + pattern, data = df)\nsimulateResiduals(model, plot = TRUE)\n\n\n\n\n\n\n\n\n\nObject of Class DHARMa with simulated residuals based on 250 simulations with refit = FALSE . See ?DHARMa::simulateResiduals for help. \n \nScaled residual values: 0.208 0.608 0.196 0.468 0.744 0.792 0.908 0.792 0.992 0.256 0.324 0.768 0.468 0.32 0.204 0.908 0.288 0.76 0.156 0.104 ..."
  },
  {
    "objectID": "lecture/lecture_week-08.html#diagnostics",
    "href": "lecture/lecture_week-08.html#diagnostics",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "diagnostics",
    "text": "diagnostics\n\n\nCode\npar(mfrow = c(2, 2))\nplot(model)"
  },
  {
    "objectID": "lecture/lecture_week-08.html#model-summary",
    "href": "lecture/lecture_week-08.html#model-summary",
    "title": "Week 8 figures - Lectures 14 and 15",
    "section": "model summary",
    "text": "model summary\n\n\nCode\n# F-statistic: 31.05 on 5 and 81 DF,  p-value: &lt; 2.2e-16\n# total SSE - SSE of residuals divided by degrees of freedom\ntotalSSE &lt;- 6.932+140.09+21.63\ntotaldf &lt;- 1+2+2\nerrorSSE &lt;- 88\nmodel_fstat &lt;- (totalSSE/5)/(errorSSE/81) \nmodel_fstat\n\n\n[1] 31.0473\n\n\nCode\n# for a single coefficient\nweightMS &lt;- 6.932\nweightdf &lt;- 1\nerrorMS &lt;- 1.086\nfvalweight &lt;- (weightMS/weightdf)/errorMS\nfvalweight\n\n\n[1] 6.383057\n\n\nCode\ncolorMS &lt;- 70.045\ncolordf &lt;- 2\nfvalcolor &lt;- (colorMS/colordf)/errorMS\nfvalcolor\n\n\n[1] 32.24908\n\n\nCode\n# residual mean sq = 1.086 (denominator)\n# equation: t = 5.5 - 0.74*W - 0.97*green + 2.1*red + 0.85*spotted + 1.2*striped\n\n\n\n\nCode\nmodel_summary &lt;- summary(model)\n\nAnova(model)\n\n\nAnova Table (Type II tests)\n\nResponse: toxicity\n           Sum Sq Df F value    Pr(&gt;F)    \nweight      1.547  1  1.4194     0.237    \ncolor     119.288  2 54.7107 9.229e-16 ***\npattern    44.843  2 20.5669 5.981e-08 ***\nResiduals  88.304 81                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmodel.sel(model)\n\n\nModel selection table \n      (Intrc) color pttrn weght df   logLik  AICc delta\nmodel   4.045     +     +     1  7 -124.095 263.6     0\nModels ranked by AICc(x) \n\n\n\\[\n\\hat{y}_h \\pm t_{(1-\\alpha/2, n-2)}*\\sqrt{MSE*(\\frac{1}{n}+\\frac{(x_h-\\bar{x})^2}{\\sum(x_i-\\bar{x})^2})}\n\\]\n\\[\nMSE = \\frac{\\sum(y_i-\\hat{y})^2}{n}\n\\]\n\n\nCode\ntidy(model, conf.int = TRUE, conf.level = 0.95)\n\n\n# A tibble: 6 × 7\n  term           estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)       4.04      1.26       3.21 1.92e- 3    1.54      6.55 \n2 weight           -0.504     0.423     -1.19 2.37e- 1   -1.35      0.338\n3 colorgreen       -0.289     0.267     -1.08 2.82e- 1   -0.821     0.243\n4 colorred          2.59      0.290      8.91 1.17e-13    2.01      3.17 \n5 patternspotted    0.952     0.303      3.14 2.34e- 3    0.349     1.55 \n6 patternstriped    1.70      0.264      6.41 8.92e- 9    1.17      2.22 \n\n\n\n\nCode\nc(\"lower\" = model_summary$coef[2,1] - qt(0.975, df = model_summary$df[2]) * model_summary$coef[2, 2],\n  \"upper\" = model_summary$coef[2,1] + qt(0.975, df = model_summary$df[2]) * model_summary$coef[2, 2])\n\n\n     lower      upper \n-1.3451604  0.3375674 \n\n\nConfidence interval for a single coefficient: in words: estimate plus or minus the t-value at your confidence level * standard error"
  },
  {
    "objectID": "lecture/lecture_week-05.html",
    "href": "lecture/lecture_week-05.html",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\n\n# data\nlibrary(palmerpenguins)\n\n# analysis\nlibrary(car)\nlibrary(effectsize)"
  },
  {
    "objectID": "lecture/lecture_week-05.html#set-up",
    "href": "lecture/lecture_week-05.html#set-up",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\n\n# data\nlibrary(palmerpenguins)\n\n# analysis\nlibrary(car)\nlibrary(effectsize)"
  },
  {
    "objectID": "lecture/lecture_week-05.html#math",
    "href": "lecture/lecture_week-05.html#math",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "1. Math",
    "text": "1. Math\n\na. sum of squares\nAmong groups:\n\\[\n\\sum^k_{i = 1}\\sum^n_{j = 1}(\\bar{y_i} - \\bar{y})^2\n\\]\nwhere k is the number of groups, i is ith group, n is the number of observations per group, j is the jth observation. \\(\\bar{y_i}\\) is the mean of group i, while \\(\\bar{y}\\) is the grand mean (of all samples pooled together).\nWithin groups:\n\\[\n\\sum^k_{i = 1}\\sum^n_{j = 1}(y_{ij} - \\bar{y_i})^2\n\\]\nwhere \\(y_{ij}\\) is the jth observation in the ith group, and \\(\\bar{y_i}\\) is the mean of group i.\nTotal sum of squares:\n\\[\n\\sum^k_{i = 1}\\sum^n_{j = 1}(y_{ij} - \\bar{y})^2\n\\]\nwhere \\(y_{ij}\\) is the jth observation in the ith group, and \\(\\bar{y}\\) is the grand mean.\n\n\nb. mean squares\nAmong groups:\n\\[\n\\frac{SS_{among \\ group}}{k - 1}\n\\]\nWithin groups:\n\\[\n\\frac{SS_{within \\ group}}{n - k}\n\\]\n\n\nc. F-ratio/F-statistic\n\\[\n\\frac{MS_{among \\ group}}{MS_{within \\ group}}\n\\]\nPut another way, the F-ratio is the ratio of among group variance to within group variance. If the among group variance is larger than within group variance, the F-ratio is large, and therefore the probability of among group variance being equal to within group variance is small. Thus, you would reject the null hypothesis if the F-ratio is large.\n\n\nd. η squared\n\\[\n\\eta^2 = \\frac{SS_{among \\ group}}{SS_{among \\ group} + SS_{within \\ group}}\n\\] ### e. U statistic \\[\n\\begin{align}\nU_1 &= \\Sigma R_1 - n_1(n_1 + 1)/2 = 17 - 5(5+1)/2 = 2 \\\\\nU_2 &= \\Sigma R_2 - n_2(n_2 + 1)/2 = 38 - 5(5+1)/2 = 23\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-05.html#warm-up-code-for-a-figure",
    "href": "lecture/lecture_week-05.html#warm-up-code-for-a-figure",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "2. Warm up: code for a figure",
    "text": "2. Warm up: code for a figure\n\n\nCode\n# random sample of 10 rows from data frame\nsample_n(chickwts, 10) %&gt;% \n  arrange(feed)\n\n\n   weight      feed\n1     318    casein\n2     217 horsebean\n3     140 horsebean\n4     141   linseed\n5     257   linseed\n6     206  meatmeal\n7     316   soybean\n8     327   soybean\n9     318 sunflower\n10    339 sunflower\n\n\nCode\nggplot(data = chickwts,           # data frame: chickwts\n       aes(x = feed,              # x-axis: feed type\n           y = weight,            # y-axis: chick weight\n           fill = feed)) +        # fill by feed type  \n  geom_boxplot() +                # creates a boxplot\n  geom_jitter(height = 0,         # prevents jitter from moving points along y-axis\n              width = 0.2) +      # narrows spread of jitter along x-axis\n  theme(legend.position = \"none\") # removes legend"
  },
  {
    "objectID": "lecture/lecture_week-05.html#analysis-of-variance",
    "href": "lecture/lecture_week-05.html#analysis-of-variance",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "3. Analysis of variance",
    "text": "3. Analysis of variance\nCentral question: How does bill length differ between penguin species?\n\na. Exploratory data visualization\n\n\nCode\npenguins_jitter &lt;- ggplot(data = penguins,\n                          aes(x = species,\n                              y = bill_length_mm,\n                              color = species)) +\n  geom_jitter(width = 0.2,\n              height = 0,\n              shape = 21) +\n  scale_color_manual(values = c(\"#209c90\", \"#018ca9\", \"#27c839\")) +\n  labs(x = \"Species\",\n       y = \"Bill length (mm)\") +\n  theme(legend.position = \"none\")\n\npenguins_jitter\n\n\n\n\n\n\n\n\n\n\n\nb. histogram and qq plots\n\n\nCode\nhist &lt;- ggplot(data = penguins,\n       aes(x = bill_length_mm,\n           fill = species)) +\n  geom_histogram(bins = 14,\n                 color = \"black\") +\n  scale_fill_manual(values = c(\"#209c90\", \"#018ca9\", \"#27c839\")) +\n  scale_y_continuous(expand = c(0, 0)) +\n  facet_wrap(~ species, scales = \"free\", ncol = 1) +\n  labs(x = \"Bill length (mm)\",\n       y = \"Count\") +\n  theme(legend.position = \"none\",\n        strip.background = element_rect(color = \"white\"),\n        strip.text = element_text(size = 20))\n\nqq &lt;- ggplot(data = penguins,\n       aes(sample = bill_length_mm)) +\n  geom_qq_line() +\n  geom_qq(aes(color = species)) +\n  scale_color_manual(values = c(\"#209c90\", \"#018ca9\", \"#27c839\")) +\n  facet_wrap(~ species, scales = \"free\", ncol = 1) +\n  labs(x = \"Theoretical quantile\",\n       y = \"Value\") +\n  theme(legend.position = \"none\",\n        strip.background = element_rect(color = \"white\"),\n        strip.text = element_text(size = 20))\n\nhist + qq\n\n\n\n\n\n\n\n\n\n\n\nc. Shapiro-Wilk normality test\nGeneral: Is the response variable normally distributed?\nExample: Is bill length normally distributed?\n\n\nCode\n# first, wrangle\nadelie &lt;- penguins %&gt;% \n  filter(species == \"Adelie\") %&gt;% \n  pull(bill_length_mm)\n\nchinstrap &lt;- penguins %&gt;% \n  filter(species == \"Chinstrap\") %&gt;% \n  pull(bill_length_mm)\n\ngentoo &lt;- penguins %&gt;% \n  filter(species == \"Gentoo\") %&gt;% \n  pull(bill_length_mm)\n\n# then, do the shapiro-wilk test\nshapiro.test(adelie)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  adelie\nW = 0.99336, p-value = 0.7166\n\n\nCode\nshapiro.test(chinstrap)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  chinstrap\nW = 0.97525, p-value = 0.1941\n\n\nCode\nshapiro.test(gentoo)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  gentoo\nW = 0.97272, p-value = 0.01349\n\n\n\n\nd. Levene test of variances\nGeneral: Are the group variances equal?\nExample: Are the species variances equal?\n\n\nCode\nleveneTest(bill_length_mm ~ species,\n           data = penguins)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)\ngroup   2  2.2425 0.1078\n      339               \n\n\n\n\ne. analysis of variance\n\n\nCode\n# do the actual test\n# model object stored as `penguins_anova`\npenguins_anova &lt;- aov(bill_length_mm ~ species,\n                      data = penguins)\n\n# output of the test\npenguins_anova\n\n\nCall:\n   aov(formula = bill_length_mm ~ species, data = penguins)\n\nTerms:\n                 species Residuals\nSum of Squares  7194.317  2969.888\nDeg. of Freedom        2       339\n\nResidual standard error: 2.959853\nEstimated effects may be unbalanced\n2 observations deleted due to missingness\n\n\nCode\n# more information\nsummary(penguins_anova)\n\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nspecies       2   7194    3597   410.6 &lt;2e-16 ***\nResiduals   339   2970       9                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2 observations deleted due to missingness\n\n\n\n\nf. post hoc test\nWhich group comparisons are different?\n\n\nCode\nTukeyHSD(penguins_anova)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = bill_length_mm ~ species, data = penguins)\n\n$species\n                      diff       lwr        upr     p adj\nChinstrap-Adelie 10.042433  9.024859 11.0600064 0.0000000\nGentoo-Adelie     8.713487  7.867194  9.5597807 0.0000000\nGentoo-Chinstrap -1.328945 -2.381868 -0.2760231 0.0088993\n\n\n\n\ng. effect size\n\n\nCode\neta_squared(penguins_anova)\n\n\n# Effect Size for ANOVA\n\nParameter | Eta2 |       95% CI\n-------------------------------\nspecies   | 0.71 | [0.67, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\n\n\nh. example of writing\nWithout the stats: Our results suggest a difference in bill length between species, with a large effect of species. Species differed in bill length, and pairwise comparisons between species showed that all three species differed from each other. Generally, Adelie penguins tend to have shorter bills than Chinstrap and Gentoo penguins. Gentoo penguins tend to have shorter bills than Chinstrap penguins.\nWith the stats: Our results suggest a difference in bill length between species, with a large (\\(\\eta^2\\) = 0.71) effect of species. Species differed in bill length (one-way ANOVA, F(2, 339) = 410.6, p &lt; 0.001, \\(\\alpha\\) = 0.05), and pairwise comparisons between species showed that all three species differed from each other. Generally, Adelie penguins tend to have 10.0 mm shorter bills than Chinstrap (Tukey HSD, p &lt; 0.001, 95% confidence interval: [9.0, 11.1] mm) penguins and 8.7 mm shorter than Gentoo (Tukey HSD, p &lt; 0.001, 95% confidence interval: [7.9, 9.6] mm) penguins. Gentoo penguins tend to have 1.3 mm shorter bills than Chinstrap penguins (Tukey HSD, p = 0.008, 95% confidence interval: [0.3, 2.4] mm).\n\n\ni. a “finalized” figure\n\n\nCode\nggplot(data = penguins,\n       aes(x = species,\n           y = bill_length_mm,\n           color = species)) +\n  geom_jitter(width = 0.2,\n              height = 0,\n              shape = 21,\n              alpha = 0.4) +\n  stat_summary(geom = \"pointrange\",\n               fun.data = mean_cl_normal,\n               size = 0.8,\n               linewidth = 1) +\n  scale_color_manual(values = c(\"#209c90\", \"#018ca9\", \"#27c839\")) +\n  labs(x = \"Species\",\n       y = \"Bill length (mm)\") +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "lecture/lecture_week-05.html#non-parametric-tests",
    "href": "lecture/lecture_week-05.html#non-parametric-tests",
    "title": "Week 5 figures - Lectures 9 and 10",
    "section": "4. Non parametric tests",
    "text": "4. Non parametric tests\n\na. Mann-Whitney U\n\n\nCode\nwilcox_df &lt;- cbind(Sample1 = c(1.1, 2.4, 1.8, 0.4, 1.6), \n                   Sample2 = c(5.4, 3.1, 2.3, 1.9, 4.2)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = Sample1:Sample2) %&gt;% \n  rename(sample = name) %&gt;% \n  arrange(sample)\n\nwilcox_df\n\n\n# A tibble: 10 × 2\n   sample  value\n   &lt;chr&gt;   &lt;dbl&gt;\n 1 Sample1   1.1\n 2 Sample1   2.4\n 3 Sample1   1.8\n 4 Sample1   0.4\n 5 Sample1   1.6\n 6 Sample2   5.4\n 7 Sample2   3.1\n 8 Sample2   2.3\n 9 Sample2   1.9\n10 Sample2   4.2\n\n\nCode\nwilcox.test(value ~ sample,\n            data = wilcox_df)\n\n\n\n    Wilcoxon rank sum exact test\n\ndata:  value by sample\nW = 2, p-value = 0.03175\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nb. Wilcoxon signed-rank\n\n\nCode\n# for a comparison of one group against a theoretical median\nwilcox.test(Sample1, mu = theoretical)\n\n# for a comparison of two groups\nwilcox.test(value ~ sample,\n            data = wilcox_df, \n            paired = TRUE)\n\n\n\n\nc. Kruskal-Wallis\n\n\nCode\nkruskal_df &lt;- cbind(Sample1 = round(rnorm(n = 5, mean = 4, sd = 1), 1), \n                    Sample2 = round(rnorm(n = 5, mean = 6, sd = 1), 1),\n                    Sample3 = round(rnorm(n = 5, mean = 8, sd = 1), 1)) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = Sample1:Sample3) %&gt;% \n  rename(sample = name) %&gt;% \n  arrange(sample)\n\nrank_by_hand &lt;- kruskal_df %&gt;% \n  arrange(value) %&gt;% \n  rownames_to_column(\"ranks\") %&gt;% \n  mutate(ranks = as.numeric(ranks)) %&gt;% \n  group_by(sample) %&gt;% \n  reframe(sum_ranks = sum(ranks))\n\nR1 &lt;- rank_by_hand[1, 2]\nR2 &lt;- rank_by_hand[2, 2]\nR3 &lt;- rank_by_hand[3, 2]\nn &lt;- 15\nn1 &lt;- 5\nn2 &lt;- 5\nn3 &lt;- 5\n\nrstatix::kruskal_test(value ~ sample,\n             data = kruskal_df)\n\n\n# A tibble: 1 × 6\n  .y.       n statistic    df      p method        \n* &lt;chr&gt; &lt;int&gt;     &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;         \n1 value    15      12.1     2 0.0024 Kruskal-Wallis\n\n\nCode\nkruskal.test(value ~ sample,\n             data = kruskal_df)\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  value by sample\nKruskal-Wallis chi-squared = 12.063, df = 2, p-value = 0.002402\n\n\nCode\n#((12 * STATISTIC / (n * (n + 1)) - 3 * (n + 1)) / (1 - sum(TIES^3 - TIES) / (n^3 - n)))\n\n(12/(n*(n+1)))*((R1^2)/n1 + (R2^2)/n2 + (R3^2)/n3) - 3*(n + 1)\n\n\n  sum_ranks\n1     12.02\n\n\nCode\nrstatix::kruskal_effsize(value ~ sample,\n                         data = kruskal_df)\n\n\n# A tibble: 1 × 5\n  .y.       n effsize method  magnitude\n* &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;ord&gt;    \n1 value    15   0.839 eta2[H] large    \n\n\nCode\nrstatix::dunn_test(value ~ sample,\n                         data = kruskal_df)\n\n\n# A tibble: 3 × 9\n  .y.   group1  group2     n1    n2 statistic        p   p.adj p.adj.signif\n* &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1 value Sample1 Sample2     5     5      1.84 0.0655   0.131   ns          \n2 value Sample1 Sample3     5     5      3.47 0.000518 0.00156 **          \n3 value Sample2 Sample3     5     5      1.63 0.103    0.131   ns"
  },
  {
    "objectID": "lecture/lecture_week-10.html",
    "href": "lecture/lecture_week-10.html",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(flextable)\nlibrary(GGally)\nlibrary(equatiomatic)\n\n# data\nlibrary(palmerpenguins)\n\n# analysis\nlibrary(car)\nlibrary(performance)\nlibrary(broom)\nlibrary(DHARMa)\nlibrary(MuMIn)\nlibrary(lmtest)"
  },
  {
    "objectID": "lecture/lecture_week-10.html#simple-linear-regression",
    "href": "lecture/lecture_week-10.html#simple-linear-regression",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "simple linear regression",
    "text": "simple linear regression\n\\[\nE[y_i] = a + bx_i\n\\]\n\\[\nvar[y_i] = s^2\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#generalized-form",
    "href": "lecture/lecture_week-10.html#generalized-form",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "generalized form:",
    "text": "generalized form:\n\\[\nE[y_i] = a + bx_i\n\\]\n\\[\nvar[y_i] = v(E[y_i])\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#random-component",
    "href": "lecture/lecture_week-10.html#random-component",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "random component",
    "text": "random component\n\\[\nY_i \\sim N(\\mu_i, \\sigma^2)\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#systematic-component",
    "href": "lecture/lecture_week-10.html#systematic-component",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "systematic component",
    "text": "systematic component\n\\[\n\\eta_i = \\sum^{p-1}_{n = 0}\\beta_jx_{ij}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-10.html#link",
    "href": "lecture/lecture_week-10.html#link",
    "title": "Week 10 figures - Lectures 17 and 18",
    "section": "link",
    "text": "link\n\\[\ng(\\mu_i) = \\eta_i\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-07.html",
    "href": "lecture/lecture_week-07.html",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(flextable)\nlibrary(modelsummary)\nlibrary(gtsummary)\n\n# analysis\nlibrary(car)\nlibrary(performance)\nlibrary(broom)"
  },
  {
    "objectID": "lecture/lecture_week-07.html#set-up",
    "href": "lecture/lecture_week-07.html#set-up",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "",
    "text": "Code\n# cleaning\nlibrary(tidyverse)\n\n# visualization\ntheme_set(theme_classic() +\n            theme(panel.grid = element_blank(),\n                  axis.text = element_text(size = 18),\n                  axis.title = element_text(size = 18),\n                  text = element_text(family = \"Lato\")))\nlibrary(patchwork)\nlibrary(ggeffects)\nlibrary(flextable)\nlibrary(modelsummary)\nlibrary(gtsummary)\n\n# analysis\nlibrary(car)\nlibrary(performance)\nlibrary(broom)"
  },
  {
    "objectID": "lecture/lecture_week-07.html#math",
    "href": "lecture/lecture_week-07.html#math",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "1. Math",
    "text": "1. Math\n\na. Residuals\nResiduals are the difference between the actual observed value (\\(y_i\\)) and the model prediction (\\(\\hat{y}\\)) at some value of \\(x\\).\n\\[\nresidual = y_i - \\hat{y}\n\\]\nOrdinary least squares minimizes the sum of squares of the residuals.\n\n\nb. Model equations\nOLS gives you an equation for a line.\n$$ \\[\\begin{align}\ny &= b + mx \\\\\n\ny &= \\beta_0 + \\beta_1x + \\epsilon \\\\\n\n\\end{align}\\] $$ \\(\\beta\\) terms (“betas”) are often referred to as “model coefficients”.\n\n\nc. Mathematical hypothesis\nStatistically, the hypotheses are:\nH_0_: the predictor variable does not predict the response\nH_A_: the predictor variable does predict the response\nMathematically, you might express that as:\n\\[\nH_0: \\beta_1 = 0  \\\\\nH_A: \\beta_1 \\neq 0\n\\]\n\n\nd. R2\n\\[\n\\begin{align}\nR^2 &= 1 - \\frac{\\sum_{i = 1}^{n}(y_i - \\hat{y})^2}{\\sum_{i = 1}^{n}(y_i - \\bar{y})^2} \\\\\n&= 1 - \\frac{SS_{residuals}}{SS_{total}}\n\\end{align}\n\\]\n\n\ne. Pearson’s correlation"
  },
  {
    "objectID": "lecture/lecture_week-07.html#formula-for-pearsons-correlation",
    "href": "lecture/lecture_week-07.html#formula-for-pearsons-correlation",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "formula for Pearson’s correlation",
    "text": "formula for Pearson’s correlation\n\\[\nr = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum(x_i-\\bar{x})^2}\\sqrt{\\sum(y_i - \\bar{y})^2}}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-07.html#test-statistic-for-pearson-correlation",
    "href": "lecture/lecture_week-07.html#test-statistic-for-pearson-correlation",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "test statistic for pearson correlation",
    "text": "test statistic for pearson correlation\n\\[\n\\begin{align}\nt &= \\frac{r\\sqrt{n - 2}}{\\sqrt{1-r^2}} \\\\\ndf &= n -2\n\\end{align}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-07.html#r2",
    "href": "lecture/lecture_week-07.html#r2",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "2. R2",
    "text": "2. R2\n\n\nCode\ndf &lt;- tibble(\n  x = seq(from = 1, to = 20, by = 1),\n  r2_1 = 3*x + 1,\n  r2_between = runif(n = 20, min = 1, max = 5)*x + runif(n = 20, min = 1, max = 5),\n  r2_0 = runif(n = 20, min = 1, max = 20)\n)\n\nlm(r2_1 ~ x, data = df) %&gt;% \n  summary()\n\n\n\nCall:\nlm(formula = r2_1 ~ x, data = df)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-3.676e-15 -1.312e-15 -5.240e-17  8.432e-16  7.220e-15 \n\nCoefficients:\n             Estimate Std. Error   t value Pr(&gt;|t|)    \n(Intercept) 1.000e+00  1.142e-15 8.757e+14   &lt;2e-16 ***\nx           3.000e+00  9.532e-17 3.147e+16   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.458e-15 on 18 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 9.905e+32 on 1 and 18 DF,  p-value: &lt; 2.2e-16\n\n\nCode\nggplot(df,\n       aes(x = x,\n           y = r2_1)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\nCode\nlm(r2_between ~ x, data = df) %&gt;% \n  summary()\n\n\n\nCall:\nlm(formula = r2_between ~ x, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.9586  -8.2880  -0.1051   5.7411  24.7204 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    1.755      6.325   0.277    0.785    \nx              2.664      0.528   5.046 8.41e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.62 on 18 degrees of freedom\nMultiple R-squared:  0.5858,    Adjusted R-squared:  0.5628 \nF-statistic: 25.46 on 1 and 18 DF,  p-value: 8.414e-05\n\n\nCode\nggplot(df,\n       aes(x = x,\n           y = r2_between)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\",\n              se = FALSE)\n\n\n\n\n\n\n\n\n\nCode\nlm(r2_0 ~ x, data = df) %&gt;% \n  summary()\n\n\n\nCall:\nlm(formula = r2_0 ~ x, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.4344 -3.7276 -0.4751  4.3101  7.6648 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)   5.5938     2.1571   2.593   0.0184 *\nx             0.4075     0.1801   2.263   0.0362 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.644 on 18 degrees of freedom\nMultiple R-squared:  0.2215,    Adjusted R-squared:  0.1782 \nF-statistic: 5.121 on 1 and 18 DF,  p-value: 0.03624\n\n\nCode\nggplot(df,\n       aes(x = x,\n           y = r2_0)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\",\n              se = FALSE)"
  },
  {
    "objectID": "lecture/lecture_week-07.html#white-abalone-example",
    "href": "lecture/lecture_week-07.html#white-abalone-example",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "3. White abalone example",
    "text": "3. White abalone example\nYou’re working on white abalone conservation and you’re concerned about warming temperatures on abalone growth.\nYou keep abalone in tanks at different temperatures that range from cold (10 °C) to warm (18 °C) for 4 weeks. You measure growth as the difference in mass between the beginning to the end of your experiment.\nHow does water temperature affect abalone growth?\n\na. generating the data\n\n\nCode\nset.seed(666)\nabalone &lt;- tibble(\n  temperature = seq(from = 10, to = 18, by = 1),\n  growth1 = runif(length(temperature), min = -0.7, max = -0.63)*temperature + runif(length(temperature), min = 15, max = 17),\n  growth2 = runif(length(temperature), min = -0.7, max = -0.63)*temperature + runif(length(temperature), min = 15, max = 17),\n  growth3 = runif(length(temperature), min = -0.7, max = -0.63)*temperature + runif(length(temperature), min = 15, max = 17)\n) %&gt;% \n  pivot_longer(cols = growth1:growth3,\n               names_to = \"rep\",\n               values_to = \"growth\") %&gt;% \n  mutate(growth = round(growth, digits = 1)) %&gt;% \n  select(temperature, growth)\n\n# look at your data:\nhead(abalone, 10)\n\n\n# A tibble: 10 × 2\n   temperature growth\n         &lt;dbl&gt;  &lt;dbl&gt;\n 1          10    9.1\n 2          10    9.6\n 3          10    9.7\n 4          11    9  \n 5          11    8.8\n 6          11    8.8\n 7          12    7.5\n 8          12    9.1\n 9          12    8.5\n10          13    6.3\n\n\nCode\nggplot(data = abalone,\n       aes(x = temperature,\n           y = growth)) +\n  geom_point() \n\n\n\n\n\n\n\n\n\nSeems like there is a linear relationship between temperature and abalone growth. As temperature increases, abalone growth decreases.\n\n\nb. fitting a model\n\n\nCode\nabalone_model &lt;- lm(growth ~ temperature,\n                    data = abalone)\n\n# just checking DHARMa residuals just in case\nDHARMa::simulateResiduals(abalone_model, plot = TRUE)\n\n\n\n\n\n\n\n\n\nObject of Class DHARMa with simulated residuals based on 250 simulations with refit = FALSE . See ?DHARMa::simulateResiduals for help. \n \nScaled residual values: 0.328 0.604 0.656 0.62 0.548 0.472 0.228 0.976 0.716 0.052 0.496 0.528 0.128 0.132 0.92 0.352 0.684 0.152 0.98 0.764 ...\n\n\nCode\n# base R residuals\npar(mfrow = c(2, 2))\nplot(abalone_model)\n\n\n\n\n\n\n\n\n\n\n\nc. looking at model coefficients\n\n\nCode\nsummary(abalone_model)\n\n\n\nCall:\nlm(formula = growth ~ temperature, data = abalone)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.15370 -0.50093  0.06019  0.34491  1.24630 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 16.40926    0.69633   23.57  &lt; 2e-16 ***\ntemperature -0.69722    0.04891  -14.25 1.65e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6562 on 25 degrees of freedom\nMultiple R-squared:  0.8904,    Adjusted R-squared:  0.8861 \nF-statistic: 203.2 on 1 and 25 DF,  p-value: 1.65e-13\n\n\nCode\n# common way of representing model summaries\n# from flextable package\nflextable::as_flextable(abalone_model)\n\n\nEstimateStandard Errort valuePr(&gt;|t|)(Intercept)16.4090.69623.5650.0000***temperature-0.6970.049-14.2540.0000***Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05Residual standard error: 0.6562 on 25 degrees of freedomMultiple R-squared: 0.8904, Adjusted R-squared: 0.8861F-statistic: 203.2 on 25 and 1 DF, p-value: 0.0000\n\n\nCode\n# better table\nflextable::as_flextable(abalone_model) %&gt;% \n  set_formatter(values = list(\"p.value\" = function(x){ # special function to represent p &lt; 0.001\n    z &lt;- scales::label_pvalue()(x)\n    z[!is.finite(x)] &lt;- \"\"\n    z\n  }))\n\n\nEstimateStandard Errort valuePr(&gt;|t|)(Intercept)16.4090.69623.565&lt;0.001***temperature-0.6970.049-14.254&lt;0.001***Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05Residual standard error: 0.6562 on 25 degrees of freedomMultiple R-squared: 0.8904, Adjusted R-squared: 0.8861F-statistic: 203.2 on 25 and 1 DF, p-value: 0.0000\n\n\nCode\n# somewhat more customizable way\n# from modelsummary package\nmodelsummary(abalone_model)\n\n\n \n\n  \n    \n    \n    tinytable_2gyxaqhn45q40otzoh59\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  16.409 \n                \n                \n                             \n                  (0.696)\n                \n                \n                  temperature\n                  -0.697 \n                \n                \n                             \n                  (0.049)\n                \n                \n                  Num.Obs.   \n                  27     \n                \n                \n                  R2         \n                  0.890  \n                \n                \n                  R2 Adj.    \n                  0.886  \n                \n                \n                  AIC        \n                  57.8   \n                \n                \n                  BIC        \n                  61.7   \n                \n                \n                  Log.Lik.   \n                  -25.899\n                \n                \n                  F          \n                  203.189\n                \n                \n                  RMSE       \n                  0.63   \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nCode\n# better table\nmodelsummary(list(\"Abalone model\" = abalone_model), # naming the model\n             fmt = 2, # rounding digits to 2 decimal places\n             estimate = \"{estimate} [{conf.low}, {conf.high}] ({p.value})\", # customizing appearance\n             statistic = NULL, # not displaying standard error\n             gof_omit = 'DF|AIC|BIC|Log.Lik.|RMSE') # taking out some extraneous info\n\n\n \n\n  \n    \n    \n    tinytable_rj8md2mmzid7f92ng9fw\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                Abalone model\n              \n        \n        \n        \n                \n                  (Intercept)\n                  16.41 [14.98, 17.84] (&lt;0.01)\n                \n                \n                  temperature\n                  -0.70 [-0.80, -0.60] (&lt;0.01)\n                \n                \n                  Num.Obs.   \n                  27                          \n                \n                \n                  R2         \n                  0.890                       \n                \n                \n                  R2 Adj.    \n                  0.886                       \n                \n                \n                  F          \n                  203.189                     \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nCode\n# using gtsummary package\ntbl_regression(abalone_model,\n               intercept = TRUE)\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n16\n15, 18\n&lt;0.001\n\n\ntemperature\n-0.70\n-0.80, -0.60\n&lt;0.001\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\n\nCode\n# more customizing\ntbl_regression(abalone_model, # model object\n               intercept = TRUE) %&gt;% # show the intercept\n  as_flex_table() # turn it into a flextable (easier to save)\n\n\nCharacteristicBeta95% CI1p-value(Intercept)1615, 18&lt;0.001temperature-0.70-0.80, -0.60&lt;0.0011CI = Confidence Interval\n\n\n\n\nCode\nanova(abalone_model)\n\n\nAnalysis of Variance Table\n\nResponse: growth\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntemperature  1 87.501  87.501  203.19 1.65e-13 ***\nResiduals   25 10.766   0.431                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nd. visualizing the model\n\n\nCode\nmodel_preds &lt;- ggpredict(abalone_model,\n                         terms = \"temperature\")\n\n# look at the output:\nmodel_preds\n\n\n# Predicted values of growth\n\ntemperature | Predicted |     95% CI\n------------------------------------\n         10 |      9.44 | 8.96, 9.92\n         11 |      8.74 | 8.34, 9.14\n         12 |      8.04 | 7.71, 8.37\n         13 |      7.35 | 7.07, 7.62\n         14 |      6.65 | 6.39, 6.91\n         15 |      5.95 | 5.67, 6.23\n         16 |      5.25 | 4.92, 5.58\n         18 |      3.86 | 3.38, 4.34\n\n\nCode\n# plotting without 95% CI\nggplot(abalone, # using the actual data\n       aes(x = temperature, # x-axis\n           y = growth)) + # y-axis\n  geom_point(color = \"cornflowerblue\", # each point is an individual abalone\n             size = 3) +\n  \n  # model prediction: actual model line\n  geom_line(data = model_preds, # model prediction table\n            aes(x = x, # x-axis\n                y = predicted), # y-axis\n            linewidth = 1) # line width\n\n\n\n\n\n\n\n\n\nCode\n# plotting\nggplot(abalone, # using the actual data\n       aes(x = temperature, # x-axis\n           y = growth)) + # y-axis\n  \n  # plot the data first\n  # each point is an individual abalone\n  geom_point(color = \"cornflowerblue\",\n             size = 3) + \n  \n  # model prediction: 95% CI\n  geom_ribbon(data = model_preds, # model prediction table\n              aes(x = x, # x-axis\n                  y = predicted, # y-axis\n                  ymin = conf.low, # lower bound of 95% CI\n                  ymax = conf.high), # upper bound of 95% CI\n              alpha = 0.2) + # transparency) \n  \n  # model prediction: actual model line\n  geom_line(data = model_preds, # model prediction table\n            aes(x = x, # x-axis\n                y = predicted), # y-axis\n            linewidth = 1) # line width\n\n\n\n\n\n\n\n\n\nCode\n# compare with:\nggplot(abalone,\n       aes(x = temperature,\n           y = growth)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\n\n\ne. outliers\n\n\nCode\nabalone %&gt;% \n  mutate(outlier = ifelse(row_number() %in% c(19, 21, 27), \"yes\", \"no\")) %&gt;% \n  ggplot(aes(x = temperature,\n             y = growth)) +\n  geom_point(aes(color = outlier), \n             size = 3) + \n  geom_line(data = model_preds,\n            aes(x = x,\n                y = predicted),\n            linewidth = 1) +\n  scale_color_manual(values = c(\"yes\" = \"red\", \"no\" = \"cornflowerblue\")) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nCode\n# new abalone data frame\nabalone2 &lt;- abalone %&gt;% \n  slice(-c(19, 21, 27))\n\nabalone_model2 &lt;- lm(growth ~ temperature,\n                    data = abalone2)\n\nsummary(abalone_model2)\n\n\n\nCall:\nlm(formula = growth ~ temperature, data = abalone2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.01641 -0.44359  0.08359  0.34163  1.05272 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 16.81772    0.60270   27.90  &lt; 2e-16 ***\ntemperature -0.73087    0.04336  -16.85 4.61e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.537 on 22 degrees of freedom\nMultiple R-squared:  0.9281,    Adjusted R-squared:  0.9249 \nF-statistic: 284.1 on 1 and 22 DF,  p-value: 4.606e-14\n\n\nCode\nmodel_preds2 &lt;- ggpredict(abalone_model2, terms = \"temperature\")\n\nggplot(data = abalone2,\n       aes(x = temperature,\n           y = growth)) +\n  geom_point(color = \"cornflowerblue\",\n             size = 3) +\n  geom_line(data = model_preds2,\n            aes(x = x,\n                y = predicted), \n            linewidth = 1)"
  },
  {
    "objectID": "lecture/lecture_week-07.html#exponential-growth-example",
    "href": "lecture/lecture_week-07.html#exponential-growth-example",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "4. Exponential growth example",
    "text": "4. Exponential growth example\nTo compare with abalone example\n\n\nCode\ndf_ex &lt;- tibble(\n  x = seq(from = 10, to = 18, length = 27),\n  y = c(15, 15, 15, \n        15, 14.3, 14.2, \n        14.1, 14, 13.9,\n        13.9, 13.8, 13.7,\n        13.2, 13.1, 13,\n        12.5, 11.1, 10,\n        9.9, 7, 5,\n        3, 1.7, 1,\n        0.5, 0.3, 0.1)\n) \n\nlm_ex &lt;- lm(y ~ x, data = df_ex)\n\nsummary(lm_ex)\n\n\n\nCall:\nlm(formula = y ~ x, data = df_ex)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.2540 -2.0605 -0.4009  2.3533  3.6288 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  38.5833     2.6772   14.41 1.29e-13 ***\nx            -2.0329     0.1885  -10.79 6.82e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.347 on 25 degrees of freedom\nMultiple R-squared:  0.8231,    Adjusted R-squared:  0.816 \nF-statistic: 116.3 on 1 and 25 DF,  p-value: 6.823e-11\n\n\nCode\nggplot(data = df_ex,\n       aes(x = x,\n           y = y)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nCode\nlm_pred &lt;- ggpredict(lm_ex, terms = ~x)\n\nex_plot_noline &lt;- ggplot(df_ex, aes(x= x, y = y)) +\n  geom_point(size = 3, color = \"orange\") +\n  theme_classic() +\n  theme(text = element_text(size = 14))\n\nex_plot_noline\n\n\n\n\n\n\n\n\n\nCode\nex_plot &lt;- ggplot(df_ex, aes(x= x, y = y)) +\n  geom_point(size = 3, color = \"orange\") +\n  geom_line(data = lm_pred, aes(x = x, y = predicted), linewidth = 1) +\n  theme(text = element_text(size = 14))\n\nex_plot\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(2, 2))\nplot(lm_ex)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# if using quarto, don't label chunk with a table... so weird\nanova_tbl &lt;- broom::tidy(anova(model1)) %&gt;% \n  mutate(across(where(is.numeric), ~ round(.x, digits = 2))) %&gt;% \n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\"\n  )) \n\nflextable(anova_tbl) %&gt;% \n  set_header_labels(term = \"Term\", \n                    df = \"Degrees of freedom\", \n                    sumsq = \"Sum of squares\", \n                    meansq = \"Mean squares\", \n                    statistic = \"F-statistic\", \n                    p.value = \"p-value\") %&gt;% \n  set_table_properties(layout = \"autofit\", width = 0.8)"
  },
  {
    "objectID": "lecture/lecture_week-07.html#model-summary",
    "href": "lecture/lecture_week-07.html#model-summary",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "model summary",
    "text": "model summary\n\n\nCode\nsummary(lm_ex)\n\n\n\nCall:\nlm(formula = y ~ x, data = df_ex)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2756.1  -660.5   226.3   843.2  1081.0 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   9431.3     1111.3   8.486 3.16e-09 ***\nx            -1642.0      156.5 -10.492 3.30e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1023 on 28 degrees of freedom\nMultiple R-squared:  0.7972,    Adjusted R-squared:   0.79 \nF-statistic: 110.1 on 1 and 28 DF,  p-value: 3.298e-11"
  },
  {
    "objectID": "lecture/lecture_week-07.html#model-plots",
    "href": "lecture/lecture_week-07.html#model-plots",
    "title": "Week 7 figures - Lectures 12 and 13",
    "section": "model plots",
    "text": "model plots\n\n\nCode\nlm_pred &lt;- ggpredict(lm_ex, terms = ~x)\n\nex_plot_noline &lt;- ggplot(df_ex, aes(x= x, y = y)) +\n  geom_point(shape = 17, size = 3, color = \"orange\") +\n  theme_classic() +\n  theme(text = element_text(size = 14))\n\nex_plot &lt;- ggplot(df_ex, aes(x= x, y = y)) +\n  geom_point(shape = 17, size = 3, color = \"orange\") +\n  geom_line(data = lm_pred, aes(x = x, y = predicted), linewidth = 1) +\n  theme_classic() +\n  theme(text = element_text(size = 14))"
  },
  {
    "objectID": "lecture/lecture_week-02.html#math",
    "href": "lecture/lecture_week-02.html#math",
    "title": "Week 2 figures - Lectures 3 and 4",
    "section": "1. Math",
    "text": "1. Math\n\na. standard error\n\\[\nstandard \\: error = SE_{\\bar{y}} = \\frac{s}{\\sqrt{n}}\n\\]\n\n\nb. confidence interval\n\\[\n\\begin{align}\nCI = estimate \\: &\\pm \\: margin \\: of \\: error \\\\\nCI = \\bar{y} \\: &\\pm \\: t_{\\alpha(2), df} \\times \\frac{s}{\\sqrt{n}} \\\\\nCI = \\bar{y} \\: &\\pm \\: z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\n\\end{align}\n\\]\n\n\nc. t-statistic\n\\[\nt_{\\alpha(2), df}\n\\]\n\\[\nt_{0.05(2), 19}\n\\]\n\n\nd. z-score\n\\[\nz = \\frac{\\bar{y} - \\mu}{\\sigma - \\sqrt{n}}\n\\]"
  },
  {
    "objectID": "lecture/lecture_week-02.html#confidence-intervals",
    "href": "lecture/lecture_week-02.html#confidence-intervals",
    "title": "Week 2 figures - Lectures 3 and 4",
    "section": "2. confidence intervals",
    "text": "2. confidence intervals\nThis is the leaf example from lecture.\n\nrandom number generation\nThis generates the “population”: 10000 trees.\n\n\nCode\nset.seed(7)\nleaf_pop &lt;- rnorm(n = 10000, mean = 4.92, sd = 0.5)\nleaves &lt;- sample(leaf_pop, size = 20, replace = FALSE)\n\n\n\n\npopulation histogram\n\n\nCode\n# population histogram\nenframe(leaf_pop) %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(fill = \"darkgreen\", \n                 color = \"darkgreen\",\n                 alpha = 0.8) +\n  geom_vline(xintercept = mean(leaf_pop),\n             linetype = 2,\n             linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0)) +\n  labs(x = \"Leaf length (cm)\",\n       y = \"Count\") +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank())\n\n\n\n\n\n\n\n\n\n\n\nsample histogram\n\n\nCode\nbreakpoints &lt;- round(seq(from = min(leaves), to = max(leaves), length.out = 7), 2)\n\nhist &lt;- enframe(leaves) %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 7, fill = \"cornflowerblue\", color = \"#000000\", breaks = breakpoints) +\n  scale_x_continuous(breaks = breakpoints) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 6), breaks = c(0, 1, 2, 3, 4, 5, 6)) +\n  theme_classic() +\n  labs(x = \"Leaf length (cm)\", y = \"Count\")\nhist\n\n\n\n\n\n\n\n\n\n\n\nsample density plot\n\n\nCode\nenframe(leaves) %&gt;% \n  ggplot(aes(x = value)) +\n  geom_density(fill = \"cornflowerblue\", color = \"#000000\", linewidth = 1) +\n  scale_x_continuous(limits = c(2.5, 7)) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.65)) +\n  geom_vline(xintercept = mean(leaves)) +\n  annotate(\"text\", x = 6, y = 0.6, label = \"sample mean = 4.84 cm\", size = 6) +\n  theme_classic() +\n  labs(x = \"Leaf length (cm)\", \n       y = \"Density\")\n\n\n\n\n\n\n\n\n\n\n\nsample dot and whisker plot with confidence intervals\n\n\nCode\nleaf_conflev &lt;- tribble(\n  ~ conflev,\n  0.85,\n  0.90,\n  0.95,\n  0.99\n) %&gt;% \n  mutate(lower = case_when(\n    conflev == 0.85 ~ mean(leaves) - -qt(p = 0.15/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.90 ~ mean(leaves) - -qt(p = 0.1/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.95 ~ mean(leaves) - -qt(p = 0.05/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.99 ~ mean(leaves) - -qt(p = 0.01/2, df = 19)*sd(leaves)/sqrt(length(leaves)) \n  ), \n  upper = case_when(\n    conflev == 0.85 ~ mean(leaves) + -qt(p = 0.15/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.90 ~ mean(leaves) + -qt(p = 0.1/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.95 ~ mean(leaves) + -qt(p = 0.05/2, df = 19)*sd(leaves)/sqrt(length(leaves)),\n    conflev == 0.99 ~ mean(leaves) + -qt(p = 0.01/2, df = 19)*sd(leaves)/sqrt(length(leaves))\n  )) %&gt;% \n  mutate(mean = mean(leaves))\n  # se &lt;- s/sqrt(n)\n\nggplot() +\n  geom_point(data = enframe(leaves), aes(x = 0.84, y = leaves),\n             alpha = 0.6, shape = 21) +\n  geom_point(data = enframe(leaves), aes(x = 0.89, y = leaves),\n             alpha = 0.6, shape = 21) +\n  geom_point(data = enframe(leaves), aes(x = 0.94, y = leaves),\n             alpha = 0.6, shape = 21) +\n  geom_point(data = enframe(leaves), aes(x = 0.98, y = leaves),\n             alpha = 0.6, shape = 21) +\n  geom_point(data = leaf_conflev, aes(x = conflev, y = mean), \n             size = 3,\n             color = \"cornflowerblue\") +\n  geom_errorbar(data = leaf_conflev, aes(x = conflev, y = mean, ymin = lower, ymax = upper), \n                width = 0.006, \n                linewidth = 1,\n                color = \"cornflowerblue\") +\n  theme_void() +\n  theme(panel.grid = element_blank()) +\n  labs(x = \"Confidence levels\", \n       y = \"Leaf length (cm)\") \n\n\n\n\n\n\n\n\n\n\n\nsample qq plot\n\n\nCode\nqq &lt;- enframe(leaves) %&gt;% \n  ggplot(aes(sample = value)) +\n  stat_qq_line(aes(sample = value)) +\n  stat_qq(aes(sample = value), color = \"cornflowerblue\", size = 3) +\n  theme_classic() +\n  labs(x = \"Theoretical quantiles\", y = \"Sample quantiles\")\n\n\n\n\nCode\nhist + qq\n\n\n\n\n\n\n\n\n\n\n\nresampling visual\n\nresampling with different sample sizes\n\n\nCode\nleaf_5 &lt;- rep(NA, length = 1000)\nleaf_20 &lt;- rep(NA, length = 1000)\nleaf_40 &lt;- rep(NA, length = 1000)\n\nleaf_20_sd &lt;- rep(NA, length = 1000)\n\n# sample 5 leaves from population 1000x\nfor(i in 1:1000) {\n  \n  # sample 5 leaves from population\n  sample_5 &lt;- sample(leaf_pop, size = 5, replace = FALSE) \n  sample_20 &lt;- sample(leaf_pop, size = 20, replace = FALSE) \n  sample_40 &lt;- sample(leaf_pop, size = 40, replace = FALSE) \n  \n  leaf_5[i] &lt;- mean(sample_5)\n  leaf_20[i] &lt;- mean(sample_20)\n  leaf_40[i] &lt;- mean(sample_40)\n  \n  leaf_20_sd[i] &lt;- sd(sample_20)\n}\n\nleaf_df &lt;- cbind(leaf_5, leaf_20, leaf_40) %&gt;% \n  as_tibble() %&gt;% \n  pivot_longer(cols = 1:3) %&gt;% \n  mutate(name = case_when(\n    name == \"leaf_5\" ~ \"n = 5\",\n    name == \"leaf_20\" ~ \"n = 20\",\n    name == \"leaf_40\" ~ \"n = 40\"\n  ),\n  name = fct_relevel(name, \"n = 5\", \"n = 20\", \"n = 40\"))\n\nleaf_df %&gt;% \n  filter(name == \"n = 20\") %&gt;% \n  ggplot() +\n  geom_histogram(aes(x = value),\n                 color = \"cornflowerblue\",\n                 fill = \"cornflowerblue\",\n                 alpha = 0.8) +\n  geom_vline(xintercept = mean(leaf_pop),\n             linetype = 2,\n             linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 280)) +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank(),\n        strip.text = element_text(size = 18)) +\n  labs(x = \"Mean leaf length (cm)\") +\n  facet_wrap(~name, ncol = 1) \n\n\n\n\n\n\n\n\n\nCode\nggplot(leaf_df) +\n  geom_histogram(aes(x = value),\n                 color = \"cornflowerblue\",\n                 fill = \"cornflowerblue\",\n                 alpha = 0.8) +\n  geom_vline(xintercept = mean(leaf_pop),\n             linetype = 2,\n             linewidth = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 280)) +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.line.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        strip.text = element_text(size = 18)) +\n  labs(x = \"Mean leaf length (cm)\") +\n  facet_wrap(~name, ncol = 1) \n\n\n\n\n\n\n\n\n\n\n\nresampling confidence intervals\n\n\nCode\nleaf_20_ci &lt;- cbind(leaf_20, leaf_20_sd) %&gt;% \n  as_tibble() %&gt;% \n  mutate(ci_low = leaf_20 - -qt(p = 0.05/2, df = 19)*leaf_20_sd/sqrt(20),\n         ci_high = leaf_20 + -qt(p = 0.05/2, df = 19)*leaf_20_sd/sqrt(20),\n         iter = rownames(.)) %&gt;% \n  mutate(color = case_when(\n    ci_low &lt;= mean(leaf_pop) & ci_high &gt;= mean(leaf_pop) ~ \"yes\",\n    TRUE ~ \"no\"\n  ),\n  color = fct_relevel(color, \"yes\", \"no\"))\n\n# selecting 8 resamples to plot\nleaf_20_ci_sample &lt;- leaf_20_ci %&gt;% \n  group_by(color) %&gt;% \n  sample_n(4) %&gt;% \n  ungroup() %&gt;% \n  mutate(iter = fct_inorder(iter))\n\nleaf_20_ci_sample\n\n\n# A tibble: 8 × 6\n  leaf_20 leaf_20_sd ci_low ci_high iter  color\n    &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;\n1    4.90      0.429   4.70    5.10 158   yes  \n2    4.86      0.443   4.66    5.07 108   yes  \n3    4.97      0.429   4.77    5.17 712   yes  \n4    4.75      0.459   4.53    4.96 298   yes  \n5    4.71      0.432   4.51    4.91 500   no   \n6    4.75      0.369   4.58    4.92 983   no   \n7    5.28      0.483   5.06    5.51 824   no   \n8    5.22      0.450   5.00    5.43 973   no   \n\n\nCode\nggplot(data = leaf_20_ci_sample, aes(x = leaf_20, y = iter, color = color)) +\n  geom_vline(xintercept = mean(leaf_pop),\n             lty = 2) +\n  geom_pointrange(aes(xmin = ci_low, xmax = ci_high)) +\n  scale_color_manual(values = c(\"yes\" = \"darkgreen\", \"no\" = \"orange\")) +\n  scale_x_continuous(limits = c(mean(leaf_pop)*0.85, mean(leaf_pop)*1.15)) +\n  scale_y_discrete(limits = rev) +\n  theme(axis.title.y = element_blank(),\n        axis.line.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()) +\n  theme(legend.position = \"none\") +\n  labs(x = \"Leaf length (cm)\")\n\n\n\n\n\n\n\n\n\n\n\n\nplotting standard error\n\n\nCode\nenframe(leaves) %&gt;% \n  mutate(group = \"Sample\") %&gt;% \n  ggplot(aes(x = group, y = value)) +\n  geom_point(position = position_jitter(width = 0.2, height = 0, seed = 1),\n             shape = 21,\n             alpha = 0.8) +\n  geom_point(aes(x = group, y = mean(value)),\n             color = \"cornflowerblue\",\n             size = 4) +\n  geom_errorbar(aes(ymin = mean(value) - sd(value)/sqrt(20), \n                    ymax = mean(value) + sd(value)/sqrt(20),\n                    width = 0.2),\n                color = \"cornflowerblue\",\n                linewidth = 1) +\n  labs(y = \"Leaf length (cm)\") +\n  theme(axis.title.x = element_blank())\n\n\n\n\n\n\n\n\n\n\n\ncalculating CI using function\n\n\nCode\nHmisc::smean.cl.normal(leaves)\n\n\n    Mean    Lower    Upper \n4.844110 4.578826 5.109393 \n\n\nCode\nggplot2::mean_cl_normal(leaves)\n\n\n        y     ymin     ymax\n1 4.84411 4.578826 5.109393\n\n\n\n\nplotting with “dry” trees\n\n\nCode\nenframe(leaves) %&gt;% \n  mutate(group = \"Sample\") %&gt;% \n  ggplot() +\n  geom_point(aes(x = group, y = value),\n             position = position_jitter(width = 0.2, height = 0, seed = 1),\n             shape = 21,\n             alpha = 0.8) +\n  geom_point(aes(x = group, y = mean(value)),\n             color = \"cornflowerblue\",\n             size = 3) +\n  geom_errorbar(data = leaf_conflev %&gt;% filter(conflev == 0.95) %&gt;% mutate(group = \"Sample\"),\n                aes(x = group, ymin = lower, ymax = upper),\n                width = 0,\n                color = \"cornflowerblue\",\n                size = 1) +\n  geom_pointrange(data = data.frame(group = \"Dry\", mean = 3.2, lower = 3.0, upper = 3.4),\n                  aes(x = group, y = mean, ymin = lower, ymax = upper),\n                  color = \"firebrick\",\n                  size = 1,\n                  linewidth = 1) +\n  labs(y = \"Leaf length (cm)\") +\n  theme(axis.title.x = element_blank())"
  },
  {
    "objectID": "lecture/lecture_week-02.html#hypothesis-testing-z-distribution",
    "href": "lecture/lecture_week-02.html#hypothesis-testing-z-distribution",
    "title": "Week 2 figures - Lectures 3 and 4",
    "section": "3. Hypothesis testing: z-distribution",
    "text": "3. Hypothesis testing: z-distribution\nExample: You’re told that the mean weight of a coast live oak acorn is \\(2.1 g\\). You question that claim. You then choose to randomly sample 30 acorns and calculate the sample mean: \\(\\bar{y} = 2.6 g\\). You also (miraculously) know the population standard deviation: \\(\\sigma = 0.3 g\\).\nDo you have evidence to refute this claim?\nFirst, store some numbers:\n\n\nCode\nacorn_mean &lt;- 2.1\nacorn_sd &lt;- 0.45\nsample_mean &lt;- 2.2\n\n\nPlotting the acorn population distribution:\n\n\nCode\nmin &lt;- acorn_mean-(3*acorn_sd)\nmax &lt;- acorn_mean+(3*acorn_sd)\n\nacorn_pop_hist &lt;- data.frame(x = min:max) %&gt;% \n  ggplot(aes(x)) +\n  stat_function(geom = \"line\", \n                n = 1000, \n                fun = dnorm, \n                args = list(mean = acorn_mean, sd = acorn_sd), \n                linewidth = 2, \n                color = \"darkgoldenrod\") +\n  geom_vline(xintercept = acorn_mean, \n             linetype = 2, \n             linewidth = 2) +\n  scale_x_continuous(breaks = c(acorn_mean-3*acorn_sd,\n                                acorn_mean-2*acorn_sd, \n                                acorn_mean-acorn_sd,\n                                acorn_mean, \n                                acorn_mean+acorn_sd,\n                                acorn_mean+2*acorn_sd,\n                                acorn_mean+3*acorn_sd),\n                     limits = c(min, max)) +\n  labs(x = \"Acorn mass (g)\") +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank())\n\nacorn_pop_hist\n\n\n\n\n\n\n\n\n\nAnd with the sample mean:\n\n\nCode\npop_with_sample &lt;- acorn_pop_hist +\n  geom_vline(xintercept = sample_mean, \n             color = \"tomato3\",\n             linewidth = 2)\npop_with_sample\n\n\n\n\n\n\n\n\n\nAnd with a sample mean at least that different:\n\n\nCode\npop_with_sample +\n  geom_vline(xintercept = acorn_mean - (sample_mean - acorn_mean), \n             color = \"tomato3\",\n             linewidth = 2)\n\n\n\n\n\n\n\n\n\nWe can calculate a z-score using the formula:\n\\[\n\\begin{align}\nz &= \\frac{\\bar{y} - \\mu}{\\sigma/\\sqrt{n}} \\\\\n&= \\frac{2.2 - 2.10}{0.45/\\sqrt{30}} \\\\\n&= 1.22\n\\end{align}\n\\]\nIn this version of the z-score formula, the number of observations \\(n\\) is included; technically, the one from before also included \\(n\\), but since we were only choosing one individual and asking about the probability of selecting that individual, \\(\\sqrt{n} = 1\\) so it cancelled out.\n\n\nCode\nacorn_z &lt;- (sample_mean - acorn_mean)/(acorn_sd/sqrt(30))\nacorn_z\n\n\n[1] 1.217161\n\n\nCode\npnorm(acorn_z, mean = 0, sd = 1, lower.tail = FALSE)\n\n\n[1] 0.1117714\n\n\nWe can plot the z-scores against each other:\n\n\nCode\ndata.frame(x = -3:3) %&gt;% \n  ggplot(aes(x)) +\n  stat_function(geom = \"area\",\n                fun = dnorm,\n                args = list(mean = 0, sd = 1),\n                xlim = c(1.96, 3),\n                fill = \"lightgrey\") +\n  stat_function(geom = \"area\",\n                fun = dnorm,\n                args = list(mean = 0, sd = 1),\n                xlim = c(-3, -1.96),\n                fill = \"lightgrey\") +\n  geom_linerange(x = 1.96, ymin = 0, ymax = 0.06) +\n  geom_linerange(x = -1.96, ymin = 0, ymax = 0.06) +\n  geom_linerange(x = acorn_z, linetype = 2, linewidth = 2,\n                 ymin = 0, ymax = 0.18) +\n  geom_linerange(x = -acorn_z, linetype = 2, linewidth = 2,\n                 ymin = 0, ymax = 0.18) +\n  stat_function(geom = \"line\", \n                n = 1000, \n                fun = dnorm, \n                args = list(mean = 0, sd = 1), \n                linewidth = 2, \n                color = \"darkgoldenrod\") +\n  scale_x_continuous(breaks = seq(-3, 3, by = 1)) +\n  scale_y_continuous(expand = c(0, 0),\n                     limits = c(0, 0.45)) +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.line.y = element_blank()) +\n  labs(x = \"Z\")"
  },
  {
    "objectID": "lecture/lecture_week-02.html#one-vs-two-tailed-figure",
    "href": "lecture/lecture_week-02.html#one-vs-two-tailed-figure",
    "title": "Week 2 figures - Lectures 3 and 4",
    "section": "4. one vs two tailed figure",
    "text": "4. one vs two tailed figure\nIn a one-tailed test (directional, greater or lesser), all the significance is in one tail of the distribution. In a two-tailed test (not directional, different from), the significance is split between two tails of the distribution.\n\n\nCode\ntwo &lt;- ggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(3, 5), fill = \"darkgrey\") +\n  geom_linerange(aes(x = 3, ymin = 0, ymax = 0.032), linewidth = 1, lty = 2, color = \"#000000\") +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(-5, -3), fill = \"darkgrey\") +\n  geom_linerange(aes(x = -3, ymin = 0, ymax = 0.032), linewidth = 1, lty = 2, color = \"#000000\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  theme_void() +\n  theme(panel.grid = element_blank())\n\none &lt;- ggplot(data.frame(x = -5:5), aes(x)) +\n  stat_function(geom = \"area\", fun = dt, args = list(df = 1), xlim = c(2, 5), fill = \"darkgrey\") +\n  geom_linerange(aes(x = 2, ymin = 0, ymax = 0.063), linewidth = 1, lty = 2, color = \"#000000\") +\n  stat_function(geom = \"line\", n = 1000, fun = dt, args = list(df = 1), linewidth = 1, color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.32)) +\n  theme_void() +\n  theme(panel.grid = element_blank())\n\none + two"
  },
  {
    "objectID": "workshop/workshop-04_2024-04-25.html",
    "href": "workshop/workshop-04_2024-04-25.html",
    "title": "Coding workshop: Week 4",
    "section": "",
    "text": "tidyverse\n\njanitor\n\n\n\n\n\n\n\nread in data using read_csv()\n\nvisualize data using ggplot()\n\n\n\n\n\nThe fish migration data is from the Columbia River DART (Data Access in Real Time) on fish migration through the Columbia River Basin in 2023.\nThe candy rankings data is from FiveThirtyEight’s candy power rankings (source, story).\nThe desert rodent measurements are from the Portal Project.\nThe shark incident data is from Riley et al.\nThe trash wheel pick up data is from the Waterfront Partnership of Baltimore."
  },
  {
    "objectID": "workshop/workshop-04_2024-04-25.html#summary",
    "href": "workshop/workshop-04_2024-04-25.html#summary",
    "title": "Coding workshop: Week 4",
    "section": "",
    "text": "tidyverse\n\njanitor\n\n\n\n\n\n\n\nread in data using read_csv()\n\nvisualize data using ggplot()\n\n\n\n\n\nThe fish migration data is from the Columbia River DART (Data Access in Real Time) on fish migration through the Columbia River Basin in 2023.\nThe candy rankings data is from FiveThirtyEight’s candy power rankings (source, story).\nThe desert rodent measurements are from the Portal Project.\nThe shark incident data is from Riley et al.\nThe trash wheel pick up data is from the Waterfront Partnership of Baltimore."
  },
  {
    "objectID": "workshop/workshop-04_2024-04-25.html#code",
    "href": "workshop/workshop-04_2024-04-25.html#code",
    "title": "Coding workshop: Week 4",
    "section": "2. Code",
    "text": "2. Code\n\n1. Set up\n\na. packages\n\nlibrary(tidyverse)\nlibrary(janitor)\n\n\n\nb. data\nData info:\n\nfish migration\n\ncandy rankings\n\ndesert rodent measurements\n\nshark incidents\n\ntrash wheel pick ups\n\n\n# fish migration\n# if you're working with fish data, note that these are cumulative counts\nfish &lt;- read_csv(\"adultdaily_1713852195_223.csv\")\n\n# candy rankings\ncandy &lt;- read_csv(\"candy-data.csv\")\n\n# desert rodent measurements\nrodents &lt;- read_csv(\"rodent_surveys.csv\")\n\n# shark incidents\nsharks &lt;- read_csv(\"sharks.csv\")\n\n# trash wheel\ntrashwheel &lt;- read_csv(\"trashwheel.csv\")\n\n\n\nc. Roles\nFill in the names of your group members/roles here:\n\nReporter: insert name here\nThis person will report out at the end of class, summarizing notes from the note-taker (if there is one) or taking notes themselves on what the process of creating a visualization from a caption was like: were there any challenges? easy parts? etc.\nMain coder: insert name here\nWith the group’s guidance, this person will write the code for the final visualization and the text for the caption. This person will also post the figure and the caption on the google slides.\nNote-taker (not every group will have this role): insert name here\nThis person will keep track of all the steps to create the final visualization and share these notes with the reporter to summarize.\n\n\n\n\n2. Create your visualization below!\nMy data set is [insert name of data set here].\nREMEMBER TO LOOK AT YOUR DATA BEFORE STARTING\n\na. cleaning/summarizing (individual)\n\n# insert code for cleaning and/or summarizing here IF NEEDED\n\n\n\nb. exploratory visualization (individual)\nDo this part on your own!\n\n# insert code for your own exploratory visualization here\n\nAfter you’re done with your exploratory visualization, discuss with your group members and decide which visualization to finalize.\n\n\nc. final visualization (group)\nThe coder will write this in their script, but follow along on yours too!\n\n# insert code for the finalized visualization here\n\nKeep this visualization to yourself; you will compare the other group’s visualization to your own!\n\n\nd. Write a caption\ninsert the text for your caption here\nCopy-paste your caption into the google slides!\nCheck links in template script\n\n\n\n3. Create a visualization based on the other group’s caption\nUse the other group’s caption to make a visualization. They will do the same for your caption, and at the end you’ll compare their visualization to your own to see how well your caption described your figure.\n\na. Caption\ninsert the other group’s caption here\n\n\nb. visualization (group)\n\n# insert code for the other group's visualization here\n\nOnce you’re done, take a screenshot of your visualization and post it on the google slides!\nRENDER YOUR DOCUMENT"
  },
  {
    "objectID": "workshop/workshop-05_2024-05-02.html",
    "href": "workshop/workshop-05_2024-05-02.html",
    "title": "Coding workshop: Week 5",
    "section": "",
    "text": "tidyverse\n\nlterdatasampler\n\neffectsize\n\nrstatix\n\ncar\n\n\n\n\n\n\n\ndo a Shapiro-Wilk test using shapiro.test()\n\ndo a Levene’s test using car::leveneTest()\n\ndo an ANOVA using aov()\n\nlook for more information from model results using summary()\n\ndo post-hoc Tukey test using TukeyHSD()\n\ncalculate effect size for ANOVA using effectsize::eta_squared()\n\ndo Kruskal-Wallis test using kruskal.test()\n\ndo Dunn’s test using rstatix::dunn_test()\n\ncalculate effect size for Kruskal-Wallis test using rstatix::kruskal_effsize()\n\n\n\n\n\nread in data using read_csv()\n\nchain functions together using %&gt;%\n\nselect columns using select()\n\nrename columns using rename()\n\nvisualize data using ggplot()\n\ncreate histograms using geom_histogram()\n\nvisualize QQ plots using geom_qq() and geom_qq_line()\n\ncreate multi-panel plots using facet_wrap()\n\ngroup data using group_by()\n\nsummarize data using reframe()\n\n\n\n\n\nThe Plum Island Ecosystem fiddler crab data is from lterdatasampler (data info here). The ramen ratings data set is a Tidy Tuesday dataset - see more about the data and its source here."
  },
  {
    "objectID": "workshop/workshop-05_2024-05-02.html#summary",
    "href": "workshop/workshop-05_2024-05-02.html#summary",
    "title": "Coding workshop: Week 5",
    "section": "",
    "text": "tidyverse\n\nlterdatasampler\n\neffectsize\n\nrstatix\n\ncar\n\n\n\n\n\n\n\ndo a Shapiro-Wilk test using shapiro.test()\n\ndo a Levene’s test using car::leveneTest()\n\ndo an ANOVA using aov()\n\nlook for more information from model results using summary()\n\ndo post-hoc Tukey test using TukeyHSD()\n\ncalculate effect size for ANOVA using effectsize::eta_squared()\n\ndo Kruskal-Wallis test using kruskal.test()\n\ndo Dunn’s test using rstatix::dunn_test()\n\ncalculate effect size for Kruskal-Wallis test using rstatix::kruskal_effsize()\n\n\n\n\n\nread in data using read_csv()\n\nchain functions together using %&gt;%\n\nselect columns using select()\n\nrename columns using rename()\n\nvisualize data using ggplot()\n\ncreate histograms using geom_histogram()\n\nvisualize QQ plots using geom_qq() and geom_qq_line()\n\ncreate multi-panel plots using facet_wrap()\n\ngroup data using group_by()\n\nsummarize data using reframe()\n\n\n\n\n\nThe Plum Island Ecosystem fiddler crab data is from lterdatasampler (data info here). The ramen ratings data set is a Tidy Tuesday dataset - see more about the data and its source here."
  },
  {
    "objectID": "workshop/workshop-05_2024-05-02.html#code",
    "href": "workshop/workshop-05_2024-05-02.html#code",
    "title": "Coding workshop: Week 5",
    "section": "2. Code",
    "text": "2. Code\n\n1. Packages\n\nlibrary(tidyverse)\nlibrary(lterdatasampler)\nlibrary(effectsize)\nlibrary(rstatix)\nlibrary(car)\n\n\n\n2. Parametric tests\n\na. Cleaning and wrangling\n\npie_crab_clean &lt;- pie_crab %&gt;% # start with the pie_crab dataset\n  filter(site %in% c(\"CC\", \"ZI\", \"VCR\")) %&gt;% # filter for Cape Cod, Zeke's Island, Virginia Coastal\n  select(site, name, size) %&gt;% # select columns of interest\n  rename(site_code = site, # rename site to be site_code\n         site_name = name) # rename name to be site_name\n\n\n\nb. Exploring the data\n\nggplot(pie_crab_clean, # use the clean data set\n       aes(x = site_name, # x-axis\n           y = size)) + # y-axis\n  geom_jitter(width = 0.2, # jitter points horizontally\n              height = 0) + # don't jitter points vertically\n  theme_minimal() # cleaner plot theme\n\n\n\n\n\n\n\n\nIs there a difference in crab size between the three sites?\ninsert response here\n\n\nc. Check 1: normally distributed variable\nDo this with a histogram:\n\nggplot(data = pie_crab_clean, # using the clean data frame\n       aes(x = size)) + # x-axis\n  geom_histogram(bins = 9) + # make a histogram\n  facet_wrap(~ site_name, # make multiple panels by site\n             scales = \"free\") # let the axes vary between panels\n\n\n\n\n\n\n\n\nAnd a qq plot:\n\nggplot(data = pie_crab_clean, # using the clean data frame\n       aes(sample = size)) + # y-axis\n  geom_qq_line() + # making a reference line\n  geom_qq() + # making the qq\n  facet_wrap(~ site_name, # make multiple panels by site\n             scales = \"free\") # let axes vary between panels\n\n\n\n\n\n\n\n\nWhat are the outcomes of your visual checks?\nsummarize outcomes here\nDo Shapiro-Wilk tests:\n\ncc_crabs &lt;- pie_crab_clean %&gt;% # use the original data set\n  filter(site_code == \"CC\") %&gt;% # filter to only include Cape Cod\n  pull(size) # extract the size column as a vector\n\nvcr_crabs &lt;- pie_crab_clean %&gt;% \n  filter(site_code == \"VCR\") %&gt;% # filter to only include Virginia Coastal\n  pull(size)\n\nzi_crabs &lt;- pie_crab_clean %&gt;% \n  filter(site_code == \"ZI\") %&gt;% # filter to only include Zeke's Island\n  pull(size)\n\n# do the Shapiro-Wilk tests\nshapiro.test(cc_crabs)\n\n\n    Shapiro-Wilk normality test\n\ndata:  cc_crabs\nW = 0.93547, p-value = 0.09418\n\nshapiro.test(vcr_crabs)\n\n\n    Shapiro-Wilk normality test\n\ndata:  vcr_crabs\nW = 0.94447, p-value = 0.12\n\nshapiro.test(zi_crabs)\n\n\n    Shapiro-Wilk normality test\n\ndata:  zi_crabs\nW = 0.97446, p-value = 0.5766\n\n\nWhat are the outcomes of your statistical checks?\nsummarize outcomes here\n\n\nd. Check 2: equal variances\nFirst, calculate the actual variances yourself:\n\n# quick summary \npie_crab_clean %&gt;% # use the clean data frame\n  group_by(site_name) %&gt;% # group by site\n  reframe(var = var(size)) # calculate variance at each site\n\n# A tibble: 3 × 2\n  site_name                       var\n  &lt;chr&gt;                         &lt;dbl&gt;\n1 Cape Cod                       4.22\n2 Virginia Coastal Reserve LTER  8.63\n3 Zeke's Island NERR             4.04\n\n\nUsing leveneTest() from car\n\n# do the Levene test\nleveneTest(size ~ site_name, # formula\n           data = pie_crab_clean) # data\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value  Pr(&gt;F)   \ngroup  2  5.0233 0.00857 **\n      89                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat are the outcomes of your variance check?\ninsert outcomes here\n\n\ne. ANOVA\n\n# creating an object called crab_anova\ncrab_anova &lt;- aov(size ~ site_name, # formula\n                  data = pie_crab_clean) # data\n\n# gives more information\nsummary(crab_anova)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)    \nsite_name    2  442.2  221.10   39.56 5.1e-13 ***\nResiduals   89  497.4    5.59                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSummarize results: is there a difference in crab size between the three sites?\ninsert results here\n\n\nf. Post-hoc: Tukey HSD\n\nTukeyHSD(crab_anova)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = size ~ site_name, data = pie_crab_clean)\n\n$site_name\n                                                       diff       lwr       upr\nVirginia Coastal Reserve LTER-Cape Cod           -0.4795185 -1.974354  1.015317\nZeke's Island NERR-Cape Cod                      -4.7514709 -6.194843 -3.308099\nZeke's Island NERR-Virginia Coastal Reserve LTER -4.2719524 -5.673993 -2.869912\n                                                     p adj\nVirginia Coastal Reserve LTER-Cape Cod           0.7255994\nZeke's Island NERR-Cape Cod                      0.0000000\nZeke's Island NERR-Virginia Coastal Reserve LTER 0.0000000\n\n\nWhich pairwise comparisons are actually different? Which ones are not different?\ninsert results here\n\n\ng. effect size\nUsing eta_squared() from effectsize\n\neffectsize::eta_squared(crab_anova)\n\n# Effect Size for ANOVA\n\nParameter | Eta2 |       95% CI\n-------------------------------\nsite_name | 0.47 | [0.34, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nWhat is the magnitude of the effect of site on crab size?\ninsert results here\n\n\nh. Putting everything together\nWe found a (insert effect size here) difference between sites in crab size (insert ANOVA info here). On average, crabs from Zeke’s Island NERR were smaller than crabs from Cape Cod and Virginia Coastal Reserve LTER (insert Tukey HSD info here).\n\n\n\n3. Non-parametric tests\n\na. Set up\n\nramen_ratings &lt;- read_csv(\"ramen_ratings.csv\")\n\n\n\nb. Clean and wrangle the data\n\nramen_ratings_clean &lt;- ramen_ratings %&gt;% # use the ramen_ratings dataframe\n  filter(brand == \"Maruchan\") %&gt;% # filter to only include Maruchan ramen\n  mutate(style = fct_relevel(style, \"Bowl\", \"Pack\", \"Tray\", \"Cup\")) # reorder style factor\n\n# look at the structure\nstr(ramen_ratings_clean)\n\ntibble [106 × 6] (S3: tbl_df/tbl/data.frame)\n $ review_number: num [1:106] 3176 3152 3141 3124 3111 ...\n $ brand        : chr [1:106] \"Maruchan\" \"Maruchan\" \"Maruchan\" \"Maruchan\" ...\n $ variety      : chr [1:106] \"Gotsumori Shio Yakisoba\" \"QTTA Curry Ramen\" \"Thai Red Curry Udon\" \"Kitsune Udon 40th Anniversary\" ...\n $ style        : Factor w/ 4 levels \"Bowl\",\"Pack\",..: 3 4 1 1 1 4 1 1 4 3 ...\n $ country      : chr [1:106] \"Japan\" \"Japan\" \"Japan\" \"Japan\" ...\n $ stars        : num [1:106] 5 5 5 4.5 4 4 3.75 2 2.5 2.5 ...\n\n\n\n\nc. Make a boxplot to compare star ratings across ramen styles\n\nggplot(data = ramen_ratings_clean, # use the clean data frame\n       aes(x = style, # x-axis\n           y = stars, # y-axis\n           fill = style)) + # fill geoms by ramen style\n  geom_boxplot() + # make a boxplot\n  scale_fill_manual(values = c(\"firebrick4\", \"orange\", \"gold\", \"darkgreen\")) + # define the colors\n  theme_minimal() + # minimal theme\n  theme(legend.position = \"none\") # take out the legend\n\n\n\n\n\n\n\n\n\n\nd. Do the Kruskal-Wallis test\n\nkruskal.test(stars ~ style, # formula\n             data = ramen_ratings_clean) # data\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  stars by style\nKruskal-Wallis chi-squared = 15.679, df = 3, p-value = 0.00132\n\n\nIs there a difference in ratings between ramen styles?\nsummarize results here\n\n\ne. Do a Dunn’s post-hoc test\nUsing dunn_test() from rstatix\n\ndunn_test(stars ~ style, # formula\n          data = ramen_ratings_clean) # data\n\n# A tibble: 6 × 9\n  .y.   group1 group2    n1    n2 statistic        p   p.adj p.adj.signif\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1 stars Bowl   Pack      33    30    -2.61  0.00898  0.0449  *           \n2 stars Bowl   Tray      33    17    -2.54  0.0112   0.0449  *           \n3 stars Bowl   Cup       33    26    -3.70  0.000213 0.00128 **          \n4 stars Pack   Tray      30    17    -0.323 0.747    0.985   ns          \n5 stars Pack   Cup       30    26    -1.16  0.244    0.733   ns          \n6 stars Tray   Cup       17    26    -0.686 0.492    0.985   ns          \n\n\nWhich pairwise comparisons of ramen styles are different from each other?\nsummarize results here\n\n\nf. Calculate an effect size\nUsing kruskal_effsize() from rstatix\n\nkruskal_effsize(stars ~ style, # formula\n                data = ramen_ratings_clean) # data\n\n# A tibble: 1 × 5\n  .y.       n effsize method  magnitude\n* &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;ord&gt;    \n1 stars   106   0.124 eta2[H] moderate \n\n\nWhat is the magnitude of the effect of ramen style on ratings?\nsummarize results here\n\n\ng. Putting it all together\nWe found a difference in ratings between ramen styles (insert KW info here). There was a large effect of style on rating (insert eta info here), with bowl-style ramen tending to be more highly rated than pack, tray, or cup style ramen (insert Dunn’s post-hoc info here)."
  },
  {
    "objectID": "workshop/workshop-06_2024-05-09.html",
    "href": "workshop/workshop-06_2024-05-09.html",
    "title": "Coding workshop: Week 6",
    "section": "",
    "text": "tidyverse\n\nlterdatasampler\n\npaletteer\n\nggthemes\n\ntvthemes\n\nggpomological\n\ngghighlight\n\npatchwork\n\ngganimate\n\nggimage\n\nplotly\n\n\n\n\n\n\n\nuse color palettes with paletteer::paletteer_c() and paletteer::paletteer_d()\n\nuse themes from tvthemes (amongst other packages)\n\nhighlight elements using gghighlight()\n\nmake figures into gifs using gganimate::transition_reveal()\n\ninsert images into figures using ggimage::geom_image()\n\nmake figures interactive using plotly::ggplotly()\n\n\n\n\n\n\n\n\nThese are all datasets from the lterdatasampler package."
  },
  {
    "objectID": "workshop/workshop-06_2024-05-09.html#summary",
    "href": "workshop/workshop-06_2024-05-09.html#summary",
    "title": "Coding workshop: Week 6",
    "section": "",
    "text": "tidyverse\n\nlterdatasampler\n\npaletteer\n\nggthemes\n\ntvthemes\n\nggpomological\n\ngghighlight\n\npatchwork\n\ngganimate\n\nggimage\n\nplotly\n\n\n\n\n\n\n\nuse color palettes with paletteer::paletteer_c() and paletteer::paletteer_d()\n\nuse themes from tvthemes (amongst other packages)\n\nhighlight elements using gghighlight()\n\nmake figures into gifs using gganimate::transition_reveal()\n\ninsert images into figures using ggimage::geom_image()\n\nmake figures interactive using plotly::ggplotly()\n\n\n\n\n\n\n\n\nThese are all datasets from the lterdatasampler package."
  },
  {
    "objectID": "workshop/workshop-06_2024-05-09.html#code",
    "href": "workshop/workshop-06_2024-05-09.html#code",
    "title": "Coding workshop: Week 6",
    "section": "2. Code",
    "text": "2. Code\n\n1. Set up\n\nlibrary(tidyverse)\nlibrary(lterdatasampler)\n\n# use color palettes\n# if using paletteer:\nlibrary(paletteer)\n# if not, insert color palette package here\n\n# use theme packages to change plot aesthetics\n# insert theme package here\nlibrary(ggthemes)\nlibrary(tvthemes)\nlibrary(ggpomological)\n\n# highlight figure components\nlibrary(gghighlight)\n\n# put multiple figures together\nlibrary(patchwork)\n\n# make figures into gifs\nlibrary(gganimate)\n\n# insert images into plots\nlibrary(ggimage)\n\n# make figures interactive\nlibrary(plotly)\n\nRun this to see datasets from lterdatasampler in your environment:\n\ndata(\"knz_bison\")\ndata(\"ntl_icecover\")\ndata(\"and_vertebrates\")\n\n\n\n2. Starter figures:\n\na. Konza Prairie Bison weights\n\n# cleaned data frame ----\nknz_bison_clean &lt;- knz_bison %&gt;% # start with knz_bison data frame\n  mutate(age = rec_year - animal_yob) %&gt;% # calculate age of bison when weighed\n  filter(animal_code %in% c(\"Y-233\", \"Y-245\", \"Y-246\", \"Y-248\", \"Y-258\", \"Y-264\")) # filter for 6 individual bison\n\n# creating a plot ----\nknz_bison_plot &lt;- ggplot(knz_bison_clean, # data\n                         aes(x = age, # x-axis\n                             y = animal_weight)) + # y-axis\n  \n  # geoms: points for each age, lines connecting age\n  geom_point(aes(color = animal_code)) +\n  geom_line(aes(color = animal_code,\n                group = animal_code)) +\n  \n  # plot appearance \n  scale_x_continuous(breaks = seq(from = 0, to = 18, by = 1)) + # line breaks for each age in years\n  labs(x = \"Age (years)\",\n       y = \"Weight (lbs)\",\n       color = \"Individual\",\n       title = \"Bison weigh more as adults than calves\")\n\n# displaying the plot\nknz_bison_plot\n\n\n\n\n\n\n\n\n\n\nb. North Temperate Lakes ice cover\n\n# creating a plot ----\nntl_ice_plot &lt;- ggplot(data = ntl_icecover, # data\n                       aes(x = year, # x-axis\n                           y = ice_duration, # y-axis\n                           color = lakeid)) + # color by lake\n  \n  # geometry: line \n  geom_line(aes(group = lakeid), # making sure line is grouped by lake\n            linewidth = 1) + # thicker line\n  \n  # plot appearance\n  labs(x = \"Year\",\n       y = \"Ice duration (days)\",\n       title = \"Yearly ice duration has declined through time\")\n\nntl_ice_plot\n\n\n\n\n\n\n\n\n\n\nc. Andrews Forest vertebrate species\nFigure of length on the x-axis, weight on the y-axis, points representing species observations\n\n# cleaned data frame ----\nand_clean &lt;- and_vertebrates %&gt;% # start with and_vertebrates\n  filter(species %in% c(\"Cutthroat trout\")) %&gt;% # filter for salamanders and trout\n  mutate(unittype = case_when(\n    unittype == \"C\" ~ \"Cascade\",\n    unittype == \"P\" ~ \"Pool\",\n    unittype == \"SC\" ~ \"Side channel\",\n    unittype == \"IP\" ~ \"Isolated pools\",\n    unittype == \"R\" ~ \"Rapid\"\n  ),\n  unittype = fct_relevel(unittype, \"Pool\", \"Cascade\", \"Rapid\", \"Side channel\", \"Isolated pools\")) %&gt;% \n  drop_na(unittype)\n\n# creating a plot ----\nand_verts_plot &lt;- ggplot(data = and_clean, # use the clean data frame\n                         aes(x = unittype, # x-axis\n                             y = length_1_mm, # y-axis\n                             color = unittype)) + # color the points by species\n  \n  # drawing points\n  geom_boxplot(outliers = FALSE) +\n  geom_jitter(width = 0.2,\n              height = 0,\n              alpha = 0.05,\n              shape = 21) +\n\n  \n  # plot appearance \n  labs(x = \"Habitat type\",\n       y = \"Weight (g)\",\n       title = \"Cutthroat trout in pools are larger than in other habitats\") \n \n# displaying the plot ----\nand_verts_plot\n\n\n\n\n\n\n\n\n\n\nd. Navigate to your section’s slides\nThese are linked in your workshop template.\n\n\n\n3. Advanced figures\n\na. quick fixes to make your plot better\n\nntl_ice_quick &lt;- ntl_ice_plot +\n  scale_color_manual(values = c(\"Lake Mendota\" = \"#6aa84f\", \n                                \"Lake Monona\" = \"#45818e\")) +\n  theme_minimal() +\n  theme(text = element_text(size = 16,\n                            family = \"Times New Roman\"),\n        axis.text = element_text(color = \"#5b5b5b\"),\n        axis.title = element_text(color = \"#5b5b5b\"),\n        plot.title = element_text(color = \"#5b5b5b\"),\n        legend.position = \"bottom\",\n        legend.title = element_blank())\n\nntl_ice_quick\n\n\n\n\n\n\n\n# run this to save your plot!\n# ggsave(\"ntl_ice_quick.png\", # what you want your plot file to be called\n#        ntl_ice_quick, # plot object name\n#        width = 12, # width (change this if necessary)\n#        height = 8, # height (change this if necessary)\n#        units = cm, # units of width and height\n#        dpi = 300) # resolution \n\n\n\nb. use color palettes\n\nand_verts_palette &lt;- and_verts_plot +\n  scale_color_manual(values = paletteer_d(\"peRReo::buenavista\")) \n\nand_verts_palette\n\n\n\n\n\n\n\n# run this to save your plot!\n# ggsave(\"and_verts_palette.png\", # what you want your plot file to be called\n#        and_verts_palette, # plot object name\n#        width = 10, # width (change this if necessary)\n#        height = 8, # height (change this if necessary)\n#        units = cm, # units of width and height\n#        dpi = 300) # resolution \n\n\n\nc. use theme packages to change plot aesthetics\n\nknz_bison_theme &lt;- knz_bison_plot +\n  theme_economist() +\n  scale_color_economist()\n\nknz_bison_theme\n\n\n\n\n\n\n\n# note that you have to install the \"Homemade Apple\" font before running this code\n# download it here: https://fonts.google.com/share?selection.family=Homemade+Apple\nknz_bison_pomological_theme &lt;- knz_bison_plot +\n  scale_color_pomological() +\n  theme_pomological_fancy()\n\nknz_bison_pomological_theme\n\n\n\n\n\n\n\n# note that you have to install the \"Slayer\" font before running this code\n# download it here: https://github.com/Ryo-N7/tvthemes/tree/master/inst/fonts/Slayer\n# click through to the font, then hit the download button\nknz_bison_avatar_theme &lt;- knz_bison_plot +\n  scale_color_avatar(palette = \"WaterTribe\") +\n  theme_avatar(title.font = \"Slayer\",\n               text.font = \"Slayer\",\n               title.size = 8,\n               subtitle.size = 8)\n\nknz_bison_avatar_theme\n\n\n\n\n\n\n\n# run this to save your plot!\n# ggsave(\"knz_bison_theme.png\", # what you want your plot file to be called\n#        knz_bison_theme, # plot object name\n#        width = 10, # width (change this if necessary)\n#        height = 8, # height (change this if necessary)\n#        units = cm, # units of width and height\n#        dpi = 300) # resolution \n\n\n\nd. highlight figure components\n\nknz_bison_highlight &lt;- knz_bison_plot +\n  gghighlight(animal_code == \"Y-233\",\n              unhighlighted_params = list(alpha = 0.8),\n              line_label_type = \"ggrepel_label\")\n\nknz_bison_highlight \n\n\n\n\n\n\n\n# run this to save your plot!\n# ggsave(\"knz_bison_highlight.png\", # what you want your plot file to be called\n#        knz_bison_highlight, # plot object name\n#        width = 10, # width (change this if necessary)\n#        height = 8, # height (change this if necessary)\n#        units = cm, # units of width and height\n#        dpi = 300) # resolution \n\n\n\ne. put multiple figures together\n\nplots_together &lt;- ntl_ice_plot / knz_bison_plot\n\nplots_together\n\n\n\n\n\n\n\n# run this to save your plot!\n# ggsave(\"plots_together.png\", # what you want your plot file to be called\n#        plots_together, # plot object name\n#        width = 12, # width (change this if necessary)\n#        height = 10, # height (change this if necessary)\n#        units = cm, # units of width and height\n#        dpi = 300) # resolution \n\n\n\nf. make figures into gifs\n\nntl_ice_gif &lt;- ntl_ice_plot +\n  transition_reveal(along = year) +\n  ease_aes('linear')\n\nntl_ice_gif\n\n\n\n\n\n\n\n# run this to save your gif!\n# anim_save(\"ntl_ice.gif\", \n#           ntl_ice_gif)\n\n\n\ng. insert images into plots\nNote: if you go with this option, you can use the bison image in this directory with the knz_bison_plot. You can also use a different plot and download another image that makes sense. Up to you!\n\nknz_bison_image &lt;- knz_bison_plot +\n  geom_image(\n    data = tibble(age = 10, animal_weight = 500),\n    aes(image = \"bison-on-konza.jpg\"),\n    size = 0.5\n  )\n\nknz_bison_image\n\n# run this to save your plot!\n# ggsave(\"knz_bison_image.png\", # what you want your plot file to be called\n#        knz_bison_image, # plot object name\n#        width = 10, # width (change this if necessary)\n#        height = 8, # height (change this if necessary)\n#        units = cm, # units of width and height\n#        dpi = 300) # resolution \n\n\nknz_bison_image &lt;- knz_bison_plot +\n  geom_image(\n    data = tibble(age = 10, animal_weight = 500),\n    aes(image = here::here(\"workshop\", \"images\", \"bison-on-konza.jpg\")),\n    size = 0.5\n  )\n\nknz_bison_image\n\n\n\n\n\n\n\n# run this to save your plot!\n# ggsave(\"knz_bison_image.png\", # what you want your plot file to be called\n#        knz_bison_image, # plot object name\n#        width = 10, # width (change this if necessary)\n#        height = 8, # height (change this if necessary)\n#        units = cm, # units of width and height\n#        dpi = 300) # resolution \n\n\n\nh. make figures interactive\n\nntl_ice_inter &lt;- ggplotly(ntl_ice_plot)\n\nntl_ice_inter\n\n\n\n\n# run this to save your object!\n# htmltools::save_html(ntl_ice_inter,\n#                      \"ntl_ice_inter.html\")"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Order By\n       Default\n         \n          Due date - Oldest\n        \n         \n          Due date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDue date\n\n\n\n\n\n\nGetting set up\n\n\nApr 3, 2024\n\n\n\n\nReflection 1\n\n\nApr 10, 2024\n\n\n\n\nHomework 1\n\n\nApr 17, 2024\n\n\n\n\nOPTIONAL practice problem - Central Limit Theorem\n\n\nApr 18, 2024\n\n\n\n\nOPTIONAL practice problem - One sample t-test\n\n\nApr 18, 2024\n\n\n\n\nHomework 2\n\n\nApr 24, 2024\n\n\n\n\nOPTIONAL practice problem - Make an ugly plot\n\n\nApr 25, 2024\n\n\n\n\nOPTIONAL practice problem - Do a Wilcoxon signed rank test by hand\n\n\nMay 1, 2024\n\n\n\n\nMidterm\n\n\nMay 8, 2024\n\n\n\n\nReflection 2\n\n\nMay 15, 2024\n\n\n\n\nOPTIONAL practice problem - everything is a linear model\n\n\nMay 22, 2024\n\n\n\n\nHomework 3\n\n\nMay 29, 2024\n\n\n\n\nChoose your own assignment - Generative art\n\n\nJun 10, 2024\n\n\n\n\nChoose your own assignment - Advanced data visualization\n\n\nJun 10, 2024\n\n\n\n\nChoose your own assignment - Quarto website\n\n\nJun 10, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "assignments/homework-02.html",
    "href": "assignments/homework-02.html",
    "title": "Homework 2",
    "section": "",
    "text": "Due on Wednesday April 24 (Week 4) at 11:59 PM\nRead the instructions carefully and double check that you have everything on the checklist."
  },
  {
    "objectID": "assignments/homework-02.html#part-1.-tasks",
    "href": "assignments/homework-02.html#part-1.-tasks",
    "title": "Homework 2",
    "section": "Part 1. Tasks",
    "text": "Part 1. Tasks\nYou do not need to submit anything for these tasks, but are expected to have completed and know the material.\n\nTask 1. Beginning steps to configure Git/GitHub: Part 2\n\nConfigure git and store your personal access token.\n\n\nInstructions for MacOS\nInstructions for Windows\n\n\n\n\n\n\n\nNote\n\n\n\nNote: make sure git is installed. You did this last week for one of your homework tasks, but if it wasn’t installed and you didn’t install it, do it now!\n\n\n\n\nTask 2. Read Lowndes and Horst 2020, “Tidy data for efficiency, reproducibility, and collaboration.”\n\n\nTask 3. Read Horst and Lowndes 2022, “GitHub for supporting, reusing, contributing, and failing safely.”\n\n\nTask 4. Install R packages\n\nlterdatasampler\nRead about the package here."
  },
  {
    "objectID": "assignments/homework-02.html#part-2.-problems",
    "href": "assignments/homework-02.html#part-2.-problems",
    "title": "Homework 2",
    "section": "Part 2. Problems",
    "text": "Part 2. Problems\n\n\n\n\n\n\nTip\n\n\n\nRemember to set up a directory specifically for this homework assignment!\n\n\n\nProblem 1. Raptor abundance between restoration plots (10 points)\nManagers at Coal Oil Point Reserve (COPR) are interested in the relationship between restored areas and raptor abundance: as different parts of the reserve are restored to native grassland, small mammal (i.e. mice, gopher, vole) abundances should increase, which should attract more raptors (i.e. hawks, falcons) to the reserve. You conduct weekly surveys for raptors at COPR from April to June in one of the restoration areas and collect the following data on the number of raptors you see for each survey:\n\\[\n0, 2, 4, 6, 1, 2, 3, 5, 1, 0\n\\]\n\nWhat kind of data did you collect, and why? Explain in 1-2 sentences. (2 points)\n\nWhat is a better description of the variability in raptor count, standard deviation or standard error? Explain why in 1-2 sentences and calculate the metric of your choice, showing your work. (4 points)\n\nWhat is a better description of the uncertainty in raptor count, standard deviation or standard error? Explain why in 1-2 sentences and calculate the metric of your choice, showing your work. (4 points)\n\n\n\nProblem 2. Sugar maple stem masses (38 points)\nUsing the hbr_maples data set from lterdatasampler, answer the question: Does mean sugar maple stem mass in 2003 differ between reference and calcium-treated watersheds?\n\n\n\n\n\n\nWorking with data in a package\n\n\n\nIf you load in the package using library(lterdatasampler), the hbr_maples data set will be ready for you to use, but you just won’t see it in your environment. To have the data set pop up in your environment, use data(hbr_maples).\n\n\nFor any calculations for which you need a confidence level, use 95% with the corresponding significance level.\n\nIn one sentence each, write your null and alternative hypotheses to address this question. (2 points)\n\nMake a QQ plot. In one sentence, describe whether the variable is normally distributed or not. (4 points)\n\nCheck variances. In one sentence, describe whether the groups have equal variances or not. (4 points)\n\nCalculate the critical value for your test. (4 points)\n\nDo a t-test. (4 points)\n\n\n\n\n\n\n\nt-test arguments\n\n\n\n\n\nDouble check your arguments to make sure you’re running the right test.\n\n\n\n\nCalculate an effect size and show the output. (4 points)\n\n\n\n\n\n\n\nCalculating an effect size\n\n\n\n\n\nYou can either calculate Cohen’s d by using the formula presented in lecture:\n\\[\nCohen's \\; d = \\frac{\\bar{y_A} - \\bar{y_B}}{\\sqrt{\\frac{(n_A - 1)\\times s^2_A + (n_B - 1)\\times s^2_B}{n_A + n_B + 2}}}\n\\]\nor you could use a function in the package effectsize called cohens_d().\n\n\n\n\nMake a figure with mean and confidence intervals showing the raw data underneath the summary information. Make sure that your plot is finalized. For full credit on your plot, adjust the ggplot()/geom_() defaults such that your plot has:\n\nDifferent colors for each watershed\n\nDifferent shapes for each watershed\n\nA different font than the default\n\nNo gridlines\n(6 points)\n\nWrite a “methods” section. In one sentence each, describe:\n\nWhy the test you chose may have been appropriate for testing your hypotheses in part a\n\nHow you evaluated normality and homogeneity of variance\n(4 points)\n\nWrite a “results” section. Describe the results in full sentences in your own words, making sure to include the:\n\nTest you ran\n\nNumber of observations for each watershed\nSignificance level\nDegrees of freedom\nTest statistic\np-value\nConfidence interval in the difference in mean stem masses between watershed\nEffect size\n(6 points)\n\n\n\n\nProblem 3. Personal data (12 points)\nBy now, you have some observations on your data sheet for your personal data. Even though it’s early on in your data collection, it’s a good idea to practice good data management. For this problem, you’ll enter your data, read it into R, and create a visualization. If you get stuck at any step, you’ll know there’s something you need to fix.\n\nCreate a spreadsheet to enter your data. Two good options include Google Sheets or Microsoft Excel.\n\nCreate the columns of your spreadsheet.\n\n\n\n\n\n\n\nSpreadsheet columns\n\n\n\n\n\nIf you organized your data sheet in “tidy format” (i.e. each row is an observation), then the columns of your spreadsheet would be exactly the same as the columns in your data sheet.\n\n\n\n\nEnter your data.\n\nSave your spreadsheet as a .csv file in your homework repository.\n\nRead your data into R.\n\nCreate a visualization to explore your data. Finalize the plot. (4 points)\n\nIn 1-2 sentences, describe what the “main message” of your visualization is. (4 points)\n\nIn 2-4 sentences, describe the process of getting your data from your spreadsheet into R. Did you encounter any challenges? If so, why do you think those challenges arose, and how did you fix them? If not, why do you think your system for collecting your data worked? (4 points)\n\n\n\n\n\n\n\nChanging your data collection scheme\n\n\n\n\n\nIf you found that entering your data from your spreadsheet and getting it into the right format to be used in R was challenging, that’s ok! This happens a lot with data collection. Feel free to change your data sheet so that you’re collecting data in a way that makes your life easier as you’re reading your data into R and using it.\n\n\n\n\n\nProblem 4. Statistical critique (10 points)\nCheck the Google sheet and choose a paper to use for your critique based on An’s/Caitlin’s recommendations. Answer the following questions about the paper in 1-2 sentences each:\n\nWhy were you interested in this paper? (2 points)\n\nWhat questions/hypotheses are the authors addressing? (2 points)\n\nWhat statistical tests are the authors doing? Is there anything confusing about what they did? (2 points)\n\nFind the figures and/or tables in the paper that is associated with the statistical tests from question (c). If you have a figure, what are the x- and y-axes, and what does the figure show (i.e. what is the main message of the figure)? If you have a table, what are the rows and columns, and what is it supposed to show? (2 points)\n\nTake a screenshot of the figures and/or tables and insert the screenshot into your homework document. (2 points)"
  },
  {
    "objectID": "assignments/homework-02.html#checklist",
    "href": "assignments/homework-02.html#checklist",
    "title": "Homework 2",
    "section": "Checklist",
    "text": "Checklist\nYour homework should\n\nInclude your name, the title (“Homework 2”), and the date you turned in the assignment (3 points)\n\nInclude for Problem 1:\n\nresponses for a-c\nfull work (hand written or R code) for parts b-c\n\nInclude for Problem 2:\n\nwritten response for part a\n\nfull work (R code), output, and written response for parts b-c\n\nfull work (R code) and output for parts d-f\n\nfull work (R code) and output for part g\n\nwritten response for parts h-i\n\n\nInclude for Problem 3:\n\nfull work (R code) and output for part f\n\nwritten responses for parts g-h\n\n\nInclude for Problem 4:\n\nwritten responses for parts a-d\n\nfigure for part e\n\n\nbe uploaded to Canvas as a single PDF (1 point)\n\nbe organized and readable (10 points)\n\n84 points total"
  },
  {
    "objectID": "assignments/homework-01.html",
    "href": "assignments/homework-01.html",
    "title": "Homework 1",
    "section": "",
    "text": "Due on Wednesday April 17 (Week 3) at 11:59 PM\nRead these instructions before starting your homework and follow them carefully. See the end of this assignment for a checklist of components that your assignment must have at minimum (i.e. to earn at least partial credit). Only submit the items in that list, in the order requested."
  },
  {
    "objectID": "assignments/homework-01.html#frequently-asked-questions",
    "href": "assignments/homework-01.html#frequently-asked-questions",
    "title": "Homework 1",
    "section": "Frequently Asked Questions",
    "text": "Frequently Asked Questions\n\nI’m having trouble rendering to PDF. What can I do?\nYou could either install all the additional things R is asking for you to install, or you can render to a word doc instead (change pdf in the top part of the document to docx) and save that doc as a PDF.\n\n\nI don’t know how to insert an image into a Quarto document. How do I do that?\nHere is a resource for Quarto. If you rendered your Quarto file to a word document, you can insert an image into that word document the same way you would with any other word doc.\n\n\nWhere is the feedback for problem 4?\nIt is in the google sheet."
  },
  {
    "objectID": "assignments/homework-01.html#part-1.-tasks",
    "href": "assignments/homework-01.html#part-1.-tasks",
    "title": "Homework 1",
    "section": "Part 1. Tasks",
    "text": "Part 1. Tasks\n\n\n\n\n\n\nNote\n\n\n\nYou will not need to submit any materials for tasks, but you are expected to complete the material.\n\n\n\nTask 1. Beginning steps to configure Git/GitHub\n\nCheck that Git is installed on your computer. It likely already is, but check anyway!\n\nInstructions for Macs\nInstructions for Windows\n\nIf you do not have git installed, follow the instructions to install it.\n\nIf you don’t have one already, create a GitHub account.\n\nRead Jenny Brian’s Happy Git with R Section 4.1: “Username advice” (for example, An’s GitHub username is an-bui and Caitlin’s is cnordheim-maestas)\n\nVisit GitHub\n\nCreate an account using your personal email (not your UCSB email, which you will lose access to once you graduate)\n\n\n\n\nTask 2. Read Julia Lowndes’ piece in Scientific American: “Open Software Means Kinder Science”"
  },
  {
    "objectID": "assignments/homework-01.html#part-2.-problems-code-and-figures",
    "href": "assignments/homework-01.html#part-2.-problems-code-and-figures",
    "title": "Homework 1",
    "section": "Part 2. Problems, code, and figures",
    "text": "Part 2. Problems, code, and figures\nCarefully read the checklist for the components that you will need to submit for each problem. Show all your work.\n\n\n\n\n\n\nSetting up\n\n\n\nYou’ll want to set up a directory specifically for this homework assignment within your class directory. For example, your class directory is called ENVS-193DS, while your directory for this homework assignment could be called something like ENVS-193DS_homework-01. Then, you can create a project within the directory for this assignment. Afterward, you can save your code and data into the same directory.\n\n\n\nProblem 1. Measures of central tendency and data spread (8 points)\nAfter the major rains this winter, you’re interested in what’s happening with the Pacific treefrog (Pseudacris hypochondriaca) population at North Campus Open Space. You’ve collected the following masses (in grams) for tree frogs in one night of sampling (frogs can be hard to catch!):\n\\[\n23, 32, 39, 25, 35, 28\n\\]\n\nIn one sentence, categorize this data set: what type of data did you collect, and why is it that type? (2 points)\n\nCalculate the sample mean. Express your answer with the correct units. (2 points)\n\nCalculate the sample variance. Express your answer with the correct units. (2 points)\n\nCalculate the sample standard deviation. Express your answer with the correct units. (2 points)\n\n\n\nProblem 2. Visualizing data (9 points)\nIn this problem, you’ll work with data collected by the National Snow and Ice Data Center on glacial mass and sea level rise.\nGetting set up:\n\nRead the overview information about the data set from the database.\n\nDownload the two data files from Canvas (linked in the Homework 1 assignment page) into your directory (aka folder) for this assignment.\n\nData file 1: glacial_volume_loss_copy.csv\n\nData file 2: glacial_volume_loss.csv\n\nOpen up the two data files and look at them side-by-side. In one sentence, explain how the data files are different. (1 point)\n\nRead the metadata (data/information about the data) in data file 2 (glacial_volume_loss.csv) to understand what each column means.\n\nCoding:\n\nMake sure your data files and your script (R script, Quarto, or RMarkdown document) is in the same folder as the data file.\n\nLoad the tidyverse package.\n\nRead in data file 1 using read_csv(“glacial_volume_loss_copy.csv”) and store that as an object named glaciers.\n\nCreate a histogram of annual sea level rise. (4 points)\n\nCreate a scatterplot of cumulative sea level rise through time (year on the x-axis, cumulative sea level rise on the y-axis). (4 points)\n\n\n\nProblem 3. Personal data (20 points total)\nThis quarter, you’ll collect data from your own life to see how data science concepts are part of your daily existence. For this homework assignment, you’ll come up with two ideas for data collection. The data you collect:\n\nhas to be something you can get at least 30 observations on by week 10 (e.g. minutes to get from ENVS 193DS to your next class, not number of shark views per week)\n\ncan’t something you can get from data collection objects (e.g. number of steps in a day)\n\nhas to be something that you could actually remember to write down (e.g. liters of water consumed in a day, not time spent on tiktok)\n\nhas to be be shaped by a question (e.g. how much water do i drink in a day?)\n\nhas to include variables that would be appropriate to share with the class\n\nFor each idea you have (remember you have to come up with two ideas), you should:\n\narticulate a question (2 points each)\n\ndescribe when you would write that data down (2 points each)\n\ndescribe what other variables you think you should measure (2 points each)\n\ndescribe what type of data your variables are (2 points each)\n\ndesign a data sheet with some example data: what are the columns and what are the rows? (2 points each)\n\nExample:\n\nQuestion: How many different types of vegetables do I eat?\n\nI would take data after every meal.\n\nDate, time of day, type of vegetable, meal, whether or not it’s cooked, if it’s eaten with other things\n\n\n\n\nDate: continuous\n\ntime of day: categorical (morning, afternoon, evening)\n\nmeal: categorical (breakfast, lunch, dinner, snack)\n\ncooked: binary (yes/no)\n\neaten with other things: binary (yes/no)\n\n\n\n\n\n\n\n\n\n\n\nWhen can you start collecting data?\n\n\n\nAn will give you feedback and recommendations for what to pursue for this project on Canvas on Thursday the 18th of April. That means that you should be able to start collecting data by the end of week 3, if not sooner.\n\n\n\n\nProblem 4. Setting up statistical critique (6 points)\nThroughout the quarter, you’ll engage in a critique of statistical methods for a published paper. Some methods are appropriate for the data and research questions, and some are not. You’ll be the judge.\nFor this homework assignment, you will find 3 candidate papers for your critique. Find 3 papers that speak to your interests - the paper could be on human health, plant restoration, agroecology, or more. Anything you might be interested in within the realm of environmental studies is fair game. Not all 3 papers have to be on the same topic.\n\nFor each paper, read the Abstract to get a general sense of what the paper is about. Then, read the Methods section, looking for information on statistical analysis. A paper is a good choice if it includes one of these terms (or something similar) in the analysis description:\n\nt-test\n\nAnalysis of variance (ANOVA)\n\nMann-Whitney U\n\nKruskal-Wallis\n\nWilcoxon rank sum\n\nLinear model or linear regression\n\nSpearman correlation\n\nPearson correlation\n\nlogistic regression\n\nGeneralized linear mixed effect model\n\nOnce you’ve verified that your paper includes at least one of the above listed terms, find the digital object identifier (DOI), which is a unique identifier in the form of a URL for a paper. You will know it is a DOI if it has doi.org somewhere in the URL.\n\nOnce you find the DOI for your paper, add it to the Google form. Repeat this for all three papers. (3 points)\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want to see what other people have chosen, see the class responses here.\n\n\n\nIn your homework document, list the papers in alphabetical order by author last name. (3 points)\nYour citations should take the form:\nLast name, first name, et al. Year. “Paper title.” Journal title volume:issue.\nExample:\nSanford, E., et al. 2019. “Widespread shifts in the coastal biota of northern California during the 2014–2016 marine heatwaves.” Scientific Reports 9:4216."
  },
  {
    "objectID": "assignments/homework-01.html#checklist",
    "href": "assignments/homework-01.html#checklist",
    "title": "Homework 1",
    "section": "Checklist",
    "text": "Checklist\nYour homework should\n\nInclude your name, the title (“Homework 1”), and the date you turned in the assignment (3 points)\n\nInclude responses for Problem 1a-d and full work (hand written or R code) for parts b-d\n\nInclude a written response to Problem 2c and all your code, annotations, and output for Problem 2h-i\n\nInclude 3 citations for Problem 3c\n\nbe uploaded to Canvas as a single PDF (1 point)\n\nbe organized and readable (2 points)\n\nAdditionally, you should\n\nPaste 3 DOIs for the papers you’re interested in in the Google form\n\n49 points total"
  },
  {
    "objectID": "assignments/choose-your-own_generative-art.html",
    "href": "assignments/choose-your-own_generative-art.html",
    "title": "Choose your own assignment - Generative art",
    "section": "",
    "text": "Due on Wednesday June 5 (week 10) at 11:59 PM"
  },
  {
    "objectID": "assignments/choose-your-own_generative-art.html#description",
    "href": "assignments/choose-your-own_generative-art.html#description",
    "title": "Choose your own assignment - Generative art",
    "section": "Description",
    "text": "Description\nWe use R within RStudio for statistical analysis, but it has the capability of creating some very cool art pieces from what is essentially a random number generator. From Danielle Navarro, a self-described “data scientist, generative artist, and recovering academic”:\n\nThis is what I think generative art really is. An automated process that takes garbage as input and creates unpredictably delightful outputs – sometimes with a little helpful human oversight and curation – is a generative art system. It is fundamentally a process of making something from nothing. Art from the void. Treasure from trash. Signal from noise. You get the idea.\n\nBy the end of this assignment, you’ll use numbers as a tool for creating art, and have created a few pieces of art on your own. Additionally, you’ll be expected to annotate your code so that you know what each line is doing to understand how the randomness all fits together to create a final art piece.\nThere are two routes for this assignment: structured and unstructured. In the structured route, you will work through a tutorial by Danielle Navarro, and create 3 art pieces using her materials. In the unstructured route, you will read and complete smaller tutorials by Meghan Harris, George Savva, and Jiwan Heo and create 3 art pieces synthesizing things you learned from each tutorial. You can decide which route to take based on your own comfort level and interest."
  },
  {
    "objectID": "assignments/choose-your-own_generative-art.html#components",
    "href": "assignments/choose-your-own_generative-art.html#components",
    "title": "Choose your own assignment - Generative art",
    "section": "Components",
    "text": "Components\n\nPart 1. Context (structured and unstructured)\n\na. Read the last entry of the Art from Code workshop, “Wrap Up”\nDanielle’s “Wrap Up” gives good context for why this kind of exercise is useful. Have fun with it!\n\n\nb. Read Nicola Rennie’s “Best (artistic) practices in R”\nNicola’s guide to artistic practices in R is useful for understanding how to structure, annotate, and share your code in the field of generative art.\n\n\nc. Read Mine Cetinkaya-Rundel’s Generative Art slides\nMine’s workshop gives a good background for some of the mechanics of creating art. There are no notes to go along with these slides, but you’ll get a sense of what the code tends to look like.\n\n\n\nPart 2a. Workshop (structured only)\n\na. Get set up.\nFork the repo from the original GitHub repository into your own account and download it into your computer.\n\n\nb. Do the introductory exercises.\nRead and complete exercises from “Get Started” (link). Annotate your code to demonstrate that you know how it works.\n\n\nc. Art of your choice: tricks\nChoose one: spatial noise tricks, polygon tricks, shading tricks\nComplete all exercises. Again, annotate your code.\n\n\nd. Art of your choice: iteration, tiles, pixels\nChoose one: iterated function systems, tiles and tessellations, pixel filters.\nComplete all exercises. Again, annotate your code.\n\n\n\n\n\n\nNote\n\n\n\nNote: these three lessons have less structured exercises - your job is to play around with the code provided and create something of your own, and not to follow written directions. Change stuff around and see what happens!\n\n\n\n\ne. Put it all together\nCreate 3 art pieces that combines elements of what you learned from parts b-d. For each piece, write an accompanying caption that includes:\n\nThe title of your piece\n\nThe date you created it\n\nA 2-3 sentence description of your inspiration\n\nA 2-3 sentence description of what specific components from each part (b-d) you drew from to create the piece\n\n\n\n\nPart 2b. Tutorials (unstructured only)\n\na. Work through tutorials\nRead and code along (i.e. copy/paste the code into your own document, annotate it, and run it) with the following tutorials:\n\nMeghan Harris’s Thinking Outside the Grid\n\none of George Savva’s tutorials on Mathematical Art and Creative Coding (you choose the one you want to do)\n\none of Jiwan Heo’s tutorials (again, you choose the one you want to do: flow fields, hypnotic squares, Truchet tiles, or rotating lines)\n\n\n\nb. Look at other people’s generative art for inspiration\nSome generative artists who work in R include:\n\neveryone featured in this gallery (look under the “Collections” tab for examples)\n\nJacquie Tran\n\nMeghan Harris\n\nGeorge Savva\n\nJiwan Heo\n\nDanielle Navarro\n\nThomas Lin Pedersen\n\nAntonio Sánchez Chinchón\n\n\n\nc. Put it all together\nCreate 3 art pieces that combine different components of Meghan, George, and Jiwan’s tutorials. For each piece, write an accompanying caption that includes:\n\nThe title of your piece\n\nThe date you created it\n\nA 2-3 sentence description of your inspiration\n\nA 2-3 sentence description of what specific components from each tutorial you drew from to create the piece"
  },
  {
    "objectID": "assignments/choose-your-own_generative-art.html#checklist",
    "href": "assignments/choose-your-own_generative-art.html#checklist",
    "title": "Choose your own assignment - Generative art",
    "section": "Checklist",
    "text": "Checklist\nYour submission should include\n\nA link to the GitHub repository where your materials for this specific assignment are (make sure it is public!)\n\nA link to a rendered HTML document with navigation bar showing where each of the exercises/tutorials are\n\nYour rendered HTML document should include\n\nyour name, the title, and the date\n\nannotated code and output for all tutorial activities\nannotated code and output for your three art pieces\n\nwritten caption for all three art pieces\n\na 8-10 sentence summary at the end about your process: What was new for you? What was familiar? What did you learn? How did following the exercises/tutorials go for you?\n\n\n\n\n\n\n\nNote\n\n\n\nNote: you can do this by making your GitHub repository connect to GitHub pages. Ask if you are unsure about how to do this."
  },
  {
    "objectID": "assignments/optional-problem-04.html",
    "href": "assignments/optional-problem-04.html",
    "title": "OPTIONAL practice problem - Do a Wilcoxon signed rank test by hand",
    "section": "",
    "text": "In this practice problem, you’ll do a Wilcoxon signed rank test comparing paired samples to each other by hand, then double check your work with R. This is the non-parametric version of the paired t-test."
  },
  {
    "objectID": "assignments/optional-problem-04.html#description",
    "href": "assignments/optional-problem-04.html#description",
    "title": "OPTIONAL practice problem - Do a Wilcoxon signed rank test by hand",
    "section": "",
    "text": "In this practice problem, you’ll do a Wilcoxon signed rank test comparing paired samples to each other by hand, then double check your work with R. This is the non-parametric version of the paired t-test."
  },
  {
    "objectID": "assignments/optional-problem-04.html#steps",
    "href": "assignments/optional-problem-04.html#steps",
    "title": "OPTIONAL practice problem - Do a Wilcoxon signed rank test by hand",
    "section": "2. Steps",
    "text": "2. Steps\n\na. Values\nStart with these values:\n\n\n\n\n\nBefore\nAfter\n\n\n\n\n1.2\n1.6\n\n\n2.0\n2.8\n\n\n0.8\n0.7\n\n\n0.6\n0.6\n\n\n1.3\n1.5\n\n\n3.2\n2.7\n\n\n0.9\n1.1\n\n\n\n\n\n\n\nb. Calculate the differences between samples\nThen, calculate the differences between those values. You should get something that looks like this:\n\n\n\n\n\nDifferences\n\n\n\n\n-0.4\n\n\n-0.8\n\n\n0.1\n\n\n0.0\n\n\n-0.2\n\n\n0.5\n\n\n-0.2\n\n\n\n\n\n\n\nc. Take out 0, arrange by magnitude\nThen, omit all observations of 0 and arrange your numbers by magnitude. You should get something that looks like this:\n\n\n\n\n\nOrdered magnitude\n\n\n\n\n0.1\n\n\n-0.2\n\n\n-0.2\n\n\n-0.4\n\n\n0.5\n\n\n-0.8\n\n\n\n\n\n\n\nd. Give each value a “sign” and a “rank”\nThis is the “signed rank” part of the test: assign each value a sign (+ or -), then rank (1, 2, 3, 4, etc.) You should get something that looks like this:\n\n\n\n\n\nOrdered magnitude\nSigned rank\n\n\n\n\n0.1\n+ 1\n\n\n-0.2\n- 2\n\n\n-0.2\n- 2\n\n\n-0.4\n- 4\n\n\n0.5\n+ 5\n\n\n-0.8\n- 6\n\n\n\n\n\n\n\ne. Sum the magnitudes of the + and - values\nSum the magnitudes of the + and - values. This will be the -W and +W statistic. You then choose the lower statistic.\nIn this case, you should get:\n+W = 1 + 5 = 6\n-W = 2 + 2 + 4 + 6 = 14\nPick the lowest one: +W = 6.\n\n\ne. Run the test in R to check your work.\nStart with this data frame:\n\n# creating a long format data frame\ndf &lt;- tibble(before = c(1.2, 2.0, 0.8, 0.6, 1.3, 3.2, 0.9), # original values\n             after = c(1.6, 2.8, 0.7, 0.6, 1.5, 2.7, 1.1)) %&gt;% \n  pivot_longer(cols = before:after, # making this long format\n               names_to = \"sample\", # creating a column called \"sample\" that has before and after\n               values_to = \"value\") %&gt;% # creating a column called value that has the values\n  mutate(sample = fct_relevel(sample, \"before\", \"after\")) %&gt;% # making sure that before appears in the data frame first\n  arrange(sample) # arranging the data frame so that before and after are all sitting \n\nThen run a Wilcoxon signed rank test (note the paired = TRUE argument).\n\nwilcox.test(value ~ sample, # formula\n            data = df, # data\n            paired = TRUE) # argument for a paired test\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with zeroes\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  value by sample\nV = 6, p-value = 0.4017\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nf. Try a one-sample test.\nCompare the following values to \\(\\mu = 7\\):\n\n\n\n\n\nSample\n\n\n\n\n2.8\n\n\n8.3\n\n\n4.5\n\n\n6.7\n\n\n8.1\n\n\n7.2\n\n\n7.8\n\n\n\n\n\nFirst, calculate the difference between each observation and the \\(\\mu\\), which is 7:\n\n\n\n\n\nSample\nDifference\n\n\n\n\n2.8\n-4.2\n\n\n8.3\n1.3\n\n\n4.5\n-2.5\n\n\n6.7\n-0.3\n\n\n8.1\n1.1\n\n\n7.2\n0.2\n\n\n7.8\n0.8\n\n\n\n\n\nThen order each difference and assign a sign and rank:\n\n\n\n\n\nOrdered magnitude\nSigned rank\n\n\n\n\n0.2\n+ 1\n\n\n-0.3\n- 2\n\n\n0.8\n+ 3\n\n\n1.1\n+ 4\n\n\n1.3\n+ 5\n\n\n-2.5\n- 6\n\n\n-4.2\n- 7\n\n\n\n\n\nThen sum the magnitudes:\n+W = 1 + 3 + 4 + 5 = 13\n-W = 2 + 6 + 7 = 15\nFor this example, W = 13.\nThen, double check your work in R:\n\nwilcox.test(c(2.8, 8.3, 4.5, 6.7, 8.1, 7.2, 7.8),\n            mu = 7)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  c(2.8, 8.3, 4.5, 6.7, 8.1, 7.2, 7.8)\nV = 13, p-value = 0.9375\nalternative hypothesis: true location is not equal to 7"
  },
  {
    "objectID": "assignments/reflection-01.html",
    "href": "assignments/reflection-01.html",
    "title": "Reflection 1",
    "section": "",
    "text": "Due on Wednesday April 10 (Week 2) at 11:59 PM\nIn this assignment, you’ll introduce yourself and come up with a plan for what you’d like to get out of the class and roughly outline what you’d like to accomplish over the course of the quarter. You’ll continue visiting the goals you set for yourself in this assignment throughout the quarter, so it’s worth it to be as clear and specific as you can."
  },
  {
    "objectID": "assignments/reflection-01.html#components",
    "href": "assignments/reflection-01.html#components",
    "title": "Reflection 1",
    "section": "Components",
    "text": "Components\n\nA brief introduction\n\nyour name\n\nyour major\nyour year\n\npronouns (only if you feel comfortable sharing)\n\n\n\nSome questions about school and life\n\nWhy are you taking this class?\n\nWhat do you hope to get out of this class?\n\nIf you have a career in mind, how does this course apply to your future career, if at all?\n\nWhat do you wish your instructors knew about you, but don’t?\n\n\n\nSome questions about the way you like to learn\n\nWhat kinds of assignments, skills, or behaviors have you felt most comfortable with/enjoy from past classes? Why do you enjoy them?\n\nHow confident do you feel in your statistics skills (however you want to interpret that)? Why?\n\nHow confident do you feel in your coding skills (again, however you want to interpret that)? Why?\n\nWhat have you struggled with in the past in math or statistics courses? Why?\n\nOf the courses you’re taking this quarter, which do you expect to be the most challenging? Most demanding?\n\nWhich learning goals from the syllabus are you most excited about?\n\nWhat other learning goals do you have for the course?\n\nMost importantly, how do you plan on accomplishing your learning goals for this course?\n\n\n\n\n\n\n\nNote\n\n\n\nBe specific here! Instead of writing, “I will complete homework assignments” or “I will study”, you can make these more specific strategies: “I will use the homework assignments as opportunities for practice. I will communicate with classmates for help after trying…”\n\n\n\n\nChecklist\nYour reflection should include\n\nyour name, major, and year (if you feel comfortable, please also include the pronouns you want to be used)\n\n1-2 sentences in response to each point (Note: you can copy/paste the questions into a document and fill them out like a form!)"
  },
  {
    "objectID": "assignments/reflection-02.html",
    "href": "assignments/reflection-02.html",
    "title": "Reflection 2",
    "section": "",
    "text": "Due on Wednesday May 15 (week 7) at 11:59 PM\nIn this assignment, you’ll reflect on your own progress in the course up until this point.\nReread your responses to reflection 1 and the feedback on Canvas. Then, address the following questions in 2-3 sentences each."
  },
  {
    "objectID": "assignments/reflection-02.html#components",
    "href": "assignments/reflection-02.html#components",
    "title": "Reflection 2",
    "section": "Components",
    "text": "Components\n\nHow have you progressed towards your learning goals for this course? Specifically, how do you know that you’ve made progress (for example, have you grown more confident in coding, have you applied statistics to new scenarios)?\nWhat skills are you proud of developing and/or building on in the last 7 weeks?\nLooking forward, how have your learning goals changed? Have they stayed the same?\nHave you learned anything into which you want to dive more deeply? Have you done so? If yes, what did you learn?\nHow would you change the structure of this course, if at all? If you wouldn’t, what in particular has been working for you?\nFill out the anonymous survey linked in the assignment description on Canvas, and answer the question at the end of the survey."
  },
  {
    "objectID": "assignments/reflection-02.html#checklist",
    "href": "assignments/reflection-02.html#checklist",
    "title": "Reflection 2",
    "section": "Checklist",
    "text": "Checklist\nYour reflection should:\n\naddress at least the 6 topics above (but please feel free to expand on these if you would like)\n\nbe uploaded to Canvas by 11:59 PM on Wednesday May 15 in PDF format"
  },
  {
    "objectID": "assignments/choose-your-own_quarto-website.html",
    "href": "assignments/choose-your-own_quarto-website.html",
    "title": "Choose your own assignment - Quarto website",
    "section": "",
    "text": "Due on Wednesday June 5 (week 10) at 11:59 PM"
  },
  {
    "objectID": "assignments/choose-your-own_quarto-website.html#description",
    "href": "assignments/choose-your-own_quarto-website.html#description",
    "title": "Choose your own assignment - Quarto website",
    "section": "Description",
    "text": "Description\nIn this assignment, you’ll create your own personal website using Quarto. By the end of this assignment, you’ll have a website that you developed using data science tools. You’ll also see how Quarto pages fit together like a puzzle to create a finished website.\nWhy make a website at all? Having a website is a great way of developing a digital portfolio of your skills and interests. Read Casey Botticello’s blog post: “5 Important Reasons Why You Still Need a Personal Website” for more.\nHow does making a website using Quarto actually work? In class, we use Quarto markdown documents to write code with text, then render the document into the format we want (usually .pdf or .docx). One major benefit to using Quarto + Rprojects is that 1) Quarto renders to .html and 2) Quarto can render a bunch of Qmd files in a single project to create a website.\nWhy make a website using Quarto? It’s a great way of demonstrating your skills to the data science community to show that you have some competency in knowing how Quarto documents work together.\nSee the checklist at the end for components you will need to turn in. Note: if deploying your website using GitHub, you will need a GitHub account (which you should have already, after completing Homework 1)."
  },
  {
    "objectID": "assignments/choose-your-own_quarto-website.html#components",
    "href": "assignments/choose-your-own_quarto-website.html#components",
    "title": "Choose your own assignment - Quarto website",
    "section": "Components",
    "text": "Components\n\nTasks\n\n1. Look at a Quarto website for some ideas regarding structure and content\nSome examples of personal Quarto websites include:\n\npast 193DS students (Maddie Manzagol, Bianca Berron, Katie Miller)\n\nprofessionals (Meghan Harris, Jadey Ryan, Bea Milz)\n\nthe instructors’ sites (Caitlin, An)\n\n\n\n2. List the “pages” you want to include on your website.\nKeeping in mind that your website is a digital portfolio, list 3 of your projects, skills, interests, etc. that you want to highlight and how you are going to display them on your website.\nFor example, you could have blog posts highlighting writing pieces you’re proud of. You can enhance these with citations, figures, etc. to fill them out. Alternatively, you could use the blog post format to highlight classes you’ve taken to show you’ve developed skills in whatever those classes are about (for example, literary criticism, GIS, visual art). Note: you can have multiple pages in “blog” format - see Sam Csik’s personal website where the “talks & workshops”, “courses”, “projects”, and “posts” pages are all “blogs”.\nYou could also have photo galleries to share any visual media you might have - illustration, photography, etc.\nLastly, you could have a dedicated “About” page, where you write a bio for yourself so that people can learn more about you!\n\n\n3. Make your website with the pages you listed in task 1.\nFollow these directions written by Sam Csik (from above!). Read the directions before you start.\n\n\n\n\n\n\nTip\n\n\n\nSam has very generously offered to answer any questions about her tutorial as you’re working through this assignment. If you have questions, feel free to email scsik@ucsb.edu with:\n1. What you want to do,\n2. What you need help with, and\n3. What you’ve done to try to fix the problem\nAlso, if you liked the tutorials, you should shoot her an email and tell her!\n\n\n\n\n4. Fill out your website.\n\nInsert a photo of yourself, educational background, short bio, and links (e.g. GitHub, LinkedIn) on the landing page.\n\nChange the theme of your website from the default (here’s a list of Quarto themes).\n\nChange the CSS and/or SASS defaults for the theme to colors, fonts, etc. of your choice (here’s Sam’s tutorial for how to do that).\n\nAt minimum, you should change:\n- The font\n- The color scheme (text, background, links, sidebar/header)\n\n\n\n\n\n\nTip\n\n\n\nIf you see a feature on someone’s Quarto website that you want to implement, go to their GitHub repository for the site to see how they made it. For example, Sam has a map of all the hikes she logged using Strava, which is an embedded product from a dashboard she created. The repository for Sam’s website is here, and the Strava dashboard is here."
  },
  {
    "objectID": "assignments/choose-your-own_quarto-website.html#checklist",
    "href": "assignments/choose-your-own_quarto-website.html#checklist",
    "title": "Choose your own assignment - Quarto website",
    "section": "Checklist",
    "text": "Checklist\nYour submission should include\n\nA link to the GitHub repository where your website is held\n\nA link to your actual website\n\n8-10 sentences summarizing your experience, addressing (for example): What was hard about this? What was easy? What was new to you? What was familiar to you? How did following the tutorial go for you?"
  },
  {
    "objectID": "workshop.html",
    "href": "workshop.html",
    "title": "Workshop documents",
    "section": "",
    "text": "Order By\n       Default\n         \n          Workshop date - Oldest\n        \n         \n          Workshop date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nWorkshop date\n\n\n\n\n\n\nCoding workshop: Week 1\n\n\nApr 4, 2024\n\n\n\n\nCoding workshop: Week 2\n\n\nApr 11, 2024\n\n\n\n\nCoding workshop: Week 3\n\n\nApr 18, 2024\n\n\n\n\nCoding workshop: Week 4\n\n\nApr 25, 2024\n\n\n\n\nCoding workshop: Week 5\n\n\nMay 2, 2024\n\n\n\n\nCoding workshop: Week 6\n\n\nMay 9, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "resources/github-pages.html",
    "href": "resources/github-pages.html",
    "title": "Setting up GitHub pages",
    "section": "",
    "text": "Why set up GitHub pages?\nIf you render/knit your documents to html, someone else who wants to see your document will have to fork/clone your repo into their computer, and open up your html document. By setting up GitHub pages, you can essentially make your repository into a website and create a URL to your rendered html document. Then, if you want to share your code, someone can just look at the page on that URL and not have to deal with your whole repository.\nIn class, we walked through the simplest way to set up GitHub pages. However, there are lots of advanced options to make your repository into a website. For example, in CHOYOA 2, you’ll set some different options when you set up GitHub pages.\n\n\n1. Create a new repository on GitHub\nMake sure you have the repository set to be public and that you are adding a README.\n\n\n\n2. Set up GitHub pages\nNavigate to the main page of your repository. Click on Settings &gt; Pages. Select your main branch as the deployed branch. Click save.\n\nYou know that this worked if you get a message at the top of the window saying “GitHub Pages source saved.”\n\n\n3. Clone your repo to your computer and create some code.\nIn the demo, we put all our code into a new folder in the repo called code. Then, create a new Quarto/RMarkdown document and make sure it is saved as either an HTML (ideal) or a PDF (also works but not as aesthetically pleasing). Save that document in the code folder.\n\n\n\n4. Adjust the YAML options.\nThere are lots of document options you can adjust in the metadata. In class, we went through how to set global options for code chunks using execute:.\n\nIn RMarkdown: this happens in the knitr set up chunk:\n\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\n\n\n\n5. Render/knit your code.\nNote the file path for the .qmd document is: code/newcode.qmd. That means the file path for the .html document is: code/newcode.html.\n\n\n\n6. Stage/commit/push those changes\nIf you are using Quarto, you’ll see a lot of files for the rendered plots, formatting options, etc. If you are using RMarkdown, you won’t. This is just a little difference between Quarto and RMarkdown.\n\n\n\n7. Return to GitHub and look at the environment\nGo back to your repository on GitHub. You should see two visual cues that this has worked:\n1. You have a brown circle by your most recent commit. This corresponds to what’s happening in…\n2. The “Environments”. You will see github-pages marked as “active”.\n\n\n\n8. Check the deployment\nClick on github-pages under Environments. You should see that the deployment (your commit/push) shows up as “Queued”. This will eventually turn into “In Progress”, then “Active”.\n\nNote: depending how how many other actions are happening on GitHub at any given time, this may take a couple minutes. Be patient! Eventually it will be active.\n\n\n9. Look at the your rendered document!\nYour deployed repository will have the URL your-github-username.github.io/repository-name. In this example, the URL is an-bui.github.io/my-repository.\nTo find your rendered html document, use the file path as your URL. In this example, the file path to the rendered document is code/newcode.html. This means the URL for the .html on my deployed repository is an-bui.github.io/my-repository/code/newcode.html.\n\nNote: sometimes it’s useful to link this URL in the README!\n\n\nexample repo\nThe repo for this example is here.\n\n\n\n\n\n\nCitationBibTeX citation:@online{bui2023,\n  author = {Bui, An},\n  title = {Setting up {GitHub} Pages},\n  date = {2023-05-17},\n  url = {https://an-bui.github.io/ES-193DS-W23/resources/github-pages.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBui, An. 2023. “Setting up GitHub Pages.” May 17, 2023. https://an-bui.github.io/ES-193DS-W23/resources/github-pages.html."
  },
  {
    "objectID": "resources/writing-a-readme.html",
    "href": "resources/writing-a-readme.html",
    "title": "Writing an informative README",
    "section": "",
    "text": "A README is a file that gives a broad overview of what is in a directory or repository. If you’re using GitHub, the README shows up on the repository page and is a markdown file (has the suffix .md). A README in a data repository (which you’ve seen on your midterm) is usually a plain text file (.txt)."
  },
  {
    "objectID": "resources/writing-a-readme.html#what-is-a-readme",
    "href": "resources/writing-a-readme.html#what-is-a-readme",
    "title": "Writing an informative README",
    "section": "",
    "text": "A README is a file that gives a broad overview of what is in a directory or repository. If you’re using GitHub, the README shows up on the repository page and is a markdown file (has the suffix .md). A README in a data repository (which you’ve seen on your midterm) is usually a plain text file (.txt)."
  },
  {
    "objectID": "resources/writing-a-readme.html#why-have-a-readme",
    "href": "resources/writing-a-readme.html#why-have-a-readme",
    "title": "Writing an informative README",
    "section": "Why have a README?",
    "text": "Why have a README?\nYou might know how your code and data are organized, but no one else does. By writing an informative README, people can read about the repository and then explore it to find what they’re looking for. You can also write a README for yourself to keep things organized (i.e. understand where you’ve put things so that you can find them again).\nIt’s an extra little step that future you and anyone else working with your code/dat will use to understand how your files are organized and where they come from."
  },
  {
    "objectID": "resources/writing-a-readme.html#what-does-a-readme-look-like-on-github",
    "href": "resources/writing-a-readme.html#what-does-a-readme-look-like-on-github",
    "title": "Writing an informative README",
    "section": "What does a README look like on GitHub?",
    "text": "What does a README look like on GitHub?\nYou can look at this repository to see where the README shows up in a repository. It is one of the first things anyone will see.\n\nYou can format your README using headers and subheaders to make it easier to navigate. The button with three lines in the top right of the README will display a table of contents."
  },
  {
    "objectID": "resources/writing-a-readme.html#what-should-go-in-a-readme",
    "href": "resources/writing-a-readme.html#what-should-go-in-a-readme",
    "title": "Writing an informative README",
    "section": "What should go in a README?",
    "text": "What should go in a README?\nFor this class, any README should have at least:\n\nGeneral information\nThis is where a general description of the repo would go. This could include (but is not limited to):\n\nnames of people working in the repo\n\nwhere the data came from\n\nbroad research questions and analyses to address those questions\n\n\n\nData and file overview\nThis is where a description of the data and files could go. For example, you could describe:\n\nthe data file format, when you accessed the data, etc.\n\nthe different code files and what they contain\n\n\n\nRendered output (specifically for this class, but nice to have in other README files too)\nFor 193DS assignments, you should put a link to the rendered .html file here so that it is easy to access.\n\n\n\n\n\n\nNote\n\n\n\nYou should have at least a “General information” section, a “Data and file overview” section, and a “Rendered output” section in your README for full credit.\n\n\nThere are also nice things to have, but for this class usually not necessary:\n\n\nSharing and accessing information\nThis is where any information regarding data/code reuse and access would go. This is mostly relevant if you’re working with your own data or data that your collaborators have collected.\n\n\nMethodological information\nThis is where any information about the methods used to collect, clean, or wrangle the data could go. If you do any cleaning/wrangling outside of the code (for example, directly in the .csv file), then you should describe what you did in this section.\n\n\nData-specific information\nThis is where the metadata would go if you don’t have a metadata file or sheet in your repository."
  },
  {
    "objectID": "resources/writing-a-readme.html#more-information-about-readme-files",
    "href": "resources/writing-a-readme.html#more-information-about-readme-files",
    "title": "Writing an informative README",
    "section": "More information about README files",
    "text": "More information about README files\n\nUCSB Library Data Service guide to writing a README\n\nCornell Data Service guide to writing “readme” stype metadata\n\nMatias Singers’s list of awesome READMEs and README 101"
  },
  {
    "objectID": "resources/communicating-results.html",
    "href": "resources/communicating-results.html",
    "title": "Clear communication = interpretable stats",
    "section": "",
    "text": "Obviously, this is a stats class - however, stats exists within the data science world, and data science includes communication about stats. It’s important for us, in this class, to understand the mechanics of the tests we use (assumptions, underlying math, etc.) but the real challenge is being able to communicate about those tests and ground what those tests reveal in the biology of the system we’re studying - that’s environmental science.\nCommunication about what statistical methods you use to address a question/answer a hypothesis should include writing along with some visualization (figures and/or tables). The following are examples from lecture. You’ve also done a lot of reading in this class, and have seen a lot of examples of how to communicate about statistics from other researchers.\nEach code chunk with what is potentially new information is annotated - however, I haven’t annotated things like tests, creating plots, etc. because we’ve gone over that in class.\n\n\nCode\n# general use\nlibrary(tidyverse)\n\n# data\nlibrary(palmerpenguins)\n\n# visualization\nlibrary(patchwork)\nlibrary(flextable)\n\n# model summary table tools\nlibrary(broom)\nlibrary(car)\nlibrary(ggeffects)\nlibrary(equatiomatic)\n\n# using the Lato font from Google fonts\nlibrary(showtext)\nfont_add_google(\"Lato\", \"Lato\")\nshowtext_auto()"
  },
  {
    "objectID": "resources/communicating-results.html#one-sample-t-test",
    "href": "resources/communicating-results.html#one-sample-t-test",
    "title": "Clear communication = interpretable stats",
    "section": "One sample t-test",
    "text": "One sample t-test\nThis example from lecture was about comparing a sample of acorn masses to a theoretical mean (2 g).\nJust generating some fake data for this example:\n\n\nCode\nset.seed(7)\nacorns &lt;- rnorm(n = 41, mean = 2, sd = 1)\n\n\n\nChecking assumptions\nFor a t-test, one of the assumptions you can check is that your variable is normally distributed. Doing this with a histogram and a QQ plot makes sense:\n\n\nCode\n```{r hist-and-qq}\n#| fig.width: 12\n#| fig.height: 6\n#| out.width: 90%\n#| fig.align: center\n\nhist &lt;- enframe(acorns) %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 7, fill = \"cornflowerblue\", color = \"#000000\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 11.5), breaks = c(0, 3, 6, 9, 12)) +\n  geom_vline(xintercept = 2, color = \"maroon\", lty = 2, linewidth = 1) +\n  theme_classic() +\n  labs(x = \"Acorn mass (g)\", y = \"Count\", \n       title = \"A)\") +\n  theme(plot.title.position = \"plot\")\n\nqq &lt;- enframe(acorns) %&gt;% \n  ggplot(aes(sample = value)) +\n  stat_qq_line(aes(sample = value)) +\n  stat_qq(aes(sample = value), color = \"cornflowerblue\", size = 3) +\n  theme_classic() +\n  labs(x = \"Theoretical quantiles\", y = \"Sample quantiles\",\n       title = \"B)\") +\n  theme(plot.title.position = \"plot\")\n\nhist + qq\n```\n\n\n\n\n\n\n\n\n\nExample caption:\n\nFigure 1. Visual checks for normally distributed variable. A) Histogram of acorn masses (g). Bars in histogram represent counts of acorns in each bin. Dashed red line represents theoretical mean (\\(\\mu\\) = 0). B) Quantile-quantile (QQ) plot. Points in QQ plot represent sample quantiles compared against theoretical quantiles from a normal distribution. Solid black line represents a 1:1 relationship between sample and theoretical quantiles.\n\n\n\n\n\n\n\nMaking sure your figures render properly\n\n\n\n\n\nYou put a lot of effort into making figures, so it’s worth making sure they appear the way you think they would in your final document! You can control these in your chunk options (i.e. within the curly brackets). There are many ways to do this, but I like adjusting the a) aspect ratio using fig.width and fig.height and b) proportion using out.width.\nIn Quarto, you can set those options within the chunk (see above) or in the curly brackets. In RMarkdown, you can only use the curly brackets, which would look like:\n{r fig.width = 12, fig.height = 6, out.width = \"90%\", fig.align = \"center\"}\n\n\n\n\n\n\n\n\n\nFormatting captions\n\n\n\n\n\nYou can write a caption in text (the easiest way) or you can try using code chunk options if you’re using Quarto. There are tips for how to do that here, though the formatting might not be the standard (i.e. bold text for figure number and title). I also changed the caption color - not required, but nice to add another visual cue that the caption is attached to the figure.\nGenerally, the font size in captions tends to be smaller than the main text. You can insert these options in Quarto by wrapping your text in a “fenced div” (see the source code for how to do that). In RMarkdown, you can use an HTML wrapper (here’s an example).\n\n\n\nExample text:\nWe visually assessed normality using a histogram and a QQ plot (Figure 1), and determined that acorn mass in our sample was normally distributed.\n\n\nTest\n\n\nCode\nacorn_test &lt;- t.test(acorns, mu = 2)\n\n\nExample text:\nWe assessed whether acorn masses in our sample differed from the claim of 2g using a one-sample two-tailed t-test. Our null hypothesis was that the mean acorn mass in our sample was the same as the claim.\n\n\nTest results\n\n\nCode\nacorn_test\n\n\n\n    One Sample t-test\n\ndata:  acorns\nt = 1.8035, df = 40, p-value = 0.07885\nalternative hypothesis: true mean is not equal to 2\n95 percent confidence interval:\n 1.964535 2.623323\nsample estimates:\nmean of x \n 2.293929 \n\n\nExample text:\nWe collected 41 acorns and found no significant difference between our sample mean mass and the claim (One-sample two-tailed t-test, t(40) = 1.8, \\(\\alpha\\) = 0.05, p = 0.079). Our data suggest that acorn masses in our sampling area are on average the same mass as the claimed mass (Figure 1A)."
  },
  {
    "objectID": "resources/communicating-results.html#chi-square",
    "href": "resources/communicating-results.html#chi-square",
    "title": "Clear communication = interpretable stats",
    "section": "Chi-square",
    "text": "Chi-square\nThis example from lecture was about surveying people to understand their priorities for restoration.\nAgain, generating fake data:\n\n\nCode\n# making a matrix (not a data frame) called `survey` ----\nsurvey &lt;- tribble(\n  ~distance, ~trails, ~dog_access, ~wildlife_habitat,\n  \"walking_distance\", 55, 38, 33,\n  \"driving_distance\", 41, 25, 29,\n  \"out_of_town\", 22, 27, 45\n) %&gt;% \n  \n  # turning the column `distance` into the matrix rownames ----\n  column_to_rownames(\"distance\")\n\n\n\nTest\n\n\nCode\nsurvey_test &lt;- chisq.test(survey)\n\n\nExample text:\nTo determine whether there was a relationship between living distance from wetland and restoration priority, we used a chi-square test using survey data from visitors (Table 1). Our null hypothesis was that there was no relationship between living distance from the wetland and restoration priority.\n\n\nTable\nExample caption:\nNote: Table captions usually go above the table.\n\nTable 1. Wetland restoration priority by living distance. Numbers in parentheses indicate proportion of responses (i.e. the 55 respondents living within walking distance of the wetland who prioritize trail development represent 44% of the total number of respondents living within walking distance (n = 126)).\n\n\n\nCode\n# calculate proportions\nsurvey_summary &lt;- survey %&gt;% \n  # turning `survey` into a data frame ----\n  as_tibble(rownames = \"distance\") %&gt;% \n  # making it long format\n  pivot_longer(cols = trails:wildlife_habitat, names_to = \"responses\", values_to = \"counts\") %&gt;% \n  \n  # calculating proportions ----\n  # grouping by living distance\n  group_by(distance) %&gt;% \n  # counting the total number of respondents per living distance\n  mutate(sum = sum(counts)) %&gt;% \n  # ungrouping to make sure that distance groups don't mess up downstream functions\n  ungroup() %&gt;% \n  # calculating proportion of responses per living distance\n  mutate(prop = counts/sum) %&gt;% \n  \n  # making the table look nicer ----\n  # making a new column where counts and proportions are displayed together\n  mutate(text = paste0(counts, \" (\", round(prop, digits = 2), \")\")) %&gt;% \n  # selecting columns of interest\n  select(distance, responses, text) %&gt;% \n  # making the data frame wider so that the columns are responses and rows are distance\n  pivot_wider(names_from = \"responses\", values_from = \"text\") %&gt;% \n  # making the row labels nicer\n  mutate(distance = case_match(\n    distance,\n    \"walking_distance\" ~ \"Walking distance\",\n    \"driving_distance\" ~ \"Driving distance\",\n    \"out_of_town\" ~ \"Out of town\"\n  )) %&gt;% \n  \n  # turning everything into a table ----\n  flextable() %&gt;% \n  # changing the column names to look nicer\n  set_header_labels(distance = \"Living distance\",\n                    trails = \"Trails\",\n                    dog_access = \"Dog access\",\n                    wildlife_habitat = \"Wildlife habitat\") %&gt;% \n  # making the table fit the viewer window\n  autofit()\n  \nsurvey_summary\n\n\nLiving distanceTrailsDog accessWildlife habitatWalking distance55 (0.44)38 (0.3)33 (0.26)Driving distance41 (0.43)25 (0.26)29 (0.31)Out of town22 (0.23)27 (0.29)45 (0.48)\n\n\n\n\n\n\n\n\nWarning\n\n\n\nRemember not to name code chunks with tables in them! Rendering gets stuck on the chunk if you do.\n\n\n\n\nTest results\n\n\nCode\nsurvey_test\n\n\n\n    Pearson's Chi-squared test\n\ndata:  survey\nX-squared = 15.276, df = 4, p-value = 0.004162\n\n\nExample text:\nBased on responses from individuals living within walking distance (n = 126), within driving distance (n = 95), and out of town (n = 94), restoration priorities differ significantly by living distance category (Table 1, \\(\\chi^2\\)(4) = 15.3, p = 0.004, \\(\\alpha\\) = 0.05).\nWhile the majority of residents within walking distance and driving distance prioritize trail use (44% and 43% respectively), residents outside the city prioritize wildlife habitat (48%).\nThese results indicate that wetland users living outside the city may have different intentions for visiting the wetland than local residents, but that restorationists can consider both trails and wildlife habitat in designing a restoration plan to suit user needs."
  },
  {
    "objectID": "resources/communicating-results.html#analysis-of-variance",
    "href": "resources/communicating-results.html#analysis-of-variance",
    "title": "Clear communication = interpretable stats",
    "section": "Analysis of variance",
    "text": "Analysis of variance\nThis example from lecture used the penguins data set from {palmerpenguins}.\n\nChecking assumptions\nFor ANOVA, you should be checking that your variable is normally distributed and that your groups have equal variances. You can check the first assumption visually using histograms and QQ plots:\n\n\nCode\n```{r penguin-hist-and-qq}\n#| fig.height: 12\n#| fig.width: 10\n#| out.width: 60%\n#| fig.align: center\n\n# setting some color options\ncol1 &lt;- \"cornflowerblue\"\ncol2 &lt;- \"orange\"\ncol3 &lt;- \"darkgreen\"\n\n# making separate data frames for each species\nadelie &lt;- penguins %&gt;% \n  filter(species == \"Adelie\")\n\nchinstrap &lt;- penguins %&gt;% \n  filter(species == \"Chinstrap\")\n\ngentoo &lt;- penguins %&gt;% \n  filter(species == \"Gentoo\")\n\n# making histograms for each species\n\nadelie_hist &lt;- ggplot(data = adelie, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 10, fill = col1, color = col1, alpha = 0.8) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 32)) +\n  labs(x = \"Bill length (mm)\", y = \"Count\",\n       title = \"A)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\nchinstrap_hist &lt;- ggplot(data = chinstrap, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 10, fill = col2, color = col2, alpha = 0.8) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 23)) +\n  labs(x = \"Bill length (mm)\", y = \"Count\",\n       title = \"C)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\ngentoo_hist &lt;- ggplot(data = gentoo, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 10, fill = col3, color = col3, alpha = 0.8) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 37)) +\n  labs(x = \"Bill length (mm)\", y = \"Count\",\n       title = \"E)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\n# making QQ plots for each species\nadelie_qq &lt;- ggplot(data = adelie, aes(sample = bill_length_mm)) +\n  stat_qq_line(linewidth = 1) +\n  stat_qq(col = col1) +\n  labs(x = \"Theoretical\", y = \"Sample\",\n       title = \"B)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\nchinstrap_qq &lt;- ggplot(data = chinstrap, aes(sample = bill_length_mm)) +\n  stat_qq_line(linewidth = 1) +\n  stat_qq(col = col2) +\n  labs(x = \"Theoretical\", y = \"Sample\",\n       title = \"D)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\ngentoo_qq &lt;- ggplot(data = gentoo, aes(sample = bill_length_mm)) +\n  stat_qq_line(linewidth = 1) +\n  stat_qq(col = col3) +\n  labs(x = \"Theoretical\", y = \"Sample\",\n       title = \"F)\") +\n  theme_bw() +\n  theme(panel.grid = element_blank(),\n        axis.text = element_text(size = 18),\n        axis.title = element_text(size = 18),\n        axis.ticks = element_blank(),\n        text = element_text(family = \"Lato\"),\n        plot.title.position = \"plot\") \n\n# putting all the plots together using `patchwork`\n\n(adelie_hist + adelie_qq) / (chinstrap_hist + chinstrap_qq) / (gentoo_hist + gentoo_qq)\n```\n\n\n\n\n\n\n\n\n\nExample caption:\n\nFigure 2. Visual checks for normally distributed variable. Visual checks for normally distributed variable. A, C, E) Histograms of penguin bill length (mm) for Adelie (A), Chinstrap (C), and Gentoo (E) penguins. Bars represent counts of bill lengths in each bin. B, D, F) QQ plots of penguin bill length. Points in QQ plot represent sample quantiles compared against theoretical quantiles from a normal distribution. Solid black lines represent a 1:1 relationship between sample and theoretical quantiles.\n\nNow a series of Shapiro-Wilk tests to statistically test for normal distribution:\n\n\nCode\nshapiro.test(adelie$bill_length_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  adelie$bill_length_mm\nW = 0.99336, p-value = 0.7166\n\n\nCode\nshapiro.test(chinstrap$bill_length_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  chinstrap$bill_length_mm\nW = 0.97525, p-value = 0.1941\n\n\nCode\nshapiro.test(gentoo$bill_length_mm)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  gentoo$bill_length_mm\nW = 0.97272, p-value = 0.01349\n\n\n\n\n\n\n\n\nMaking decisions about normality\n\n\n\n\n\nIn lecture, we talked about making a decision: do you think this deviation from normality is a big enough deal or not? ANOVA is fairly robust against violations of the normality assumption, and we have a lot of observations. We might decide to continue with the ANOVA (especially since the variances between groups are equal - see below). However, you could also try a transformation (e.g. a log transformation) on bill length, and see if that fixes your problem.\n\n\n\nChecking for equal variances:\n\n\nCode\nleveneTest(bill_length_mm ~ species, data = penguins)\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)\ngroup   2  2.2425 0.1078\n      339               \n\n\nExample text:\n Prior to our analysis, we checked assumptions for analysis of variance. We tested for equality of variances between groups using Levene’s test and found no statistically significant differences in variances between groups (F(2, 339) = 2.24, p = 0.11, \\(\\alpha\\) = 0.05). We visually assessed normality using histograms and QQ plots (Figure 2) and statistically tested for normality of penguin bill length using Shapiro-Wilk tests for each species. Adelie and Chinstrap bill length did not indicate any deviations from normality (Adelie: W W = 0.99, p = 0.72; Chinstrap: W = 0.98, p = 0.19), but Gentoo bill length did (W = 0.97, p = 0.01). Taking this together, we decided to continue using analysis of variance given our sample size (n = 342) and that analysis of variance tends to be robust to slight violations of the normality assumption.Note that you only really need to state your \\(\\alpha\\) once in a report. The assumption is that you’re not changing your significance level for each test.\n\n\nTest\nANOVA:\n\n\nCode\npenguins_anova &lt;- aov(bill_length_mm ~ species, data = penguins)\n\n\nTukey HSD:\n\n\nCode\npenguins_HSD &lt;- TukeyHSD(penguins_anova)\n\n\nExample text:\nWe tested for differences between penguin species in bill length using analysis of variance. Our null hypothesis was that species did not differ in mean bill length. We used Tukey’s Honestly Significant Difference (Tukey HSD) as a post-hoc test to determine pair-wise differences between groups.\n\n\nTest results\n\n\nCode\npenguins_anova\n\n\nCall:\n   aov(formula = bill_length_mm ~ species, data = penguins)\n\nTerms:\n                 species Residuals\nSum of Squares  7194.317  2969.888\nDeg. of Freedom        2       339\n\nResidual standard error: 2.959853\nEstimated effects may be unbalanced\n2 observations deleted due to missingness\n\n\nANOVA table:\nExample caption:\n\nTable 2. ANOVA table. Bolded p-value indicates significance.\n\n\n\nCode\n# getting table from ANOVA object ----\ntidy(penguins_anova) %&gt;% \n  # changing very small p-values to &lt; 0.001\n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\"\n  )) %&gt;%\n  # rounding values in numerical columns to 1 decimal point\n  mutate(across(sumsq:statistic, ~ round(.x, digits = 1))) %&gt;% \n  # changing the row names to be nicer (capitalizing Species)\n  mutate(term = case_match(\n    term, \n    \"species\" ~ \"Species\",\n    .default = term\n  )) %&gt;% \n  \n  # turning the data frame into a flextable ----\n  flextable() %&gt;% \n  # changing the column names to be nicer\n  set_header_labels(term = \"Source of variation\",\n                    df = \"Degrees of freedom\",\n                    sumsq = \"Sum of squares\",\n                    meansq = \"Mean squares\",\n                    statistic = \"F-statistic\",\n                    p.value = \"p-value\") %&gt;% \n  # making small p-values bold\n  bold(~ p.value == \"&lt; 0.001\", 6) %&gt;% \n  # fitting the table to the viewer\n  autofit()\n\n\nSource of variationDegrees of freedomSum of squaresMean squaresF-statisticp-valueSpecies27,194.33,597.2410.6&lt; 0.001Residuals3392,969.98.8\n\n\nTukey HSD results:\n\n\nCode\npenguins_HSD\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = bill_length_mm ~ species, data = penguins)\n\n$species\n                      diff       lwr        upr     p adj\nChinstrap-Adelie 10.042433  9.024859 11.0600064 0.0000000\nGentoo-Adelie     8.713487  7.867194  9.5597807 0.0000000\nGentoo-Chinstrap -1.328945 -2.381868 -0.2760231 0.0088993\n\n\nExample text (if you decided not to make a table:\n We found a significant difference in bill length across species (analysis of variance, F(2, 339) = 410.6, p &lt; 0.001). Adelie penguins tend to have the shortest bills: on average, Gentoo penguins have 8.7 mm (Tukey HSD 95% confidence interval: [7.9, 9.6] mm) longer bills than Adelie penguins, and Chinstrap penguins have 10.0 mm ([9.0, 11.1] mm) longer bills than Adelie penguins.If you decide not to go with a table, the F-statistic, degrees of freedom, and p-value should be in parentheses. This is the only difference between this example and the one below.\nExample text (with a table):\nWe found a significant difference in bill length across species (Table 2). Adelie penguins tend to have the shortest bills: on average, Gentoo penguins have 8.7 mm (Tukey HSD 95% confidence interval: [7.9, 9.6] mm) longer bills than Adelie penguins, and Chinstrap penguins have 10.0 mm ([9.0, 11.1] mm) longer bills than Adelie penguins."
  },
  {
    "objectID": "resources/communicating-results.html#linear-models",
    "href": "resources/communicating-results.html#linear-models",
    "title": "Clear communication = interpretable stats",
    "section": "Linear models",
    "text": "Linear models\nThis first example was from lecture. We only talked about the equation and significant predictors, but I’ll break it down further here.\nGenerating data:\n\n\nCode\nset.seed(666)\n# sample size\nn &lt;- 64\nplant_df &lt;- tibble(\n  # predictor variables\n  temperature = round(rnorm(n = n, mean = 28, sd = 1), digits = 1),\n  light = round(rnorm(n = n, mean = 1, sd = 0.2), digits = 1),\n  ph = rnorm(n = n, mean = 7, sd = 0.01),\n  \n  # response: growth in cm/week\n  growth = light*rnorm(n = n, mean = 0.3, sd = 0.1) + temperature/round(rnorm(n = n, mean = 5, sd = 0.1))\n) \n\n\n\nBuilding a model\n\n\nCode\nplant_model &lt;- lm(growth ~ light + temperature + ph, data = plant_df)\n\n\nDiagnostics:\nI changed the chunk options for this to make sure it displayed correctly - see the code chunk! I also chose which plots to plot using the which() function, and added a title to each using title(). The syntax is a little different from a standard ggplot() figure because these are all done in base R, but labelling plots is an option.\n\n\nCode\n```{r plant-diagnostics}\n#| fig-width: 10\n#| fig-height: 10\n#| out.width: 90%\n#| fig.align: center\n\npar(mfrow = c(2, 2))\nplot(plant_model, which = c(1))\ntitle(\"A)\", adj = 0)\nplot(plant_model, which = c(2))\ntitle(\"B)\", adj = 0)\nplot(plant_model, which = c(3))\ntitle(\"C)\", adj = 0)\nplot(plant_model, which = c(5))\ntitle(\"D)\", adj = 0)\n```\n\n\n\n\n\n\n\n\n\nExample caption:\n\nFigure 3. Model diagnostic plots. In all plots, points represent residuals. Red lines (residuals vs fitted, scale-location, and residuals vs leverage) are lines depicting patterns in residuals. Grey dashed lines represent reference lines.\n\nExample text:\nWe tested the predictive relationship between plant growth and light, temperature, and soil pH using a linear model. Our null hypothesis was that none of these variables would predict plant growth. We used diagnostic plots to visually assess residual normality (Figure 3B) and homoskedasticity (Figures 3A and 3C). Additionally, we determined there were no outliers influencing our model predictions using Cook’s distance (Figure 3D).\n\n\nModel predictions\nJust to see what the original summary object is:\n\n\nCode\nsummary(plant_model)\n\n\n\nCall:\nlm(formula = growth ~ light + temperature + ph, data = plant_df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23209 -0.06571  0.01010  0.06173  0.19950 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -6.67140    6.80194  -0.981    0.331    \nlight        0.35196    0.05939   5.926 1.63e-07 ***\ntemperature  0.19626    0.01058  18.558  &lt; 2e-16 ***\nph           0.96241    0.96806   0.994    0.324    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0911 on 60 degrees of freedom\nMultiple R-squared:  0.8759,    Adjusted R-squared:  0.8696 \nF-statistic: 141.1 on 3 and 60 DF,  p-value: &lt; 2.2e-16\n\n\nTable option 1:\n\nTable 3. Model prediction table. Bolded p-value indicates significant difference from 0.\n\n\n\nCode\nplant_model %&gt;%\n  # turning the model object into a flextable ----\n  as_flextable() %&gt;% \n  \n  # changing the row labels using `compose()` ----\n  # i selects the row, j selects the column\n  compose(i = 2, j = 1, \n          # value is whatever you want to change the text to\n          value = as_paragraph(\n            # `as_sup()` makes something a superscript - good for units etc.\n            \"Light (watts/m\", as_sup(\"2\"), \")\"\n          )) %&gt;% \n  compose(i = 3, j = 1, \n          value = as_paragraph(\n            \"Temperature (°C)\"\n          )) %&gt;% \n  compose(i = 4, j = 1, \n          value = as_paragraph(\n            \"pH\"\n          )) %&gt;% \n  \n  # formatting the numbers to display to 3 decimal points ----\n  set_formatter(estimate = function(x) sprintf(\"%.03f\", x),\n                std.error = function(x) sprintf(\"%.03f\", x),\n                statistic = function(x) sprintf(\"%.03f\", x),\n                p.value = function(x) sprintf(\"%.03f\", x)) %&gt;% \n  \n  # changing the p.value to display as &lt; 0.001 when very small ----\n  compose(j = \"p.value\", i = ~ p.value &lt; 0.001,\n          value = as_paragraph(\n            \"&lt; 0.001\"\n          )) %&gt;% \n  \n  # adding model equation at the top ----\n  # inserting new header row (to make space for equation)\n  add_header_lines(\"\", top = TRUE) %&gt;% \n  # putting in equation\n  compose(\n    # choosing row 1, column 1, indicating that is a header\n    j = 1, i = 1, part = \"header\",\n    # putting in the equation using as_equation and extract_eq from {equatiomatic}\n    value = as_paragraph(\n      as_equation(extract_eq(plant_model), \n                  # formatting equation\n                  width = 2, height = .5)\n    )) %&gt;% \n  # making sure the equation is centered on the table\n  align(i = 1, part = \"header\", align = \"center\") %&gt;% \n  \n  # formatting header labels ----\n  set_header_labels(statistic = \"t-statistic\",\n                    p.value = \"p-value\") %&gt;% \n  \n  # making cells bold when p.value &lt; 0.05 ----\n  bold(i = ~ p.value &lt; .05, j = \"p.value\") %&gt;% \n  \n  # making table fit viewer ----\n  autofit()\n\n\n\ngrowth⁡=α+β1(light⁡)+β2(temperature⁡)+β3(ph⁡)+ϵ\\operatorname{growth} = \\alpha + \\beta_{1}(\\operatorname{light}) + \\beta_{2}(\\operatorname{temperature}) + \\beta_{3}(\\operatorname{ph}) + \\epsilongrowth=α+β1​(light)+β2​(temperature)+β3​(ph)+ϵEstimateStandard Errort-statisticp-value(Intercept)-6.6716.802-0.9810.331   Light (watts/m2)0.3520.0595.926&lt; 0.001***Temperature (°C)0.1960.01118.558&lt; 0.001***pH0.9620.9680.9940.324   Signif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05Residual standard error: 0.0911 on 60 degrees of freedomMultiple R-squared: 0.8759, Adjusted R-squared: 0.8696F-statistic: 141.1 on 60 and 3 DF, p-value: 0.0000\n\n\n\n\n\n\n\n\nIncluding tables and full tables with {flextable}\n\n\n\n\n\nWhen writing about models, you have to make decisions about whether or not you want to include a table of the model summary. In multiple linear regression (and for more complex models), it’s a good idea to include a table of the model summary.\nIf you wanted to make a table of the model estimates and the relevant information at the bottom of that summary (for example, \\(R^2\\), F-statistic, degrees of freedom, etc.), you could use flextable::as_flextable() which takes the model object - this is Table 3. This skips the step of creating an intermediate data frame and just turns everything into a flextable object. However, this can be a bit tricky: the formatting to make it look “good” takes some getting used to. You can go either way, but this is one option if you’d rather condense the information from the model prediction table and ANOVA table into one. It is also somewhat easier to interpret than the model prediction + ANOVA table combo (Tables 4 + 5).\n\n\n\nTable option 2:\nTable 4. Model prediction table. Bolded p-value indicates significance.\n\n\nCode\nplant_model %&gt;% \n  tidy() %&gt;% \n  mutate(across(estimate:p.value, ~round(.x, digits = 3))) %&gt;% \n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\",\n    TRUE ~ as.character(p.value)\n  )) %&gt;% \n  flextable() %&gt;% \n  # changing the row labels using `compose()`\n  compose(i = 2, j = 1, \n          value = as_paragraph(\n            \"Light (watts/m\", as_sup(\"2\"), \")\"\n          )) %&gt;% \n  compose(i = 3, j = 1, \n          value = as_paragraph(\n            \"Temperature (°C)\"\n          )) %&gt;% \n  compose(i = 4, j = 1, \n          value = as_paragraph(\n            \"pH\"\n          )) %&gt;% \n  # formatting header labels\n  set_header_labels(term = \"Term\",\n                    estimate = \"Estimate\",\n                    std.error = \"Standard error\",\n                    statistic = \"t-statistic\",\n                    p.value = \"p-value\") %&gt;% \n  bold(j = 5, i = ~p.value == \"&lt; 0.001\") %&gt;% \n  autofit()\n\n\nTermEstimateStandard errort-statisticp-value(Intercept)-6.6716.802-0.9810.331Light (watts/m2)0.3520.0595.926&lt; 0.001Temperature (°C)0.1960.01118.558&lt; 0.001pH0.9620.9680.9940.324\n\n\nANOVA table:\nTable 5. Model ANOVA table. Bolded p-value indicates significant difference from 0.\n\n\nCode\nAnova(plant_model) %&gt;% \n  tidy() %&gt;% \n  mutate(across(sumsq:p.value, ~round(.x, digits = 3))) %&gt;% \n  mutate(p.value = case_when(\n    p.value &lt; 0.001 ~ \"&lt; 0.001\",\n    TRUE ~ as.character(p.value)\n  )) %&gt;% \n  flextable() %&gt;% \n  # changing the row labels using `compose()`\n  compose(i = 1, j = 1, \n          value = as_paragraph(\n            \"Light (watts/m\", as_sup(\"2\"), \")\"\n          )) %&gt;% \n  compose(i = 2, j = 1, \n          value = as_paragraph(\n            \"Temperature (°C)\"\n          )) %&gt;% \n  compose(i = 3, j = 1, \n          value = as_paragraph(\n            \"pH\"\n          )) %&gt;% \n  # formatting header labels\n  set_header_labels(term = \"Source of variation\",\n                    sumsq = \"Sum of squares\",\n                    df = \"Degrees of freedom\",\n                    statistic = \"F-statistic\",\n                    p.value = \"p-value\") %&gt;% \n  bold(j = 5, i = ~p.value == \"&lt; 0.001\") %&gt;% \n  autofit()\n\n\nSource of variationSum of squaresDegrees of freedomF-statisticp-valueLight (watts/m2)0.291135.122&lt; 0.001Temperature (°C)2.8581344.412&lt; 0.001pH0.00810.9880.324Residuals0.49860\n\n\n\n\nVisualization\n\n\nCode\ntemp_pred &lt;- ggpredict(plant_model, terms = \"temperature\")\n\nlight_pred &lt;- ggpredict(plant_model, terms = \"light\")\n\ntemp_plot &lt;- ggplot(data = plant_df, aes(x = temperature, y = growth)) +\n  geom_point() +\n  geom_ribbon(data = temp_pred, aes(x = x, y = predicted, ymin = conf.low, ymax = conf.high), alpha = 0.2) +\n  geom_line(data = temp_pred, aes(x = x, y = predicted), color = \"blue\", linewidth = 1) +\n  theme_classic() +\n  labs(x = \"Temperature (°C)\", y = \"Growth (cm/week)\",\n       title = \"A)\") +\n  theme(plot.title.position = \"plot\",\n        text = element_text(size = 15))\n\nlight_plot &lt;- ggplot(data = plant_df, aes(x = light, y = growth)) +\n  geom_point() +\n  geom_ribbon(data = light_pred, aes(x = x, y = predicted, ymin = conf.low, ymax = conf.high), alpha = 0.2) +\n  geom_line(data = light_pred, aes(x = x, y = predicted), color = \"darkorange\", linewidth = 1) +\n  theme_classic() +\n  labs(x = expression(paste(\"Light (watts/\"~m^2~\")\")), y = \"Growth (cm/week)\",\n       title = \"B)\") +\n  theme(plot.title.position = \"plot\",\n        text = element_text(size = 15))\n\ntemp_plot + light_plot\n\n\n\n\n\n\n\n\n\nExample caption:\n\nFigure 4. Predicted growth as a function of A) temperature and B) light. In both panels, points represent observations, colored lines represent model predictions, and shaded areas represent 95% confidence intervals. In A), growth is predicted as a function of temperature for a constant light level of 0.98 watts/m2 and pH 7. In B), growth is predicted as a function of light for a constant temperature of 27.9 °C and pH 7.\n\n\n\n\n\n\n\nUnderstanding predictions\n\n\n\n\n\nRemember that for multiple linear regression, the slopes represent change in the response variable for each 1 unit change in the predictor for all else held constant. When getting model estimates for slopes, the “constant” values are the mean of the variable. When using ggeffects::ggpredict(), these values are printed below the prediction table (you can double check this by calculating the mean yourself!).\n\n\n\n\n\nTest results\nExample text:\nWe found that light and temperature significantly predicted plant growth, but not pH (Table 3). The overall model accounted for 87% of the variance in plant growth. For each 1 °C increase in temperature at constant light and pH, we expect 0.20 \\(\\pm\\) 0.01 increase in plant growth (Figure 4A). For each 1 watt/m2 increase in light at constant temperature and pH, we expect a 0.35 \\(\\pm\\) 0.06 increase in plant growth (Figure 4B).\n\n\n\n\n\n\nChoosing which parameters to highlight\n\n\n\n\n\nWith multiple linear regression and generalized linear models, you’re usually working with pretty complex model structure. It’d be impossible (and not that interesting, necessarily) to discuss all the predictors. You can choose which one(s) you want to highlight in your visualizations and text based on what you think is most interesting/biologically relevant."
  },
  {
    "objectID": "lecture.html",
    "href": "lecture.html",
    "title": "Lecture visualizations",
    "section": "",
    "text": "Order By\n       Default\n         \n          Lecture date - Oldest\n        \n         \n          Lecture date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nLecture date\n\n\n\n\n\n\nWeek 1 figures - Lectures 1 and 2\n\n\nApr 1, 2024\n\n\n\n\n\nWeek 2 figures - Lectures 3 and 4\n\n\n\nApr 8, 2024\n\n\n\n\n\n\nWeek 3 figures - Lectures 5 and 6\n\n\n\nApr 16, 2024\n\n\n\n\n\nWeek 4 figures - Lectures 7 and 8\n\n\nApr 21, 2024\n\n\n\n\nWeek 5 figures - Lectures 9 and 10\n\n\nApr 29, 2024\n\n\n\n\nWeek 6 figures - Lecture 11\n\n\nMay 6, 2024\n\n\n\n\nWeek 7 figures - Lectures 12 and 13\n\n\nMay 13, 2024\n\n\n\n\nWeek 8 figures - Lectures 14 and 15\n\n\nMay 21, 2024\n\n\n\n\nWeek 10 figures - Lectures 17 and 18\n\n\nJun 3, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "weekly-materials.html",
    "href": "weekly-materials.html",
    "title": "Weekly materials",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nWeek 1 materials\n\n\nApr 1, 2024\n\n\n\n\n\nNo matching items"
  }
]