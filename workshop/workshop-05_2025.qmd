---
title: "Coding workshop: Week 5"
subtitle: "Parametric and non-parametric comparisons of more than 2 groups"
categories: [tidyverse, lterdatasampler, effectsize, rstatix, car, shapiro.test, leveneTest, aov, summary, TukeyHSD, eta_squared, kruskal.test, dunn_test, kruskal_effectsize, read_csv, pipe operators, '|>', select, rename, ggplot, geom_histogram, geom_qq, geom_qq_line, facet_wrap, group_by, summarize, as_factor, mutate]
format:
  html:
    toc: true
    toc-depth: 8
---

[Workshop dates: May 1 (Thursday), May 2 (Friday)]{style="color: #79ACBD; font-size: 24px;"}

## 1. Summary

### Packages
- `tidyverse`  
- `lterdatasampler`  
- `rstatix`  
- `car`  

### Operations

#### New functions

- make sure a variable is a factor using `as_factor()`
- do a Shapiro-Wilk test using `shapiro.test()`  
- do a Levene's test using `car::leveneTest()`  
- do an ANOVA using `aov()`  
- look for more information from model results using `summary()`  
- do post-hoc Tukey test using `TukeyHSD()`  
- calculate effect size for ANOVA using `rstatix::eta_squared()`  
- do Kruskal-Wallis test using `kruskal.test()`  
- do Dunn's test using `rstatix::dunn_test()`  
- calculate effect size for Kruskal-Wallis test using `rstatix::kruskal_effsize()`

#### Review

- read in data using `read_csv()`  
- chain functions together using ` |> `  
- modify columns using `mutate()`  
- select columns using `select()`  
- rename columns using `rename()`  
- visualize data using `ggplot()`  
- create histograms using `geom_histogram()`  
- visualize QQ plots using `geom_qq()` and `geom_qq_line()`  
- create multi-panel plots using `facet_wrap()`  
- group data using `group_by()`  
- summarize data using `summarize()`  

### Data sources

The Plum Island Ecosystem fiddler crab data is from `lterdatasampler` (data info [here](https://lter.github.io/lterdatasampler/articles/pie_crab_vignette.html)). The ramen ratings data set is a Tidy Tuesday dataset - see more about the data and its source [here](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-06-04).

## 2. Code

### 1. Packages

```{r read-packages}
#| eval: false

library(tidyverse)
library(lterdatasampler)
library(effectsize)
library(rstatix)
library(car)

# for parametric tests
data(pie_crab)

# for non-parametric tests
ramen_ratings <- read_csv("ramen_ratings.csv")
```

```{r data-for-website}
#| echo: false
#| message: false

library(tidyverse)
library(lterdatasampler)
library(effectsize)
library(rstatix)
library(car)

# for parametric tests
data(pie_crab)

ramen_ratings <- read_csv(here::here("workshop", "data", "ramen_ratings.csv"))
```


### 2. Parametric tests

#### a. Cleaning and wrangling

- Create a new object called `pie_crab_clean`.
- Filter to only include the following sites: Cape Cod, Virginia Coastal Reserve LTER, and Zeke's Island NERR.
- Make sure `site` is a factor.
- Select the columns of interest: `site`, `name`, and `code`.
- Rename the column `name` to `site_name` and `code` to `site_code`. 

```{r crab-cleaning}
pie_crab_clean <- pie_crab |> # start with the pie_crab dataset
  filter(site %in% c("CC", "ZI", "VCR")) |> # filter for Cape Cod, Zeke's Island, Virginia Coastal
  mutate(name = as_factor(name)) |> # make sure site name is being read in as a factor
  select(site, name, size) |> # select columns of interest
  rename(site_code = site, # rename site to be site_code
         site_name = name) # rename name to be site_name
```

#### b. Quick summary

- Create a new object called `pie_crab_summary`.
- Calculate the mean, variance, and sample size. Display the object.

```{r crab-summary}
# creating a new object called pie_crab_summary
pie_crab_summary <- pie_crab_clean |> # starting with clean data frame
  group_by(site_name) |> # group by site
  summarize(mean = mean(size), # calculate mean size
            var = var(size), # calculate variance of size
            n = length(size)) # calculate number of observations per site (sample size)

# display pie_crab_summary
pie_crab_summary
```

#### c. Exploring the data

Create a jitter plot with the mean crab size for each site.

```{r crab-explore-viz}
# base layer: ggplot
ggplot(pie_crab_clean, # use the clean data set
       aes(x = site_name, # x-axis
           y = size)) + # y-axis
  # first layer: jitter (each point is an individual crab)
  geom_jitter(height = 0, # don't jitter points vertically
              width = 0.15) + # narrower jitter (easier to see)
  # second layer: point representing mean
  stat_summary(geom = "point", # geometry being plotted
               fun = mean, # function (calculating the mean)
               color = "red", # color to make it easier to see
               size = 5) + # larger point size
  theme_minimal() # cleaner plot theme
```

Is there a difference in mean crab size between the three sites?  

**Yes, and Zeke's Island NERR crabs tend to be smaller than those from Cape Cod or Virginia Coastal Reserve LTER.**

#### d. Check 1: normally distributed variable

- Create a histogram of crab size.
- Facet your histogram so that you have 3 panels, with one panel for each site.

```{r crab-histogram}
# base layer: ggplot
ggplot(data = pie_crab_clean, 
       aes(x = size)) + # x-axis
  # first layer: histogram
  geom_histogram(bins = 9) + # number of bins from Rice Rule
  # faceting by site_name: creating 3 different panels
  facet_wrap(~ site_name) 
```

- Create a QQ plot of crab size. 
- Facet your QQ plot so that you have 3 panels, with one panel for each site.

```{r crab-qq}
# base layer: ggplot
ggplot(data = pie_crab_clean, 
       aes(sample = size)) + # y-axis
  # first layer: QQ plot reference line
  geom_qq_line(color = "orange") + 
  # second layer: QQ plot points (actual observations)
  geom_qq() + 
  # faceting by site_name
  facet_wrap(~ site_name, 
             scales = "free") # let axes vary between panels
```

What are the outcomes of your visual checks?  

**Not perfect (crab sizes from VCR LTER seem not normally distributed) but with large sample sizes for each group, this might not matter too much.**  

Do Shapiro-Wilk tests:

```{r crab-normality-test}
cc_crabs <- pie_crab_clean |> # use the original data set
  filter(site_code == "CC") |> # filter to only include Cape Cod
  pull(size) # extract the size column as a vector

vcr_crabs <- pie_crab_clean |> 
  filter(site_code == "VCR") |> # filter to only include Virginia Coastal
  pull(size)

zi_crabs <- pie_crab_clean |> 
  filter(site_code == "ZI") |> # filter to only include Zeke's Island
  pull(size)

# do the Shapiro-Wilk tests
shapiro.test(cc_crabs)
shapiro.test(vcr_crabs)
shapiro.test(zi_crabs)
```

What are the outcomes of your statistical checks?  

**With Shapiro-Wilk normality tests, there seems to be no deviation from normality for Cape Cod crab sizes (W = 0.9, p = 0.09), VCR LTER crab sizes (W = 0.9, p = 0.12), or Zeke's Island crab sizes (W = 1, p = 0.6).**  

#### e. Check 2: equal variances

Do a gut check: is the largest variance less than 4Ã— the smallest variance?

```{r crab-variances}
4.04*4 > 8.63
```

Using `leveneTest()` from `car`

```{r crab-levene}
# do the Levene test
leveneTest(
  size ~ site_name, # formula: crab size as a function of site
  data = pie_crab_clean # data frame
)
```

What are the outcomes of your variance check?  

**There's a deviation from homogeneity of variance (in other words, the variances are not equal), but since the largest variance is less than 4 times the smallest variance (and the sample sizes are large), this may still be ok.**

#### f. ANOVA

```{r crab-anova}
# creating an object called crab_anova
crab_anova <- aov(size ~ site_name, # formula
                  data = pie_crab_clean) # data

# gives more information
summary(crab_anova)
```

Summarize results: is there a difference in crab size between the three sites?  

**There is a difference in crab size between Cape Cod, Virginia Coastal Reserve LTER, and Zeke's Island NERR (one-way ANOVA, F(2, 89) = 39.6, p < 0.001, $\alpha$ = 0.05).**

#### g. Post-hoc: Tukey HSD

```{r crab-tukey}
TukeyHSD(crab_anova)
```

Which pairwise comparisons are actually different? Which ones are not different?  

**Zeke's Island NERR and Cape Cod crabs are different, and Zeke's Island NERR and Virginia Coastal Reserve LTER crabs are different. Virginial Coastal Reserve LTER and Cape Cod crabs are not different.**

#### h. effect size

Using `eta_squared()` from `rstatix`

```{r crab-effectsize}
eta_squared(crab_anova)
```

What is the magnitude of the differences between sites in crab size?  

**There is a large difference in crab size between sites.**

#### i. Putting everything together

We found a large ($\eta^2$ = 0.47) difference between sites in mean crab size (one-way ANOVA, F(2, 89) = 39.6, p < 0.001, $\alpha$ = 0.05). The smallest crabs were from Zeke's Island NERR, which were on average 12.1 mm. Zeke's Island crabs were 4.8 mm (95% CI: [3.3, 6.2] mm) smaller than crabs from Cape Cod (Tukey's HSD: p < 0.001) and 4.3 mm (95% CI: [2.9, 5.7] mm) smaller than crabs from Virginia Coastal Reserve LTER (Tukey's HSD: p < 0.001).  

### 3. Non-parametric tests

#### a. Clean and wrangle the data

```{r ramen-wrangle}
ramen_ratings_clean <- ramen_ratings |> # use the ramen_ratings dataframe
  filter(brand == "Maruchan") |> # filter to only include Maruchan ramen
  mutate(style = fct_relevel(style, "Bowl", "Pack", "Tray", "Cup")) # reorder style factor

# look at the structure
str(ramen_ratings_clean)
```

#### b. Quick summary

```{r ramen-summary}
# create a new object called ramen_ratings_summary
ramen_ratings_summary <- ramen_ratings_clean |> # start with the cleaned data frame
  # group by stle
  group_by(style) |> 
  # calculate the median
  summarize(median = median(stars))

# display the object
ramen_ratings_summary 
```


#### c. Make a boxplot to compare star ratings across ramen styles

```{r ramen-explore-viz}
# base layer: ggplot
ggplot(data = ramen_ratings_clean, 
       aes(x = style, # x-axis
           y = stars, # y-axis
           color = style)) + # fill geoms by ramen style
  # first layer: boxplot
  geom_boxplot(color = "darkgrey", 
               outliers = FALSE) + # taking out outliers because they will be shown in the jitter
  # second layer: jitter
  geom_jitter(height = 0,
              width = 0.1,
              size = 2,
              alpha = 0.6) +
  # set custom colors
  scale_color_manual(values = c("firebrick4", "orange", "gold", "darkgreen")) + 
  # minimal theme
  theme_minimal() + 
  # take out the legend
  theme(legend.position = "none") 
```

#### d. Do the Kruskal-Wallis test

```{r ramen-kw}
kruskal.test(
  stars ~ style, # formula: star ratings as a function of ramen style
  data = ramen_ratings_clean # data frame
)
```

Is there a difference in ratings between ramen styles?  

**Ramen styles differ in ratings (Kruskal-Wallis rank sum test, $\chi^2$(3) = 15.7, p = 0.0013).**

#### e. Do a Dunn's post-hoc test

Using `dunn_test()` from `rstatix`

```{r ramen-post-hoc}
dunn_test(
  stars ~ style, # formula: star ratings as a function of ramen style
  data = ramen_ratings_clean # data frame
)
```

Which pairwise comparisons of ramen styles are different from each other?  

**Bowls and packs are different, bowls and trays are different, bowls and cups are different.**

#### f. Calculate an effect size

Using `kruskal_effsize()` from `rstatix`

```{r ramen-effect-size}
kruskal_effsize(
  stars ~ style, # formula: star ratings as a function of ramen style
  data = ramen_ratings_clean # data frame
)
```

What is the magnitude of the effect of ramen style on ratings?  

**There is a moderate ($\eta^2$ = 0.12) effect of ramen style on ratings.**

#### g. Putting everything together

We found a moderate ($\eta^2$ = 0.12) difference in ratings between ramen styles (Kruskal-Wallis rank sum test, $\chi^2$(3) = 15.7, p = 0.0013). Bowl-style ramen had a median rating of 4.25 stars, which tended to be more highly rated than pack (Dunn's post-hoc test: Holm adjusted p = 0.04, median rating = 3.75 stars), tray (Dunn's post-hoc test: Holm adjusted p = 0.04, median rating = 3.75 stars), or cup style ramen (Dunn's post-hoc test: Holm adjusted p = 0.0013, median rating = 3.5 stars).

